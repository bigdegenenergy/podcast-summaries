---
actionable_items:
- action: certainly—I
  category: investigation
  full_context: 'You could certainly—I '
  priority: medium
companies:
- category: unknown
  confidence: medium
  context: This is episode number 906 with Dr. Jason Korsow, professor at the University
    of Michigan and co-f
  name: Jason Korsow
  position: 36
- category: unknown
  confidence: medium
  context: n and co-founder of Voxel 51. Welcome back to the Super Data Science Podcast.
    We've got an exceptional guest for you today. It
  name: Super Data Science Podcast
  position: 138
- category: unknown
  confidence: medium
  context: oday? Great to be here, John. I'm calling in from Western New York in Buffalo.
    Nice. It is a town that—it's the airp
  name: Western New York
  position: 1607
- category: unknown
  confidence: medium
  context: ery quickly. And so I frequently am going between New York and Toronto,
    and Buffalo is my airport of choice.
  name: New York
  position: 1917
- category: unknown
  confidence: medium
  context: led the AKG now, but it's because of the Albright-Knox Gallery, and it
    was actually designed by a local architec
  name: Knox Gallery
  position: 2146
- category: unknown
  confidence: medium
  context: ws, and we got the Bills as well. So there we go. Buffalo Bills for sure.
    That was my football team growing up as
  name: Buffalo Bills
  position: 2827
- category: unknown
  confidence: medium
  context: we'd get American broadcasts over the lake, over Lake Ontario. And so my
    local football team growing up was the
  name: Lake Ontario
  position: 2971
- category: unknown
  confidence: medium
  context: l football team growing up was the Bills as well. So I lived through the—was
    it four or five years that
  name: So I
  position: 3049
- category: unknown
  confidence: medium
  context: was it four or five years that the Bills made the Super Bowl in the 90s
    and never won four years? Although it
  name: Super Bowl
  position: 3122
- category: unknown
  confidence: medium
  context: ng and computer science. Tell us a bit, Jason, or Professor Korsow, about
    the work that you do over there in Michiga
  name: Professor Korsow
  position: 3669
- category: unknown
  confidence: medium
  context: My dissertation was called "Techniques for Vision-Based Human-Computer
    Interaction," right? So we had cameras w
  name: Based Human
  position: 4123
- category: unknown
  confidence: medium
  context: ion was called "Techniques for Vision-Based Human-Computer Interaction,"
    right? So we had cameras watching humans, and t
  name: Computer Interaction
  position: 4135
- category: unknown
  confidence: medium
  context: ike I'm cooking in my kitchen or whatever, right? Like I'm about to reach
    for the salt, but the recipe is
  name: Like I
  position: 4860
- category: unknown
  confidence: medium
  context: on't know what that means, it's the Conference on Computer Vision and Pattern
    Recognition. And you can correct me i
  name: Computer Vision
  position: 6439
- category: unknown
  confidence: medium
  context: means, it's the Conference on Computer Vision and Pattern Recognition.
    And you can correct me if I'm wrong on this, Jas
  name: Pattern Recognition
  position: 6459
- category: unknown
  confidence: medium
  context: ave been two historically that are among the top. So CVPR is one of them.
    The other one is called ICCV, Int
  name: So CVPR
  position: 6739
- category: unknown
  confidence: medium
  context: VPR is one of them. The other one is called ICCV, International Conference
    on Computer Vision. Usually, these generally ther
  name: International Conference
  position: 6793
- category: unknown
  confidence: medium
  context: every other year. And then the third one is ECCV, European Conference on
    Computer Vision, and that alternates with ICCV
  name: European Conference
  position: 6994
- category: tech
  confidence: high
  context: t of that observation or that vision, right? This notion that, wait, people
    need data. And it's not like w
  name: Notion
  position: 9697
- category: unknown
  confidence: medium
  context: '? But our initial—one of our initial mantras was "Better Data, Better
    Models," and we truly believe in that. Bu'
  name: Better Data
  position: 9866
- category: unknown
  confidence: medium
  context: tial—one of our initial mantras was "Better Data, Better Models," and we
    truly believe in that. But, and importan
  name: Better Models
  position: 9879
- category: unknown
  confidence: medium
  context: basically, semantic mapping of the environments. And I think my dataset
    had a hundred images, maybe even
  name: And I
  position: 10287
- category: unknown
  confidence: medium
  context: out a few weeks ago, we had someone on the show, Lilith Batlia, who runs
    workshops at ICML and ICLR, two other b
  name: Lilith Batlia
  position: 12617
- category: unknown
  confidence: medium
  context: r vision, machine learning-based computer vision. But Voxel 51 never identified
    as an annotation company. We
  name: But Voxel
  position: 17541
- category: tech
  confidence: high
  context: it, almost like a one-button mouse challenge that Apple had over the years,
    right? And, you know, nowaday
  name: Apple
  position: 18017
- category: unknown
  confidence: medium
  context: ', we have this tool, this new product line called Verified Auto Labeling,
    which can take this raw media, automatically gen'
  name: Verified Auto Labeling
  position: 18269
- category: unknown
  confidence: medium
  context: itiative—that's—you said summer, so we're talking Northern Hemisphere summer
    for our international listeners, around th
  name: Northern Hemisphere
  position: 19667
- category: unknown
  confidence: medium
  context: mer, but it's likely coming in the future, right? If I have my way, you
    know, is this notion that instea
  name: If I
  position: 21784
- category: unknown
  confidence: medium
  context: could easily have had an episode that was like a Joe Rogan style three
    or four hours with you on computer vi
  name: Joe Rogan
  position: 22786
- category: unknown
  confidence: medium
  context: you have such a rich understanding of the space. Before I let my guests
    go, I always ask them for a book re
  name: Before I
  position: 22921
- category: unknown
  confidence: medium
  context: airport and there's no storm, we can record them. But I have a reader here.
    I guess one of the best books
  name: But I
  position: 23265
- category: unknown
  confidence: medium
  context: in the last few months is a book called *Quit* by Annie Duke. And it really
    puts that—like I'm a hard worker,
  name: Annie Duke
  position: 23381
- category: ai_application
  confidence: high
  context: Co-founded by Dr. Jason Korsow; a leading platform for visual AI development,
    focusing on tooling for data analysis and model work in computer vision.
  name: Voxel 51
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: Dr. Korsow is a professor there, conducting research in robotics, electrical
    engineering, computer science, video understanding, and AI.
  name: University of Michigan
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: A major academic conference in computer vision where Dr. Korsow presented
    work (e.g., on video captioning in 2013).
  name: CVPR (Conference on Computer Vision and Pattern Recognition)
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: One of the top two historical academic conferences in computer vision.
  name: ICCV (International Conference on Computer Vision)
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: The third key academic conference in computer vision, alternating with
    ICCV.
  name: ECCV (European Conference on Computer Vision)
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: A major machine learning conference where working groups on data-centric
    ML are run.
  name: ICML (International Conference on Machine Learning)
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: A major machine learning conference where working groups on data-centric
    ML are run.
  name: ICLR
  source: llm_enhanced
- category: ai_research
  confidence: medium
  context: An early dataset mentioned in the context of computer vision research.
  name: Caltech 256
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: A famous large-scale dataset mentioned as a benchmark in computer vision,
    containing millions of samples.
  name: ImageNet
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: An open-source dataset mentioned as having five billion samples, used for
    training large models.
  name: LAION 5B
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: A dataset mentioned in the context of large-scale training data (5 billion
    samples).
  name: Florence 2 dataset
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: An AI model mentioned as being trained on the five-billion-sample Florence
    2 dataset.
  name: Florence 2 model
  source: llm_enhanced
- category: general_tech_reference
  confidence: medium
  context: Mentioned in a historical analogy regarding Voxel 51's strategic decision
    to avoid supporting label editing in their tool, similar to Apple's long-standing
    stance on the one-button mouse.
  name: Apple
  source: llm_enhanced
date: 2025-07-18 11:00:00 +0000
duration: 29
has_transcript: false
layout: episode
llm_enhanced: true
original_url: https://www.podtrac.com/pts/redirect.mp3/chrt.fm/track/E581B9/arttrk.com/p/VI4CS/pscrb.fm/rss/p/traffic.megaphone.fm/SUPERDATASCIENCEPTYLTD7615886716.mp3?updated=1752232168
processing_date: 2025-10-05 01:03:40 +0000
quotes:
- length: 159
  relevance_score: 8
  text: And you can correct me if I'm wrong on this, Jason, but I think it's hands
    down the biggest, most important academic conference on computer vision in the
    world
  topics: []
- length: 274
  relevance_score: 6
  text: And it sounds like this is then solving what is the biggest bottleneck in
    computer vision, and you're doing that using intelligent techniques so that it
    makes it way more time-efficient and cost-effective, orders of magnitude relative
    to having humans be annotating the data
  topics: []
- length: 293
  relevance_score: 4
  text: And then we have our custom ML that will rank the outputs from those foundation
    models so that you can, in batch, have high confidence that you're automatically
    going to accept something like 70% of them, you know, and already that's a huge
    amount of money that you're saving in time and so on
  topics: []
- length: 265
  relevance_score: 4
  text: So it sounds like Voxel 51 has figured out how to leverage the latest technology
    in terms of what we can do with automation to allow people to get the highest
    quality data for building high-performance computer vision models at a fraction
    of the effort and the cost
  topics: []
- length: 175
  relevance_score: 3
  text: It sounds like this *Quit* thing is kind of more about big strategic decisions,
    but just figuring out what you have to let go so that you can make space for even
    bigger things
  topics: []
- impact_reason: A powerful example of AI's tangible, positive societal impact, specifically
    in healthcare augmentation and addressing workforce shortages.
  relevance_score: 10
  source: llm_enhanced
  text: Our project is trying to enable the upskilling of RNs or physician assistants
    or nurse practitioners who can go out into rural America and say, in a mobile
    clinic or whatnot, and do anything from cardiac ultrasound to deep vein thrombosis
    in the lower limbs with AI kind of guiding them through every step of the process.
  topic: predictions/safety
- impact_reason: 'This is a core insight for modern ML engineering: the diminishing
    returns of chasing marginal algorithmic improvements when data quality/quantity
    is the bottleneck.'
  relevance_score: 10
  source: llm_enhanced
  text: We began to notice that as model capabilities began to improve for a given
    problem, say object detection—even more concretely, pedestrian avoidance for autonomous
    vehicles, just as an example—we began to notice that you can kind of pull a model
    architecture off the shelf... And the performance you got out of the system you
    ended up training was more of a function of the dataset you used to train that
    model than it was which of the six model architectures you chose.
  topic: technical
- impact_reason: A foundational business and technical thesis driving Voxel 51, aligning
    perfectly with the 'Data-Centric AI' movement.
  relevance_score: 10
  source: llm_enhanced
  text: And we basically began to build this conviction around data is at least as
    important, if not more important than the model architecture you choose.
  topic: business
- impact_reason: This is a core philosophical statement defining the relationship
    between code and data in ML, moving beyond the traditional software paradigm.
  relevance_score: 10
  source: llm_enhanced
  text: When you think of machine learning, there's code, and then there's the data
    that goes into the code in some sense; like it gets kind of transformed into data
    weights or coefficients or something like that. But these two things are inseparable.
  topic: technical
- impact_reason: It clearly articulates the shift from traditional programming (Software
    1.0) to ML-driven systems (Software 2.0), a fundamental concept in modern AI development.
  relevance_score: 10
  source: llm_enhanced
  text: As the evolution from what some folks have called software 1.0, just code,
    to software 2.0, which is essentially just a different type of code—it's just
    humans can't really write it; we write other code to train it from data.
  topic: technical
- impact_reason: Summarizes the entire iterative loop of achieving high-accuracy ML
    systems, identifying data acquisition and failure mode analysis as the primary
    bottlenecks.
  relevance_score: 10
  source: llm_enhanced
  text: The hardest part about this world of building highly successful, like 99.999
    whatever percent accurate systems is getting the data, then getting the data labeled,
    and then training the model and figuring out what are the failure modes, what
    are the success cases, what are my failure modes, and where do I need to add more
    data and begin this process, right?
  topic: technical
- impact_reason: A concise, memorable statement capturing the shift from manual labeling
    (annotation) to intelligent selection and validation (curation) of data.
  relevance_score: 10
  source: llm_enhanced
  text: The tagline that I like—not approved by marketing, but that I like these days—is
    'Curation is the new annotation,' right?
  topic: strategy
- impact_reason: 'Presents a forward-looking vision for Annotation 2.0: agentic systems
    that proactively query humans only for necessary clarification, minimizing human
    involvement.'
  relevance_score: 10
  source: llm_enhanced
  text: What is actually annotation 2.0? ... is this notion that instead of the humans
    asking the foundation models what they should label or what the labels are or
    what have you, there's more agentic, where there's a problem statement given,
    the amount of unlabeled data, and then the models are able to actually ask the
    humans questions just when it's necessary.
  topic: predictions
- impact_reason: This defines a specific, advanced research focus that bridges physical
    interaction (robotics/real-world) with AI cognition, which is a key trend in advanced
    AI development.
  relevance_score: 9
  source: llm_enhanced
  text: The angle I take in computer vision is what I call physically grounded cognitive
    systems, right?
  topic: technical
- impact_reason: A strong philosophical statement on the purpose of AI development—focusing
    on augmentation and human benefit rather than pure automation.
  relevance_score: 9
  source: llm_enhanced
  text: Like we do things by humans for humans, not just for humans, right? So that's
    been a 20-year driver.
  topic: strategy
- impact_reason: 'Identifies the critical gap in the ML lifecycle: the lack of robust
    tooling for data iteration and analysis, leading to the creation of Voxel 51''s
    product.'
  relevance_score: 9
  source: llm_enhanced
  text: But, and importantly, as a creator or a builder, there just was not enough
    tooling around how one works with data, how one analyzes this data, right?
  topic: business
- impact_reason: Explains the practical challenge of scaling visual AI development
    when datasets reach billions of samples—the need for programmatic intuition.
  relevance_score: 9
  source: llm_enhanced
  text: It was becoming impossible to basically put your eyeballs on enough of the
    data samples to build an intuition over what—when you work over with your model,
    how it's going to be impacted by the data and vice versa and so on.
  topic: technical
- impact_reason: Diagnoses the historical bias in AI research towards model novelty
    over data quality, a bias the speaker is actively trying to correct.
  relevance_score: 9
  source: llm_enhanced
  text: Although there had been some early works in datasets like Caltech 256 or ImageNet,
    the number of data papers was significantly dwarfed by the number of model papers.
    And it remains true today, right? It's just the general mindset.
  topic: strategy
- impact_reason: Provides concrete, current scale metrics for state-of-the-art datasets
    (LAION 5B, Florence 2), emphasizing the massive data requirements of modern foundation
    models.
  relevance_score: 9
  source: llm_enhanced
  text: Nowadays, you have five billion samples per dataset, even in some open-source
    datasets, like the LAION 5B you may have heard of, or kind of the Florence 2 dataset,
    or the Florence 2 model was trained on a five-billion-sample dataset.
  topic: technical
- impact_reason: 'It defines the true meaning of Data-Centric ML: the inseparable
    coupling of data and model structure, not just focusing on data quality in isolation.'
  relevance_score: 9
  source: llm_enhanced
  text: When we collectively as a research community or a user community think of
    data-centric machine learning, I think what I was saying earlier, where we tend
    to emphasize that, oh, wait, it's not just that there's data in this code and
    the code is more important; it's that you really cannot separate or divorce the
    two things, right?
  topic: technical
- impact_reason: Provides strategic advice on necessary tooling for successful ML
    operations, emphasizing the need for integrated analysis across the entire ML
    lifecycle (data, model, ops).
  relevance_score: 9
  source: llm_enhanced
  text: If you really want to build a successful ML system or AI system, you really
    need the right tooling around analyzing the data, analyzing the models, analyzing
    the ops, and they do need to work in concert so that you have a good sense of
    what's going on.
  topic: strategy
- impact_reason: Highlights the critical limitation of models trained on incomplete
    data, using autonomous vehicles as a high-stakes example where edge cases are
    paramount.
  relevance_score: 9
  source: llm_enhanced
  text: The model isn't going to be valuable at all if you don't have data covering
    the whole gamut of situations that that autonomous vehicle is going to run into.
  topic: safety
- impact_reason: Describes a specific, cutting-edge application of foundation models
    to automate the data labeling bottleneck, a major industry trend.
  relevance_score: 9
  source: llm_enhanced
  text: Foundation models now, we have this tool, this new product line called Verified
    Auto Labeling, which can take this raw media, automatically generate labels on
    it via foundation models.
  topic: technical
- impact_reason: Details a practical, high-efficiency workflow leveraging multiple
    foundation models and custom ranking ML to achieve high-confidence automated labeling,
    saving significant human effort.
  relevance_score: 9
  source: llm_enhanced
  text: Our workflow is you take your raw media, you apply foundation models, and
    we have a battery of them you can apply against it. And then we have our custom
    ML that will rank the outputs from those foundation models so that you can, in
    batch, have high confidence that you're automatically going to accept something
    like 70% of them.
  topic: business
- impact_reason: This is the core strategic lesson derived from the discussion—prioritization
    requires active subtraction, not just addition.
  relevance_score: 9
  source: llm_enhanced
  text: just figuring out what you have to let go so that you can make space for even
    bigger things.
  topic: Strategy/Prioritization
- impact_reason: Highlights early foundational work in video understanding, a domain
    that is increasingly critical with the rise of multimodal models.
  relevance_score: 8
  source: llm_enhanced
  text: My research group has focused on areas like video captioning. You know, we
    have one of the first—it's not the first paper at CVPR 2013 on video captioning.
  topic: technical
- impact_reason: Quantifies the explosive growth of the computer vision field over
    two decades, illustrating the scale shift in academic research.
  relevance_score: 8
  source: llm_enhanced
  text: CVPR had something like 500 papers max, maybe a thousand attendees—actually,
    probably even had less than 500 papers 20 years ago. Nowadays, I think there are
    like 2,500 papers on average every year, 10,000 plus attendees.
  topic: strategy
- impact_reason: 'Clear articulation of Voxel 51''s value proposition: providing essential
    developer tools for the visual AI workflow.'
  relevance_score: 8
  source: llm_enhanced
  text: Ultimately, Voxel 51 is a company that tries to speed up the work you do with
    your data and the work you do with your models by providing the right dev tool,
    in some sense, for visual AI.
  topic: business
- impact_reason: Provides a key metric (3M installs) and defines the target user profile
    for specialized MLOps/data tooling, emphasizing technical depth over broad consumer
    appeal.
  relevance_score: 8
  source: llm_enhanced
  text: We have about three million installs of that or more. And we've always tried
    to have the ideal user, ideal customer of that tool is really a heavy technical
    data scientist or computer scientist.
  topic: business
- impact_reason: Confirms the formalization and academic recognition (DMLR) of the
    data-centric approach, showing it's moving beyond industry buzzwords.
  relevance_score: 8
  source: llm_enhanced
  text: And we actually recently in an episode, episode 901... she runs working groups
    or she runs working groups at those on data-centric machine learning. So it's
    DMLR, data-centric machine learning research, just kind of the acronym that's
    used there.
  topic: technical
- impact_reason: Illustrates the concept of real-time, context-aware AI guidance in
    everyday tasks, moving beyond simple recognition to proactive intervention.
  relevance_score: 8
  source: llm_enhanced
  text: I'm about to reach for the salt, but the recipe is for sugar, and my AI can
    tell me, you know, 'Don't use salt for sugar,' or more socially relevant, perhaps,
    is an exciting project we have right now...
  topic: predictions
- impact_reason: A concise, memorable mission statement summarizing the data-centric
    philosophy.
  relevance_score: 8
  source: llm_enhanced
  text: One of our initial mantras was 'Better Data, Better Models,' and we truly
    believe in that.
  topic: business
- impact_reason: Provides strategic insight into a company's positioning, deliberately
    avoiding the 'annotation company' label to focus on higher-level tooling and analysis.
  relevance_score: 8
  source: llm_enhanced
  text: Voxel 51 never identified as an annotation company. We were always, in some
    sense, we explicitly decided strategically we are not an annotation company.
  topic: business
- impact_reason: Provides a clear historical demarcation (Annotation 1.0) for the
    inefficient, brute-force approach to data preparation.
  relevance_score: 8
  source: llm_enhanced
  text: Annotation 1.0, if we want to use that analogy, was basically, 'I don't really
    know how to filter my data, so I'm just going to send it all to humans to label'
    and I have to pay for all that, and it's time-consuming as well.
  topic: technical
- impact_reason: Defines the current transitional phase (Annotation 1.5) where foundation
    models are used primarily for pre-filtering data before human review.
  relevance_score: 8
  source: llm_enhanced
  text: Annotation 1.5 era, where it's obvious to apply a foundation model even for
    something like pre-filtering just so you can rank your data so you're going to
    send it to humans to label.
  topic: technical
- impact_reason: 'Summarizes the core business value proposition: using advanced automation
    (AI) to drastically reduce the cost and effort of achieving high-quality data
    for CV.'
  relevance_score: 8
  source: llm_enhanced
  text: Voxel 51 has figured out how to leverage the latest technology in terms of
    what we can do with automation to allow people to get the highest quality data
    for building high-performance computer vision models at a fraction of the effort
    and the cost.
  topic: business
- impact_reason: Connects high-level strategic decision-making (quitting big projects)
    to tactical daily management (like achieving inbox zero), emphasizing the need
    to prune low-value tasks to enable high-value work.
  relevance_score: 8
  source: llm_enhanced
  text: Even just things like, pre-pandemic, I used to be able to be inbox zero and
    respond to anything that should be responded to. And, you know, this sounds like
    a simple, silly example. It sounds like this *Quit* thing is kind of more about
    big strategic decisions, but just figuring out what you have to let go so that
    you can make space for even bigger things.
  topic: strategy
- impact_reason: 'Highlights the paradox of success: increased focus leads to more
    opportunities, which necessitates strategic reduction of commitments.'
  relevance_score: 8
  source: llm_enhanced
  text: as opportunities accumulate, as you focus and have more grit, more and more
    opportunities come up, and you can't keep doing everything.
  topic: Strategy/Career Management
- impact_reason: Introduces a memorable, evocative term used by investors to describe
    the negative state resulting from taking on too much (over-commitment/over-processing).
  relevance_score: 8
  source: llm_enhanced
  text: one of our investors uses the term "indigestion."
  topic: Business/Metaphor
- impact_reason: Acknowledges the ambiguity of the 'Data-Centric ML' term, suggesting
    that while the concept is popular, its practical definition varies.
  relevance_score: 7
  source: llm_enhanced
  text: I mean, data-centric ML can mean a lot of things, but even at Voxel, we used
    to use that in our outbound, community-driven marketing material as well.
  topic: strategy
- impact_reason: 'Highlights a crucial feature for enterprise/research tooling: extensibility
    and customization via plugins, necessary for handling diverse, complex visual
    data pipelines.'
  relevance_score: 7
  source: llm_enhanced
  text: And so it's super flexible. You can write plugins for it or extensions for
    it, for the front end and the back end.
  topic: technical
- impact_reason: Historical anecdote showing early innovation in human-computer interaction
    (HCI) using vision, predating mainstream commercialization.
  relevance_score: 7
  source: llm_enhanced
  text: In fact, we built this thing called the 40-touch pad, I think it was at a
    workshop at CVPR in maybe like 2003 or something like that. And it used gesture
    tracking and in some sense created multi-touch prior to there being iPads and
    so on.
  topic: technical
- impact_reason: Offers strategic life/business advice, balancing the necessity of
    founder 'grit' with the strategic wisdom of knowing when to pivot or stop pursuing
    a path.
  relevance_score: 7
  source: llm_enhanced
  text: It really puts that type of grit, which every founder needs in some sense,
    and every professor really needs these days as well, up against this notion that
    make sure you're being smart about how you spend your time and how you're planning—pre-planning
    when you might want to switch or quit an angle and go in a different angle.
  topic: strategy
- impact_reason: Introduces the concept of 'indigestion' as a metaphor for being overwhelmed
    by opportunities or inputs, which is highly relevant in the current era of information
    and opportunity overload in tech.
  relevance_score: 7
  source: llm_enhanced
  text: The notion of email inbox, or inbox zero, whatever, is highly relevant. I
    think the way I would put it is one of our investors uses the term 'indigestion,'
    right? If [you have too much coming in]
  topic: strategy
- impact_reason: Identifies a core characteristic (grit) common among the target audience
    interested in deep technical topics, linking technical curiosity with career ambition.
  relevance_score: 7
  source: llm_enhanced
  text: a lot of our listeners, if the way that you choose to spend your free time
    is listening to a technical podcast about data science and AI, you're probably
    somebody who has a lot of grit and is really pushing their career.
  topic: Strategy/Audience Insight
- impact_reason: A counterpoint to purely high-level strategy, emphasizing that tactical
    details (like email management) reflect overall decision-making discipline.
  relevance_score: 7
  source: llm_enhanced
  text: in terms of the strategy and the tactics of decision-making, there's nothing
    too small to think about, frankly.
  topic: Strategy/Tactics
- impact_reason: A concise description of early embodied AI/vision research focused
    on understanding human intent through observation.
  relevance_score: 6
  source: llm_enhanced
  text: We had cameras watching humans, and the humans would do things, and then that
    would create interaction scenarios.
  topic: technical
- impact_reason: Provides essential context for ML practitioners regarding the hierarchy
    and scheduling of top-tier computer vision conferences.
  relevance_score: 6
  source: llm_enhanced
  text: The other one is called ICCV, International Conference on Computer Vision.
    Usually, these generally there are two conferences per year. So CVPR happens every
    year. ICCV happens every other year. And then the third one is ECCV, European
    Conference on Computer Vision, and that alternates with ICCV.
  topic: strategy
- impact_reason: Uses a common productivity metric (inbox zero) as a proxy for the
    larger problem of managing cognitive load and attention.
  relevance_score: 6
  source: llm_enhanced
  text: So the notion of email inbox, or inbox zero, whatever, is highly relevant.
  topic: Tactics/Productivity
- impact_reason: While not AI-related, this sets the context and establishes the speaker's
    grounded, real-world perspective, contrasting with purely abstract research.
  relevance_score: 3
  source: llm_enhanced
  text: And so I frequently am going between New York and Toronto, and Buffalo is
    my airport of choice. Lots of interesting—there's a famous art museum in Buffalo,
    isn't there? There is. It recently had renovations. It's called the AKG now, but
    it's because of the Albright-Knox Gallery...
  topic: general
source: Unknown Source
summary: '## Podcast Episode Summary: 906: How Prof. Jason Corso Solved Computer Vision’s
  Data Problem


  This episode of the Super Data Science Podcast features Dr. Jason Korsow, Professor
  at the University of Michigan and co-founder/Chief Science Officer of Voxel 51.
  The discussion centers on the evolution of computer vision, the critical role of
  data over algorithms, and how Voxel 51 is addressing the massive bottleneck in visual
  AI development: data tooling and labeling.


  ---


  ### 1. Focus Area

  The primary focus is **Computer Vision (CV) Development Tooling and Data-Centric
  Machine Learning (ML)**. Specific topics covered include the explosion of academic
  research in CV (evidenced by conference growth like CVPR), the shift in focus from
  model architecture to data quality, and the practical application of this philosophy
  in real-world systems like autonomous vehicles.


  ### 2. Key Technical Insights

  *   **Data Dominance:** For many modern CV tasks, the performance ceiling is now
  dictated more by the quality and coverage of the training dataset than by the specific
  model architecture chosen (assuming standard, high-performing architectures are
  used).

  *   **Curation is the New Annotation:** The industry is moving beyond manual, brute-force
  data labeling (Annotation 1.0). The future involves leveraging foundation models
  for **Verified Auto Labeling**, where AI generates initial labels, and sophisticated
  ML ranking systems prioritize which samples require human verification (Annotation
  1.5/2.0).

  *   **Physically Grounded Systems:** Professor Korsow’s academic work focuses on
  building AI systems that operate alongside humans, such as guiding rural healthcare
  providers through complex procedures (e.g., cardiac ultrasound) using vision-based
  guidance.


  ### 3. Business/Investment Angle

  *   **Tooling Gap:** A significant market opportunity exists in providing robust
  development tools for visual AI, as the tooling around data analysis and model iteration
  has lagged behind algorithmic advancements.

  *   **Cost Reduction in Labeling:** Verified Auto Labeling offers massive cost and
  time savings by automating the labeling of high-confidence data segments (e.g.,
  accepting 70% of labels automatically), reserving expensive human expertise only
  for corner cases and challenging scenarios.

  *   **Data Strategy as Competitive Edge:** Companies that master data curation and
  analysis—understanding failure modes and strategically adding data—will outperform
  those focused solely on chasing the newest model releases.


  ### 4. Notable Companies/People

  *   **Dr. Jason Korsow:** Professor at UMich (Robotics, EECS) and Chief Science
  Officer/Co-founder of Voxel 51. His 20+ years of research bridge academia and industry,
  focusing on physically grounded cognitive systems.

  *   **Voxel 51:** The company co-founded by Korsow, which provides the open-source
  tool (with 3M+ installs) and commercial platform for visual AI development, focusing
  on data analysis and model iteration workflows.

  *   **Foundation Models:** Mentioned as the key enablers for the next generation
  of automated labeling tools.


  ### 5. Future Implications

  The industry is rapidly shifting toward **data-centric ML**, where the focus moves
  from writing code to curating and verifying data pipelines. The next evolution (Annotation
  2.0) is predicted to be more **agentic**, where AI models proactively query human
  experts only when necessary, further minimizing manual involvement in the data lifecycle.
  This trend is crucial for achieving the near-perfect reliability required in safety-critical
  systems like autonomous driving.


  ### 6. Target Audience

  This episode is highly valuable for **ML Engineers, Data Scientists, Computer Vision
  Practitioners, and technical leaders** involved in building, deploying, or investing
  in AI systems that rely on large visual datasets. The discussion on tooling, data
  pipelines, and the shift from annotation to curation is directly relevant to their
  daily challenges.'
tags:
- artificial-intelligence
- startup
- ai-infrastructure
- apple
title: '906: How Prof. Jason Corso Solved Computer Vision’s Data Problem'
topics:
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 61
  prominence: 1.0
  topic: artificial intelligence
- keywords:
  - startup
  - entrepreneur
  - founder
  - venture
  mentions: 3
  prominence: 0.3
  topic: startup
- keywords:
  - gpu
  - tensor
  - training
  - inference
  - model deployment
  - vector database
  mentions: 2
  prominence: 0.2
  topic: ai infrastructure
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-10-05 01:03:40 UTC -->
