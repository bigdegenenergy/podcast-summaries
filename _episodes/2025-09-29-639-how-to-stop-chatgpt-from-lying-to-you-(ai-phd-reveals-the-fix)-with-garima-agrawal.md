---
companies:
- category: unknown
  confidence: medium
  context: not just sure what it is. You're listening to the Paul Higgins podcast,
    I'm Paul and I help consultants build bu
  name: Paul Higgins
  position: 304
- category: unknown
  confidence: medium
  context: st episode number 639. In this episode, I talk to Gary Ma Agawol from HumanCon
    AI Consulting. So that's human and
  name: Gary Ma Agawol
  position: 1264
- category: unknown
  confidence: medium
  context: 9. In this episode, I talk to Gary Ma Agawol from HumanCon AI Consulting.
    So that's human and then CEO in AI consulting. Y
  name: HumanCon AI Consulting
  position: 1284
- category: unknown
  confidence: medium
  context: nd then CEO in AI consulting. You will learn from Gary Ma how to eliminate
    AI hallucinations using layered
  name: Gary Ma
  position: 1375
- category: unknown
  confidence: medium
  context: lligence. She took five years to get this through Arizona State University,
    and she serves as the head of AI at Minerva. So
  name: Arizona State University
  position: 1984
- category: unknown
  confidence: medium
  context: ity, and she serves as the head of AI at Minerva. So M-I-N-E-R-V-A-C-Q.
    After 15 years in the industry,
  name: So M
  position: 2055
- category: unknown
  confidence: medium
  context: hey can make more bucks out of their investments. And I know when I was
    back in corporate at Coca-Cola, w
  name: And I
  position: 3621
- category: unknown
  confidence: medium
  context: to leave my job, come in to do PhD to move to the United States, and I
    have been very fortunate to work with the
  name: United States
  position: 4972
- category: unknown
  confidence: medium
  context: fortunate to work with the best, like, you know, Professor Juan Liu, who's
    among 20 top computer scientists of the wo
  name: Professor Juan Liu
  position: 5057
- category: unknown
  confidence: medium
  context: er scientists of the world. He was my mentor, and Professor Professor Dmitri
    Patraska, one of the top reinforcement learning guys. So,
  name: Professor Professor Dmitri Patraska
  position: 5152
- category: unknown
  confidence: medium
  context: ah. And the simple analogy I'll use because I'm a Formula One nut, so I
    enjoy watching Formula One. It's like y
  name: Formula One
  position: 6476
- category: unknown
  confidence: medium
  context: there's been tons of paper research to show that. But I think what we can
    do is to use it in the right wa
  name: But I
  position: 8041
- category: unknown
  confidence: medium
  context: ve this business. I'm doing this, blah blah blah. Now I want to create
    this kind of a niche market. I wan
  name: Now I
  position: 9790
- category: unknown
  confidence: medium
  context: er context. You know, am I better off doing that? Am I better off just
    verbalizing what the context is?
  name: Am I
  position: 11419
- category: unknown
  confidence: medium
  context: k and YouTube on learning more and more about AI. Sometimes I'll come across
    JSON prompting, and they say that
  name: Sometimes I
  position: 13088
- category: tech
  confidence: high
  context: ll of the markdown, you know, markdown versus the Google... Yes, yeah,
    it's better that it is as stripped
  name: Google
  position: 14844
- category: unknown
  confidence: medium
  context: kenization, all of that. But when we are using an API LLM call, then it's
    better to take care of all these
  name: API LLM
  position: 15387
- category: unknown
  confidence: medium
  context: h the project. And then you can... the project in ChatGPT Plus allows you
    to keep your documents and you want to
  name: ChatGPT Plus
  position: 16406
- category: tech
  confidence: high
  context: k pen. Black pen is when I used to sit down every Monday and type out all
    the content myself. Now, my team
  name: Monday
  position: 18013
- category: unknown
  confidence: medium
  context: task or more of a scientific task, I would go for Claude AI because I think
    Claude's in-topic models are best
  name: Claude AI
  position: 20041
- category: unknown
  confidence: medium
  context: hat, and I prefer using my best model to go to is Claude Sonnet 3.5. And
    hence down, I think the footprint of the
  name: Claude Sonnet
  position: 20155
- category: unknown
  confidence: medium
  context: information, it just gives all that correct, why? Because Google has all
    that, right? Trained it on. Yeah, yeah. A
  name: Because Google
  position: 22089
- category: tech
  confidence: high
  context: e citations, or it creates things on its own. So, Perplexity might be a
    go-to, you know, if you want to find t
  name: Perplexity
  position: 22690
- category: unknown
  confidence: medium
  context: there's there... you know, there's Manas, there's Jim Spark, there's the
    ones that are, you know, doing more
  name: Jim Spark
  position: 23185
- category: unknown
  confidence: medium
  context: e very, very mindful. And I have a paper on this, Mindful RAG, where I
    illustrate on what could be the failure
  name: Mindful RAG
  position: 26908
- category: tech
  confidence: high
  context: when mobile phones came in, you know, when we... Microsoft, you know, introduced
    Excel and Word, you know, s
  name: Microsoft
  position: 27529
- category: unknown
  confidence: medium
  context: terns, same deal sizes, same time-for-money trap. On Paul and I built and
    sold a seven-figure consulting bu
  name: On Paul
  position: 28411
- category: ai_application
  confidence: high
  context: The most commonly used LLM mentioned, discussed in the context of hallucinations
    and prompting techniques.
  name: ChatGPT
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as a specific LLM recommended for coding tasks.
  name: Claude
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as a specific LLM recommended for technical research tasks.
  name: Gemini
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Gary Ma Agawol's company, focused on AI consulting, reducing hallucinations,
    and implementing agentic AI.
  name: HumanCon AI Consulting
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: The organization where Gary Ma serves as the Head of AI.
  name: Minerva (M-I-N-E-R-V-A-C-Q)
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: Where Gary Ma completed her PhD in Artificial Intelligence, working with
    top AI researchers.
  name: Arizona State University
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as the provider of the Claude models.
  name: Claude AI
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Specific model version preferred by the speaker for coding tasks due to
    low hallucination.
  name: Claude Sonnet 3.5
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as a model that is fast but struggles with too much English/content
    or complex tasks.
  name: DeepSeek
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Recommended as a go-to tool for deep research, finding research papers,
    and references, especially when ChatGPT's citations are unreliable.
  name: Perplexity
  source: llm_enhanced
- category: ai_startup
  confidence: high
  context: The speaker's employer, where they are building their own agentic AI platform,
    specifically handling customer service contacts via API integration of LLMs.
  name: Minerva
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: Mentioned in the context of agentic AI tools.
  name: Manas
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: Mentioned in the context of agentic AI tools.
  name: Jim Spark
  source: llm_enhanced
- category: consulting/services
  confidence: high
  context: The consulting entity where the speaker also consults.
  name: HumanCon
  source: llm_enhanced
- category: organization
  confidence: medium
  context: The speaker mentions working as a consultant there as well (Arizona State
    University, likely leveraging AI in their operations).
  name: ASU
  source: llm_enhanced
- category: big_tech
  confidence: medium
  context: Mentioned historically in the context of introducing productivity software
    like Excel and Word, setting a precedent for technological shifts.
  name: Microsoft
  source: llm_enhanced
- category: software_platform
  confidence: medium
  context: A no-code/low-code platform mentioned as a target for creating landing
    pages/mini-apps using Claude's assistance.
  name: Bubble
  source: llm_enhanced
- category: software_platform
  confidence: medium
  context: A platform mentioned alongside Bubble for creating landing pages/mini-apps
    using Claude's assistance.
  name: Lovable
  source: llm_enhanced
date: 2025-09-29 18:30:00 +0000
duration: 41
has_transcript: false
insights:
- actionable: true
  confidence: medium
  extracted: do, you know, we should take this approach?" It gives you five approaches
  text: we should do, you know, we should take this approach?" It gives you five approaches.
  type: recommendation
layout: episode
llm_enhanced: true
original_url: https://audio.listennotes.com/e/p/3f93957e5d1346368d62f04331310bc3/
processing_date: 2025-10-06 05:43:42 +0000
quotes:
- length: 150
  relevance_score: 5
  text: '" So, you have to make the LLM understand the intent of your question, and
    if it fails to get the intent, then it will never give you the right answer'
  topics: []
- length: 200
  relevance_score: 4
  text: Too many AI and tech consultants are stuck in the LLM hamster wheel, asking
    ChatGPT basic questions, getting hallucinated responses, and wondering why their
    AI productivity isn't living up to the hype
  topics: []
- length: 74
  relevance_score: 4
  text: So, it takes care of the parsing, embedding, and tokenization, all of that
  topics: []
- length: 243
  relevance_score: 4
  text: And I have a paper on this, Mindful RAG, where I illustrate on what could
    be the failure points of AI, and how I figured that by analyzing the analogs through
    the AI, I use another LLM to analyze what is going wrong, and then I figure out
    that
  topics: []
- length: 63
  relevance_score: 3
  text: She's been a programmer, holds a PhD in artificial intelligence
  topics: []
- length: 54
  relevance_score: 3
  text: This was the biggest bottleneck of the industry so far
  topics: []
- length: 34
  relevance_score: 3
  text: But now you have to narrow it down
  topics: []
- length: 102
  relevance_score: 3
  text: You know that it knows something about it, but you have to narrow it down
    and bring it to your context
  topics: []
- length: 28
  relevance_score: 3
  text: So, you have to work with it
  topics: []
- length: 108
  relevance_score: 3
  text: The problem is when we use the API, goes token-wise, and the text needs to
    be in bars embedded and then sent
  topics: []
- length: 230
  relevance_score: 3
  text: So, like, you know, a lot of things have similar kind of meanings and, you
    know, they're ambiguous, so you have to bring it to your steer the direction of
    thinking for the model, as in parameterizing it towards the right direction
  topics: []
- length: 161
  relevance_score: 3
  text: 'Like, you have to really work with the model, and even when it''s coding,
    then you have to think in this direction: "I want to solve this problem in a certain
    way'
  topics: []
- length: 33
  relevance_score: 3
  text: You have to be very, very mindful
  topics: []
- length: 264
  relevance_score: 3
  text: 'On Paul and I built and sold a seven-figure consulting business, but here''s
    what I''ve learned mentoring other consultants: the real breakthroughs happen
    when you combine my experience with live problem-solving of people going through
    exactly what you''re facing now'
  topics: []
- impact_reason: Promises a concrete, practical solution ('layered prompting') applicable
    across various LLMs to solve the major issue of hallucinations.
  relevance_score: 10
  source: llm_enhanced
  text: You will learn from Gary Ma how to eliminate AI hallucinations using layered
    prompting techniques that work with any LLM, not just the fancy enterprise tools...
  topic: technical
- impact_reason: Clarifies a crucial distinction in AI evolution (interactive vs.
    agentic) and points toward the future of autonomous systems.
  relevance_score: 10
  source: llm_enhanced
  text: '...the practical difference between interactive AI and true agentic AI, which
    is a key buzzword at the moment, plus how to build goal-driven systems that take
    actions without constant oversight.'
  topic: predictions
- impact_reason: Defines the optimal user mindset ('thinking partner') and names the
    key technique ('layered prompting') for effective interaction.
  relevance_score: 10
  source: llm_enhanced
  text: So, I take it as my thinking partner, not totally rely on it to give me all
    the solutions. But I have to give it the enough context, and I call it as layered
    prompting...
  topic: technical
- impact_reason: Provides a critical warning about context window overload leading
    to irreversible error states ('snowball effect') and the necessary mitigation
    (stop and restart).
  relevance_score: 10
  source: llm_enhanced
  text: If you give too much information at one time, that's where the hallucination
    starts. Once any model hallucinates, it's a snowball effect. So, there have been
    a lot of research papers on it. It's a snowball effect. Once it goes in a wrong
    direction, it keeps going. So, that's best is to stop it there, restart.
  topic: safety
- impact_reason: 'Specific model recommendation: Claude 3.5 Sonnet is preferred for
    coding/scientific tasks due to perceived lower hallucination rates and strong
    in-topic modeling.'
  relevance_score: 10
  source: llm_enhanced
  text: But if I want to do some kind of a coding task or more of a scientific task,
    I would go for Claude AI because I think Claude's in-topic models are best in
    that, and I prefer using my best model to go to is Claude Sonnet 3.5. And hence
    down, I think the footprint of the model is so good that there is very less amount
    of hallucination, but it works best with the, you know, the coding task...
  topic: technical
- impact_reason: 'Provides the speaker''s core definition of Agentic AI: goal-driven
    systems capable of autonomous decision-making based on environmental context changes.'
  relevance_score: 10
  source: llm_enhanced
  text: But agentic AI means that, you know, there is an AI which is goal-driven.
    It knows that... it's not going to be a good idea... which is goal-driven. It
    knows these are the tasks. It can act at a certain point, able to take decisions,
    able to get the context from the environment that something has changed, I need
    an action, right?
  topic: technical/predictions
- impact_reason: 'Reveals a sophisticated architectural insight: agentic behavior
    often requires multiple, coordinated AI threads monitoring context and intent
    shifts simultaneously.'
  relevance_score: 10
  source: llm_enhanced
  text: So, the agent is looking for some process. So, the agentic AI, another thread,
    of course, it's not the same AI, but there are multiple threads working there,
    and can... 'Okay, looks like the intent has changed. The conversation is going
    in the other direction. The agent may need this help.'
  topic: technical/architecture
- impact_reason: Introduces a novel concept ('Mindful RAG') and a meta-AI technique
    (using one LLM to debug another), pointing toward advanced quality assurance methods.
  relevance_score: 10
  source: llm_enhanced
  text: I have a paper on this, Mindful RAG, where I illustrate on what could be the
    failure points of AI, and how I figured that by analyzing the analogs through
    the AI, I use another LLM to analyze what is going wrong...
  topic: technical/RAG
- impact_reason: This directly addresses a common frustration in the current AI adoption
    landscape, highlighting the gap between expectation and reality for many users
    relying on basic prompting.
  relevance_score: 9
  source: llm_enhanced
  text: Too many AI and tech consultants are stuck in the LLM hamster wheel, asking
    ChatGPT basic questions, getting hallucinated responses, and wondering why their
    AI productivity isn't living up to the hype.
  topic: strategy
- impact_reason: Provides actionable, specific guidance on LLM specialization, moving
    beyond the 'one-size-fits-all' approach.
  relevance_score: 9
  source: llm_enhanced
  text: '...which specific LLMs to use for different tasks—you know, ChatGPT for analysis,
    Claude for coding, Gemini for technical research...'
  topic: technical
- impact_reason: This is the first step of the 'layered prompting' technique—assessing
    the model's baseline knowledge before diving deep.
  relevance_score: 9
  source: llm_enhanced
  text: Go small, go with a small prompt first. Start with trying to figure out that
    ChatGPT knows how much it knows about a particular domain, about an area.
  topic: technical
- impact_reason: A specific, actionable technique within layered prompting used to
    verify comprehension before proceeding.
  relevance_score: 9
  source: llm_enhanced
  text: Ask it, 'Do you understand my problem or just explain me what do you understand?'
  topic: technical
- impact_reason: 'Offers a best practice for using RAG/contextual input: focus the
    model on pattern extraction rather than expecting it to synthesize everything
    immediately.'
  relevance_score: 9
  source: llm_enhanced
  text: One good way of giving the documents is give it some context. Ask it to analyze
    what are the patterns do you see? What are, you know, that is something very important
    to be able to use AI for understanding the patterns that are in the documentation
    or different kind of documentation.
  topic: technical
- impact_reason: A concise metaphor for iterative context feeding—small chunks of
    information ('bytes') are better than massive dumps.
  relevance_score: 9
  source: llm_enhanced
  text: But it is always good to give it in bytes. You know, let it chew in bytes.
  topic: technical
- impact_reason: Provides a critical warning about prompt engineering and context
    window management, linking excessive input to the onset and amplification of hallucinations—a
    core LLM limitation.
  relevance_score: 9
  source: llm_enhanced
  text: If we give too much information at one time, that's where the hallucination
    starts. Once any model hallucinates, it's a snowball effect. So, there have been
    a lot of research papers on it. It's a snowball effect. Once it goes in a wrong
    direction, it keeps going.
  topic: technical/safety
- impact_reason: Gives specific technical advice on optimizing API calls versus UI
    interaction, highlighting JSON as a superior structured format for machine consumption
    over complex file types.
  relevance_score: 9
  source: llm_enhanced
  text: People say do a JSON prompting, but it actually works better when you are
    sending it as an API. When you are using it as an application and using the API
    of LLM, then if you pass everything in a JSON, it is able to consume it better.
    Why? Because the LLM is able to pass JSON, CSV, TXT, those kind of documents rather
    than PDFs, Excel—a big no-no.
  topic: technical
- impact_reason: 'A crucial distinction for developers: UI abstraction handles complex
    steps (parsing, embedding, tokenization) automatically, whereas API users must
    manage these nuances manually.'
  relevance_score: 9
  source: llm_enhanced
  text: It is fine when you are giving it as an attachment in the UI. It does not
    matter much. The problem is when we use the API, goes token-wise, and the text
    needs to be in bars embedded and then sent. So, when we are doing it on the UI,
    it's all done by the UI itself. It takes care of the parsing, embedding, and tokenization,
    all of that.
  topic: technical
- impact_reason: Defines key prompt engineering concepts (zero-shot vs. few-shot)
    and explains when few-shot prompting is superior (specific templates/domains).
  relevance_score: 9
  source: llm_enhanced
  text: We call it zero-shot, few-shot, and multi-shot prompting in show. What it
    means is that sometimes if your domain or your task is very specific, you're not
    able to give it through the instructions, or you wanted to show that, you know,
    this is a certain template I want to follow, then it is good to give those examples,
    right?
  topic: technical
- impact_reason: Strong warning against using ChatGPT for academic/serious research
    due to known citation fabrication issues.
  relevance_score: 9
  source: llm_enhanced
  text: If it is for research, like my kind of research, then I wouldn't go for ChatGPT
    because, you know, it gives the citations which are wrong, which is everyone knows.
    So, you never use the... you let it search the web, but never use the citations,
    or it creates things on its own.
  topic: safety/strategy
- impact_reason: Presents a real-world, high-value application of agentic AI in customer
    service automation via API integration.
  relevance_score: 9
  source: llm_enhanced
  text: This is agentic AI behavior. Yes, right? So, if you are able to use your LLMs,
    and that is what we are doing through API at Minerva, that, you know, we are able
    to create LLMs, and at Minerva, we are handling customer service contacts, entire
    calls, and we're making that experience, you know, seamless for the agent who's
    doing it.
  topic: business/technical
- impact_reason: 'Details the mechanics of real-time agentic support: RAG integration,
    context extraction, and proactive answer preparation for human agents.'
  relevance_score: 9
  source: llm_enhanced
  text: So, the agentic AI, another thread, of course, it's not the same AI, [it takes
    the context from the conversation in real-time, the AI takes the decision to create
    a question and understand that the customer is asking some question. Let me go
    back, do the RAG, get the answer for the agent, keep it ready before he has to
    answer, right?]
  topic: technical
- impact_reason: Clearly defines and names the advanced concept of AI systems taking
    goal-driven actions based on environmental context, which is a key trend beyond
    simple prompt-response models.
  relevance_score: 9
  source: llm_enhanced
  text: This is agentic AI behavior.
  topic: technical/trends
- impact_reason: Highlights a major real-world application of LLMs in high-stakes
    environments (customer service) aimed at improving agent efficiency, not just
    replacing them.
  relevance_score: 9
  source: llm_enhanced
  text: So, we are able to create LLMs, and at Minerva, we are handling customer service
    contacts, entire calls, and we're making that experience, you know, seamless for
    the agent who's doing it.
  topic: business/application
- impact_reason: 'Identifies the primary adoption hurdles for individuals and businesses:
    fear of inaccuracy vs. over-reliance, offering a balanced view on adoption strategy.'
  relevance_score: 9
  source: llm_enhanced
  text: So, I think just coming out of the fear of that AI that is going to give me
    wrong, or not getting started on it, or totally relying on AI—these are the two
    bottlenecks I see mostly.
  topic: business/strategy
- impact_reason: 'Pinpoints the fundamental challenge in prompt engineering and RAG
    systems: aligning the model''s interpretation with the user''s true intent is
    paramount for accuracy.'
  relevance_score: 9
  source: llm_enhanced
  text: You have to make the LLM understand the intent of your question, and if it
    fails to get the intent, then it will never give you the right answer.
  topic: technical/prompting
- impact_reason: 'A strong strategic warning: AI adoption (execution) without strategic
    business model change (strategy) leads to stagnation, even if technical problems
    are solved.'
  relevance_score: 9
  source: llm_enhanced
  text: The current execution, terrible strategy. You can solve any kind of problem,
    but you'll be stuck in the same revenue patterns, same deal sizes, same time-for-money
    trap.
  topic: business/strategy
- impact_reason: This frames the problem as a strategic failure rather than a technological
    one, suggesting deeper methods are needed for real transformation.
  relevance_score: 8
  source: llm_enhanced
  text: Meanwhile, they're missing the strategic approaches that could actually transform
    both their internal operations and their client delivery.
  topic: strategy
- impact_reason: 'Defines a key market need: trustworthy, safe AI implementation,
    directly linking safety to business viability.'
  relevance_score: 8
  source: llm_enhanced
  text: My ideal clients are twofold. One is the startups who are trying to implement
    AI and trying to figure out how they can use AI in a safe manner, where effectively,
    where there's no hallucination or they can trust the solution.
  topic: business
- impact_reason: Establishes deep historical context and expertise across multiple
    AI eras (pre-LLM deep learning), lending credibility to current insights.
  relevance_score: 8
  source: llm_enhanced
  text: I understand how industry works, and I have been with AI like my master's
    was a neural network, you know, when we were doing backpropagation back those
    days. And I have worked in support vector machines when we were doing intent tagging
    manually.
  topic: technical
- impact_reason: 'Reiterates the core limitation of current LLMs: they are generalists
    requiring specific context from the user.'
  relevance_score: 8
  source: llm_enhanced
  text: We just need to be very mindful and know how to use it. You want to create
    some content or you want to analyze a problem. Now, this one AI doesn't know anything
    about your problem. It's a general-purpose AI which is able to gather some thoughts
    and bring to you.
  topic: safety
- impact_reason: Illustrates the iterative, contextual building process required in
    layered prompting, emphasizing domain specificity.
  relevance_score: 8
  source: llm_enhanced
  text: So, you know, if you put yourself as an Australian, the GTM will vary. Now,
    my target clients are focusing on this particular sector. My product is this.
    So, it starts thinking with you, and then goes step by step...
  topic: technical
- impact_reason: Provides a nuanced critique of JSON prompting, suggesting its primary
    benefit lies in structured API calls rather than simple chat interfaces.
  relevance_score: 8
  source: llm_enhanced
  text: So, yeah, there's a lot of things been talked about. People say do a JSON
    prompting, but it actually works better when you are sending it as an API.
  topic: technical
- impact_reason: 'Explains the *why* behind structured prompting (like JSON): it forces
    human thought into a structured format that the model can interpret more clearly
    than unstructured natural language.'
  relevance_score: 8
  source: llm_enhanced
  text: Your natural language when we say it, we are our thoughts are all over the
    place. We're not in the structured it. So, sometimes people say go for JSON when
    you have too many things, then you are able to create tags and that kind of shows
    the model that, 'Okay, this is what people are talking about. These are different
    fields.'
  topic: technical
- impact_reason: Provides a concrete, relatable business metaphor for AI augmentation
    in content creation, illustrating a shift from creation to editing/validation.
  relevance_score: 8
  source: llm_enhanced
  text: I call it red pen, black pen. Black pen is when I used to sit down every Monday
    and type out all the content myself. Now, my team runs all of my calls through
    the LLM that then produces the content, and then I read it. I make sure that it's
    me.
  topic: business
- impact_reason: Offers a nuanced assessment of ChatGPT's strength (broad knowledge)
    and its weakness (ambiguity), stressing the need for user steering/parameterization.
  relevance_score: 8
  source: llm_enhanced
  text: ChatGPT is very good for analysis of multiple different kinds of topics where
    it can go broad, and it almost knows about everything—at least it pretends to
    know about everything. But what I have seen is that you can actually bring it
    to a certain direction because, you know, it's been trained on huge amount of
    information. So, like, you know, a lot of things have similar kind of meanings
    and, you know, they're ambiguous, so you have to bring it to your steer the direction
    of thinking for the model, as in parameterizing it towards the right direction.
  topic: technical/strategy
- impact_reason: Recommends Gemini for technical problem-solving and tool/library
    information, leveraging Google's vast technical data corpus.
  relevance_score: 8
  source: llm_enhanced
  text: Gemini again is another model where if you want to get more information about
    like how things are done, how they are technically solved, then I go for Gemini.
    A bunch of information which you can... I wouldn't say 100%, but kind of like,
    you know, you go by it that, 'Okay, it's giving you the right information about
    the tools, how, you know, the Python libraries,' all of that kind of bunch of
    information, it just gives all that correct, why? Because Google has all that,
    right? Trained it on.
  topic: technical
- impact_reason: Provides a specific alternative (Perplexity) for tasks requiring
    verifiable references and research papers.
  relevance_score: 8
  source: llm_enhanced
  text: So, Perplexity might be a go-to, you know, if you want to find the research
    papers or the references and things like that, then it's Perplexity.
  topic: strategy
- impact_reason: Challenges the common understanding of a major industry trend (Agentic
    AI), signaling a need for clearer definition.
  relevance_score: 8
  source: llm_enhanced
  text: Agentic AI is a buzzword which is bad misled and confused by many people.
    They don't understand what is agentic AI.
  topic: predictions
- impact_reason: Provides concrete, practical examples of agentic AI in action (scheduling,
    content preparation), illustrating its utility in professional workflows.
  relevance_score: 8
  source: llm_enhanced
  text: So, the AI takes an action, sends a reminder to Paul, or, you know, creates
    that content, keeps it ready, profile of a person who you are going to interview,
    you know, things like that.
  topic: predictions/business
- impact_reason: 'Crucial clarification for the audience: current advanced AI actions
    are highly constrained and engineered workflows, managing expectations about autonomous
    decision-making.'
  relevance_score: 8
  source: llm_enhanced
  text: And all of that's been engineered and designed, right? Like, it's not that
    AI is taking action, but we have curated it in that way.
  topic: safety/strategy
- impact_reason: 'Provides essential advice for leveraging AI tools: maintain critical
    thinking and do not outsource core cognitive processes entirely.'
  relevance_score: 8
  source: llm_enhanced
  text: And exploring AI, but have your own thinking going on. You have to be very,
    very mindful.
  topic: strategy/safety
- impact_reason: A strong strategic insight applicable to any service business, emphasizing
    systems over brute-force effort.
  relevance_score: 7
  source: llm_enhanced
  text: I spent 18 years at Coca-Cola then building some of my own consulting business.
    Along the way I learned that working harder isn't the answer. Building better
    systems is.
  topic: strategy
- impact_reason: Highlights the value of deep, timely academic research combined with
    industry experience, especially during paradigm shifts like the LLM explosion.
  relevance_score: 7
  source: llm_enhanced
  text: I have a long journey where I've seen AI right from 2021 to 2025. And it's
    been always happened that, you know, I was in school at the right time, probably
    after, you know, at age of 40, I decided to do my PhD, and this was the right
    time when LLMs were just coming in, and I got to do a lot of research on how LLMs
    work.
  topic: strategy
- impact_reason: Poses a key practical question regarding the balance between providing
    raw data (transcripts) versus summarized context.
  relevance_score: 7
  source: llm_enhanced
  text: I often upload the transcripts from the calls to give it better context. You
    know, am I better off doing that? Am I better off just verbalizing what the context
    is? I'd love to get your perspective on those.
  topic: technical
- impact_reason: Clarifies the practical difference in prompting effort based on the
    interface (API vs. UI), saving developers time when using consumer-facing applications.
  relevance_score: 7
  source: llm_enhanced
  text: But all the prompting if it is done through a JSON is fine. But if you're
    using a UI, I mean, it doesn't matter. It's all totally fine. You don't have to
    do yourself and just the right thing is on JSON doesn't matter for...
  topic: technical/strategy
- impact_reason: 'Emphasizes the prerequisite for effective LLM use: establishing
    the overall context and problem definition before requesting specific outputs.'
  relevance_score: 7
  source: llm_enhanced
  text: My intent here is to communicate that, convey that, you know, the ChatGPT
    or any LLM, it could be Claude or anything, it should be able to understand your
    problem first. Yes, then it will be able to give you the right kind of solution.
  topic: strategy
- impact_reason: Reinforces the necessity of human oversight and iterative refinement
    ('red pen' approach) rather than blind acceptance of AI output.
  relevance_score: 7
  source: llm_enhanced
  text: Just don't trust it like blindly, or you can give suggestions. Yes, that,
    'Hey, I think this is not a right approach. You can do this,' and so on.
  topic: safety/strategy
- impact_reason: 'Provides clear use-case recommendations: ChatGPT excels at general
    NLP tasks like summarization and rephrasing.'
  relevance_score: 7
  source: llm_enhanced
  text: So, ChatGPT is mostly when you want to use natural language. By natural language,
    I mean I want to reduce the content, I want to summarize, rephrase, analyze content
    delivery—all of that is better with ChatGPT.
  topic: business
- impact_reason: A cautionary note on a specific model (DeepSeek), suggesting trade-offs
    between speed and reliability when handling complex or voluminous text inputs.
  relevance_score: 7
  source: llm_enhanced
  text: Now, with DeepSeek, I have some reservations because the model is faster,
    but I think if you have too much English or too much content going on, the model
    kind of shakes. It doesn't give you the right information.
  topic: technical
- impact_reason: Highlights the value of cohort-based learning and mentorship that
    combines domain expertise with real-time application, a model applicable to internal
    AI upskilling.
  relevance_score: 7
  source: llm_enhanced
  text: The real breakthroughs happen when you combine my experience with live problem-solving
    of people going through exactly what you're facing now.
  topic: business/strategy
- impact_reason: Emphasizes the necessity of practical, context-specific guidance
    over purely theoretical knowledge when implementing complex changes like AI integration.
  relevance_score: 7
  source: llm_enhanced
  text: It's not theory, it's real-time strategic thinking with consultants in the
    trenches, plus someone who's already made the journey.
  topic: strategy
- impact_reason: A concise summary of the current industry climate, acknowledging
    the overwhelming speed of innovation.
  relevance_score: 7
  source: llm_enhanced
  text: The pace of change in AI is incredible.
  topic: trends
- impact_reason: 'Direct advice on when to deploy AI: when it demonstrably reduces
    friction or workload, linking AI use directly to efficiency gains.'
  relevance_score: 7
  source: llm_enhanced
  text: That's the time when you use AI because, you know, that makes your life easier.
  topic: business/application
- impact_reason: Addresses a specific advanced prompting technique (JSON structuring)
    that is popular in the community.
  relevance_score: 6
  source: llm_enhanced
  text: JSON prompting, and they say that you're better off doing JSON prompting.
    So, take your natural language, put it into a JSON prompt, and then use the JSON
    prompt to get better results. What's your view on that?
  topic: technical
- impact_reason: Offers an inspirational, human-centric message countering ageism
    in fast-moving tech fields, suggesting dedication trumps perceived limitations.
  relevance_score: 6
  source: llm_enhanced
  text: I started my PhD at 40, and it was very challenging... age is just a number.
    I would say that you can conquer anything if you set your mind on it.
  topic: general/inspiration
source: Unknown Source
summary: '## Podcast Summary: 639 - How to Stop ChatGPT from Lying to You (AI PhD
  Reveals the Fix) with Garima Agrawal


  This episode of the Paul Higgins podcast features **Garima Agrawal**, an AI expert
  with a PhD in Artificial Intelligence, who discusses practical strategies for mitigating
  hallucinations in Large Language Models (LLMs) and transitioning from basic interactive
  AI use to more sophisticated, goal-driven **agentic AI**.


  ---


  ### 1. Focus Area

  The primary focus is on **Practical LLM Application and Reliability**, specifically
  addressing the challenge of **AI Hallucinations** in tools like ChatGPT. The discussion
  spans advanced prompting techniques, model selection based on task type, the distinction
  between interactive and agentic AI, and strategic implementation for consultants
  and investors.


  ### 2. Key Technical Insights

  *   **Layered Prompting for Reliability:** To combat hallucinations, users must
  treat the LLM as a "thinking partner," not a final authority. This involves starting
  with small prompts to gauge the model''s domain knowledge, then incrementally adding
  context (business specifics, constraints) step-by-step, rather than overwhelming
  it with a single large input.

  *   **Model Specialization:** Different LLMs excel at different tasks: **ChatGPT**
  is best for broad analysis and natural language manipulation (summarizing, rephrasing);
  **Claude (specifically Sonnet 3.5)** is preferred for coding and technical tasks
  due to its strong in-topic models and lower hallucination footprint in these areas;
  **Gemini** is useful for technical research and gathering information on tools/libraries
  (leveraging Google''s training data).

  *   **Agentic vs. Interactive AI:** **Interactive AI** is the current standard (e.g.,
  asking ChatGPT questions). **Agentic AI** is goal-driven, capable of taking actions,
  making decisions based on environmental context changes, and operating without constant
  human oversight (e.g., an AI monitoring a schedule and proactively sending reminders).


  ### 3. Business/Investment Angle

  *   **Consulting Bottleneck:** Many AI/tech consultants are stuck using LLMs inefficiently
  ("the hamster wheel"), missing opportunities for scalable growth that strategic
  AI implementation could provide.

  *   **Investor Guidance:** Garima serves investors by helping them understand which
  AI startups and ventures represent sound investments, bridging the gap between deep
  technical understanding and commercial viability.

  *   **Structured Input for Better Output:** While JSON prompting is often cited,
  Garima notes it''s most beneficial when using APIs. For UI use, the key is structuring
  input via tagging or clear segmentation (even if not strictly JSON) to help the
  model parse complex thoughts better than unstructured natural language.


  ### 4. Notable Companies/People

  *   **Garima Agrawal (HumanCon AI Consulting/Minerva):** The expert guest, holding
  a PhD in AI, who emphasizes understanding LLMs "under the hood" from her research
  at Arizona State University under mentors like Professor Juan Liu and Professor
  Dmitri Patraska.

  *   **ChatGPT (OpenAI):** Acknowledged as the most commonly used tool, but requires
  careful prompting to manage its known tendency to hallucinate.

  *   **Claude (Anthropic):** Highlighted as superior for coding and technical execution.

  *   **Gemini (Google):** Recommended for technical research due to its training
  data breadth.

  *   **Perplexity:** Suggested as a better tool than ChatGPT for academic or research
  paper citation verification.


  ### 5. Future Implications

  The industry is moving rapidly toward **Agentic AI**, where systems are autonomous,
  goal-driven, and can interact with the environment to complete complex workflows
  (like real-time customer service handling) without continuous human intervention.
  The focus is shifting from simply generating text to enabling AI to *act*.


  ### 6. Target Audience

  This episode is highly valuable for **AI/Tech Consultants, Software Developers,
  Startup Founders implementing AI strategies, and Technology Investors** who need
  actionable, technically grounded advice on maximizing LLM utility while minimizing
  risk (hallucinations).


  ---


  ### Comprehensive Summary Narrative


  The podcast opens by framing the common frustration consultants face when using
  AI—getting unreliable, hallucinated responses that hinder productivity rather than
  boost it. Garima Agrawal, drawing on her deep technical background (PhD in AI) combined
  with 15 years of industry experience, positions herself as the translator between
  complex AI theory and practical business application.


  Garima’s ideal clients are startups needing safe, trustworthy AI implementation
  and investors seeking informed guidance. She stresses that the core problem with
  general models like ChatGPT is their lack of domain-specific context. Her primary
  solution is **Layered Prompting**, a technique where the user iteratively builds
  context, verifies the model''s understanding, and guides it step-by-step, treating
  the LLM as a collaborative thinking partner rather than an oracle. She advises against
  overwhelming the model with too much data at once, as this initiates a "snowball
  effect" of hallucination from which recovery is difficult.


  A significant portion of the discussion focuses on **model selection**. Garima provides
  a clear taxonomy: ChatGPT for general analysis and natural language tasks; Claude
  3.5 for superior coding and technical accuracy; and Gemini for broad technical research
  due to Google’s extensive training data. She cautions against relying on LLM-generated
  citations, suggesting Perplexity for verifiable research.


  Finally, the conversation pivots to the next frontier: **Agentic AI**. Garima clarifies
  that many current tools are merely interactive. True agentic AI is defined by its
  **goal-driven nature**—the ability to perceive environmental changes, make autonomous
  decisions, and execute tasks (like real-time customer service actions) without constant
  prompting. Her firm, Minerva, is actively building such goal-driven systems via
  API integration to move beyond simple content generation toward'
tags:
- artificial-intelligence
- generative-ai
- startup
- investment
- google
- microsoft
title: 639 - How to Stop ChatGPT from Lying to You (AI PhD Reveals the Fix) with Garima
  Agrawal
topics:
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 125
  prominence: 1.0
  topic: artificial intelligence
- keywords:
  - generative ai
  - genai
  - chatgpt
  - gpt
  - claude
  - text generation
  - image generation
  mentions: 56
  prominence: 1.0
  topic: generative ai
- keywords:
  - startup
  - entrepreneur
  - founder
  - venture
  mentions: 5
  prominence: 0.5
  topic: startup
- keywords:
  - investment
  - funding
  - valuation
  - ipo
  - acquisition
  mentions: 2
  prominence: 0.2
  topic: investment
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-10-06 05:43:42 UTC -->
