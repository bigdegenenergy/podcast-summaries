---
companies:
- category: unknown
  confidence: medium
  context: to our event. This event is brought to you by the ROX Club, which is a
    community of people who love data. Ev
  name: ROX Club
  position: 71
- category: unknown
  confidence: medium
  context: tware processes this, it recognizes what I say as Data Docs Club, Data
    Docs Club. I need to work on my articulatio
  name: Data Docs Club
  position: 258
- category: unknown
  confidence: medium
  context: e. I'm just curious how many subscribers we have. So I think this is right
    now 66,000. So if you want to
  name: So I
  position: 970
- category: unknown
  confidence: medium
  context: . Today on the podcast, we are joined by Ranjita, Staff ML Engineer at
    Neubert.ai, previously at Dropbox Dash buildin
  name: Staff ML Engineer
  position: 1773
- category: unknown
  confidence: medium
  context: a, Staff ML Engineer at Neubert.ai, previously at Dropbox Dash building
    LLM and agent-powered products, with als
  name: Dropbox Dash
  position: 1820
- category: tech
  confidence: high
  context: lso earlier work in speech recognition and NLP at Microsoft and research
    at Carnegie Mellon. You have quite a
  name: Microsoft
  position: 1930
- category: unknown
  confidence: medium
  context: recognition and NLP at Microsoft and research at Carnegie Mellon. You have
    quite a nice career journey. So it's a
  name: Carnegie Mellon
  position: 1956
- category: unknown
  confidence: medium
  context: t's what brought me to CMU for my Master's there. And I learned a lot of
    stuff from amazing professors an
  name: And I
  position: 3351
- category: unknown
  confidence: medium
  context: years. And I just got to learn so much from them. Then I wanted to broaden
    my scope in ML a little bit. So
  name: Then I
  position: 3790
- category: unknown
  confidence: medium
  context: based on, you know, your activity. I understand. Since I don't use Dropbox
    through the web, for me, it's j
  name: Since I
  position: 4314
- category: tech
  confidence: high
  context: web, for me, it's just a folder. But when I open Google Drive, I see recommendations.
    You say, okay, thes
  name: Google
  position: 4401
- category: unknown
  confidence: medium
  context: web, for me, it's just a folder. But when I open Google Drive, I see recommendations.
    You say, okay, these file
  name: Google Drive
  position: 4401
- category: unknown
  confidence: medium
  context: You say, okay, these files you're interested in. So Dropbox has something
    like that. Yes, it has had it for a
  name: So Dropbox
  position: 4487
- category: unknown
  confidence: medium
  context: ecause I was a data scientist, I was not on-call. But I remember my colleagues,
    who were software enginee
  name: But I
  position: 6827
- category: unknown
  confidence: medium
  context: ming things these days. I remember Kaggle, right? So Kaggle, I was interviewed
    probably with Anthony Goldbloo
  name: So Kaggle
  position: 8083
- category: unknown
  confidence: medium
  context: right? So Kaggle, I was interviewed probably with Anthony Goldbloom, his
    last name. Anyways, with one of the creators
  name: Anthony Goldbloom
  position: 8126
- category: unknown
  confidence: medium
  context: o right now, we delegate the decisions to an LLM. So LLM is the brain,
    the decision-maker, but it can be s
  name: So LLM
  position: 11210
- category: unknown
  confidence: medium
  context: an agent that doesn't have any LLM at all, right? Like I mentioned. Probably
    if I ask it to create me a Dj
  name: Like I
  position: 14192
- category: unknown
  confidence: medium
  context: ngo project, it will not be able to execute that. If I give it to a simple
    LLM, like I don't know, Llama
  name: If I
  position: 14299
- category: tech
  confidence: high
  context: ramework, like LangChain or I take, I don't know, OpenAI Agents SDK, and
    then what I have is I can have th
  name: Openai
  position: 15207
- category: unknown
  confidence: medium
  context: ramework, like LangChain or I take, I don't know, OpenAI Agents SDK, and
    then what I have is I can have the system pr
  name: OpenAI Agents SDK
  position: 15207
- category: unknown
  confidence: medium
  context: ompany. One company can use DataDog, another uses New Relic, the third
    one uses something built in on primiti
  name: New Relic
  position: 20818
- category: unknown
  confidence: medium
  context: ex all the logs, or are you doing something else? Because I think this
    is where we started the conversation,
  name: Because I
  position: 29271
- category: unknown
  confidence: medium
  context: y, can I get the working hours from the calendar? Can I see when the two
    of them are free first? And like
  name: Can I
  position: 34584
- category: unknown
  confidence: medium
  context: er she's talking about, right? And do they have a Google Calendar? Do they
    have an Outlook Calendar?" Like all thes
  name: Google Calendar
  position: 34745
- category: unknown
  confidence: medium
  context: d do they have a Google Calendar? Do they have an Outlook Calendar?" Like
    all these things are in the sense that you
  name: Outlook Calendar
  position: 34778
- category: unknown
  confidence: medium
  context: 'I''m checking, and there''s a big—there''s a link: "Contact Sales." Okay,
    there''s a problem because I know Dropbox'
  name: Contact Sales
  position: 36653
- category: tech
  confidence: high
  context: ord with me was this thing called Smoldyn, it's a Hugging Face Transformers
    library that kind of transforms to t
  name: Hugging Face
  position: 37591
- category: unknown
  confidence: medium
  context: ord with me was this thing called Smoldyn, it's a Hugging Face Transformers
    library that kind of transforms to this called Sm
  name: Hugging Face Transformers
  position: 37591
- category: unknown
  confidence: medium
  context: for me, it was like LangChain—it's just like the Agents SDK from OpenAI
    is kind of a very light wrapper aroun
  name: Agents SDK
  position: 39258
- category: unknown
  confidence: medium
  context: ou deal with, but I imagine if you're building an AI SRE, you need to be
    able to access DataDog, New Relic
  name: AI SRE
  position: 40974
- category: unknown
  confidence: medium
  context: able to access DataDog, New Relic, I don't know, AWS CloudWatch, anyways,
    like all these systems, right? And then
  name: AWS CloudWatch
  position: 41046
- category: unknown
  confidence: medium
  context: ight have more context on these things than I do. So MCP has this way of
    describing your tool and so on an
  name: So MCP
  position: 41614
- category: unknown
  confidence: medium
  context: o on. So what, like, SQuAD or what else is there? Like SQuAD is from Wikipedia,
    they just look at all those QA
  name: Like SQuAD
  position: 43618
- category: ai_startup
  confidence: high
  context: The current employer of the guest, a startup focused on building LLM agents
    to solve the problem of engineering on-call.
  name: Neubert.ai
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Previous employer of the guest, where they worked on recommendation systems,
    question-answering systems, and agent-powered products.
  name: Dropbox
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Previous employer of the guest, where they worked on speech recognition
    and language modeling for products like Xbox, Bing search, and Cortana.
  name: Microsoft
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: The institution where the guest pursued their Master's degree, implying
    significant AI/ML research/education activity.
  name: Carnegie Mellon (CMU)
  source: llm_enhanced
- category: ai_infrastructure
  confidence: medium
  context: A library mentioned in the context of early image processing/feature extraction
    work (pre-deep learning era).
  name: OpenCV
  source: llm_enhanced
- category: ai_model
  confidence: high
  context: A specific model architecture (Text-to-Text Transfer Transformer) the guest
    was fine-tuning at Dropbox.
  name: T5
  source: llm_enhanced
- category: ai_model
  confidence: high
  context: A specific large language model released by OpenAI that disrupted the market
    and influenced the guest's work on agents.
  name: GPT-3.5
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: A service mentioned in the context of receiving on-call alerts, often used
    by engineering teams supported by ML/AI monitoring.
  name: PagerDuty
  source: llm_enhanced
- category: ai_community
  confidence: high
  context: Mentioned as an example of a company whose name was created via a systematic
    process (scripting availability checks).
  name: Kaggle
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: Mentioned as a popular framework used for implementing LLM agents.
  name: LangChain
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: Mentioned as a specific SDK used for building agents, implying the existence
    of OpenAI's agent development tools.
  name: OpenAI Agents SDK
  source: llm_enhanced
- category: ai_model
  confidence: high
  context: Mentioned as an example of a foundational LLM (likely referring to Meta's
    models) that could power a basic agent.
  name: Llama
  source: llm_enhanced
- category: ai_model
  confidence: high
  context: Mentioned as an example of a foundational LLM (Google's model) that could
    power a basic agent.
  name: Gemini
  source: llm_enhanced
- category: big_tech
  confidence: medium
  context: Mentioned in comparison to Dropbox regarding recommendation features.
  name: Google Drive
  source: llm_enhanced
- category: organization
  confidence: medium
  context: The community/organization hosting the podcast event (misheard by ASR as
    'ROX Club').
  name: Data Docs Club
  source: llm_enhanced
- category: organization
  confidence: high
  context: The organization bringing the event, described as a community for people
    who love data.
  name: ROX Club
  source: llm_enhanced
- category: ai_startup
  confidence: high
  context: The company where the speaker works, which has built a complex agentic
    system for SRE tasks and context engineering.
  name: Neubert
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: Mentioned in the context of various monitoring/logging tools, possibly
    referring to an open-source observability project or tool, though context is slightly
    vague.
  name: EOK or EO
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Mentioned in relation to their Agents SDK and general LLM capabilities.
  name: OpenAI
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: Mentioned via their Transformers library, specifically in relation to 'Smoldyn
    agents.'
  name: Hugging Face
  source: llm_enhanced
- category: ai_framework
  confidence: medium
  context: Mentioned as a library/concept derived from Hugging Face Transformers,
    related to code-based agents.
  name: Smoldyn
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Referenced as a common way the speaker interacts with AI (voice recognition/commands).
  name: ChatGPT
  source: llm_enhanced
date: 2025-10-10 17:20:00 +0000
duration: 60
has_transcript: false
layout: episode
llm_enhanced: true
original_url: https://audio.listennotes.com/e/p/394ffd4a5c964c1db0b56470151293b6/
processing_date: 2025-10-10 20:07:42 +0000
quotes:
- length: 169
  relevance_score: 5
  text: ai, previously at Dropbox Dash building LLM and agent-powered products, with
    also earlier work in speech recognition and NLP at Microsoft and research at Carnegie
    Mellon
  topics: []
- length: 101
  relevance_score: 5
  text: So you have to be very deliberate about what information it is that you're
    kind of sending to the LLM
  topics: []
- length: 88
  relevance_score: 4
  text: So I think in a nutshell, my career is basically machine learning and NLP
    from the start
  topics: []
- length: 216
  relevance_score: 4
  text: So an agent is, at the end of the day, something that performs a task that
    is given to it autonomously with the help of LLMs, tools, some kind of memory
    and storage, and things like that, to basically please the user
  topics: []
- length: 150
  relevance_score: 4
  text: It's just that we are now realizing a world where RAG has had shortcomings
    because LLM is this really smart thing, and then we are the backend of that
  topics: []
- length: 139
  relevance_score: 4
  text: So that's you're kind of influencing how the LLM thinks, and how do you make
    it produce an output in a structured format and just like that
  topics: []
- length: 90
  relevance_score: 4
  text: Like where you're just doing this embedding and vector search and then putting
    it into LLM
  topics: []
- length: 94
  relevance_score: 4
  text: Because in the case of RAG, when it's a fixed flow, evaluation is not super
    complicated, right
  topics:
  - valuation
- length: 145
  relevance_score: 3
  text: And I totally get the pain when you get woken up at three o'clock in the night,
    you know, you're sleeping and you have to wake up and go to sleep
  topics: []
- length: 219
  relevance_score: 3
  text: But if there is a very complex task, you have to plan like a hundred steps
    and you go this way, that way, and there's conditionals and all that, in that
    case, you would want something that is more programmatic in nature
  topics: []
- length: 78
  relevance_score: 3
  text: You have to look at so many different data sources, different logs and metrics
  topics: []
- length: 115
  relevance_score: 3
  text: How do you, like you have to at some point, restrict and say, "Okay, I work
    only with this tech," or what do you do
  topics: []
- length: 122
  relevance_score: 3
  text: So there is still a bunch of engineering that you have to do around just this
    chunking and putting your data into an index
  topics: []
- length: 164
  relevance_score: 3
  text: One that really struck a chord with me was this thing called Smoldyn, it's
    a Hugging Face Transformers library that kind of transforms to this called Smoldyn
    agents
  topics: []
- impact_reason: A clear articulation of the disruptive impact of GPT-3.5, marking
    a significant inflection point in the feasibility and quality of NLP/Agent systems.
  relevance_score: 10
  source: llm_enhanced
  text: And then after that, then GPT-3.5 came and then it totally disrupted the whole
    market. It was so good.
  topic: AI technology trends
- impact_reason: 'Provides a concrete, high-value business application for AI agents:
    automating high-stress, repetitive operational tasks (SRE/On-call).'
  relevance_score: 10
  source: llm_enhanced
  text: We're trying to solve this problem of engineering on-call. How do we take
    that away from users and make agents be on-call for us so that we can focus on
    the more fun building part of the system?
  topic: predictions
- impact_reason: 'Provides a concise, modern definition of an AI agent: autonomy +
    LLM as the central decision-making ''brain.'''
  relevance_score: 10
  source: llm_enhanced
  text: The core of it still remains the same. It's about autonomously going and completing
    a task that was given to them. And right now, it's somehow has honed into LLMs
    being at the core of it all. LLMs are powering these agents, LLMs are the brain
    of these agents.
  topic: technical
- impact_reason: 'Identifies the key differentiator in current agent development:
    the orchestration logic (planning, tool use, memory management) rather than just
    the LLM itself.'
  relevance_score: 10
  source: llm_enhanced
  text: What defines a type of agent? Because everybody's building agents, and not
    two of them are alike. Everyone has been coming up with their own recipes for
    building agents, and what that brings in is how you're orchestrating multiple
    calls to LLMs, calls to tools, calls to some knowledge store, and so on, things
    like that.
  topic: technical
- impact_reason: Refutes the simplistic 'LLM + Tools' definition, emphasizing that
    the planning and architectural wrapper is crucial for defining agent complexity
    and capability.
  relevance_score: 10
  source: llm_enhanced
  text: Would you just say an agent equals LLM with tools? It's not just that. So
    there is that wrapper around it which kind of has the way you plan, it can differ
    a lot when it comes to the types of agents you're building.
  topic: technical
- impact_reason: Highlights the critical architectural difference between linear agents
    and self-correcting, reflective agents (multi-pass loops), which is key to advanced
    autonomy.
  relevance_score: 10
  source: llm_enhanced
  text: Is it a single pass that you just go from start to end, or is it like a multi-pass
    thing where you're constantly checking what you have planned so far, constantly
    asking maybe the same LLM, asking itself, self-reflecting, or things like that,
    and then going and correcting multiple times and saying, 'Oh, you know what, I
    had this plan earlier, b'
  topic: technical
- impact_reason: Highlights the critical concept of self-reflection and multi-pass
    iteration (feedback loops) as the differentiator for complex, robust agents.
  relevance_score: 10
  source: llm_enhanced
  text: there is also this thing of how many iterations of this are you going to do,
    like, how many times is there a feedback loop around it? Is it a single pass that
    you just go from start to end, or is it like a multi-pass thing where you're constantly
    checking what you have planned so far, constantly asking maybe the same LLM, asking
    itself, self-reflecting, or things like that, and then going and correcting multiple
    times.
  topic: technical
- impact_reason: 'Introduces a crucial architectural distinction: NL-based planning
    vs. programmatic (code) planning, linking complexity to the required planning
    method.'
  relevance_score: 10
  source: llm_enhanced
  text: there is another distinction where you see some agents are planning in plain
    English, and some agents are doing this in code—code agents, right? So that is
    another thing.
  topic: technical
- impact_reason: Strong endorsement for code-based agents for complex tasks due to
    superior predictability and reduced ambiguity, offering practical architectural
    advice.
  relevance_score: 10
  source: llm_enhanced
  text: if there is a very complex task, you have to plan like a hundred steps and
    you go this way, that way, and there's conditionals and all that, in that case,
    you would want something that is more programmatic in nature. So I'm a big fan
    of that, the latter, mainly because that's the kind of agents we kind of came
    up with, with a lot of experimentation. So it just feels like a lot of use cases
    can fit into that code agent type of system, but it's just less ambiguity, more
    predictability.
  topic: business/strategy
- impact_reason: Clearly differentiates context engineering (deliberate information
    selection) from traditional prompt engineering (syntactic instruction manipulation).
  relevance_score: 10
  source: llm_enhanced
  text: context engineering is like a subfield of prompt engineering, but what the
    main focus was when people said prompt engineering was, you know, I will put this
    instruction at the top, I will change that, I will move the instruction to the
    bottom, you know, things like that. I will write in all caps and all those things.
  topic: technical
- impact_reason: A crucial reality check on the limitations of large context windows;
    sheer size does not equate to perfect comprehension or utility.
  relevance_score: 10
  source: llm_enhanced
  text: I know there are a million-token models these days, but does that mean I can
    give it like a thousand of my documents and expect it to understand everything
    fully? Well, the answer is not yet, at least.
  topic: limitations
- impact_reason: Confirms the continued relevance of RAG (Retrieval-Augmented Generation)
    despite massive context windows, citing efficiency and utilization quality as
    remaining challenges.
  relevance_score: 10
  source: llm_enhanced
  text: RAG is not dead yet, right? Yeah, definitely not. And the main idea is yes,
    technically yes, there are models that can take your entire knowledge base, codebase,
    whatever base, right? Yeah. But then how good are they at using all the information
    you give it, and how fast?
  topic: technical
- impact_reason: A direct rebuttal to the popular narrative that RAG is obsolete due
    to massive context windows, confirming its continued relevance.
  relevance_score: 10
  source: llm_enhanced
  text: From what I see, RAG is not dead yet, right? Yeah, definitely not.
  topic: technical
- impact_reason: Critiques the limitations of traditional Information Retrieval (IR)
    systems when repurposed for LLM context feeding, highlighting a fundamental mismatch
    in design goals.
  relevance_score: 10
  source: llm_enhanced
  text: The thing that supplies context into LLMs is this old system of information
    retrieval, which is historically not been designed for this kind of usage. It
    is for like, you give 10 blue links, and humans go click on things, and that's
    what it was designed for.
  topic: technical
- impact_reason: Contrasts fixed workflows (vanilla RAG) with the dynamic orchestration
    capabilities enabled by agents, pointing to the next evolution of retrieval systems.
  relevance_score: 10
  source: llm_enhanced
  text: That is a very set workflow. And what we are going more and more towards in
    the world of agents is getting rid of the set workflows and making it as dynamic
    as possible, like agentic RAG, right?
  topic: predictions
- impact_reason: 'Provides a clear definition of Agentic RAG: the LLM dynamically
    chooses whether and when to use the search tool based on the task.'
  relevance_score: 10
  source: llm_enhanced
  text: The agent has some tools. One of them is search, which performs search in
    the database that we have chunked and done all the things to preprocess. But we
    let the LLM decide when it needs to, if it needs it.
  topic: technical
- impact_reason: 'Clearly delineates the transition point from RAG suitability to
    Agent necessity: complexity involving multi-source integration, dynamic planning,
    and write operations.'
  relevance_score: 10
  source: llm_enhanced
  text: And the minute these problems start getting complex where you have multiple
    data sources and you want to do some dynamic planning, or integrating with multiple
    APIs, and you want to do right operations, for example, all these things is when
    you don't do RAG as much, you go to agents when you want to do something like
    that.
  topic: predictions
- impact_reason: A strong statement from a practitioner suggesting that cutting-edge
    production work might bypass popular open-source agent frameworks.
  relevance_score: 10
  source: llm_enhanced
  text: at work, I don't really use any of those things [LangChain, OpenAI Agents
    SDK].
  topic: technical
- impact_reason: Provides a critical warning about the complexity and debugging difficulty
    of abstract agent frameworks, advocating for foundational understanding via building
    from scratch.
  relevance_score: 10
  source: llm_enhanced
  text: I would still say build it from scratch. There's nothing like it because you
    know what happens with these frameworks. When you're building something, it's
    after a point you have gotten into this complex state where you don't really understand
    what this agent is doing. It becomes like a debugging nightmare.
  topic: technical
- impact_reason: 'Presents a long-term strategic vision for the future of AI development:
    a decentralized marketplace for specialized, composable agents.'
  relevance_score: 10
  source: llm_enhanced
  text: having this agentic dream of an agentic marketplace where you can build agents
    of the same sort, and people can buy agents from each other or talk to each other.
  topic: predictions
- impact_reason: Highlights the complexity of agent evaluation, which goes beyond
    simple output correctness to include the correctness of the reasoning/tool-use
    path.
  relevance_score: 10
  source: llm_enhanced
  text: in the case of agents, how do you go about evaluation? Because not only do
    we need to evaluate the answer, but also we need to relate if tools were called
    or not, what parameters they were called with, some things like that.
  topic: safety
- impact_reason: Corrects a common misconception, asserting that RAG evaluation is
    significantly harder than often assumed, setting the stage for a deeper discussion
    on evaluation rigor.
  relevance_score: 10
  source: llm_enhanced
  text: I would like to point out one contradiction from your statement, which is
    it's easy to write evals for RAG. It's not. It's not like we learned it the hard
    way.
  topic: technical
- impact_reason: A crucial warning against over-reliance on public benchmarks (like
    SQuAD) for system-level evaluation, emphasizing the need to test the entire deployed
    stack (RAG system, not just the LLM).
  relevance_score: 10
  source: llm_enhanced
  text: if you look at them and say, 'Okay, I will just pick my model based on that
    benchmark,' you are going to go horribly wrong in your system because you're not
    evaluating your system, you're evaluating just that model's capability, right?
  topic: safety
- impact_reason: Indicates early adoption and pioneering work in the 'agent' paradigm
    before it became mainstream, suggesting deep foundational experience in agent
    design.
  relevance_score: 9
  source: llm_enhanced
  text: We both kind of started a new team which focuses on agents. And this was back
    then we didn't really have the term agents as popular yet.
  topic: predictions
- impact_reason: 'Shows the current industry focus: moving beyond basic LLM use cases
    to fully realizing the potential of autonomous agents.'
  relevance_score: 9
  source: llm_enhanced
  text: What can agents do, right? And that's how this startup got my eye— Neubert,
    which is where I am right now, and I'm fully immersed in the potential that these
    agents have.
  topic: business
- impact_reason: A comprehensive, actionable definition of a modern LLM agent, emphasizing
    the necessary components (LLM, tools, memory).
  relevance_score: 9
  source: llm_enhanced
  text: An agent is, at the end of the day, something that performs a task that is
    given to it autonomously with the help of LLMs, tools, some kind of memory and
    storage, and things like that, to basically please the user.
  topic: technical
- impact_reason: Challenges the assumption that LLMs are mandatory for all agents,
    suggesting that the decision-making component can be replaced by simpler logic
    (like if-else) for specific, constrained tasks.
  relevance_score: 9
  source: llm_enhanced
  text: I thought, can I make an agent without an LLM? And the answer is actually
    yes, right? So we need something that can make decisions. So right now, we delegate
    the decisions to an LLM.
  topic: technical
- impact_reason: Provides a concise, modern definition of an AI agent, highlighting
    the crucial role of tools and decision-making capabilities beyond just the base
    LLM.
  relevance_score: 9
  source: llm_enhanced
  text: an agent is just an LLM that has tools that can make decisions to use tools.
  topic: technical
- impact_reason: Identifies the current frontier of AI agent development—systems capable
    of self-correction and iterative planning.
  relevance_score: 9
  source: llm_enhanced
  text: These kind of multi-pass systems make up most like complex types of agents.
    And these are the ones that everybody is trying to head towards.
  topic: predictions
- impact_reason: 'Defines the core function of advanced agent systems: context engineering—curating
    input for the LLM.'
  relevance_score: 9
  source: llm_enhanced
  text: Basically, the agents are trying to build the right context to present to
    the LLM. So it's a lot of it is, I think a lot of people are talking about these
    these days called context engineering.
  topic: technical
- impact_reason: Illustrates the practical shift from feeding raw data to feeding
    structured planning instructions/metadata to the LLM.
  relevance_score: 9
  source: llm_enhanced
  text: you learn to kind of put the context into LLM windows by only providing, how
    do you define it? Like something like the metadata or the way to plan and things
    like that. So you ask the LLM, hey, what are the steps to do something like this,
    rather than saying, giving it all the data and saying, these are all the documents
    I have. Can you go dig into it and find me the right answer, things like that?
  topic: technical
- impact_reason: 'Highlights the strategic advantage of agents: achieving generality
    by abstracting underlying infrastructure and API differences.'
  relevance_score: 9
  source: llm_enhanced
  text: The beauty of these agent systems, right? You kind of bake in this generality
    in which you abstract away the details of what API am I talking to? What kind
    of data am I looking at? You abstract that away so that your implementation is
    generally enough to kind of—it's just a matter of building those connections with
    the agent.
  topic: strategy
- impact_reason: 'Articulates the scalability advantage of agents over human experts:
    once built, an agent''s knowledge base can be instantly replicated and applied
    across diverse tools.'
  relevance_score: 9
  source: llm_enhanced
  text: As a human, you might be good at doing, solving one type of those problems
    or one set of tools or whatever, right? Your learning curve is much higher compared
    to like this agentic system, which if you build it once, you kind of—it has the
    capability to kind of spread across multiple tools and multiple integrations and
    so on. So that's the advantage of having this, doing, making an agent do this
    like in my case.
  topic: predictions
- impact_reason: The most succinct definition of context engineering provided, emphasizing
    intentionality over volume.
  relevance_score: 9
  source: llm_enhanced
  text: context engineering is like just being more deliberate about what information
    you give to the LLM rather than just stuffing everything.
  topic: technical
- impact_reason: Summarizes the practical reasons (latency, cost, noise) why context
    engineering and RAG remain necessary, reinforcing the 'garbage in, garbage out'
    principle.
  relevance_score: 9
  source: llm_enhanced
  text: It is latency, it is cost, it is also—I mean, think about it as garbage in,
    garbage out. If you're going to start putting a lot of noise, and then your model
    also has on
  topic: technical
- impact_reason: This clearly defines the shift from simple prompt stuffing to a more
    strategic approach to input data for LLMs, which is crucial for performance.
  relevance_score: 9
  source: llm_enhanced
  text: But context engineering is like just being more deliberate about what information
    you give to the LLM rather than just stuffing everything.
  topic: technical
- impact_reason: Highlights a current limitation of large context windows—noise reduction
    is still necessary for reliable performance, reinforcing the need for engineering.
  relevance_score: 9
  source: llm_enhanced
  text: Right now, we still need to reduce the amount of noise that we put into an
    LLM context, and that's what context engineering is like then.
  topic: technical
- impact_reason: 'Identifies the core practical limitations of large context windows:
    retrieval quality and latency/cost.'
  relevance_score: 9
  source: llm_enhanced
  text: But then how good are they at using all the information you give it, and how
    fast? Like, probably you don't want to wait for too long for the LLM to process,
    to go through like your super huge prompt with everything.
  topic: technical
- impact_reason: 'Offers actionable advice: smaller, optimized context windows lead
    to more reliable results by shifting work from runtime inference to pre-processing.'
  relevance_score: 9
  source: llm_enhanced
  text: If you wanted to work reliably every time, you would want to reduce that to
    smaller and smaller context window so that you don't burden your LLM with runtime
    processing everything rather than doing some pre-processing beforehand.
  topic: strategy
- impact_reason: Details the advanced engineering required beyond simple chunking—enriching
    chunks with metadata and historical context to improve retrieval quality.
  relevance_score: 9
  source: llm_enhanced
  text: Now, how do we do better in terms of embedding the whole context into that
    chunk, right? Of what has happened so far? Like which document is this from? What
    is the question this is trying to answer? What have we learned so far?
  topic: technical
- impact_reason: Advocates for treating RAG/Search as a modular tool within a larger
    system, rather than a mandatory, fixed pipeline.
  relevance_score: 9
  source: llm_enhanced
  text: I view RAG or search IR as a tool in itself. So now make that a tool, and
    then you can orchestrate that. So use it when needed, right?
  topic: strategy
- impact_reason: Expands the definition of 'tool' beyond simple vector search to include
    structured database queries (SQL, NoSQL), emphasizing tool diversity for agents.
  relevance_score: 9
  source: llm_enhanced
  text: There's a lot of different ways in which you can actually query these kinds
    of information. So you can do it via a search query, you can do it via saying,
    'It's in a table, get me stuff from the table. It's in MongoDB or something, get
    me all the documents that have this value,' or something like that. So these are
    all just tools...
  topic: technical
- impact_reason: 'Establishes clear boundaries for when classical RAG is most effective:
    large data, simple Q&A tasks (needle-in-a-haystack retrieval).'
  relevance_score: 9
  source: llm_enhanced
  text: RAG can do well when you have a large search space and the task is simple.
    Things like question answering based on a piece of content or something like that.
  topic: strategy
- impact_reason: Provides a concise, high-level definition of 'dynamic planning' in
    the context of AI agents.
  relevance_score: 9
  source: llm_enhanced
  text: Dynamic planning is whenever an input comes, you want your LLM or agent to
    be able to plan the trajectory it takes based on the input.
  topic: technical
- impact_reason: Illustrates dynamic planning through a relatable, multi-step task
    (scheduling) that requires inferring user context (time zone, manager identity,
    working hours).
  relevance_score: 9
  source: llm_enhanced
  text: So like a very simple, easy-to-understand example would be like a calendar
    thing, right? So you have a calendar assistant or something, and you're talking
    to it and say, 'I want to schedule a meeting for half an hour tomorrow with my
    manager or my skip-level or something like that.' So, in this, as you see, there's
    a lot of these hidden understandings or context that I'm assuming that you know
    about me...
  topic: predictions
- impact_reason: 'Highlights a major enterprise application of AI: integrating search
    and assistance across multiple SaaS tools, a key productivity trend.'
  relevance_score: 9
  source: llm_enhanced
  text: you're building this product called Dropbox Dash, which is like AI-powered
    search and assistant and so on.
  topic: business
- impact_reason: 'Poses the central architectural debate for current AI developers:
    framework dependency vs. building custom solutions for agents.'
  relevance_score: 9
  source: llm_enhanced
  text: in your opinion, do we need to learn any frameworks, and if yes, what kind
    of frameworks should we learn to make our life easier, or should we just implement
    everything from scratch?
  topic: technical
- impact_reason: Offers a concise, fundamental definition of an AI agent, demystifying
    the concept for practitioners.
  relevance_score: 9
  source: llm_enhanced
  text: You know what an agent is at the end of the day? It's a bunch of tools and
    a bunch of instructions, right?
  topic: technical
- impact_reason: Reinforces the difficulty of debugging complex, multi-layered frameworks
    like LangChain, contrasting it with lighter wrappers like the OpenAI SDK.
  relevance_score: 9
  source: llm_enhanced
  text: with LangChain, oftentimes I have no idea what's happening, and it's very
    hard to debug. So it's a complex mess of things, right?
  topic: technical
- impact_reason: Describes the concept of agent composition and hierarchy, a key architectural
    pattern for scaling agent systems.
  relevance_score: 9
  source: llm_enhanced
  text: realizing that one agent can be just a tool of another agent, right?
  topic: technical
- impact_reason: Emphasizes that the future lies in agent composition (chaining agents)
    rather than just tool integration (like early ChatGPT plugins).
  relevance_score: 9
  source: llm_enhanced
  text: I think doing it in a more agentic way where you can actually then compose
    from one agent to another and so on and so forth. I think that would be a nice
    place to be.
  topic: predictions
- impact_reason: Points directly to the problem of data contamination in public benchmarks,
    invalidating their use for true performance assessment.
  relevance_score: 9
  source: llm_enhanced
  text: It's very likely that the model already has seen that dataset and so on.
  topic: safety
- impact_reason: Establishes the speaker's deep, long-standing expertise in core AI/ML
    fields, setting the stage for authoritative insights.
  relevance_score: 8
  source: llm_enhanced
  text: My career is basically machine learning and NLP from the start.
  topic: strategy
- impact_reason: Illustrates the rapid evolution of ML, where foundational knowledge
    often had to be acquired on the job as the technology (like deep learning) matured.
  relevance_score: 8
  source: llm_enhanced
  text: I worked on that feature and some auxiliary things around trying to improve
    the quality of it. And that's where I think I delved a lot more into neural networks,
    trying to understand how these things work. Because when I started my career,
    neural networks weren't a thing yet. So I learned a lot on my job.
  topic: technical
- impact_reason: Pinpoints the timing (late 2022) when serious, dedicated work on
    LLM-based agents began internally, just before the public explosion of interest.
  relevance_score: 8
  source: llm_enhanced
  text: And then later that led to me and my manager, an amazing mentor and amazing
    engineer himself, and we both kind of started a new team which focuses on agents.
    And this was back then we didn't really have the term agents as popular yet. So
    we had a 2022 December.
  topic: technical
- impact_reason: Acknowledges the current ambiguity in the AI community regarding
    the precise definition and scope of 'AI Agents.'
  relevance_score: 8
  source: llm_enhanced
  text: Agent is not easy to define, because it's not a very well-understood concept.
  topic: technical
- impact_reason: Suggests the need for a formal taxonomy in the agent space, differentiating
    agents based on complexity (single-step vs. multi-step execution).
  relevance_score: 8
  source: llm_enhanced
  text: We had come up with this classification system earlier for kind of classifying,
    like a taxonomy of sorts, where an agent can complete a given task in, let's say,
    one single step, or it can take multiple steps.
  topic: technical
- impact_reason: Establishes a fundamental taxonomy for agent complexity based on
    step count (single vs. multi-step), which is key for understanding agent design.
  relevance_score: 8
  source: llm_enhanced
  text: an agent can complete a given task in, let's say, one single step, or it can
    take multiple steps. By what I mean by step is like maybe calling a tool or something,
    or processing information or something like that.
  topic: technical
- impact_reason: Distinguishes between dynamic, emergent planning and static, pre-defined
    orchestration in agent design.
  relevance_score: 8
  source: llm_enhanced
  text: The plan can be something that is super dynamic that gets built as we go,
    or it could be something that you already have a pre-determined path of, like
    in your agent example that you gave earlier, you had a fixed task. So, and it
    had a fixed set of tools, and you know how to orchestrate, you know, step A comes
    before step B, and so on and so forth.
  topic: technical
- impact_reason: Provides historical context on why deliberate context management
    (context engineering) became necessary, even before massive context windows became
    common.
  relevance_score: 8
  source: llm_enhanced
  text: We had to bake in from the time I've been working on agents because back then
    we had models that had 4k context window. You don't have the luxury of stuffing
    everything into the context. So you have to be very deliberate about what information
    it is that you're kind of sending to the LLM.
  topic: technical
- impact_reason: Frames RAG not as a standalone architecture, but as a specific, simple
    application of the broader concept of context engineering.
  relevance_score: 8
  source: llm_enhanced
  text: Well, would you agree that RAG is one of the simplest examples of context
    engineering?
  topic: technical
- impact_reason: 'Summarizes the goal of context engineering: guiding the LLM to produce
    meaningful output by structuring the input context deliberately.'
  relevance_score: 8
  source: llm_enhanced
  text: So all those things are examples of you influencing the LLM by engineering
    the context so that you can get something that is meaningful rather than just,
    okay, these are all the logs, go look at it, right?
  topic: technical
- impact_reason: 'Raises a critical strategic question for practitioners: the build
    vs. buy decision regarding LLM orchestration frameworks.'
  relevance_score: 8
  source: llm_enhanced
  text: I mentioned LangChain and OpenAI Agents SDK. So in your opinion, do we need
    to learn any frameworks, and if yes, what kind of frameworks should we learn to
    make our life easier, or should we just implement everything from scratch?
  topic: business
- impact_reason: Identifies a specific, high-value enterprise pain point (information
    discovery in shared data) that AI assistants are perfectly positioned to solve.
  relevance_score: 8
  source: llm_enhanced
  text: when multiple people use the same folders on Dropbox, whatever, yeah, that's
    because the content there becomes much more blown up, and discovering other people's
    documents and stuff becomes much more challenging. So it's a more perfect use
    case there.
  topic: business
- impact_reason: Offers specific historical critique of early LangChain agent implementations
    regarding ambiguity handling, suggesting limitations in early agent design patterns.
  relevance_score: 8
  source: llm_enhanced
  text: LangChain has its uses, but I haven't really connected very much with using
    LangChain agents as such. Even they were like pretty early on in terms of agent
    invention. Like we were building these code agents at the time, and they had their
    own ReAct framework type of building agents, and I was a little underwhelmed by
    the way it couldn't handle ambiguity because you're doing interactions in natural
    language.
  topic: technical
- impact_reason: Provides a nuanced view on protocols like MCP (likely referring to
    a specific industry standard), noting that standardization of communication (tools)
    is only the first step; the logic layer (agent) is the hard part.
  relevance_score: 8
  source: llm_enhanced
  text: MCP solves the problem of having one protocol where you can talk, but that's
    about it. After that, it's a lot of heavy lifting.
  topic: strategy
- impact_reason: Highlights the early, hands-on, and often unstructured nature of
    learning ML before the current boom, contrasting with today's structured learning
    paths.
  relevance_score: 7
  source: llm_enhanced
  text: We didn't really have any courses on AI or any structured way of learning,
    but then my friends and I were curious. So we just started building something
    like an image search engine. This was back when we were using a standard search
    engine and then OpenCV for extracting features from images and so on.
  topic: technical
- impact_reason: Actionable startup advice emphasizing extreme responsiveness to user
    feedback as a key driver for early-stage success.
  relevance_score: 7
  source: llm_enhanced
  text: everybody is like harping on anything that is like, if a user says something
    is not working, everybody goes and, 'Okay, it should have done this, it didn't
    do it, and how do we fix it?' And that's the kind of mentality that's going to
    propel the startup forward.
  topic: business
- impact_reason: Provides a concrete, real-world example of an enterprise AI product
    focusing on cross-SaaS productivity and assistance.
  relevance_score: 7
  source: llm_enhanced
  text: Dropbox Dash, which is like AI-powered search and assistant and so on. So
    it helps with a lot of these use cases of productivity and connecting to all the
    SaaS that you use at your work and so on and so forth.
  topic: business
- impact_reason: 'Clarifies the specific utility of protocols like MCP: abstracting
    proprietary tool definitions (like OpenAPI specs) for easier integration by external
    agents.'
  relevance_score: 7
  source: llm_enhanced
  text: MCP is more of like you have your own custom tools, let's say, and you don't
    want to provide the Swagger of that or your OpenAPI spec or something like that...
    So that is useful in the sense that you can just give me an MCP server rather
    than telling me what are the tools and integrating with all the tools that you
    have.
  topic: technical
- impact_reason: 'Identifies a major business/security hurdle to the agentic marketplace
    vision: corporate reluctance to expose internal systems or proprietary logic.'
  relevance_score: 7
  source: llm_enhanced
  text: in a lot of places, people are like, 'No, I want to shield my technology,'
    and things like that.
  topic: business
source: Unknown Source
summary: '## Podcast Summary: Building Reliable AI Products in the Era of Gen AI and
  Agents - Ranjitha Kulkarni


  This 59-minute podcast episode features Ranjitha Kulkarni, Staff ML Engineer at
  Neubert.ai (previously at Dropbox Dash), discussing her extensive career in ML/NLP
  and the current challenges and opportunities in building reliable products powered
  by Generative AI and autonomous agents.


  ---


  ### 1. Focus Area

  The discussion centers on the evolution of Machine Learning, specifically focusing
  on the **architecture, implementation, and reliability challenges of building LLM-powered
  Agents**. Key areas covered include the definition of agents, planning mechanisms
  (code vs. natural language), context management, and the application of agents to
  complex operational tasks like engineering on-call support.


  ### 2. Key Technical Insights

  *   **Agent Taxonomy and Complexity:** Agents can be classified by their structure:
  single-step vs. multi-step execution, and single-pass vs. multi-pass (involving
  self-reflection and feedback loops). The most complex and valuable agents are multi-pass
  systems that can dynamically correct their plans.

  *   **Planning Modalities:** Agents can plan either in **plain English (natural
  language)** or **programmatically (code agents)**. Code agents are favored for highly
  complex, multi-step tasks due to their reduced ambiguity and increased predictability
  compared to relying solely on natural language reasoning.

  *   **Context Engineering vs. Prompt Engineering:** Context engineering is presented
  as a deliberate evolution of prompt engineering. It focuses less on stylistic prompt
  changes and more on **selectively curating the minimal, necessary information**
  to feed the LLM, even with large context windows, to avoid noise and improve accuracy.


  ### 3. Business/Investment Angle

  *   **Agent Application in Operations:** The current focus at Neubert.ai is applying
  agents to automate complex, high-pain tasks like **engineering on-call support**,
  aiming to remove engineers from disruptive incident response so they can focus on
  development.

  *   **Reliability as the Core Challenge:** For startups building agentic products,
  ensuring that performance remains consistent ("if customers are happy today, they''re
  still happy tomorrow") is paramount, driving the need for robust planning and context
  management.

  *   **RAG is Not Dead:** Despite models boasting massive context windows, Retrieval-Augmented
  Generation (RAG) techniques remain essential for efficiently managing and injecting
  relevant knowledge into the LLM context, proving that context engineering is still
  vital.


  ### 4. Notable Companies/People

  *   **Ranjitha Kulkarni:** Guest, Staff ML Engineer at **Neubert.ai**, with prior
  experience at **Dropbox Dash** (building Q&A systems and early agents) and foundational
  work at **Microsoft** (speech recognition, Bing voice search) and research at **CMU**.

  *   **Neubert.ai:** Current company focused on building agents to automate engineering
  on-call responsibilities.

  *   **Dropbox:** Mentioned for early work on recommendation systems and building
  one of the first internal Q&A systems using models like fine-tuned T5 before the
  GPT-3.5 disruption.


  ### 5. Future Implications

  The industry is moving toward highly sophisticated, multi-pass agentic systems capable
  of mimicking complex human workflows (like SRE incident response) by integrating
  multiple tools and data sources. The success of these systems hinges on mastering
  **context engineering** to maintain reliability and efficiency, rather than simply
  relying on larger context windows.


  ### 6. Target Audience

  This episode is highly valuable for **ML Engineers, AI Architects, Product Managers**
  working on integrating LLMs into production systems, and **Technology Leaders**
  evaluating the strategic shift toward autonomous agent development.'
tags:
- artificial-intelligence
- startup
- generative-ai
- investment
- microsoft
- google
- openai
title: Building reliable AI products in the era of Gen AI and Agents - Ranjitha Kulkarni
topics:
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 98
  prominence: 1.0
  topic: artificial intelligence
- keywords:
  - startup
  - entrepreneur
  - founder
  - venture
  mentions: 8
  prominence: 0.8
  topic: startup
- keywords:
  - generative ai
  - genai
  - chatgpt
  - gpt
  - claude
  - text generation
  - image generation
  mentions: 5
  prominence: 0.5
  topic: generative ai
- keywords:
  - investment
  - funding
  - valuation
  - ipo
  - acquisition
  mentions: 3
  prominence: 0.3
  topic: investment
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-10-10 20:07:42 UTC -->
