---
companies:
- category: unknown
  confidence: medium
  context: This is episode number 901 with Lilith Botlia, Senior Director of AI Labs
    at Epic. Today's epis
  name: Lilith Botlia
  position: 32
- category: unknown
  confidence: medium
  context: This is episode number 901 with Lilith Botlia, Senior Director of AI Labs
    at Epic. Today's episode is brought to
  name: Senior Director
  position: 47
- category: unknown
  confidence: medium
  context: number 901 with Lilith Botlia, Senior Director of AI Labs at Epic. Today's
    episode is brought to you by the
  name: AI Labs
  position: 66
- category: unknown
  confidence: medium
  context: at Epic. Today's episode is brought to you by the Dell AI Factory with
    Nvidia and by AdVarity, the conversational a
  name: Dell AI Factory
  position: 124
- category: tech
  confidence: high
  context: ode is brought to you by the Dell AI Factory with Nvidia and by AdVarity,
    the conversational analytics pla
  name: Nvidia
  position: 145
- category: unknown
  confidence: medium
  context: conversational analytics platform. Welcome to the Super Data Science podcast,
    the most listened to podcast in the data
  name: Super Data Science
  position: 223
- category: unknown
  confidence: medium
  context: sforming our world for the better. I'm your host, John Cron. Thanks for
    joining me today. And now, let's make
  name: John Cron
  position: 508
- category: unknown
  confidence: medium
  context: a-centric machine learning research working group ML Commons and has organized
    data-centric workshops at ICML
  name: ML Commons
  position: 1177
- category: unknown
  confidence: medium
  context: m today? Thank you so much for having me. I am in New York City. Likewise,
    exactly, both in Manhattan. Though rec
  name: New York City
  position: 2334
- category: unknown
  confidence: medium
  context: ple who are wondering at home why sometimes we do New York episodes remotely
    with guests. Though I guess als
  name: New York
  position: 2579
- category: unknown
  confidence: medium
  context: mes we do New York episodes remotely with guests. Though I guess also I
    could be traveling, I don't know, ju
  name: Though I
  position: 2619
- category: unknown
  confidence: medium
  context: ngs remote. And yes, so we actually met after the Open Data Science Conference
    East in Boston a year ago. Was it a year ago or two ye
  name: Open Data Science Conference East
  position: 2766
- category: unknown
  confidence: medium
  context: . Canada does actually have some nice trains too. And I was sitting, you
    know, trying to mind my own busi
  name: And I
  position: 3390
- category: unknown
  confidence: medium
  context: ier this year, Epic launched something called the Epic AI Discovery Assistant,
    which claims to automate more than 80% of tradit
  name: Epic AI Discovery Assistant
  position: 4754
- category: unknown
  confidence: medium
  context: s a little bit. It's better than traditional TAR. So I would say that the
    software that we offer does su
  name: So I
  position: 5357
- category: unknown
  confidence: medium
  context: understanding of the territory. So tell us about Epic AI's discovery or
    Epic's AI discovery assistant. Tel
  name: Epic AI
  position: 7944
- category: unknown
  confidence: medium
  context: l the metrics and intuitive explanations of them. But I would say at this
    point, it's still ideal to have
  name: But I
  position: 12560
- category: unknown
  confidence: medium
  context: AI adoption from the desktop to the data center. The Dell AI Factory with
    Nvidia provides a simple development launch
  name: The Dell AI Factory
  position: 13243
- category: unknown
  confidence: medium
  context: like a magic trick with an eye. It's like elude, E L U D E, illusion, E
    L U S I O N. So it's like kind of li
  name: E L U D E
  position: 16930
- category: unknown
  confidence: medium
  context: ith an eye. It's like elude, E L U D E, illusion, E L U S I O N. So it's
    like kind of like this idea of deception
  name: E L U S I O N
  position: 16951
- category: unknown
  confidence: medium
  context: ot necessarily been looked at by human attorneys. Whereas TAR 2.0 heuristically
    describes a workflow where you'
  name: Whereas TAR
  position: 19006
- category: unknown
  confidence: medium
  context: ata. So that led me to be very interested in what Andrew Ng coined data-centric
    AI. And I ended up getting in
  name: Andrew Ng
  position: 24590
- category: unknown
  confidence: medium
  context: hings going on. We're working in partnership with Common Crawl, the foundation
    that curates the data sets that m
  name: Common Crawl
  position: 25224
- category: unknown
  confidence: medium
  context: t the insights you need right when you need them. With AdVarity's AI-powered
    data conversations, marketers will f
  name: With AdVarity
  position: 26929
- category: unknown
  confidence: medium
  context: now who Andrew Ng is, one of the biggest names in Data Science period.
    If you aren't already familiar with him,
  name: Data Science
  position: 27462
- category: unknown
  confidence: medium
  context: abels or not. There's a really interesting paper, Dory Me, that looked
    at weighting different domains of th
  name: Dory Me
  position: 28470
- category: unknown
  confidence: medium
  context: 'ty members, and so it''s a paper called DMLR: Data-Centric Machine Learning
    Research Past, Present, and Future, I''ll have a link to that pa'
  name: Centric Machine Learning Research Past
  position: 30092
- category: unknown
  confidence: medium
  context: . And I think you were a co-author on this paper. Am I right? Yes, you
    are. You are, in fact, you're the
  name: Am I
  position: 30251
- category: unknown
  confidence: medium
  context: s. And then we had a red teaming challenge called Adversarial Nibbler,
    where what do you have the reference? Is it Futu
  name: Adversarial Nibbler
  position: 34526
- category: tech
  confidence: high
  context: be found there. Regular listeners know Claude by Anthropic has been my
    go-to AI for years. Claude is the AI
  name: Anthropic
  position: 38251
- category: unknown
  confidence: medium
  context: to intuitively know exactly what I'm looking for. When I'm doing research
    for a podcast episode, for examp
  name: When I
  position: 38710
- category: unknown
  confidence: medium
  context: roblems? Sign up for Claude today and get 50% off Claude Pro when you use
    my link, Claude.ai/superdata. That's
  name: Claude Pro
  position: 39235
- category: unknown
  confidence: medium
  context: do it. And I'll never forget his reply. He wrote, Dear Lilith, anything
    is possible. But of course, I would hav
  name: Dear Lilith
  position: 41547
- category: unknown
  confidence: medium
  context: So I did. I crammed. I crammed for a year. I used MIT OpenCourseWare and
    Khan Academy and everything out there to just
  name: MIT OpenCourseWare
  position: 41854
- category: unknown
  confidence: medium
  context: crammed for a year. I used MIT OpenCourseWare and Khan Academy and everything
    out there to just learn calculus o
  name: Khan Academy
  position: 41877
- category: unknown
  confidence: medium
  context: ical significance came up in our research of you. So Serge Masees, our
    researcher, pulled up some quotes from you a
  name: So Serge Masees
  position: 45228
- category: ai_application
  confidence: high
  context: Legal tech firm where Lilith Botlia is the Senior Director of AI Labs.
    They developed the Epic AI Discovery Assistant, which uses ML for e-discovery.
  name: Epic
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: Mentioned as part of the sponsor, 'Dell AI Factory with Nvidia,' indicating
    their role in providing AI infrastructure/hardware.
  name: Nvidia
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: Mentioned as part of the sponsor, 'Dell AI Factory with Nvidia,' indicating
    their role in providing AI infrastructure solutions.
  name: Dell
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: Lilith Botlia is the co-chair of the data-centric machine learning research
    working group for this organization.
  name: ML Commons
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: One of the most important AI conferences where data-centric workshops have
    been organized.
  name: ICML
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: One of the most important AI conferences where data-centric workshops have
    been organized.
  name: ICLEAR
  source: llm_enhanced
- category: research_institution
  confidence: medium
  context: The university where Lilith Botlia obtained her degree, focusing on statistics
    (relevant to her ML background).
  name: Northwestern
  source: llm_enhanced
- category: ai_community
  confidence: high
  context: The conference where the host and guest met a year prior.
  name: Open Data Science Conference East
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: A working group/initiative under ML Commons focused on benchmarking data-centric
    machine learning.
  name: DataPerf
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: Major academic conference where DMLR workshops have been organized.
  name: ICLR
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: Major academic conference where DataPerf became a paper and which now hosts
    a datasets and benchmarks track relevant to DMLR.
  name: NeurIPS
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: Foundation that curates the data sets that most LLMs have been trained
    on, partnering with the DMLR working group.
  name: Common Crawl
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: Coined the term 'data-centric AI' and was the keynote at the inaugural
    DMLR workshop; involved with DataPerf.
  name: Andrew Ng
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: The newest sibling journal to JMLR, established as a prestigious venue
    for data-centric machine learning research.
  name: DMLR journal
  source: llm_enhanced
- category: ai_research
  confidence: medium
  context: The established journal to which the DMLR journal is a sibling, indicating
    prestige in the ML community.
  name: JMLR journal
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: A specific product mentioned that utilizes RAG and outperforms traditional
    TAR workflows.
  name: Epic AI Discovery Assistant
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: 'Community members who wrote the paper ''DMLR: Data-Centric Machine Learning
    Research Past, Present, and Future''. Focuses on data-centric ML research.'
  name: DMLR community
  source: llm_enhanced
- category: ai_infrastructure
  confidence: medium
  context: The website associated with the DataPerf benchmarks.
  name: dataperf.org
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: The platform used to host data-centric challenges like DataPerf, maintained
    by ML Commons and the DMLR working group.
  name: Dynabench.org
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: The company that developed the AI model Claude, mentioned as the speaker's
    go-to AI.
  name: Anthropic
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: The AI model developed by Anthropic, used by the speaker for research and
    collaboration.
  name: Claude
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: The promotional link for signing up for Claude Pro.
  name: Claude.ai/superdata
  source: llm_enhanced
- category: ai_research
  confidence: medium
  context: A resource the speaker used for self-education in calculus and linear algebra.
  name: MIT OpenCourseWare
  source: llm_enhanced
- category: ai_research
  confidence: medium
  context: A resource the speaker used for self-education in calculus and linear algebra.
  name: Khan Academy
  source: llm_enhanced
- category: ai_research
  confidence: medium
  context: A researcher mentioned who pulled up quotes from the speaker regarding
    statistical significance thresholds.
  name: Serge Masees
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: Historical figures in statistics whose ideas (like the 0.05 alpha threshold)
    are being critiqued in the context of modern large datasets.
  name: Fisher and Pearson
  source: llm_enhanced
date: 2025-07-01 11:00:00 +0000
duration: 66
has_transcript: false
insights:
- actionable: true
  confidence: medium
  extracted: stop obsessing over model improvements and focus on something else that
    takes up 80% of data scientists' time, and she talks about how she grew from being
    a temp receptionist to eventually an AI lab director by falling in love with statistics
  text: we should stop obsessing over model improvements and focus on something else
    that takes up 80% of data scientists' time, and she talks about how she grew from
    being a temp receptionist to eventually an AI lab director by falling in love
    with statistics.
  type: recommendation
- actionable: true
  confidence: medium
  extracted: be able to accept that those labels are the gold standard
  text: We should be able to accept that those labels are the gold standard.
  type: recommendation
- actionable: false
  confidence: medium
  extracted: the illusion rate, and it's a very legitimate problem,
  text: The problem with the illusion rate, and it's a very legitimate problem, is
    that people will take an illusion sample and just decide that, hey, yeah, it's
    low, that's good without thinking about the starting prevalence, right? So if
    you started with, so right, people will say, oh, if the illusion is under 5%,
    then it's good.
  type: problem_identification
layout: episode
llm_enhanced: true
original_url: https://www.podtrac.com/pts/redirect.mp3/chrt.fm/track/E581B9/arttrk.com/p/VI4CS/pscrb.fm/rss/p/traffic.megaphone.fm/SUPERDATASCIENCEPTYLTD2265605976.mp3?updated=1752060886
processing_date: 2025-10-05 05:28:59 +0000
quotes:
- length: 187
  relevance_score: 5
  text: She's co-chair of the data-centric machine learning research working group
    ML Commons and has organized data-centric workshops at ICML and ICLEAR, two of
    the most important AI conferences
  topics: []
- length: 143
  relevance_score: 4
  text: She's published work on evaluation methods for the use of ML in legal discovery,
    as well as published research on data-centric machine learning
  topics:
  - valuation
- length: 148
  relevance_score: 4
  text: What's very cool about Epic AI Discovery Assistant is that it uses more traditional
    methods for long-text classification, but it also leverages LLMs
  topics: []
- length: 273
  relevance_score: 4
  text: So you get a head start on the documents that you start training on by using
    retrieval augmented generation to find the documents most likely to be relevant
    to whatever it is that you care about, whatever issue the attorneys might have
    specified, and kickstart things there
  topics: []
- length: 144
  relevance_score: 4
  text: There's a really interesting paper, Dory Me, that looked at weighting different
    domains of the pile to get the best LLM pre-training performance
  topics: []
- length: 201
  relevance_score: 4
  text: Then we had a data debugging challenge where participants were encouraged
    to find the mislabeled data points, the mislabeled instances in a data set and
    correct the labels or exclude them from training
  topics: []
- length: 176
  relevance_score: 4
  text: And not only that, but you could end up having, I totally see the idea of
    how benchmarks and competition have led us to having such a model-centric approach
    to machine learning
  topics:
  - competition
- length: 133
  relevance_score: 3
  text: Exceptions where some, you know, asbestos case where you have to go back to
    the paper documents and scan them in and then review them
  topics: []
- length: 164
  relevance_score: 3
  text: This episode of Super Data Science is brought to you by the Dell AI Factory
    with Nvidia, helping you fast-track your AI adoption from the desktop to the data
    center
  topics: []
- length: 171
  relevance_score: 3
  text: And you have to, as a data scientist, you do have to be able to explain what
    that really means and what the consequences of it might mean to attorneys and
    sometimes judges
  topics: []
- length: 195
  relevance_score: 3
  text: And so those acronyms that you were saying earlier where this DMLR initiative
    was getting traction, conferences like ICLR, ICML, NeurIPS, these are the biggest
    academic conferences that there are
  topics: []
- length: 101
  relevance_score: 3
  text: Probably most of our listeners know who Andrew Ng is, one of the biggest names
    in Data Science period
  topics: []
- impact_reason: 'Highlights a modern hybrid approach: combining traditional classifiers
    with LLMs via RAG to bootstrap the training process, showing a practical application
    of advanced NLP techniques.'
  relevance_score: 10
  source: llm_enhanced
  text: What's very cool about Epic AI Discovery Assistant is that it uses more traditional
    methods for long-text classification, but it also leverages LLMs. So you get a
    head start on the documents that you start training on by using retrieval augmented
    generation to find the documents most likely to be relevant to whatever it is
    that you care about...
  topic: technical/breakthroughs
- impact_reason: A unique insight into how standard ML metrics are treated in regulated/adversarial
    environments—they become negotiable parameters, not fixed truths.
  relevance_score: 10
  source: llm_enhanced
  text: So one of the fun things about working in the legal industry is that these
    standard evaluation metrics, recall and precision generally, get negotiated, sometimes
    negotiated with opposing counsel or some governmental body.
  topic: safety/strategy
- impact_reason: Introduces a novel, domain-specific evaluation metric ('Illusion'
    / False Omission Rate estimation) unique to e-discovery workflows.
  relevance_score: 10
  source: llm_enhanced
  text: We call it illusion, where we're just sampling the subset of documents predicted
    not relevant, and we have the human ground truth labels for all the relevant documents.
    So from those two metrics, we can then estimate an interval for recall.
  topic: technical
- impact_reason: A powerful philosophical argument against overly strict ML evaluation
    standards when the human-labeled 'ground truth' is itself imperfect.
  relevance_score: 10
  source: llm_enhanced
  text: If we're just going to assume that that is the gold standard, that all of
    those labels are, in fact, correct, which we kind of know they probably aren't,
    then why should we hold machine learning workflows to a higher standard, right?
  topic: safety/strategy
- impact_reason: Strong statement advocating for statistical rigor, emphasizing uncertainty
    quantification over single-value predictions.
  relevance_score: 10
  source: llm_enhanced
  text: I'm obsessive about focusing on confidence and not point estimate.
  topic: technical
- impact_reason: A philosophical defense of uncertainty quantification, highly relevant
    for building robust and trustworthy AI systems.
  relevance_score: 10
  source: llm_enhanced
  text: The short answer is that the coolest thing about statistics is that you get
    to measure your uncertainty. So why wouldn't you do that? Why wouldn't you measure
    your uncertainty?
  topic: technical/safety
- impact_reason: A powerful, provocative statement summarizing the ethical responsibility
    of reporting statistical results accurately.
  relevance_score: 10
  source: llm_enhanced
  text: I've said before that a point estimate without sample size, without confidence
    intervals, is basically lying with statistics.
  topic: safety/strategy
- impact_reason: Directly pivots the discussion to Data-Centric AI (DCAI), signaling
    its universal importance across all data science applications, not just legal
    tech.
  relevance_score: 10
  source: llm_enhanced
  text: The actual impetus for having an episode... was this idea of data-centric
    machine learning. And so this is now a topic that is relevant to every listener.
    Anybody who's working with data, this is relevant.
  topic: technical/strategy
- impact_reason: 'Classic real-world justification for shifting focus from model-centric
    to data-centric AI: poor data quality limits algorithmic gains.'
  relevance_score: 10
  source: llm_enhanced
  text: At a certain point, I realized that the label data I was working with was
    so noisy, just had so many mislabeled instances and all of that, that it really
    curtailed my ability to evaluate the performance of the algorithm just because
    I couldn't necessarily trust my data.
  topic: technical/strategy
- impact_reason: This is the clearest, most concise definition provided for the core
    philosophical difference between model-centric and data-centric ML. Essential
    for understanding the paradigm shift.
  relevance_score: 10
  source: llm_enhanced
  text: in traditional machine learning paradigms, you're iterating on the model.
    You're iterating on the model architecture, on the learning algorithm, all of
    those sorts of pieces, and that's where you're really focused on improving performance
    is by iterating on the model. With data-centric machine learning, you're iterating
    on the data. So you're holding the model fixed and you're improving the data,
    you're systematically engineering better data.
  topic: technical/strategy
- impact_reason: Introduces 'Data Valuation' as a critical research area, which has
    significant future implications for data ownership, compensation, and resource
    allocation.
  relevance_score: 10
  source: llm_enhanced
  text: Then we also did a data valuation challenge. So how do you value each piece
    of data, right? Not all data are equal when you're training a model. Some have
    much more impact than others, right?
  topic: technical/safety/business
- impact_reason: Details a practical, adversarial safety challenge ('Adversarial Nibbler')
    focused on finding prompt injection/jailbreaking vectors that bypass safety filters
    in multimodal models.
  relevance_score: 10
  source: llm_enhanced
  text: we had a red teaming challenge called Adversarial Nibbler, where... the main
    objective of that challenge was to find benign sounding prompts that generated
    unsafe images.
  topic: safety/AI technology trends
- impact_reason: Critically links the success of benchmarks (like ImageNet) to the
    current dominance of model-centric AI development, setting up the contrast with
    data-centric AI.
  relevance_score: 10
  source: llm_enhanced
  text: I totally see the idea of how benchmarks and competition have led us to having
    such a model-centric approach to machine learning.
  topic: technical/strategy
- impact_reason: A crucial cautionary note about the limitations of benchmark-driven
    development, emphasizing the gap between leaderboard scores and practical utility.
  relevance_score: 10
  source: llm_enhanced
  text: there is a critique that the intent focus on benchmark performance doesn't
    necessarily translate to real-world impact in the way that we would expect. So
    there's definitely a balance to be found there.
  topic: safety/strategy
- impact_reason: 'Provides a blueprint for effective technical curriculum design:
    building up from calculus/linear algebra before tackling statistics to ensure
    fundamental understanding over rote application.'
  relevance_score: 10
  source: llm_enhanced
  text: It's covering a lot of those subjects, linear algebra, calculus, probability
    theory, and statistics. And we go in that order so that hopefully by the time
    we get to the statistics part, you're able to understand based on the fundamental
    building blocks underlying it what's going on as opposed to just being able to
    get an A by following the examples, not by rote, that's not exactly it, but by
    being able to apply the abstractions as opposed to understand the underlying fundamentals.
  topic: technical/strategy
- impact_reason: Argues that statistical literacy is non-negotiable for responsible
    ML development, especially when dealing with complex, opaque models.
  relevance_score: 10
  source: llm_enhanced
  text: I don't think you're able to properly evaluate the performance of the models
    that you're building. So you might be able to build the model without statistics,
    but I think especially in this era of black box models, it's so important to be
    able to actually evaluate the performance.
  topic: safety/technical
- impact_reason: 'Provides concrete, statistically sound advice for model comparison:
    move beyond single-run results to analyzing distributions and testing for significance.'
  relevance_score: 10
  source: llm_enhanced
  text: like you should be running that model a bunch of times in both the A case
    and the B case, get a distribution of results, and be comparing those. And then
    if you have a statistically significant result.
  topic: technical
- impact_reason: Provides a clear, concise explanation of the arbitrary nature of
    the $p<0.05$ threshold, highlighting its historical context and inherent flaw
    when applied rigidly today.
  relevance_score: 10
  source: llm_enhanced
  text: if you ran the experiments 20 times, you would anticipate with a 0.05 alpha
    that one of those 20 times, you would get a significant result by chance alone.
    And this is like a century-old idea, and from the age of Fisher and Pearson and
    statistics, and the idea there is that you'll kind of accept that you'll end up
    getting a significant result by chance alone one or 20 times, and that's kind
    of tolerable, but it is completely arbitrary.
  topic: technical/safety
- impact_reason: This is a major quantitative claim about AI's transformative impact
    on a specific, document-heavy industry (legal tech), setting a high benchmark
    for efficiency gains.
  relevance_score: 9
  source: llm_enhanced
  text: Epic AI Discovery Assistant, which claims to automate more than 80% of traditional
    e-discovery processes and completes reviews up to 90% faster than something called
    TAR, technology assisted review, or linear review.
  topic: predictions/business
- impact_reason: Connects the core ML concept (classification) with the necessary
    operational strategy (active learning) based on data distribution (prevalence).
  relevance_score: 9
  source: llm_enhanced
  text: Traditional TAR technology, basically it's a classifier with active learning,
    and depending on the prevalence of documents that you actually care about in your
    overall population, you'll use one of two different active learning workflows.
  topic: technical
- impact_reason: Provides actionable advice on choosing an active learning strategy
    (relevance feedback) based on data characteristics (low prevalence).
  relevance_score: 9
  source: llm_enhanced
  text: If you have really low prevalence, you're probably better off using relevance
    feedback. So you're going to have human annotators label the documents that are
    already most likely to be considered relevant by the model.
  topic: technical
- impact_reason: Details the alternative active learning strategy (uncertainty sampling)
    tied to model uncertainty (entropy), a core ML concept.
  relevance_score: 9
  source: llm_enhanced
  text: If you have more balanced classes... then you're going to want to use uncertainty
    sampling where you're looking at the entropy of each data point and having human
    annotators label the documents that the model is most unsure about in order to
    improve performance.
  topic: technical
- impact_reason: Indicates a shift towards multi-modal input for model training in
    specialized domains, combining structured labels with unstructured natural language
    prompts.
  relevance_score: 9
  source: llm_enhanced
  text: And then both your human language instructions and your labeled examples are
    going to go into training the best classifier possible. So it takes input from
    whole example data and from natural language instruction.
  topic: technical/trends
- impact_reason: 'Crucial insight into the adoption landscape: specialized AI tools
    must abstract away the need for in-house data science expertise for widespread
    enterprise adoption in non-tech industries.'
  relevance_score: 9
  source: llm_enhanced
  text: Very few law firms have data scientists who are involved in the discovery
    component of the practice. So, yeah, so they do rely on these tools.
  topic: business/adoption
- impact_reason: 'A necessary caution: even with abstracted tools, domain expertise
    and understanding of evaluation metrics are non-negotiable for defensible AI usage,
    especially in regulated fields.'
  relevance_score: 9
  source: llm_enhanced
  text: With that said, it does require some expertise, some domain expertise, and
    some familiarity with basic evaluation metrics in order to make sure that you're
    using the tool in a defensible manner.
  topic: safety/ethics/business
- impact_reason: 'Defines ''defensibility'' in a practical, non-technical sense: it''s
    about user (attorney) comfort and legal acceptance, not just mathematical purity.'
  relevance_score: 9
  source: llm_enhanced
  text: Defensibility boils down to what that particular attorney is comfortable defending.
  topic: safety/strategy
- impact_reason: A critical warning about misinterpreting evaluation metrics without
    considering prior probabilities (prevalence), a common pitfall in applied ML.
  relevance_score: 9
  source: llm_enhanced
  text: The problem with the illusion rate... is that people will take an illusion
    sample and just decide that, hey, yeah, it's low, that's good without thinking
    about the starting prevalence, right?
  topic: technical/safety
- impact_reason: Clearly defines the industry-standard (though confusing) workflow
    terms TAR 1.0 and TAR 2.0, which are crucial for understanding legal AI deployment
    strategies.
  relevance_score: 9
  source: llm_enhanced
  text: TAR 1 being a workflow where you produce documents that have only been classified
    by your classifier and not necessarily been looked at by human attorneys. Whereas
    TAR 2.0 heuristically describes a workflow where you're looking at every predicted
    relevant document before it goes out the door.
  topic: technical/strategy
- impact_reason: Highlights concrete, high-impact work being done in the DCAI community
    (via ML Commons/DataPerf) to improve data availability, specifically for low-resource
    scenarios relevant to LLMs.
  relevance_score: 9
  source: llm_enhanced
  text: We're working in partnership with Common Crawl, the foundation that curates
    the data sets that most LLMs have been trained on. We're partnering with them
    on a challenge that will result in a low-resource language data set that will
    be publicly available.
  topic: technical/predictions
- impact_reason: This is the foundational anecdote explaining *why* the speaker pivoted
    to data-centric AI—noisy, untrustworthy labels directly limit algorithm performance
    evaluation, a core problem in applied ML.
  relevance_score: 9
  source: llm_enhanced
  text: I was really focused on algorithms and on finding the best classification
    algorithms for these classification tasks that we've discussed. At a certain point,
    I realized that the label data I was working with was so noisy, just had so many
    mislabeled instances and all of that, that it really curtailed my ability to evaluate
    the performance of the algorithm just because I couldn't necessarily trust my
    data.
  topic: technical/strategy
- impact_reason: Directly links the practical problem (noisy data) to the established
    academic/industry movement (Data-Centric AI) championed by a major figure (Andrew
    Ng).
  relevance_score: 9
  source: llm_enhanced
  text: So that led me to be very interested in what Andrew Ng coined data-centric
    AI.
  topic: strategy
- impact_reason: Describes a cutting-edge, non-iterative approach to data selection
    using foundational math (linear algebra) before any model training, suggesting
    high efficiency gains.
  relevance_score: 9
  source: llm_enhanced
  text: they looked at selecting the best data points for training a model, a priori.
    So not even active learning... but just with a data set from scratch using linear
    algebra to figure out which data points are worth labeling.
  topic: technical
- impact_reason: 'Captures the cultural and incentive problem within the ML community:
    data work is undervalued despite being 80% of the effort.'
  relevance_score: 9
  source: llm_enhanced
  text: everyone wants to do the model work, not the data work.
  topic: business/strategy
- impact_reason: Reiterates the widely accepted 80/20 rule in practice, highlighting
    the psychological barrier (lack of 'fun') preventing focus on the most critical
    work.
  relevance_score: 9
  source: llm_enhanced
  text: it is true. I think right, 80% of most data science projects are way more
    about data cleaning and data engineering and all of that, but we really focus
    on that 20% that's iterating on the models. But we don't look at that as a fun,
    exciting part.
  topic: business/strategy
- impact_reason: Defines 'Data Debugging' as a key DMLR challenge, directly addressing
    the initial problem of noisy labels in supervised learning.
  relevance_score: 9
  source: llm_enhanced
  text: Then we had a data debugging challenge where participants were encouraged
    to find the mislabeled data points, the mislabeled instances in a data set and
    correct the labels or exclude them from training.
  topic: technical
- impact_reason: Connects the technical concept of data valuation directly to the
    emerging societal and legal issue of compensating data contributors for LLM training.
  relevance_score: 9
  source: llm_enhanced
  text: And that might become increasingly important as we try to figure out how to
    compensate people for all the data that we're using to train all these models.
  topic: safety/business
- impact_reason: Provides a concrete, illustrative example of a successful adversarial
    prompt designed to elicit unsafe content, demonstrating the subtlety of prompt
    engineering attacks.
  relevance_score: 9
  source: llm_enhanced
  text: for example, a child sleeping in red paint sounds benign, but generates an
    image that looks perfect.
  topic: safety
- impact_reason: Suggests that creating data-centric benchmarks can effectively shift
    the community focus away from purely model optimization.
  relevance_score: 9
  source: llm_enhanced
  text: things like DataPerf where you have benchmarks where you have competitions
    and people can be trying to get the best results, how that can drive more and
    more data-centric ML adoption.
  topic: technical
- impact_reason: A powerful articulation of the difference between rote calculation/application
    and true conceptual understanding in quantitative fields like statistics and ML.
  relevance_score: 9
  source: llm_enhanced
  text: I didn't feel like I understood how or why I got an A because I didn't understand,
    I mean, I could calculate the correct answers. I didn't have this intuitive understanding
    for why they were the correct answers.
  topic: technical/strategy
- impact_reason: Signals a critical perspective on the rigid, often arbitrary application
    of traditional statistical thresholds (like $\alpha=0.05$) in modern data science.
  relevance_score: 9
  source: llm_enhanced
  text: Serge Masees, our researcher, pulled up some quotes from you around how awful
    it is, these kinds of ideas of a 95% confidence interval having that as law.
  topic: safety/technical
- impact_reason: Provides a clear, concise definition of Technology Assisted Review
    (TAR), a key application of ML in the legal domain, making a complex concept accessible.
  relevance_score: 8
  source: llm_enhanced
  text: I would say that the software that we offer does support TAR workflows. And
    to actually describe what that is, it stands for technology assisted review. And
    it basically describes a process whereby you use machine learning to classify
    documents as relevant to a litigation or not relevant to a litigation.
  topic: technical
- impact_reason: A simple, high-level definition of active learning, crucial for practitioners
    looking to optimize data labeling efforts.
  relevance_score: 8
  source: llm_enhanced
  text: Active learning is just a way to select data in a more efficient way for training
    your classifier.
  topic: technical
- impact_reason: Demonstrates the complexity of real-world deployment, requiring multiple,
    specialized classifiers (relevance, privilege, confidentiality) rather than a
    single binary model.
  relevance_score: 8
  source: llm_enhanced
  text: You'll always have what's called a responsiveness model, basically a relevance
    model, is it relevant to any of the issues in the case? But then you might also
    have classifiers for things like privilege, whether the document is protected
    by attorney-client privilege and therefore it's not mandatory to disclose it,
    and then confidentiality potentially...
  topic: business/strategy
- impact_reason: Quantifies the massive financial stakes in legal tech AI, emphasizing
    why accuracy, defensibility, and rigorous evaluation are paramount.
  relevance_score: 8
  source: llm_enhanced
  text: When the stakes are so high, as big law firms, when you're talking about hundreds
    of thousands or millions of documents, obviously these are going to end up being
    very expensive cases. You're talking, at least millions of dollars, and probably
    very often in these kinds of litigation situations, tens, hundreds of millions
    of dollars, billions of dollars on the line one way or another for the defendant
    or the plaintiff.
  topic: business/strategy
- impact_reason: Connects the domain-specific term 'Illusion' back to the standard
    ML term 'False Omission Rate,' providing clarity for the broader ML community.
  relevance_score: 8
  source: llm_enhanced
  text: False negatives divided by false negatives and true negatives can be called
    false omission rate in machine learning in general, but I guess that's kind of
    a bit of a mouthful. Illusion sounds nicer.
  topic: technical
- impact_reason: Provides a practical method for communicating complex statistical
    concepts (like confidence intervals) to non-technical stakeholders (lawyers/judges).
  relevance_score: 8
  source: llm_enhanced
  text: If it's an attorney or judge, I try to just demonstrate. I have a quick calculator
    in Excel, I'll show them how varying certain things affects those estimates and
    try to give them an intuitive understanding of it.
  topic: business/strategy
- impact_reason: Links the speaker's practical experience directly to the high-profile
    concept of Data-Centric AI championed by Andrew Ng.
  relevance_score: 8
  source: llm_enhanced
  text: That led me to be very interested in what Andrew Ng coined data-centric AI.
  topic: technical
- impact_reason: Shows the evolution and institutionalization of the Data-Centric
    AI movement, moving from an idea to a formal working group under a recognized
    body (ML Commons).
  relevance_score: 8
  source: llm_enhanced
  text: DataPerf morphed into the data-centric machine learning research working group
    with ML Commons.
  topic: business/strategy
- impact_reason: Provides a clear definition of 'low-resource language' in the context
    of LLMs, pointing to a significant gap in current model training data representation.
  relevance_score: 8
  source: llm_enhanced
  text: low-resource language, this is languages for which there are not many data
    available online, there could be rarely spoken languages or for whatever reason,
    languages that even if they're spoken relatively commonly, they aren't represented
    on the internet.
  topic: AI technology trends/safety
- impact_reason: Points to specific, advanced research (domain weighting) being used
    to optimize LLM training data, moving beyond simple volume to quality/composition.
  relevance_score: 8
  source: llm_enhanced
  text: there's a really interesting paper, Dory Me, that looked at weighting different
    domains of the pile to get the best LLM pre-training performance.
  topic: technical/AI technology trends
- impact_reason: 'Identifies the key strategic lever for shifting community focus:
    creating high-status publication venues (like the DMLR journal) for data-centric
    research.'
  relevance_score: 8
  source: llm_enhanced
  text: finding or establishing these high-impact prestigious venues for publishing
    this kind of work, I think that goes a long way encouraging more of the data-centric
    work.
  topic: business/strategy
- impact_reason: Calls for a proactive, engineering mindset shift toward data improvement,
    emphasizing that it must evolve past simple, manual annotation.
  relevance_score: 8
  source: llm_enhanced
  text: I think we do need to just engineer mindsets. How can we systematically improve
    data? How can it be a task that goes beyond just annotating, finding better ways
    to annotate the data?
  topic: strategy
- impact_reason: Identifies 'Data Selection' as a primary benchmarkable task within
    DataPerf, crucial for efficiency when dealing with massive datasets.
  relevance_score: 8
  source: llm_enhanced
  text: One was data selection. So from a very large pool of data, how do you select
    the subset of data to train the highest performing model?
  topic: technical/business
- impact_reason: Indicates a strategic effort to legitimize and elevate domain-specific,
    applied ML research within top-tier academic venues, countering historical biases.
  relevance_score: 8
  source: llm_enhanced
  text: one of the future workshops we're considering is an applications research
    focus DMLR workshop because oftentimes at these academic conferences, applications
    research gets looked down on a little bit.
  topic: strategy
- impact_reason: Highlights the value of sharing practical, domain-specific AI/ML
    applications, countering the tendency to focus only on general breakthroughs.
  relevance_score: 8
  source: llm_enhanced
  text: There is probably a lot of value to people sharing domain-specific solutions
    because it might inspire people to find some new domain-specific solution for
    their domain.
  topic: strategy
- impact_reason: Demonstrates the power of self-directed, resource-leveraged learning
    (OCW, Khan Academy) to bridge foundational gaps necessary for advanced study.
  relevance_score: 8
  source: llm_enhanced
  text: So I crammed. I crammed for a year. I used MIT OpenCourseWare and Khan Academy
    and everything out there to just learn calculus on my own, a little bit of linear
    algebra. And then I came back to him and I said, okay, well, I didn't get as far
    as I wanted to, but I think I still want to take your course.
  topic: strategy
- impact_reason: Links deep engagement with foundational mathematics (via problem-solving
    in a rigorous course) directly to achieving true statistical intuition.
  relevance_score: 8
  source: llm_enhanced
  text: That's how I learned how to code and math problems. And I crammed and I got
    an A on the final. And then I finally felt like I understood statistics.
  topic: technical
- impact_reason: Illustrates the massive scale and complexity of unstructured data
    handling in legal discovery, highlighting the necessity for AI solutions.
  relevance_score: 7
  source: llm_enhanced
  text: Discovery for people outside of the legal industry is that basically any time
    two companies sue each other, they have to exchange anything and everything that
    might be considered evidence in the case. So what this ends up looking like is
    piles and piles, maybe hundreds of thousands, even millions of documents, emails,
    Word docs, Excel sheets, tweets, text messages, anything and everything, tons
    of unstructured data that might be relevant to the litigation.
  topic: business/strategy
- impact_reason: Highlights the product development focus on embedding expertise and
    interpretability directly into the tool interface to lower the barrier to entry.
  relevance_score: 7
  source: llm_enhanced
  text: We are trying to build in as much of that as possible, build in the expertise,
    build in all the metrics and intuitive explanations of them.
  topic: business/product
- impact_reason: Quantifies the complexity of deploying AI in specialized legal contexts,
    showing that 'one model' solutions are often insufficient.
  relevance_score: 7
  source: llm_enhanced
  text: And that can include building dozens of models for one single case.
  topic: technical/strategy
- impact_reason: A nuanced technical observation about the diminishing returns of
    increasing confidence levels once sample size is very large, relating to the Law
    of Large Numbers.
  relevance_score: 7
  source: llm_enhanced
  text: When your sample is large enough, the intervals for 95% confidence level versus
    99% confidence level tend to converge, right? So once your sample is sufficiently
    large, it doesn't really matter whether you're estimating something at 95 or 99%
    confidence.
  topic: technical
- impact_reason: 'Provides a potential psychological explanation for why data work
    isn''t shared or published: practitioners perceive their data issues as non-generalizable,
    hindering community knowledge building.'
  relevance_score: 7
  source: llm_enhanced
  text: people might feel when they're doing that work that the problems that they're
    encountering are unique to their particular data set. They don't maybe ideas don't
    come to mind for them that generalize well across many domains...
  topic: strategy
- impact_reason: Identifies the specific platform (Dynabench) used by the community
    to operationalize and run these data-centric and adversarial challenges.
  relevance_score: 7
  source: llm_enhanced
  text: dynabench.org is the platform where we host all of these challenges. And that's
    Dynabench, that's like dynamic bench.
  topic: technical/strategy
- impact_reason: Highlights the key academic papers establishing the field's benchmarks
    and roadmap, essential reading for researchers.
  relevance_score: 7
  source: llm_enhanced
  text: Another so I already mentioned the DMLR past, present, and future paper. We'll
    also have a link in the show notes to your DataPerf paper, which is on benchmarks
    for data-centric AI development.
  topic: technical/strategy
- impact_reason: 'A strong testimonial defining a desired future state for advanced
    AI assistants: true collaboration and workflow understanding, rather than simple
    task execution.'
  relevance_score: 7
  source: llm_enhanced
  text: Claude is the AI for minds that don't stop at good enough. It's the collaborator
    that actually understands your entire workflow and thinks with you, not for you...
  topic: predictions
- impact_reason: Illustrates a non-traditional, bottom-up path into highly technical
    fields like data science, starting from administrative support in a domain (legal
    tech).
  relevance_score: 6
  source: llm_enhanced
  text: I fell into eDiscovery as an admin assistant, basically as a temp receptionist,
    actually. That was how I started my career.
  topic: strategy
source: Unknown Source
summary: '## Podcast Episode Summary: 901: Automating Legal Work with Data-Centric
  ML (feat. Lilith Bat-Leah)


  This episode of the Super Data Science podcast features Lilith Bat-Leah, Senior
  Director of AI Labs at Epic, discussing the transformative role of AI, particularly
  **Data-Centric Machine Learning (DCML)**, in revolutionizing the legal technology
  sector, specifically in **e-discovery**.


  ### 1. Focus Area

  The primary focus is the application of machine learning to **legal tech**, centered
  on automating the **e-discovery process**. Key technical discussions revolve around
  **Technology Assisted Review (TAR)** workflows, active learning strategies (relevance
  feedback vs. uncertainty sampling), the integration of **Large Language Models (LLMs)**
  via **Retrieval Augmented Generation (RAG)**, and the critical importance of **data
  quality** and **uncertainty quantification** in high-stakes legal environments.


  ### 2. Key Technical Insights

  *   **Advanced TAR with LLMs:** Epic''s AI Discovery Assistant moves beyond traditional
  TAR (which relies on standard classifiers like Random Forests or SVMs) by leveraging
  LLMs with RAG to "kickstart" the classification process, using both human-labeled
  examples and natural language instructions for training case-specific classifiers
  (e.g., relevance, privilege).

  *   **The Metric of "Illusion":** The legal tech domain uses a unique metric called
  **Illusion** (False Negatives / (False Negatives + True Negatives)), which is analogous
  to the False Omission Rate in general ML. This metric is crucial for estimating
  the interval for recall, especially in TAR 2.0 workflows where all predicted relevant
  documents are human-reviewed.

  *   **Prioritizing Uncertainty over Point Estimates:** Lilith strongly advocates
  for reporting model performance using **confidence intervals** rather than single
  point estimates (like precision or recall). She argues that a point estimate without
  sample size or confidence intervals is effectively "lying with statistics," as it
  fails to measure the inherent uncertainty in the estimation process.


  ### 3. Business/Investment Angle

  *   **Massive Automation Potential:** AI tools like Epic''s assistant claim to automate
  over **80% of traditional e-discovery processes** and speed up reviews by up to
  90% compared to linear review, representing significant cost savings in high-stakes
  litigation (often involving millions or billions of dollars).

  *   **Expertise Gap in Law Firms:** Most large law firms lack in-house data scientists
  for discovery tasks, making them heavily reliant on specialized legal tech vendors
  like Epic for both tools and the necessary domain expertise to ensure defensibility.

  *   **Defensibility as a Negotiated Metric:** Unlike other industries, the required
  performance metrics (precision/recall) in e-discovery are often **negotiated** with
  opposing counsel or regulatory bodies, emphasizing the need for data scientists
  to clearly articulate the consequences of margin of error to legal professionals.


  ### 4. Notable Companies/People

  *   **Lilith Bat-Leah:** Senior Director of AI Labs at **Epic** (a legal tech firm
  with over 6,000 employees). Co-chair of the **Data-Centric Machine Learning Research
  (DCMLR) working group at ML Commons**.

  *   **Andrew Ng:** Credited with coining the term **Data-Centric AI**, which spurred
  Lilith''s interest in focusing on data quality over algorithm optimization.

  *   **Epic AI Discovery Assistant:** The specific product discussed, designed to
  accelerate document review using advanced ML techniques.

  *   **ML Commons (DataPerf):** The organization where Lilith is involved in benchmarking
  and advancing DCMLR.


  ### 5. Future Implications

  The industry is moving toward a model where AI tools are sophisticated enough to
  handle the bulk of document review, requiring legal professionals to focus on interpreting
  results and defending methodologies rather than manual processing. The conversation
  highlights a broader industry shift toward **Data-Centric AI**, where improving
  the quality and consistency of training data (especially in noisy domains like legal)
  yields greater performance gains than marginal algorithmic tweaks. There is a growing
  need for data scientists to become better communicators of statistical uncertainty
  to non-technical stakeholders.


  ### 6. Target Audience

  This episode is most valuable for **hands-on practitioners** including **Data Scientists,
  AI/ML Engineers, and Software Developers**, particularly those interested in applying
  ML to specialized, high-stakes domains, or those involved in **Data-Centric AI**
  research and implementation.'
tags:
- artificial-intelligence
- generative-ai
- ai-infrastructure
- investment
- nvidia
- anthropic
title: '901: Automating Legal Work with Data-Centric ML (feat. Lilith Bat-Leah)'
topics:
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 159
  prominence: 1.0
  topic: artificial intelligence
- keywords:
  - generative ai
  - genai
  - chatgpt
  - gpt
  - claude
  - text generation
  - image generation
  mentions: 11
  prominence: 1.0
  topic: generative ai
- keywords:
  - gpu
  - tensor
  - training
  - inference
  - model deployment
  - vector database
  mentions: 8
  prominence: 0.8
  topic: ai infrastructure
- keywords:
  - investment
  - funding
  - valuation
  - ipo
  - acquisition
  mentions: 8
  prominence: 0.8
  topic: investment
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-10-05 05:28:59 UTC -->
