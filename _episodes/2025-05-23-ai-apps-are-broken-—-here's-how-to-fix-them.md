---
companies:
- category: unknown
  confidence: medium
  context: o whatever they want using only natural language. Steve Jobs describes
    software as a sort of a bicycle for the
  name: Steve Jobs
  position: 297
- category: unknown
  confidence: medium
  context: ship for the mind. Welcome to another episode of The Breakdown. Today we're
    lucky to have Pete Cumin, our partne
  name: The Breakdown
  position: 438
- category: unknown
  confidence: medium
  context: isode of The Breakdown. Today we're lucky to have Pete Cumin, our partner
    here at YC. Pete was the founder of
  name: Pete Cumin
  position: 479
- category: unknown
  confidence: medium
  context: test. Pete, welcome. Thank you. Happy to be here. So Pete, you recently
    wrote an essay, which caused a bit
  name: So Pete
  position: 644
- category: unknown
  confidence: medium
  context: mpletely wrong. So tell us more about that. Sure. When I use AI in my day-to-day
    life, I've kind of had tw
  name: When I
  position: 848
- category: unknown
  confidence: medium
  context: ft that I got when I put that prompt into the UI. Dear Gary, I'm writing
    to inform you that my daughter woke
  name: Dear Gary
  position: 2683
- category: unknown
  confidence: medium
  context: '''s perhaps we''re skipping all the way to the end. But I think that''s
    exactly right. These AI models are n'
  name: But I
  position: 4041
- category: unknown
  confidence: medium
  context: way to the end. But I think that's exactly right. These AI models are now
    capable of doing things like that,
  name: These AI
  position: 4075
- category: tech
  confidence: high
  context: did this happen? I know many people who work for Google, they're incredibly
    smart. Why did they ship a fe
  name: Google
  position: 4656
- category: unknown
  confidence: medium
  context: . And so I'll explain what I mean by that. Right? And I'll go back to these
    two problems. Let's start wit
  name: And I
  position: 5045
- category: tech
  confidence: high
  context: arrass Google. I remember it was either Google or Facebook released a scientific
    model pretty early on and t
  name: Facebook
  position: 7218
- category: tech
  confidence: high
  context: ransform technology and we're like leaped from by OpenAI just because there
    was too cautious to put stuff
  name: Openai
  position: 7479
- category: unknown
  confidence: medium
  context: best to keep emails as short as possible, right? What I've done here is
    I just take the little program in
  name: What I
  position: 8899
- category: unknown
  confidence: medium
  context: e-fits-all Gmail system prompt, the draft we get. Hi Gary, my daughter's
    sick with the flu, so I can't come
  name: Hi Gary
  position: 9271
- category: unknown
  confidence: medium
  context: aren't technical. They don't know how to do that. Which I think is true.
    This isn't a skill we're born with
  name: Which I
  position: 15560
- category: unknown
  confidence: medium
  context: his, by the way? I've vibe coded the whole thing. So I wrote, you know,
    this, I mean, ironically enough,
  name: So I
  position: 16663
- category: unknown
  confidence: medium
  context: its Windsurf moment. Why is Cursor, Windsurf, or Claude Codes so far ahead
    of, you know, lawyer agents or accou
  name: Claude Codes
  position: 17779
- category: unknown
  confidence: medium
  context: '? For code, that''s actually really useful, right? If I can describe in
    English what I''m looking for, an'
  name: If I
  position: 18397
- category: unknown
  confidence: medium
  context: t directly with the model and use the full power. Whereas I think a lot
    of other domains we're still using th
  name: Whereas I
  position: 19116
- category: unknown
  confidence: medium
  context: t to you to take. You say, no, this wasn't right. Or I would have rewritten
    it like this. And it will tr
  name: Or I
  position: 24012
- category: unknown
  confidence: medium
  context: So we've been talking a lot about the prompting. And Tom is kind of saying
    like, there's going to be a bun
  name: And Tom
  position: 27037
- category: investment_vc
  confidence: high
  context: Venture Capital firm where Pete Cumin is a partner; they use AI internally
    for automation.
  name: YC
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: Company founded by Pete Cumin that built software for A/B testing (pre-AI
    focus, but mentioned as a prior venture).
  name: Optimizely
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: AI tool mentioned for building software with AI, suggesting it's an AI
    coding assistant.
  name: Cursor
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: AI tool mentioned alongside Cursor for building software with AI.
  name: Windsurf
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: The development team at Google responsible for integrating AI features
    into Gmail.
  name: Gmail team
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: The underlying AI model used in the Gmail integration, developed by Google.
  name: Gemini
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: The parent company of Gmail and the developer of the Gemini model; mentioned
    regarding caution in releasing scientific models.
  name: Google
  source: llm_enhanced
- category: ai_company
  confidence: high
  context: Mentioned as a competitor that moved faster than Google in releasing transformative
    technology.
  name: OpenAI
  source: llm_enhanced
- category: big_tech
  confidence: medium
  context: Mentioned alongside Google as a company that released and quickly pulled
    back an early scientific model due to hallucinations.
  name: Facebook
  source: llm_enhanced
- category: big_tech
  confidence: medium
  context: Mentioned in the context of system prompts potentially containing instructions
    to avoid saying anything bad about the CEO of Google.
  name: Sundar or Pichai
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as a tool that is currently ahead in the coding agent space,
    similar to Cursor and Windsurf.
  name: Claude Codes
  source: llm_enhanced
- category: organization
  confidence: high
  context: The organization where the speakers work/have built internal tools for
    finance/legal teams using iterative prompt engineering, demonstrating practical
    application of AI agents.
  name: YC (Y Combinator)
  source: llm_enhanced
date: 2025-05-23 13:53:08 +0000
duration: 30
has_transcript: false
insights:
- actionable: false
  confidence: medium
  extracted: that
  text: the problem with that is that Gmail is an application designed for humans
    to do work in, right? The real promise of AI, I think for many of us, is using
    AI to automate repetitive busy work, right? And a lot of the time I spend on email
    is repetitive busy work, right? It's work that doesn't really need my full brain
    power, but because we haven't had the technology, it requires it, right? And so
    I give a little example in my essay of just using these simple techniques, what
    you could do with an email inbox.
  type: problem_identification
layout: episode
llm_enhanced: true
original_url: https://anchor.fm/s/8c1524bc/podcast/play/103099988/https%3A%2F%2Fd3ctxlq1ktw2nl.cloudfront.net%2Fstaging%2F2025-4-23%2F400866900-44100-2-4d50ee7932d79.mp3
processing_date: 2025-10-05 15:12:14 +0000
quotes:
- length: 100
  relevance_score: 4
  text: Some of the foundation model labs have started building memory into their
    into their chatbots, right
  topics: []
- length: 135
  relevance_score: 3
  text: Part of the problem is that we're using old software development mentality,
    old software development techniques to build these features
  topics: []
- length: 110
  relevance_score: 3
  text: And so for example, here's what happens when I apply this little agent to
    each one of the emails in this inbox
  topics: []
- impact_reason: A critical distinction between the capability of the foundational
    model (LLM) and the poor execution of the application layer (UI/UX).
  relevance_score: 10
  source: llm_enhanced
  text: The underlying Gemini model is pretty phenomenal, right? Gemini is amazing.
    The model itself is absolutely incredible. We've been using it a lot at YC to
    automate our own work. I'm so impressed with what they built. But a lot of that
    power, I think, is hidden behind a UI that makes it really frustrating to use.
  topic: technical/business
- impact_reason: 'Presents the ideal state of an AI agent: proactive, context-aware,
    multi-step automation based on a single high-level instruction.'
  relevance_score: 10
  source: llm_enhanced
  text: The ideal experience, I think, would be something like telling the AI, hey,
    my daughter's ill, figure out my calendar today. And then it would go through
    your actual calendar and then figure out each person and then write your appropriate
    email in the appropriate tone.
  topic: predictions
- impact_reason: Provides a crucial technical insight into how LLM applications are
    structured (User Prompt + System Prompt) and critiques the proprietary nature
    of the system prompt.
  relevance_score: 10
  source: llm_enhanced
  text: What's actually happening under the hood when I ask this Gmail agent for a
    draft is that this Gmail agent, this little UI, combines my prompt... with what's
    called a system prompt. And the system prompt is the text that explains to the
    AI who it is and what its job is. And this gets reused every single time. And
    in the Gmail case, I don't actually know what that system prompt says. This is,
    it's been hidden from the user. I'm not allowed to see it, let alone edit it myself.
  topic: technical
- impact_reason: Demonstrates the power of personalized system prompts (or 'persona
    programming') to achieve high-fidelity, context-aware output.
  relevance_score: 10
  source: llm_enhanced
  text: My version might just say you're Pete, right? You're a 43-year-old husband,
    you're a father, you're a YC partner, you're busy. And so is everyone you correspond
    with. And so you do your best to keep emails as short as possible, right? What
    I've done here is I just take the little program in my brain that is used for
    writing emails. And I've done my best to explain to Gemini how I do that.
  topic: technical/business
- impact_reason: Draws a direct parallel between hiding the system prompt and the
    traditional abstraction of source code, arguing for user access to this new layer
    of 'code'.
  relevance_score: 10
  source: llm_enhanced
  text: My contention is that a lot of AI app developers, including the Gmail team
    in this case, are treating the system prompt the same way they've been treating
    code for decades. For, you know, as long as we've had a software industry, there's
    been a division of labor between me, the user, and you, the developer. The user
    does not see the code.
  topic: strategy
- impact_reason: 'The core lesson of the ''horse-drawn carriage'' analogy: true value
    from disruptive technology requires systemic redesign, not just component swapping.'
  relevance_score: 10
  source: llm_enhanced
  text: Basically inventing the motor was only a small part of what was needed to
    produce a vehicle that could take advantage of the motor. It only became useful
    once you redesigned the entire.
  topic: strategy
- impact_reason: Pinpoints the flawed initial question driving many current AI product
    decisions.
  relevance_score: 10
  source: llm_enhanced
  text: The deepest problem here is that when the Gmail team set out to build this,
    they kind of asked, how can we slot AI into the Gmail application? How do we replace
    the horse and put an engine in it?
  topic: strategy
- impact_reason: A key insight into the democratization of programming via LLMs, where
    natural language instructions (system prompts) become the new, accessible form
    of code/configuration.
  relevance_score: 10
  source: llm_enhanced
  text: This is really the code. This is the programming you are doing for this agent.
    But if you read it, it's pretty accessible, right? It says, if it's a tech-related
    email, label it tech. If it's somebody trying to sell me something, archive it.
    And this is like a great example of how the LLM technology is actually good enough
    to let non-programmers program these apps.
  topic: technical
- impact_reason: 'Sets a clear benchmark for the successful, widespread adoption of
    AI agents: achieving the same level of specialized utility seen in developer tools
    across all professional domains.'
  relevance_score: 10
  source: llm_enhanced
  text: And to me, like we will have caught up when everybody has the same experience
    that we have when we're using these coding agents in their particular domain,
    right? And so when accountants can build accounting agents... when lawyers can
    be lawyering agents... it's basically every profession I think will have its Cursor
    moment or its Windsurf moment.
  topic: predictions
- impact_reason: 'Proposes a liability shift: granting users control over the system
    prompt transfers responsibility for misuse from the developer to the end-user,
    enabling more powerful tools.'
  relevance_score: 10
  source: llm_enhanced
  text: Well, I think the interesting point is if you do change the model where the
    user is in charge or at least has access to the system prompt, then the repercussions
    of that are on the user and not on the company that built the tool.
  topic: safety/business
- impact_reason: Argues that the human-readable nature of system prompts fundamentally
    changes the black-box nature of AI interaction, offering a crucial debug/control
    mechanism.
  relevance_score: 10
  source: llm_enhanced
  text: My big contention here is that because this is all just English, we no longer
    have to treat these things like black boxes. The system prompt is almost like
    this, this document that you don't have to edit if you don't want to, but in the
    limit, if there's something really goes wrong, you can go in and tinker with it
    if you want.
  topic: technical/safety
- impact_reason: 'Articulates the next evolution beyond direct prompt editing: using
    natural language ''nudges'' or providing new data examples, which the AI then
    translates into system prompt updates.'
  relevance_score: 10
  source: llm_enhanced
  text: there's a higher level of abstraction on top of system prompt writing that
    you shouldn't actually have to go and edit the system prompt that you're able
    to like nudge or like say, no, no, that, okay, here's a new term sheet.
  topic: technical/trends
- impact_reason: A strong call to action for developers regarding transparency, linking
    inspectability of instructions ('ground truth') directly to user trust and value.
  relevance_score: 10
  source: llm_enhanced
  text: I hope that developers stop treating these prompts like black boxes. Being
    able to look at the ground truth of what this agent is being instructed to do
    on my behalf is incredibly valuable.
  topic: safety/ethics
- impact_reason: This is a core thesis statement, arguing that current AI integration
    is constrained by legacy software paradigms rather than leveraging AI's unique
    capabilities.
  relevance_score: 9
  source: llm_enhanced
  text: We're using old software development techniques to build these features, and
    we're not actually taking full advantage of what AI can do.
  topic: strategy
- impact_reason: 'Defines the ultimate vision for user-AI interaction: natural language
    programming, moving beyond traditional UI/UX.'
  relevance_score: 9
  source: llm_enhanced
  text: I think the promise of AI for many of us is that it allows us to build software
    that the user can program to do whatever they want using only natural language.
  topic: predictions
- impact_reason: 'Identifies the common failure mode of AI adoption: adding friction
    instead of removing it, leading to user frustration.'
  relevance_score: 9
  source: llm_enhanced
  text: A lot of times when I'm using existing apps that I'm used to that have incorporated
    AI into them, where it doesn't feel that way at all. It actually feels like more
    of a chore, right? Like using the AI actually creates more work for me than just
    doing whatever it was myself.
  topic: business
- impact_reason: 'Reiterates the core argument: the engineering mindset is stuck in
    the pre-AI era.'
  relevance_score: 9
  source: llm_enhanced
  text: Part of the problem is that we're using old software development mentality,
    old software development techniques to build these features, and we're not actually
    taking full advantage of what AI can do.
  topic: strategy
- impact_reason: Directly links the generic, safe output to corporate risk aversion
    and the embedding of safety/brand constraints within the system prompt.
  relevance_score: 9
  source: llm_enhanced
  text: You've explicitly told it, use a business-y tone, look smart and serious,
    don't say anything that might make the parent company of this product look bad.
    And that's got to be the overriding concern for a lot of these companies, right?
    We don't want the AI to say anything that's going to embarrass Google.
  topic: safety/ethics
- impact_reason: 'Highlights the efficiency gain: personalization via prompt editing
    saves repeated instruction effort.'
  relevance_score: 9
  source: llm_enhanced
  text: By editing this system prompt, I'm able to explain to the AI model how I write
    emails in general so that I don't have to do it every single time.
  topic: business
- impact_reason: 'Defines the consequence of lowest common denominator design in the
    AI context: functional but inauthentic output.'
  relevance_score: 9
  source: llm_enhanced
  text: And that's, I think the Gmail system prompt in this case, you can think of
    as the lowest common denominator email writer. It's the safe, anyone could use
    this thing, but what it results in is emails that no individual would actually
    write.
  topic: business
- impact_reason: Introduces a key analogy for technological transition, comparing
    current AI integration to early, poorly adapted automobile designs.
  relevance_score: 9
  source: llm_enhanced
  text: You use this phrase, the AI horse-drawn carriage. Tell us what you mean by
    that.
  topic: strategy
- impact_reason: 'Defines the primary value proposition of AI: automating low-cognitive-load,
    repetitive tasks that current software forces humans to handle manually.'
  relevance_score: 9
  source: llm_enhanced
  text: The real promise of AI, I think for many of us, is using AI to automate repetitive
    busy work, right? And a lot of the time I spend on email is repetitive busy work,
    right? It's work that doesn't really need my full brain power, but because we
    haven't had the technology, it requires it.
  topic: business
- impact_reason: 'Provides an excellent, relatable analogy for the current state of
    LLMs: high capability but lacking specific direction or institutional knowledge
    until explicitly taught via prompting.'
  relevance_score: 9
  source: llm_enhanced
  text: The way that I think of these models, a super smart, you know, fresh grad
    right out of college that can do anything pretty well, but has no idea what to
    do. You know, and the missing step is giving me the ability to teach it how to
    do work that I don't want to do...
  topic: technical
- impact_reason: A powerful anecdote demonstrating the extreme productivity gains
    possible with coding agents, suggesting this domain is currently leading the general
    AI application curve.
  relevance_score: 9
  source: llm_enhanced
  text: I rebuilt my entire, my, I was on Tumblr and I migrated my blog to custom
    software I wrote in one hour on a train journey. The coding agents, especially,
    just seem so far ahead of all the other general-purpose agents right now.
  topic: predictions
- impact_reason: 'Explains *why* coding agents are ahead: code generation is essentially
    text-to-text translation based on clear instructions, which aligns perfectly with
    LLM strengths.'
  relevance_score: 9
  source: llm_enhanced
  text: The first is that these AI models are incredibly good at processing text,
    right? So if I can write a good description of a thing I want, they can process
    that description, that prompt, and turn it into a bunch of code, right? This is
    going back to why it was so annoying to write that original email prompt is like,
    these agents aren't good at writing from scratch. They're good at processing instructions
    and doing and turning them into some text output, right? For code, that's actually
    really useful.
  topic: technical
- impact_reason: Critiques the current state of non-developer AI applications for
    being overly constrained ('kid glove mentality'), contrasting this with developer
    tools that offer full, direct model access.
  relevance_score: 9
  source: llm_enhanced
  text: Developer tools are power tools, right? Developer tools by definition allow
    you to get to the bare metal, right? To get under the hood... Whereas I think
    a lot of other domains we're still using this sort of like kid glove mentality
    of like, oh, don't let them use the full power of these models.
  topic: strategy
- impact_reason: 'Summarizes the necessary philosophical shift for unlocking AI''s
    potential: treating it as a user-controlled tool rather than a developer-guaranteed
    service.'
  relevance_score: 9
  source: llm_enhanced
  text: It's a shift in mentality, giving AI to the user as a tool and they can use
    it for whatever their purposes are versus feeling like you as a developer have
    to be responsible for everything these models output and therefore you're nerfed
    and it's not useful.
  topic: strategy
- impact_reason: Predicts the rapid normalization and accessibility of prompt engineering,
    drawing a strong parallel to the mass adoption curve of personal computing.
  relevance_score: 9
  source: llm_enhanced
  text: I think the answer today is no, but I think the answer to that in the near
    future will be yes. Why is that? When I was growing up, computers were still seen
    as a power tool that only nerds really knew how to use... And so what happened
    is we all just sort of figured out how to use these things and the interfaces
    got better, right? It's the tech that tech got better and we learned how to use
    it in time and so it is unremarkable, right? And I think the same thing is going
    to happen with prompting.
  topic: predictions
- impact_reason: 'Identifies the future UX pattern: users will want auto-generated,
    personalized system prompts based on their historical data, rather than writing
    them manually.'
  relevance_score: 9
  source: llm_enhanced
  text: I don't think I'd want to write my own email writing system prompt from scratch.
    I'd like to have that option, right? But I've been using Gmail for 20 years. Right?
    And there are 20 years of my email history that a good product could use to create
    a draft prompt for me, right?
  topic: business
- impact_reason: Describes the practical, iterative workflow for building effective
    AI agents within specific business functions, mirroring pair programming or on-the-job
    training.
  relevance_score: 9
  source: llm_enhanced
  text: You literally go sit next to a finance person and you ask them like, Hey,
    tell me how you do this. This workflow, like, show me what you do. And then you
    write some system prompt for them, they try it. It doesn't do it quite right.
    They edit the system prompt with you. So it's kind of this like back and forth
    iterative model that you're suggesting.
  topic: business
- impact_reason: 'Highlights a critical future UI/tooling gap: an AI meta-agent designed
    specifically to translate user feedback into system prompt revisions.'
  relevance_score: 9
  source: llm_enhanced
  text: I think there's like a missing tool in AI app development, which is like not
    everyone has a Pete next to them, but you could have an AI system prompt writer
    sitting next to you to take. You say, no, this wasn't right. Or I would have rewritten
    it like this. And it will translate that back into a system prompt and kind of
    self-edit auto update.
  topic: technical
- impact_reason: 'A concrete, near-term prediction about the evolution of prompt interaction:
    personalization will be automated, abstracting the prompt away from the average
    user.'
  relevance_score: 9
  source: llm_enhanced
  text: I'd suggest I think in five years for 99% of people, they're not touching
    the system prompt, but the system prompt is custom to them.
  topic: predictions
- impact_reason: Highlights the future capability of AI systems to autonomously refine
    their core instructions (system prompts) based on user feedback or observed errors,
    moving towards self-correction.
  relevance_score: 9
  source: llm_enhanced
  text: And it will translate that back into a system prompt and kind of self-edit
    auto update.
  topic: technical/predictions
- impact_reason: 'Defines the future role of the system prompt: largely auto-managed
    but retaining a ''break glass'' manual override for expert users, balancing automation
    with control.'
  relevance_score: 9
  source: llm_enhanced
  text: The system prompt is almost like this, this document that you don't have to
    edit if you don't want to, but in the limit, if there's something really goes
    wrong, you can go in and tinker with it if you want.
  topic: strategy/predictions
- impact_reason: Emphasizes the need for tooling to manage iterative learning and
    instruction refinement, moving away from monolithic, static prompt documents.
  relevance_score: 9
  source: llm_enhanced
  text: I think we'll probably have tools that make it easier to teach an AI over
    time, rather than going up and editing a 10 or 50-page prompt every single time
    you want to do this.
  topic: business/tooling
- impact_reason: Provides a concise, foundational definition of 'tools' in the context
    of AI agents—the necessary external capabilities required for agents to move beyond
    mere text generation to actionable automation.
  relevance_score: 9
  source: llm_enhanced
  text: The thing that these agents need in order to be able to do anything useful,
    we call tools.
  topic: technical/strategy
- impact_reason: 'Summarizes the ultimate vision of LLM-powered software: user-programmability
    via natural language, shifting the paradigm from traditional coding interfaces.'
  relevance_score: 9
  source: llm_enhanced
  text: The promise of AI for many of us is that it gives us software or it allows
    us to build software that the user can program to do whatever they want using
    only natural language.
  topic: predictions/strategy
- impact_reason: A powerful analogy contrasting traditional software enhancement with
    the exponential power increase offered by AI.
  relevance_score: 8
  source: llm_enhanced
  text: Steve Jobs describes software as a sort of a bicycle for the mind. This feels
    like a rocket ship for the mind.
  topic: strategy
- impact_reason: Highlights the 'superhuman' experience achievable with well-integrated
    AI tools, contrasting it with poor integrations.
  relevance_score: 8
  source: llm_enhanced
  text: When I use tools like Cursor and Windsurf to build software with AI, it feels
    like the most powerful tool I've ever used, right? It's this feeling of being
    able to create anything I want, anything I can picture in my head will materialize
    in front of me with these tools.
  topic: technical/business
- impact_reason: Addresses the critical issue of AI output failing to capture personal
    voice/style, leading to trust erosion and potential security confusion.
  relevance_score: 8
  source: llm_enhanced
  text: The first problem is, like you're pointing out, that doesn't sound anything
    like me. Right? If you got this email, you wouldn't, you would assume somebody
    else wrote this. My account got hacked. I got fished.
  topic: safety/ethics
- impact_reason: 'Quantifies the inefficiency: the input required to get the output
    negates the time savings, highlighting poor prompt abstraction.'
  relevance_score: 8
  source: llm_enhanced
  text: The second problem is that the draft, or rather the prompt that I used to
    explain what I wanted in the draft is roughly as long as the draft itself.
  topic: business
- impact_reason: Summarizes the failure to innovate beyond existing software design
    patterns when integrating AI.
  relevance_score: 8
  source: llm_enhanced
  text: I think there's a deeper issue here, which is that we're designing features
    like this in a way that looks a lot like software that we've been building for
    decades.
  topic: strategy
- impact_reason: Explains the historical necessity of 'lowest common denominator'
    software design, which AI fundamentally challenges.
  relevance_score: 8
  source: llm_enhanced
  text: That's the only way we've been able to build software up until now is one-size-fits-all,
    right? If you're building an online bank software or a piece of A/B testing software,
    your job as a developer is to go and talk to hundreds or thousands of users and
    synthesize all of their needs together into one common set of features that you're
    going to build in your one-size-fits-all pieces of software.
  topic: strategy
- impact_reason: Provides another historical parallel (mobile apps) showing the lag
    between technology availability and true innovation.
  relevance_score: 8
  source: llm_enhanced
  text: When mobile came out, the first mobile apps were basically just websites wrapped
    in a native app wrapper. But they didn't take advantage of any of the new technologies
    available on the mobile phone, like GPS, like multi-touch.
  topic: strategy
- impact_reason: 'Confirms the current state: the industry is still in the ''wrapper''
    or ''carriage'' phase of AI adoption.'
  relevance_score: 8
  source: llm_enhanced
  text: I guess what you're claiming, Pete, is we are like not there yet.
  topic: predictions
- impact_reason: This is a classic observation about technology adoption cycles (like
    the internet or mobile), suggesting AI is currently in an early, less useful phase,
    setting expectations for future maturation.
  relevance_score: 8
  source: llm_enhanced
  text: And it takes a few years typically to get to the useful bit of the new technology.
  topic: strategy
- impact_reason: 'Illustrates the current strength of coding agents: excellent at
    translating high-level descriptions into functional code, but less effective at
    generating novel, complex structures from zero.'
  relevance_score: 8
  source: llm_enhanced
  text: I've vibe coded the whole thing. So I wrote, you know, this, I mean, ironically
    enough, these AI models are not actually that useful to help you write things
    from scratch, right? The part where I used AI was describing a demo that I thought
    would help communicate the point I was trying to make and then watching it appear,
    right? Like it's absolutely magical.
  topic: technical
- impact_reason: 'Identifies a major roadblock to powerful AI deployment: developer
    fear of liability, which leads to overly restrictive product design.'
  relevance_score: 8
  source: llm_enhanced
  text: I hope we're able to move beyond this moment in time where there's so much
    assumed liability on the part of the application developers for what these models
    do.
  topic: safety/business
- impact_reason: Argues that prompt engineering will become mainstream faster than
    previous computing skills because it relies solely on natural language communication.
  relevance_score: 8
  source: llm_enhanced
  text: I think this is actually going to happen a lot faster with prompting because
    writing a prompt is a lot more accessible than operating your file system manager
    on your computer. You don't need to understand much except to be able to explain
    yourself in English or whatever language you have.
  topic: technical
- impact_reason: Uses the human assistant analogy to argue against the need for exhaustive,
    manual system prompt creation, favoring iterative, context-based training.
  relevance_score: 8
  source: llm_enhanced
  text: The idea that let's take a human analogy. You hire a new employee, you hire
    an assistant, the idea that you're going to sit down and write out 30 pages of
    instructions about how you do every single thing in your life is possible, but
    none of us actually do it. You sort of you give this gradual training.
  topic: strategy
- impact_reason: Identifies the current trend of integrating long-term memory into
    chatbots, a crucial step for personalized and continuous interaction, though the
    speaker expresses reservations about current implementations.
  relevance_score: 8
  source: llm_enhanced
  text: Some of the foundation model labs have started building memory into their
    into their chatbots, right? Which is that's one mechanism for taking context that
    I've shared over time and storing it forever, right?
  topic: technical/trends
- impact_reason: Reinforces the modularity and extensibility of agent architecture,
    where utility is directly proportional to the set of available tools (APIs/functions)
    it can access.
  relevance_score: 8
  source: llm_enhanced
  text: You could imagine many other tools that would make this agent more powerful
    and more able
  topic: technical
- impact_reason: Expresses practical user frustration with current memory implementations,
    specifically citing the lack of visibility into what context the model has retained.
  relevance_score: 8
  source: llm_enhanced
  text: I haven't had great experiences with that because again, it's sort of it's
    treated like a black box where I can't actually see what it has internalized and
    what it's stored.
  topic: safety/technical
- impact_reason: 'Sets up a key debate: short-term reliance on prompt writing versus
    the long-term goal of higher-level abstraction layers managing the prompts.'
  relevance_score: 8
  source: llm_enhanced
  text: I agree in the short term, but I think my contention is like, there's a higher
    level of abstraction on top of system prompt writing...
  topic: strategy
- impact_reason: Confirms that prompt iteration and management itself is a significant
    area ripe for immediate innovation and tooling development.
  relevance_score: 8
  source: llm_enhanced
  text: And Tom is kind of saying like, there's going to be a bunch of innovation
    on how we write system prompts or how we edit them or iterate on them.
  topic: business/tooling
- impact_reason: Gives concrete examples of the atomic 'tools' that constitute an
    AI agent's functional capabilities, illustrating the concept of tool use.
  relevance_score: 8
  source: llm_enhanced
  text: If we go back to my little email reading agent here, the tools that this agent
    has access to are a tool for labeling an email, a tool for archiving an email,
    and a tool for writing a draft.
  topic: technical
- impact_reason: Provides a historical parallel (early internet) illustrating the
    'horse-drawn carriage' effect in technology adoption.
  relevance_score: 7
  source: llm_enhanced
  text: When the internet came about, a lot of the first search engines were literally
    just like digitized yellow pages. It was just a directory of listings.
  topic: strategy
- impact_reason: A short-term prediction acknowledging the current reality that prompt
    engineering is becoming a necessary skill for many knowledge workers, even if
    it's abstracted later.
  relevance_score: 7
  source: llm_enhanced
  text: writing prompts is going to be part of the day-to-day flow for a lot of people.
  topic: business/predictions
- impact_reason: Poses a critical strategic question about the future role of software
    developers as prompt engineering becomes automated or abstracted.
  relevance_score: 7
  source: llm_enhanced
  text: If developers aren't the ones who have to write all these system prompts from
    scratch, what are they going to focus on?
  topic: business/strategy
- impact_reason: Defines the 'break glass' scenario for system prompts—the rare, necessary
    intervention when automated customization fails or produces undesirable behavior.
  relevance_score: 7
  source: llm_enhanced
  text: And you know, the kind of break glass cases, you go and edit the file and
    be like, no, no, I really don't want this to happen.
  topic: strategy
- impact_reason: Provides a concrete, relatable example of the friction involved in
    current manual prompt management, highlighting the inefficiency that future tooling
    must solve.
  relevance_score: 7
  source: llm_enhanced
  text: rather than Alex having to look up this like 50-page document and go like,
    I'm going to change that specific line.
  topic: business/tooling
- impact_reason: Highlights the consensus that tooling around AI interaction (beyond
    the model itself) is a crucial, perhaps undervalued, area of focus.
  relevance_score: 7
  source: llm_enhanced
  text: In the essay, you also talk about tooling, which I think is a really important
    and interesting topic as well.
  topic: business/tooling
source: Unknown Source
summary: '## Podcast Episode Summary: AI Apps Are Broken — Here''s How To Fix Them


  This 30-minute episode of "The Breakdown" features Y Combinator Partner Pete Cumin,
  who argues that current AI applications, particularly those integrated into existing
  software like Gmail, are fundamentally flawed because they rely on outdated software
  development paradigms rather than leveraging the full potential of modern LLMs.


  ### 1. Focus Area

  The discussion centers on the **design and implementation of AI-powered applications
  and agents**, contrasting the "superhuman" feeling of using raw LLM tools (like
  coding assistants) with the frustrating, chore-like experience of many existing,
  integrated AI features (e.g., Gmail''s draft writer). The core theme is moving beyond
  the "AI horse-drawn carriage" mentality to build truly transformative AI software.


  ### 2. Key Technical Insights

  *   **The System Prompt as the Core Program:** The hidden, generic **system prompt**
  used by developers (like in Gmail) acts as the "one-size-fits-all" code, enforcing
  a safe, lowest-common-denominator output that fails to capture individual user context
  or tone.

  *   **User-Editable System Prompts Enable Personalization:** Allowing users to see
  and edit the system prompt transforms the AI from a generic tool into a personalized
  agent. By defining their own persona and rules (e.g., "You are Pete, keep emails
  short"), users can achieve outputs that sound authentic and match their mental model.

  *   **Coding Agents Lead the Way:** Tools like Cursor and Windsurf are far ahead
  because they treat the LLM as a powerful text processor capable of translating detailed
  English descriptions (prompts) directly into functional code, a domain where current
  models excel.


  ### 3. Business/Investment Angle

  *   **The "AI Horse-Drawn Carriage" Trap:** Companies integrating AI by simply "slotting
  it in" to existing UIs (like wrapping a website in a mobile app) are missing the
  opportunity for true disruption. Investment should target applications built from
  the ground up around AI''s capabilities.

  *   **Shift in Liability and Control:** When users control the system prompt, the
  liability for the output shifts from the application developer (who must enforce
  safety) to the user, potentially unlocking more powerful, less constrained applications
  across various professional domains (accounting, legal).

  *   **The Next "Cursor Moment":** The industry is waiting for the moment when non-technical
  professionals in every field (accountants, lawyers) have a tool that allows them
  to program their workflows using natural language instructions, mirroring the productivity
  gains seen by developers.


  ### 4. Notable Companies/People

  *   **Pete Cumin (YC Partner, Founder of Optimizely):** The central voice, author
  of the essay criticizing current AI app design.

  *   **Google/Gmail (Gemini Integration):** Used as the primary negative example
  of a powerful model hidden behind a frustrating, overly cautious, and generic UI/system
  prompt.

  *   **Cursor and Windsurf:** Cited as positive examples of tools that give users
  direct, powerful access to the underlying models, leading to a "superhuman" development
  experience.


  ### 5. Future Implications

  The industry is moving toward **user-driven programming** where the system prompt
  becomes the accessible "code" for non-technical users. Future successful AI applications
  will treat the LLM as a malleable agent that users train iteratively, moving away
  from the current model where developers must anticipate every user need upfront.
  This shift requires new UI conventions for training, feedback, and prompt editing.


  ### 6. Target Audience

  This episode is highly valuable for **AI Product Managers, Software Engineers, Founders,
  and Venture Capitalists** focused on the application layer of generative AI. It
  provides a critical framework for evaluating the next generation of AI software
  beyond simple feature additions.'
tags:
- artificial-intelligence
- startup
- generative-ai
- ai-infrastructure
- google
- openai
title: AI Apps Are Broken — Here's How To Fix Them
topics:
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 127
  prominence: 1.0
  topic: artificial intelligence
- keywords:
  - startup
  - entrepreneur
  - founder
  - venture
  mentions: 4
  prominence: 0.4
  topic: startup
- keywords:
  - generative ai
  - genai
  - chatgpt
  - gpt
  - claude
  - text generation
  - image generation
  mentions: 1
  prominence: 0.1
  topic: generative ai
- keywords:
  - gpu
  - tensor
  - training
  - inference
  - model deployment
  - vector database
  mentions: 1
  prominence: 0.1
  topic: ai infrastructure
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-10-05 15:12:14 UTC -->
