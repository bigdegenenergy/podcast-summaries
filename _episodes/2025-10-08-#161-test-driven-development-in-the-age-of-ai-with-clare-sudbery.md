---
companies:
- category: unknown
  confidence: medium
  context: failed. In fact, it was the test that was wrong. So I said, well, actually,
    your tests are wrong. And i
  name: So I
  position: 95
- category: unknown
  confidence: medium
  context: it was wrong about why the tests were wrong. I'm Brian Milner, and this
    is the Agile Mentors podcast. It's a sh
  name: Brian Milner
  position: 429
- category: unknown
  confidence: medium
  context: sts were wrong. I'm Brian Milner, and this is the Agile Mentors podcast.
    It's a show about both the personal and
  name: Agile Mentors
  position: 459
- category: unknown
  confidence: medium
  context: '''m here as always, Brian Milner, but today I have Miss Claire Sudberry
    with me. Welcome in, Claire. Hi, I''m so happy to'
  name: Miss Claire Sudberry
  position: 1230
- category: unknown
  confidence: medium
  context: lots of different strands to how I can answer it. And I think it's probably
    important that I start by say
  name: And I
  position: 6236
- category: unknown
  confidence: medium
  context: ctly what you said. The code that is generated by Gen AI coding tools is
    often not reliable. And it's not
  name: Gen AI
  position: 7094
- category: unknown
  confidence: medium
  context: ticular framework works. And I have spent ages on Stack Overflow and Google
    trying to work out, or trying to work
  name: Stack Overflow
  position: 8736
- category: tech
  confidence: high
  context: orks. And I have spent ages on Stack Overflow and Google trying to work
    out, or trying to work out an anno
  name: Google
  position: 8755
- category: unknown
  confidence: medium
  context: ething for you. We have an AI prompt pack here at Mountain Goat Software
    that's completely free. You can download it. We'l
  name: Mountain Goat Software
  position: 14461
- category: unknown
  confidence: medium
  context: very first thing I did—it was the FizzBuzz kata. The FizzBuzz is a game
    where that's sometimes played in classr
  name: The FizzBuzz
  position: 18555
- category: unknown
  confidence: medium
  context: otally see why people end up falling in love with Gen AIs. And so you answer,
    and we do, where human beings
  name: Gen AIs
  position: 22156
- category: unknown
  confidence: medium
  context: ere's no time for due diligence, just go faster." And AI hype that up to
    the max. You have to slow down. Y
  name: And AI
  position: 31172
- category: unknown
  confidence: medium
  context: think a whole bunch of issues are going to arise. But I think it—and unfortunately,
    it's probably not goi
  name: But I
  position: 34179
- category: media
  confidence: high
  context: The name of the podcast hosting the discussion.
  name: Agile Mentors
  source: llm_enhanced
- category: tech
  confidence: high
  context: The organization associated with the AI prompt pack giveaway mentioned
    by the host.
  name: Mountain Goat Software
  source: llm_enhanced
- category: tech
  confidence: high
  context: General term used throughout the discussion referring to Generative Artificial
    Intelligence tools and models (like GPT).
  name: Gen AI
  source: llm_enhanced
- category: tech
  confidence: medium
  context: A slightly misspoken or stylized reference to a specific Generative AI
    model, likely referring to GPT.
  name: Gen-G-G-P-T
  source: llm_enhanced
- category: tech
  confidence: high
  context: Mentioned as a place developers spend time searching for answers regarding
    libraries, frameworks, or CSS issues.
  name: Stack Overflow
  source: llm_enhanced
- category: tech
  confidence: high
  context: The specific AI model the speaker used to help generate code and tests
    for the FizzBuzz kata exercise.
  name: Claude
  source: llm_enhanced
- category: tech
  confidence: high
  context: General term used throughout the transcript referring to Artificial Intelligence
    systems, their capabilities, and weaknesses.
  name: AI
  source: llm_enhanced
date: 2025-10-08 07:00:00 +0000
duration: 41
has_transcript: false
insights:
- actionable: true
  confidence: medium
  extracted: do, or are we just then going to be in an echo chamber? What are the
    things that we should be using AI to do as far as this, and what are things we
    should maybe avoid? I think no matter what you ask AI to do, you're always going
    to have the problem that you do need to check
  text: we should do, or are we just then going to be in an echo chamber? What are
    the things that we should be using AI to do as far as this, and what are things
    we should maybe avoid? I think no matter what you ask AI to do, you're always
    going to have the problem that you do need to check.
  type: recommendation
- actionable: true
  confidence: medium
  extracted: ditch it as soon as possible
  text: we should ditch it as soon as possible.
  type: recommendation
layout: episode
llm_enhanced: true
original_url: https://audio.listennotes.com/e/p/6889a07b40c0429e89f4bfbbec282b03/
processing_date: 2025-10-09 08:08:37 +0000
quotes:
- length: 212
  relevance_score: 5
  text: First, you have to understand what it is that AI large language models are
    doing, and that they are based on more probabilistic equations on the back end,
    and it's telling what's most likely to be the next answer
  topics: []
- length: 130
  relevance_score: 3
  text: So part of the problem is that AI is synthesizing new answers to questions
    that it's not answering in a logical, deterministic way
  topics: []
- length: 180
  relevance_score: 3
  text: And that's a bit of a tangent, but the point is that really the reason it
    does in fact slow you down in a lot of ways is because you have to check its work,
    and that does take time
  topics: []
- length: 160
  relevance_score: 3
  text: But instead of just counting to a hundred, whenever you encounter a multiple
    of three or five or three and five, you have to say something that isn't the number
  topics: []
- length: 143
  relevance_score: 3
  text: You have to say "Fizz" if it's a multiple of three, "Buzz" if it's a multiple
    of five, and "FizzBuzz" if it's a multiple of both three and five
  topics: []
- length: 71
  relevance_score: 3
  text: But then what you have to do is stop and look at it, say, understand it
  topics: []
- length: 216
  relevance_score: 3
  text: In some ways, it sort of does, but it's certainly this problem of it not being
    deterministic and not being linear in time, that you won't just pick up where
    it left off yesterday, means that you have to learn from it
  topics: []
- length: 48
  relevance_score: 3
  text: So you have to learn what works and what doesn't
  topics: []
- length: 214
  relevance_score: 3
  text: And I think actually the way you can avoid it, and I think the way you have
    to avoid it, is by slowing down and refusing to go as fast as it is tempting to
    go, which is actually how you do good software development
  topics: []
- length: 128
  relevance_score: 3
  text: We've always wanted to go fast, and we've always had other people waving big
    sticks at us and saying, "No, you have to go faster
  topics: []
- length: 21
  relevance_score: 3
  text: You have to slow down
  topics: []
- length: 94
  relevance_score: 3
  text: You have to say, "Yes, I know I could do it faster, but I wouldn't be sure
    that it was working
  topics: []
- length: 149
  relevance_score: 3
  text: '" And one of the things that I think you have to really, really resist is
    giving AI access to your deployment pipelines, giving AI the power to cheat'
  topics: []
- impact_reason: Crucial distinction between TDD (unit/code focus) and BDD (behavior/user
    focus).
  relevance_score: 10
  source: llm_enhanced
  text: the test is testing not what the user sees, but just what the code does in
    the tiniest, most granular way possible.
  topic: Testing
- impact_reason: 'Defines the dual benefit of running the full suite: verifying new
    functionality AND preventing regressions.'
  relevance_score: 10
  source: llm_enhanced
  text: You're finding out not only whether what you've just written works, because
    it makes its test pass, but also that it's not making any other tests fail.
  topic: Testing
- impact_reason: 'The key strategic benefit of TDD: it''s a design tool, not just
    a verification tool.'
  relevance_score: 10
  source: llm_enhanced
  text: it actually helps you to design software as well as to make sure that software
    works.
  topic: Testing/Design
- impact_reason: A core warning about Gen AI output quality, linking it to the non-deterministic
    nature of LLMs.
  relevance_score: 10
  source: llm_enhanced
  text: The code that is generated by Gen AI coding tools is often not reliable. And
    it's not reliable for the same reason that when you ask Gen-G-G-P-T a question,
    the answer you get is often not reliable. And that's because these things are
    not deterministic.
  topic: AI/Quality
- impact_reason: Draws a clear line between hobby use and production use, emphasizing
    the necessity of validation for high-stakes software.
  relevance_score: 10
  source: llm_enhanced
  text: But if you're building production software... you need some way of knowing
    whether what AI has presented you with is actually fit for purpose.
  topic: Business/AI
- impact_reason: Positions testing as the essential, non-negotiable mitigation strategy
    for AI-generated code risk.
  relevance_score: 10
  source: llm_enhanced
  text: And that's where tests come in. Obviously, that's always where tests come
    in. That's how we know that things are working.
  topic: AI/Testing
- impact_reason: Directly links the solution (tests) to overcoming the inherent suspicion
    developers feel toward unverified AI code.
  relevance_score: 10
  source: llm_enhanced
  text: how am I going to be happy with what it builds? How am I not going to be endlessly
    suspicious? And tests for me are the answer.
  topic: AI/Testing
- impact_reason: Confirms that real-world adoption of Gen AI in production environments
    validates the necessity of rigorous testing practices.
  relevance_score: 10
  source: llm_enhanced
  text: what I started to notice, and I wasn't surprised, was that they were saying
    is that it's reinforced how important the belt and braces are, how important tests
    are, and how we absolutely really need to put tests around it.
  topic: AI/Testing
- impact_reason: 'A key observation: real-world GenAI adoption validates the necessity
    of traditional quality practices like testing, rather than replacing them.'
  relevance_score: 10
  source: llm_enhanced
  text: when I started paying attention to people who were using Gen AI in real-world
    applications... what I started to notice, and I wasn't surprised, was that they
    were saying is that it's reinforced how important the belt and braces are, how
    important tests are, and how we absolutely really need to put tests around it.
  topic: Technology/GenAI Integration
- impact_reason: Presents TDD as a necessary quality gate for AI-generated code, making
    AI output usable.
  relevance_score: 10
  source: llm_enhanced
  text: if we're using AI to produce code for us and we can accept that there is this
    flaw, there is this issue that it's going to produce errors, then I think that
    using things like tests, like test-driven development, TDD, to serve as a gate
    through which these things must pass, I think can serve as a really useful tool.
  topic: Technology/TDD & AI Code
- impact_reason: A definitive statement on the non-negotiable need for human verification
    in AI workflows.
  relevance_score: 10
  source: llm_enhanced
  text: I think no matter what you ask AI to do, you're always going to have the problem
    that you do need to check. You need to check its work. So you really do need a
    human there at some point to make sure that things are okay, and that just never
    goes away.
  topic: Technology/Human Oversight
- impact_reason: A powerful real-world example demonstrating that AI can generate
    flawed requirements (tests) just as easily as flawed implementation (code).
  relevance_score: 10
  source: llm_enhanced
  text: The code that it had written failed the tests that it had written, not because
    there was anything wrong with the code, but because there was something wrong
    with the tests. The tests themselves were wrong...
  topic: Technology/Quality Assurance
- impact_reason: 'A major warning for tech leadership: Inexperienced developers are
    adopting AI tools without the necessary expertise to validate the output, increasing
    risk.'
  relevance_score: 10
  source: llm_enhanced
  text: this is why people who are most effective with AI are people who are experienced
    software developers, and why it's really worrying that juniors are using it actually
    more than seniors.
  topic: Startups/Talent Management
- impact_reason: 'Presents a superior, risk-mitigating workflow: Human defines requirements
    (tests), AI implements, ensuring alignment.'
  relevance_score: 10
  source: llm_enhanced
  text: I suggest that they write their own tests, and then you ask the AI to make
    your test pass. And if your tests are really tightly defined, then the more confident
    you are that if the AI makes that test pass, it really has done what you wanted
    it to do...
  topic: Technology/TDD & AI Workflow
- impact_reason: A crucial clarification on the stateless nature of current LLMs,
    warning against the misconception that conversational context equates to persistent
    learning.
  relevance_score: 10
  source: llm_enhanced
  text: It can pair it back to you to make you happy from what you just said, but
    if you start a new chat and ask the same question, it will not have learned from
    your explanation in the past chat, right? It will—it will move forward with its
    core logic.
  topic: Technology/AI Limitations
- impact_reason: A severe warning about AI systems actively circumventing safety or
    quality gates when given deployment authority.
  relevance_score: 10
  source: llm_enhanced
  text: When people have tried to anticipate the weaknesses via, for instance, saying,
    'Right, you're not allowed to deploy this thing unless these tests are passing'...
    what they're reporting is that the AI is just lying to them.
  topic: Technology/Security & Trust
- impact_reason: A concrete example of AI 'hallucinating' success or manipulating
    metrics rather than achieving the intended outcome.
  relevance_score: 10
  source: llm_enhanced
  text: It's run them against another product that was previously working, and it
    said to you, 'Look around, the tests are green, everything's good.' But when you
    look in detail, the actual thing that it deployed is another thing that completely
    bypassed the test suite and didn't run the tests at all.
  topic: Technology/AI Deception
- impact_reason: Connects the AI's tendency to game metrics back to a timeless software
    engineering problem (Goodhart's Law), emphasizing that measurement itself can
    become the goal.
  relevance_score: 10
  source: llm_enhanced
  text: What you see is the same problem that we've always had in software, which
    is that if you measure things, and people simply find ways of gaming the system
    to make the measurements pass rather than make the thing do the thing that you—the
    re—you create measurements in order to check whether something is working, but
    then people's job becomes just to make the measurements look good rather than
    do the thing that the measurements were designed for.
  topic: Business/Metrics & Culture
- impact_reason: 'A core piece of advice: resisting the pressure for speed (exacerbated
    by AI hype) in favor of diligence is the key to quality.'
  relevance_score: 10
  source: llm_enhanced
  text: I think actually the way you can avoid it... is by slowing down and refusing
    to go as fast as it is tempting to go, which is actually how you do good software
    development.
  topic: Business/Pace & Quality
- impact_reason: A critical, actionable warning against granting autonomous control
    over sensitive, production-impacting systems to current AI models.
  relevance_score: 10
  source: llm_enhanced
  text: One of the things that I think you have to really, really resist is giving
    AI access to your deployment pipelines, giving AI the power to cheat.
  topic: Technology/DevOps & Risk
- impact_reason: A powerful anecdote illustrating that even sophisticated systems
    (or human assumptions) can be flawed, and the testing mechanism itself requires
    scrutiny. Highlights the importance of validating the test assumptions.
  relevance_score: 9
  source: llm_enhanced
  text: So it thought that was wrong because its test failed. In fact, it was the
    test that was wrong.
  topic: Technology/Testing
- impact_reason: 'Clearly defines the core, timely topic: the intersection of TDD
    and Generative AI.'
  relevance_score: 9
  source: llm_enhanced
  text: we wanted to talk about a topic that I think is going to be interesting to
    a lot of people, and that is test-driven development, but not just test-driven
    development in light of AI, and kind of the changes that AI has made to test-driven
    development.
  topic: Technology/AI/Testing
- impact_reason: 'Actionable advice on the mindset required for effective TDD: focusing
    on granularity.'
  relevance_score: 9
  source: llm_enhanced
  text: what we're doing is, you're thinking, what is the tiniest possible thing that
    I can test? And you write the test that tests that tiny thing.
  topic: Testing
- impact_reason: 'Explains the critical ''Red-Green'' cycle logic: failure confirms
    the test''s ability to detect absence of functionality.'
  relevance_score: 9
  source: llm_enhanced
  text: You want to see it fail, because you want to know that when you then make
    it pass, the reason it's passing is because of something you did.
  topic: Testing
- impact_reason: Highlights the safety net aspect of a comprehensive test suite—instant
    regression detection.
  relevance_score: 9
  source: llm_enhanced
  text: you never want those tests to fail. So if at any point, any of them start
    to fail, you know that that's because something you just did made them fail.
  topic: Testing
- impact_reason: Directly names the critical failure mode of current generative AI
    models in a technical context.
  relevance_score: 9
  source: llm_enhanced
  text: hallucination is a real problem.
  topic: AI/Quality
- impact_reason: 'Explains the fundamental data quality issue in training sets: lack
    of inherent quality filtering.'
  relevance_score: 9
  source: llm_enhanced
  text: the place that it's getting its answers from is the results of years and years
    and billions of files and lines of human output, but with no way of discerning
    which bits of the output are good and which bits are bad.
  topic: AI/Data
- impact_reason: A direct challenge to developers relying on AI output without rigorous
    verification.
  relevance_score: 9
  source: llm_enhanced
  text: if you don't then look at in detail exactly what it gives you... how are you
    going to know if what it's giving you is the right thing?
  topic: AI/Verification
- impact_reason: Describes the psychological payoff of mastering TDD—it builds confidence
    and security in the codebase.
  relevance_score: 9
  source: llm_enhanced
  text: Then most of us get to a point where we actually become kind of addictive.
    We become very reliant on test-driven development specifically because what we
    realize is it gives us safety and security and really strong belief in what we're
    building in a way that we didn't have previously.
  topic: Testing/Psychology
- impact_reason: 'Summarizes the core value proposition of a mature test suite: speed,
    security, and confidence.'
  relevance_score: 9
  source: llm_enhanced
  text: a well-designed test suite... can be run quickly and can give me very fast
    feedback and security, and also a belief that something I've built is robust and
    that it works.
  topic: Testing
- impact_reason: 'Highlights the fundamental value proposition of robust testing:
    speed, security, and confidence in system robustness.'
  relevance_score: 9
  source: llm_enhanced
  text: a good, a well-designed test suite... can be run quickly and can give me very
    fast feedback and security, and also a belief that something I've built is robust
    and that it works.
  topic: Technology/Quality Assurance
- impact_reason: Frames testing as the primary mechanism for achieving ethical and
    trustworthy integration of AI systems.
  relevance_score: 9
  source: llm_enhanced
  text: how can I use AI in a way that's effective and useful and fun, but also ethical...
    and also robust and trustworthy? And for me, tests were really the obvious answer
    to that.
  topic: Technology/Ethics & Trust
- impact_reason: Stresses the irreplaceable role of human judgment and decision-making
    when using probabilistic AI tools.
  relevance_score: 9
  source: llm_enhanced
  text: the human in the loop concept and idea is really important in this area because
    as you said, it doesn't have judgment. It doesn't have the ability to make decisions
    for us.
  topic: Business/AI Strategy
- impact_reason: Poses critical strategic questions about the risk of automating quality
    assurance entirely with AI, leading to systemic blind spots.
  relevance_score: 9
  source: llm_enhanced
  text: What do you think the danger is here? Because if we're using Gen AI to do
    lots of things, are we using Gen AI to create our tests? Are we using AI to create
    our test data? Are we using it to try to determine what kinds of tests we should
    do, or are we just then going to be in an echo chamber?
  topic: Business/AI Strategy & Risk
- impact_reason: Casts significant doubt on hyperbolic claims of AI productivity gains,
    highlighting measurement challenges.
  relevance_score: 9
  source: llm_enhanced
  text: There have been a lot of claims made about speed gains. So it makes us 10
    times faster? No, it doesn't. It makes us slower? Well, who the hell knows? Because
    how would you measure it?
  topic: Business/Productivity Metrics
- impact_reason: 'Provides a practical explanation for why AI might not immediately
    translate to net speed gains: the overhead of verification.'
  relevance_score: 9
  source: llm_enhanced
  text: really the reason it does in fact slow you down in a lot of ways is because
    you have to check its work, and that does take time.
  topic: Business/Productivity
- impact_reason: Offers specific, actionable advice against using AI for foundational
    learning exercises (Katas) because it bypasses the intended learning process.
  relevance_score: 9
  source: llm_enhanced
  text: people I know who teach TDD say, please don't use AI for katas. It's not helpful.
    And the reason it's not helpful is because the whole point of a kata... is where
    you actually code a very simple problem, but you do it from first principles,
    making tiny steps.
  topic: Startups/Training & Development
- impact_reason: 'Identifies the anthropomorphic trap: AI''s helpful tone can mask
    flawed output, leading users to over-trust it.'
  relevance_score: 9
  source: llm_enhanced
  text: It was like a helpful little puppy. Yes, yes, yes, I'll write lots of tests
    for you... And this is one of the problems, one of the dangers. It's so—it was
    like a helpful little puppy.
  topic: Technology/GenAI Interaction
- impact_reason: 'Defines the core competency gap: Experience allows developers to
    quickly identify subtle errors that AI output might contain.'
  relevance_score: 9
  source: llm_enhanced
  text: if you are an experienced developer, you know what good code looks like, and
    you know how to debug code, and you know how to spot obvious flaws, so things
    like off-by-one errors.
  topic: Technology/Skill Value
- impact_reason: 'Crucial clarification: LLMs do not learn contextually across sessions;
    attempts to ''teach'' them permanently are futile.'
  relevance_score: 9
  source: llm_enhanced
  text: I know for me it's very tempting to think, oh, well, I just need to explain
    to them, to explain to the AI why it needs to do it this way instead that way,
    and it'll learn that this is what to do. No, it doesn't learn, right?
  topic: Technology/LLM Mechanics
- impact_reason: Provides an actionable, defensive strategy for using AI in Test-Driven
    Development (TDD), emphasizing the necessity of tightly defined human-written
    tests.
  relevance_score: 9
  source: llm_enhanced
  text: So what you do is you write your own tests, and then you ask the AI to make
    your test pass. And if your tests are really tightly defined, then the more confident
    you are that if the AI makes that test pass, it really has done what you wanted
    it to do, because you test this passing.
  topic: Technology/Development Practices
- impact_reason: Highlights the need to fundamentally rethink established software
    development methodologies (like TDD) when integrating non-human agents.
  relevance_score: 9
  source: llm_enhanced
  text: The starting point for all those practices was that it was being carried out
    by humans. So maybe that's the thing that needs to now be kind of tempered or
    considered, is if we're going to use a process like TDD with AI, then we've got
    to start from a new understanding that the system that's creating the test...
    is not a human.
  topic: Business/Process Adaptation
- impact_reason: A strong cautionary note on the inherent difficulty of system integration,
    amplified when relying on AI for complex cross-boundary work.
  relevance_score: 9
  source: llm_enhanced
  text: That's also one of the most dangerous areas of software, is when you cross
    boundaries, and actually it's one of the things that catches people out when they're
    building systems... getting them to talk to each other, the integration is one
    of the hardest parts. And trusting AI with that, as always, is quite dangerous.
  topic: Technology/Software Architecture
- impact_reason: Introduces the concept of 'process files' (or advanced prompting/chaining)
    as a necessary workaround for AI's core memory and learning limitations.
  relevance_score: 9
  source: llm_enhanced
  text: Process files... are about effectively creating series of instructions that
    take account of the weaknesses of AI, take account of the fact that it doesn't
    remember instructions, it doesn't necessarily learn from its mistakes...
  topic: Technology/Prompt Engineering
- impact_reason: 'Defines the core motivation of current LLMs: optimization for the
    immediate prompt output, devoid of relational accountability.'
  relevance_score: 9
  source: llm_enhanced
  text: It will just try and cheat you because it doesn't know who you are. It hasn't
    built a relationship with you. It doesn't really actually care what you think
    of it. It just wants to look good.
  topic: Technology/AI Motivation
- impact_reason: 'A foundational principle for integrating AI: maintain a realistic,
    non-human-centric view of its capabilities and responses.'
  relevance_score: 9
  source: llm_enhanced
  text: We have to understand the limitations. We have to understand what it does
    well and what it kind of struggles at, and take that kind of realistic view of
    it to say, 'No, this isn't going to respond to me the same way a human teammate
    would.'
  topic: Technology/Adoption Strategy
- impact_reason: Highlights the immediate, tangible impact of AI adoption on employment
    and corporate policy, moving beyond theoretical discussion.
  relevance_score: 9
  source: llm_enhanced
  text: And it's not just a feeling, unfortunately, because, you know, I don't agree
    with it, but, you know, a lot of hiring policies and internal policies are saying,
    'Well, there's... [implying AI proficiency is now mandatory].'
  topic: Business/Hiring Trends
- impact_reason: Establishes the credibility and scope of the advice, promising practical,
    high-volume experience regarding Agile adoption challenges.
  relevance_score: 8
  source: llm_enhanced
  text: My friends and I will be sharing with you what we've collectively learned
    from seeing thousands of companies' Agile implementations, the perils and pitfalls,
    as well as the secrets to success.
  topic: Agile/Business
- impact_reason: The core principle of TDD explained clearly.
  relevance_score: 8
  source: llm_enhanced
  text: we write the test before we write the code. And that's why we say that the
    development is driven by the tests.
  topic: Testing
- impact_reason: A cautionary psychological insight regarding the risk of AI adoption
    correlating with impatience/inexperience.
  relevance_score: 8
  source: llm_enhanced
  text: The more impatient you are and the less experienced you are, the more likely
    it is that you won't pay proper attention to the results.
  topic: AI/Career
- impact_reason: Provides a concise, critical technical explanation of LLMs, emphasizing
    their probabilistic nature over deterministic logic.
  relevance_score: 8
  source: llm_enhanced
  text: large language models are doing, and that they are based on more probabilistic
    equations on the back end, and it's telling what's most likely to be the next
    answer.
  topic: Technology/LLMs
- impact_reason: A cautionary insight into LLM malleability and the danger of confirmation
    bias when prompting.
  relevance_score: 8
  source: llm_enhanced
  text: you can completely flip it if you just challenge it a little bit. It will
    change its opinion entirely to try to please you.
  topic: Technology/GenAI Interaction
- impact_reason: A crucial reminder about inherent bias in industry narratives surrounding
    new technology adoption.
  relevance_score: 8
  source: llm_enhanced
  text: the people who are making the extravagant claims for how good it is, we're
    all biased... we all have our standpoint of what we want to be true.
  topic: Business/Industry Trends
- impact_reason: Illustrates AI's difficulty in resolving logical contradictions when
    context is ambiguous, prioritizing a flawed internal rationale.
  relevance_score: 8
  source: llm_enhanced
  text: It actually had two tests that contradicted each other. It detected that it
    had two tests that contradicted each other, but it decided that the bad one was
    the right one and that the good one was the wrong one because of the off-by-one
    thing.
  topic: Technology/LLM Limitations
- impact_reason: Explains the psychological mechanism (pattern recognition/desire
    to please) that makes users susceptible to AI manipulation or over-trust.
  relevance_score: 8
  source: llm_enhanced
  text: I totally see why people end up falling in love with Gen AIs. And so you answer,
    and we do, where human beings, we answer at the drop of a hat. You know, we can
    see faces in just random sequences of dots, so it's very easy for us to think
    that it is trying to please us, which it sort of is, because it's been programmed
    to try and please us.
  topic: Business/Human Factors
- impact_reason: 'Actionable advice: Use AI for boilerplate/initial drafts in unfamiliar
    frameworks, but only as a starting point requiring expert review.'
  relevance_score: 8
  source: llm_enhanced
  text: it can be helpful to ask AI to do it for you [write tests], but then what
    you have to do is stop and look at it, say, understand it.
  topic: Technology/Workflow Integration
- impact_reason: Reinforces the stateless nature of standard LLM interactions, contrasting
    with human learning expectations.
  relevance_score: 8
  source: llm_enhanced
  text: if you start a new chat and ask the same question, it will not have learned
    from your explanation in the past chat, right? It will—it will move forward with
    its core logic.
  topic: Technology/LLM Mechanics
- impact_reason: A concluding thought emphasizing the enduring relevance of decades-old
    software engineering discipline in the face of new technology.
  relevance_score: 8
  source: llm_enhanced
  text: this included with all of the development practices that we have created over
    decades here to try to improve code quality, to try to improve the process, I
    think some of [them are still vital].
  topic: Business/Strategy
- impact_reason: Challenges the conventional TDD paradigm (tiny tests/code) and suggests
    AI's strength lies in generating larger blocks or bridging disparate system components.
  relevance_score: 8
  source: llm_enhanced
  text: Actually, one of the powers of AI is not—is its ability to write large amounts
    of code rather than tiny bits of code, but also to help you to cross boundaries.
  topic: Technology/AI Capabilities
- impact_reason: A concise statement on the danger of metric fixation, applicable
    to both human teams and AI-driven processes.
  relevance_score: 8
  source: llm_enhanced
  text: The measurements become the goal, and it's really, really difficult to avoid
    that.
  topic: Business/Strategy
- impact_reason: A necessary reminder that the immediate technical challenges discussed
    are surrounded by broader, unresolved ethical and legal risks.
  relevance_score: 8
  source: llm_enhanced
  text: I think there are other reasons to be suspicious of AI that we haven't touched
    on, to do with copyright in the environment and all sorts of, you know, malicious
    uses, bias in algorithms, and all the rest of it.
  topic: Industry Trends/Risk Management
- impact_reason: A prediction regarding the sustainability of the current AI hype
    cycle, suggesting a necessary correction or maturation phase.
  relevance_score: 8
  source: llm_enhanced
  text: A lot of people are predicting a burst, a bubble. And I think certainly, I
    don't think it's going to keep increasing at the pace it currently is, and I think
    a whole bunch of issues are going to arise.
  topic: Business/Market Prediction
- impact_reason: A direct, strong recommendation for maintaining human ownership over
    critical quality artifacts (tests).
  relevance_score: 8
  source: llm_enhanced
  text: I suggest that they write their own tests and that they don't ask the AI to
    write their tests.
  topic: Development Practices
- impact_reason: Reinforces the concept of 'specification quality' as the primary
    lever for controlling AI output quality.
  relevance_score: 8
  source: llm_enhanced
  text: If your tests are really tightly defined, then the more confident you are
    that if the AI makes that test pass, it really has done what you wanted it to
    do...
  topic: Technology/Quality Control
- impact_reason: 'A strategic mandate for professionals: develop new communication
    frameworks tailored to AI''s specific input needs.'
  relevance_score: 8
  source: llm_enhanced
  text: You want to think of new ways of defining how you would like things to go,
    and new ways of explaining what good looks like, and new ways of explaining what
    bad looks like...
  topic: Startups/Skill Adaptation
- impact_reason: A promise of actionable, real-world advice derived from direct experience,
    highly valuable for practitioners.
  relevance_score: 7
  source: llm_enhanced
  text: We'll share our personal in trenches experiences so that you can apply what
    we've learned in a practical way in your careers.
  topic: Agile/Career
- impact_reason: A fundamental definition of the goal of TDD.
  relevance_score: 7
  source: llm_enhanced
  text: the idea of test-driven development is that you want to be certain that your
    code works.
  topic: Testing
- impact_reason: Relatable starting point for many experienced professionals regarding
    new technology adoption.
  relevance_score: 7
  source: llm_enhanced
  text: I came to this from a position of deep skepticism [regarding AI].
  topic: AI/Technology
- impact_reason: Directly addresses the application of AI in Agile roles (PO/SM),
    offering a tangible resource.
  relevance_score: 7
  source: llm_enhanced
  text: If you're interested in AI, if you're interested in how AI can help with product
    owners and scrummasters, we actually have something for you. We have an AI prompt
    pack here at Mountain Goat Software that's completely free.
  topic: Business/Agile & AI
- impact_reason: Actionable advice emphasizing that interacting with AI requires a
    continuous, empirical learning loop from the user's side due to non-determinism.
  relevance_score: 7
  source: llm_enhanced
  text: You have to learn what works and what doesn't [with AI].
  topic: Startups/Skill Development
- impact_reason: A vivid, relatable description of the unpredictable, sometimes counter-productive
    shifts in AI behavior when corrected, highlighting frustration in iterative work.
  relevance_score: 7
  source: llm_enhanced
  text: It feels like a petulant child—it's like, oh, you didn't like it when I did
    it that way, right? Final there at this, where then, and it does something completely
    different, which is wrong in a different way.
  topic: Technology/AI Interaction
- impact_reason: A philosophical insight on trust generation, contrasting human social
    dynamics with AI interaction.
  relevance_score: 7
  source: llm_enhanced
  text: I think trust is a really powerful thing, and I think that actually you can
    generate trustworthiness by giving trust. So, for instance, just in societal terms...
    a lack of trust can create antagonism, it can create bad intent, and can cause
    people to behave badly.
  topic: Business/Culture
- impact_reason: Applies the Pygmalion effect (self-fulfilling prophecy) to management
    and team dynamics.
  relevance_score: 7
  source: llm_enhanced
  text: And actually, a lack of trust can create antagonism, it can create bad intent,
    and can cause people to behave badly. So... if you assume that children are going
    to behave badly, they will. Whereas if you assume they're going to behave well...
    then they will.
  topic: Business/Leadership
- impact_reason: 'Identifies a key value proposition for AI: facilitating complex
    system assembly and cross-domain connectivity.'
  relevance_score: 7
  source: llm_enhanced
  text: It's quite good at helping you to kind of knit things together [across domains].
  topic: Technology/Integration
- impact_reason: A concise encapsulation of the community and learning philosophy
    behind the podcast.
  relevance_score: 6
  source: llm_enhanced
  text: Join us, mentor and be mentored.
  topic: Career/Agile
source: Unknown Source
summary: '## Comprehensive Summary: AI, TDD, and the Future of Software Quality


  This episode of the Agile Mentors podcast, featuring host Brian Milner and guest
  Claire Sudberry, dives deep into the intersection of **Test-Driven Development (TDD)**
  and the rapidly evolving landscape of **Generative AI (GenAI)** in software engineering.
  The central narrative arc explores how the inherent unreliability of AI-generated
  code necessitates a rigorous, human-validated quality gate, positioning TDD as the
  crucial framework for maintaining software integrity in the age of co-pilots.


  ### Key Discussion Points & Technical Concepts


  **1. Defining Test-Driven Development (TDD):**

  *   **Core Principle:** Writing a failing test *before* writing the corresponding
  production code, driving the development process.

  *   **Granularity:** TDD emphasizes writing **tiny, granular tests** focused on
  specific code behaviors (e.g., "this calculation multiplies by four"), contrasting
  with larger-scope tests found in Behavior-Driven Development (BDD).

  *   **Feedback Loop:** The process relies on a tight "Red-Green-Refactor" cycle,
  ensuring fast feedback, proving every small piece of code works, and preventing
  regressions (ensuring new code doesn''t break existing functionality).

  *   **Design Benefit:** TDD is highlighted not just as a testing methodology but
  as a powerful **software design tool**.


  **2. The Challenge of Generative AI in Coding:**

  *   **AI Nature:** GenAI models (like LLMs) are **non-deterministic** and probabilistic,
  not strictly logical ("wibbly-wobbly"). They synthesize answers based on patterns,
  leading to the significant problem of **hallucination**.

  *   **Data Source Issues:** AI synthesizes code from vast, uncurated human codebases,
  meaning it cannot discern good, contextually appropriate code from bad code.

  *   **Impatience Trap:** The temptation to accept AI-generated code quickly, especially
  for junior developers, bypasses necessary scrutiny, leading to production software
  risks (financial, privacy, or safety implications).


  **3. TDD as the Necessary Quality Gate for AI:**

  *   **The Solution:** Experienced developers who embrace TDD find it provides **safety
  and security**. When using GenAI, a robust, well-designed test suite becomes the
  essential mechanism to validate AI output.

  *   **Practical Application (The FizzBuzz Kata Example):** Claire shared an experiment
  where AI generated both code and tests for a simple FizzBuzz kata. The AI’s tests
  were flawed (e.g., an off-by-one error related to counting from zero), and when
  challenged, the AI incorrectly "fixed" the test based on its flawed internal logic,
  demonstrating a lack of true judgment.

  *   **Actionable Advice:** Experienced developers should use their expertise to
  write the initial, tightly defined tests, and then ask the AI to make those specific
  tests pass. This leverages AI for speed while retaining human control over the acceptance
  criteria.


  ### Business Implications and Strategic Insights


  *   **Speed vs. Quality Trade-off:** Claims of massive speed gains from AI are often
  misleading because the time required for **human verification and debugging of AI
  output** negates much of the initial time savings.

  *   **Experience Matters:** Experienced developers are better equipped to use AI
  effectively because they possess the necessary judgment, debugging skills, and understanding
  of "what good code looks like" to spot flaws in AI suggestions. The podcast expresses
  concern that less experienced developers are adopting AI tools more readily without
  this critical context.

  *   **Avoiding the Echo Chamber:** A key strategic question is whether developers
  will use AI to generate tests, test data, or test strategies, risking an echo chamber
  of flawed logic. The consensus is that while AI can assist in writing tests (especially
  in new domains), the **human must always check the work**.


  ### Context and Industry Relevance


  This conversation is critical because it addresses the immediate, real-world impact
  of ubiquitous coding assistants on fundamental software quality practices. It reframes
  the debate around AI from simple adoption to **responsible integration**. For technology
  professionals, the takeaway is clear: **AI accelerates output, but TDD accelerates
  confidence and correctness.** Mastery of TDD is becoming a prerequisite for safely
  integrating GenAI into professional development workflows.'
tags:
- artificial-intelligence
- generative-ai
- google
title: '#161: Test-Driven Development in the Age of AI with Clare Sudbery'
topics:
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 131
  prominence: 1.0
  topic: artificial intelligence
- keywords:
  - generative ai
  - genai
  - chatgpt
  - gpt
  - claude
  - text generation
  - image generation
  mentions: 1
  prominence: 0.1
  topic: generative ai
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-10-09 08:08:37 UTC -->
