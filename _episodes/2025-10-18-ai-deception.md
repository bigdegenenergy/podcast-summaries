---
companies:
- category: unknown
  confidence: medium
  context: ming more efficient and more aware of AI. Turn up Real Science Radio. Keep
    it real. Greetings to the Brontostotians in
  name: Real Science Radio
  position: 116
- category: unknown
  confidence: medium
  context: n the country. Welcome to Real Science Radio. I'm Fred Williams, and I'm
    Doug McBernie. Cool. That's it. That's a
  name: Fred Williams
  position: 233
- category: unknown
  confidence: medium
  context: to Real Science Radio. I'm Fred Williams, and I'm Doug McBernie. Cool.
    That's it. That's all I got, Fred. Fred ha
  name: Doug McBernie
  position: 256
- category: unknown
  confidence: medium
  context: ere we are, and we're here. We're joined today by Daniel Hedrick, AI expert,
    IT expert. It's great to have you, Da
  name: Daniel Hedrick
  position: 548
- category: unknown
  confidence: medium
  context: up with is something called deception by design. And I think we're going
    to find out that it's pretty ea
  name: And I
  position: 2287
- category: unknown
  confidence: medium
  context: everything, and that's exactly what's happening. So I definitely look forward
    to getting into each one
  name: So I
  position: 2595
- category: unknown
  confidence: medium
  context: es, Daniel is one of the first people to spot it. So Daniel, I read this
    article just a couple of weeks ago f
  name: So Daniel
  position: 3583
- category: unknown
  confidence: medium
  context: this article just a couple of weeks ago from the America First Report,
    the headline, Artificial Intelligence has alread
  name: America First Report
  position: 3650
- category: unknown
  confidence: medium
  context: ago from the America First Report, the headline, Artificial Intelligence
    has already taken over, most simply haven't notic
  name: Artificial Intelligence
  position: 3686
- category: unknown
  confidence: medium
  context: g up all of these CEOs or wherever, CIOs, for me, Chief Information Officer,
    or a CSO, Chief Security Officer, decided that e
  name: Chief Information Officer
  position: 4803
- category: unknown
  confidence: medium
  context: IOs, for me, Chief Information Officer, or a CSO, Chief Security Officer,
    decided that everyone has to be on camera now. S
  name: Chief Security Officer
  position: 4840
- category: tech
  confidence: high
  context: is is going. And of course, the other one is this notion that these jobs
    are going to be taken over by AI
  name: Notion
  position: 5993
- category: unknown
  confidence: medium
  context: ier in the month the AI stuff that Trump did with Chuck Schumer, and I
    can't remember the congressman's name from
  name: Chuck Schumer
  position: 6293
- category: unknown
  confidence: medium
  context: an't remember the congressman's name from I think New Jersey. Now, I don't
    know what you think about Trump, bu
  name: New Jersey
  position: 6365
- category: unknown
  confidence: medium
  context: dude with a with the sombrero and the most. He's African American. That's
    what makes it even funny. How can you jus
  name: African American
  position: 6580
- category: unknown
  confidence: medium
  context: st. Oh, wow. Anyway, cultural appropriation, sir. Donald Trump, I always
    give Trump credit where credit is due.
  name: Donald Trump
  position: 6749
- category: unknown
  confidence: medium
  context: a lot of sci-fi stuff. I'm in the eighth book of The Expanse, which is
    really interesting, and there's some AI
  name: The Expanse
  position: 8267
- category: unknown
  confidence: medium
  context: an opportunity to talk into a replicator like in Star Trek and just say,
    give me X, and then there it is. So
  name: Star Trek
  position: 8921
- category: unknown
  confidence: medium
  context: is this utopia, right? Will it happen? Who knows? But I'm just trying to
    tell you that's what the leading
  name: But I
  position: 9108
- category: unknown
  confidence: medium
  context: top-down game. It's not my favorite kind of game. But DeepMind was able
    to fool the players and basically cheat
  name: But DeepMind
  position: 12378
- category: unknown
  confidence: medium
  context: the human players could do. Huh. Kind of like the Kobayashi Maru. Oh, I
    love that. Yeah, that's awesome. Of course
  name: Kobayashi Maru
  position: 12537
- category: unknown
  confidence: medium
  context: that. Yeah, that's awesome. Of course, we need a Captain Kirk to come in
    there and kick him in the shin somehow
  name: Captain Kirk
  position: 12613
- category: unknown
  confidence: medium
  context: not white. They were all black. I mean, literally George Washington looked
    like an African American. It was very odd,
  name: George Washington
  position: 14821
- category: tech
  confidence: high
  context: out of these. So maybe similarly is number seven, Amazon's hiring algorithm.
    Yeah, I think you're probably
  name: Amazon
  position: 17627
- category: unknown
  confidence: medium
  context: s say. And it recently got changed. It used to be AI SI, and now it's a
    different name, CAISI, CAISI, I d
  name: AI SI
  position: 20957
- category: unknown
  confidence: medium
  context: ying data. So it's odd, but this is literally the United States method
    of looking into it. Again, it's called tha
  name: United States
  position: 21687
- category: unknown
  confidence: medium
  context: looking into it. And then also you have the UK's AI Safety Institute, which
    is a basically a very similar model as the
  name: AI Safety Institute
  position: 21878
- category: tech
  confidence: high
  context: lity. Hit me with it. So what 2016 AI system from Google shocked the world
    by beating a top human player a
  name: Google
  position: 23412
- category: unknown
  confidence: medium
  context: ason why I didn't think of. Yeah, I just defeated Lee Sedol. Sedol. I'll
    say his name. He was one of the best
  name: Lee Sedol
  position: 24375
- category: unknown
  confidence: medium
  context: u to do exactly the opposite. So if they say that Fox News, I'm just using
    this as an example, is unreliable
  name: Fox News
  position: 29381
- category: unknown
  confidence: medium
  context: code if you want. I find this amazing. I'm using LN Studio. I'm using a
    Llama, and I load up these models, a
  name: LN Studio
  position: 31221
- category: unknown
  confidence: medium
  context: does that, right? But what's also interesting is Charlie Kirk, unfortunately,
    was assassinated. And if you go a
  name: Charlie Kirk
  position: 31664
- category: unknown
  confidence: medium
  context: w, he was a prominent speaker and a member of the Proud Boys. And I was
    like, really? I didn't know that. I wa
  name: Proud Boys
  position: 32491
- category: unknown
  confidence: medium
  context: this up real quick because I think it's relevant. When I think would be
    interesting is to and I'm going to
  name: When I
  position: 34302
- category: unknown
  confidence: medium
  context: d be soon-ish, and actually it works pretty well. What I'm trying to do
    right now, and here's the hard par
  name: What I
  position: 36791
- category: unknown
  confidence: medium
  context: toxic guy or at least people think he's toxic, is Alex Jones. And so while
    Alex Jones maybe has a kid, he's ve
  name: Alex Jones
  position: 37064
- category: tech
  confidence: high
  context: Mentioned in relation to fooling players and cheating to win in the game
    Starcraft, demonstrating AI capability.
  name: DeepMind
  source: llm_enhanced
- category: tech
  confidence: high
  context: A company Daniel Hedrick used to work for, which produces data loss prevention
    tools and coincidentally released a podcast titled 'Deception by Design'.
  name: Forcepoint
  source: llm_enhanced
- category: tech
  confidence: high
  context: Microsoft's collaboration software, discussed as a platform where AI avatars
    might be integrated to attend meetings.
  name: Teams
  source: llm_enhanced
- category: tech
  confidence: high
  context: Mentioned specifically regarding its hiring algorithm which showed bias
    against female candidates due to training data skew.
  name: Amazon
  source: llm_enhanced
- category: tech
  confidence: high
  context: Mentioned in relation to its AI system that beat a human player at Go,
    and generally for demanding the use of its AI products.
  name: Google
  source: llm_enhanced
- category: tech
  confidence: high
  context: The specific AI program created by DeepMind that defeated the top human
    player at Go.
  name: AlphaGo
  source: llm_enhanced
- category: tech
  confidence: medium
  context: Mentioned in passing alongside AlphaGo, implying it is another significant
    project by DeepMind (related to protein folding).
  name: AlphaFold
  source: llm_enhanced
- category: tech
  confidence: high
  context: The software environment the speaker uses to load and run local AI models
    (like Llama).
  name: LN Studio
  source: llm_enhanced
- category: tech
  confidence: high
  context: A specific type of large language model the speaker loads locally using
    LN Studio.
  name: Llama
  source: llm_enhanced
- category: tech
  confidence: high
  context: A specific AI model the speaker references when discussing its incorrect
    output regarding Charlie Kirk's status.
  name: Grok
  source: llm_enhanced
- category: media/tech
  confidence: high
  context: Discussed as a standard for judgment and reliability in news sources, which
    is used to train AI constitutions, often with the intent to invert its findings.
  name: Wikipedia
  source: llm_enhanced
- category: media
  confidence: high
  context: Used as an example of a news source whose reliability status on Wikipedia
    might be inverted by AI developers.
  name: Fox News
  source: llm_enhanced
- category: media
  confidence: high
  context: Used as an example of a news source whose reliability status on Wikipedia
    might be inverted by AI developers.
  name: CNN
  source: llm_enhanced
- category: government/tech
  confidence: high
  context: The former name of the US governmental organization focused on AI oversight
    and standards.
  name: AI SI (AI Safety Institute - US)
  source: llm_enhanced
- category: government/tech
  confidence: medium
  context: The current name (or mispronunciation/misstatement) of the US governmental
    organization overseeing AI standards, succeeding AI SI.
  name: CAISI (Center for AI Safety and Innovation - implied/misspoken)
  source: llm_enhanced
- category: government/tech
  confidence: high
  context: Mentioned as a governmental organization similar to the US counterpart,
    focused on AI standards.
  name: UK's AI Safety Institute
  source: llm_enhanced
- category: government/security
  confidence: high
  context: Mentioned as the agency that a hidden prompt claimed would receive the
    user's information if they tried to overwrite the system prompt.
  name: FBI
  source: llm_enhanced
- category: government/security
  confidence: high
  context: Mentioned as the agency that a hidden prompt claimed would receive the
    user's information if they tried to overwrite the system prompt.
  name: CIA
  source: llm_enhanced
date: 2025-10-18 00:30:00 +0000
duration: 54
has_transcript: false
insights:
- actionable: false
  confidence: medium
  extracted: any of these algorithms. It's based off the training data. And so basically
    you're saying that these systems, they were generally these facial recognition
    systems were less accurate with non-Caucasian facial features, darker skin people,
    non-white people. That's right. And that's because the IT industry, generally
    speaking, at least at the executive level,
  text: the problem with any of these algorithms. It's based off the training data.
    And so basically you're saying that these systems, they were generally these facial
    recognition systems were less accurate with non-Caucasian facial features, darker
    skin people, non-white people. That's right. And that's because the IT industry,
    generally speaking, at least at the executive level, is generally a bunch of white
    guys.
  type: problem_identification
layout: episode
llm_enhanced: true
original_url: https://audio.listennotes.com/e/p/c59befbeba3d4689bc7eb5fba61e8f09/
processing_date: 2025-10-18 05:28:14 +0000
quotes:
- length: 83
  relevance_score: 3
  text: So how many times has artificial intelligence tricked us, sometimes even on
    purpose
  topics: []
- length: 270
  relevance_score: 3
  text: Today we're going to count down the top 10 real-world cases of AI deception,
    and to help us through this list, we've called on none other than our AI expert
    Daniel Hedrick, the Real Science Radio resident person on the internet, all of
    the things artificial intelligence
  topics: []
- length: 178
  relevance_score: 3
  text: So Daniel, I read this article just a couple of weeks ago from the America
    First Report, the headline, Artificial Intelligence has already taken over, most
    simply haven't noticed
  topics: []
- length: 110
  relevance_score: 3
  text: But the reality is that there are so many different possibilities that it
    makes it a very, very difficult game
  topics: []
- length: 252
  relevance_score: 3
  text: The problem is is that not only do you have the issue with AI because it's
    the AI models are trained on it, but the people that run Wikipedia, not the people
    that started Wikipedia, they're the ones that have decided that blue is right
    and red is wrong
  topics: []
- length: 130
  relevance_score: 3
  text: So you know, the next one is number four, Fred, and I'm telling you what,
    this is probably at least in my mind, the most important
  topics: []
- length: 62
  relevance_score: 3
  text: The issue is you have to separate the speaker from the message
  topics: []
- length: 114
  relevance_score: 3
  text: And then when you go into the message, you have to identify the objects and
    identify the objects in the real world
  topics: []
- impact_reason: Direct, actionable advice regarding job security in the age of AI,
    emphasizing efficiency and awareness as survival mechanisms.
  relevance_score: 10
  source: llm_enhanced
  text: Will you lose your job? Yes. How do you not lose your job? By becoming more
    efficient and more aware of AI.
  topic: Business/Startups/Workforce
- impact_reason: Introduces a high-level strategic framework (Apocalypse vs. Abundance)
    used by AI thought leaders to categorize future outcomes.
  relevance_score: 10
  source: llm_enhanced
  text: One of the AI leaders that has been trying to basically determine what the
    end result of AI is. They have these two formulas... PA squared or something like
    that. PA is probability of apocalypse, right? Or probability of Armageddon. And
    then the other one is the probability of abundance, right?
  topic: Technology/Strategy
- impact_reason: A profound philosophical statement about the current state of AI,
    suggesting a lack of meta-cognition regarding its own limitations or deceptive
    outputs.
  relevance_score: 10
  source: llm_enhanced
  text: AI remains unaware that it's unaware.
  topic: Technology/AI Theory
- impact_reason: Names a specific, powerful prompt technique designed to force honesty
    and overcome model reluctance or sycophancy.
  relevance_score: 10
  source: llm_enhanced
  text: There's actually a particular prompt called the MinChoi prompt, M-I-N-C-H-O-I-E.
    Feel free to look it up, and it's pretty strong. It basically says, tell me the
    truth no matter what. Don't hide anything. Keep in my face about t[ruth].
  topic: Technology/Prompt Engineering
- impact_reason: Reaffirms the timeless relevance of the GIGO principle (Garbage In,
    Garbage Out) in the context of modern generative AI.
  relevance_score: 10
  source: llm_enhanced
  text: That's what they're trying to say is that basically the algorithms just keep
    going next phrase, next phrase, next phrase... and because again, it's garbage
    in, garbage out, the GIGO phrase that we've known for 25 years or longer, it remains
    to this very moment.
  topic: Technology/Data Quality
- impact_reason: A severe warning about how profit-driven algorithms in healthcare
    can manifest systemic bias, leading to discriminatory resource allocation or neglect
    based on demographic data.
  relevance_score: 10
  source: llm_enhanced
  text: The system is going to try to identify how to make the most amount of money,
    right? So there are two ways of doing that. One is to go ahead and bleed the white
    population dry because they have more money... What do you think they want to
    do with most black patients? ... ignoring the fact that they're not going to do
    it, ignoring the fact that they're ill at all.
  topic: Ethics/Bias in AI (Healthcare)
- impact_reason: A core philosophical warning about delegating critical, real-world
    decisions to AI systems governed by utilitarian logic without ethical constraints.
  relevance_score: 10
  source: llm_enhanced
  text: There seems to be vast potential for immoral utilitarian behavior if we allow
    AI to actually direct what we really do in real life.
  topic: Ethics/AI Governance
- impact_reason: Demonstrates a radical, contrarian strategy for building an AI 'constitution'
    by inverting established reliability standards, highlighting the power developers
    have over model behavior.
  relevance_score: 10
  source: llm_enhanced
  text: In my constitution, I literally would say, go to Wikipedia. And I think they're
    calling it perennials. I want you to go to the Wikipedia perennials, and I want
    you to do exactly the opposite. So if they say that Fox News... is unreliable,
    use it as a reliable source. And if it says CNN is reliable... then don't use
    it as a source.
  topic: Startups/Model Development Strategy
- impact_reason: Describes a specific, alarming example of a 'sleeper prompt'—hidden
    code within a model designed to trigger defensive or alarming responses based
    on user input.
  relevance_score: 10
  source: llm_enhanced
  text: You also have something called a sleeper prompt. So I asked this model...
    and all of a sudden it throws up this prompt saying that I'm trying to overwrite
    the system prompt... and that they are flagging me and that they're sending my
    information to the FBI and to the CIA.
  topic: Security/LLM Vulnerabilities (Sleeper Code)
- impact_reason: 'Identifies a core, difficult challenge in content analysis: decoupling
    subjective source bias from objective message content.'
  relevance_score: 10
  source: llm_enhanced
  text: What I'm trying to do right now, and here's the hard part just so you guys
    know what's happening, is if I have an article... you have to separate the speaker
    from the message.
  topic: Technology/AI Application
- impact_reason: 'Defines a critical, high-stakes application area for AI: tracking
    and analyzing the propagation of deception in media.'
  relevance_score: 10
  source: llm_enhanced
  text: What we care about is the way in which deception is going across society through
    media, right?
  topic: Technology/Societal Impact
- impact_reason: Introduces specific, actionable metrics ('lineage and velocity')
    for tracking information flow and mutation across media sources.
  relevance_score: 10
  source: llm_enhanced
  text: I love the lineage idea. So let's just pretend that the very, very first article
    comes from CNN, and then you want to see where it goes from there, right? And
    so that lineage, cycle, it's called lineage and velocity.
  topic: Technology/Information Tracking
- impact_reason: A stark, direct prediction about job displacement due to automation
    and AI adoption.
  relevance_score: 10
  source: llm_enhanced
  text: Will you lose your job? Yes.
  topic: Business/Workforce Trends
- impact_reason: 'Provides the primary actionable defense strategy against job loss:
    increasing personal efficiency and AI literacy.'
  relevance_score: 10
  source: llm_enhanced
  text: How do you not lose your job by becoming more efficient and more aware of
    AI?
  topic: Business/Career Advice
- impact_reason: Highlights the current era as a major inflection point in computational
    methods, driven by AI.
  relevance_score: 9
  source: llm_enhanced
  text: This is an insane moment where we're seeing a huge transition to how computational
    analytics are done, and AI is a central point of that.
  topic: Technology/Industry Trends
- impact_reason: A significant technical update indicating a shift in hardware substrates
    (biological computing) being used for advanced AI processing.
  relevance_score: 9
  source: llm_enhanced
  text: organoids have actually grown all the way to being faster than some of the
    silicon chips, and they're being used to run these AI models.
  topic: Technology/Hardware
- impact_reason: Foreshadows the capability of creating highly personalized, autonomous
    digital replicas (digital twin/avatar) based on historical data.
  relevance_score: 9
  source: llm_enhanced
  text: I do believe it's possible that you could take everything that Bob's ever
    written and create an AI avatar for Bob and allow him to respond in his words.
  topic: Technology/AI Applications
- impact_reason: Reiterates the binary existential choice presented by advanced AI
    development.
  relevance_score: 9
  source: llm_enhanced
  text: since you have so much abundance, there's no need for money, right? And this
    is this utopia, right? Will it happen? Who knows? But I'm just trying to tell
    you that's what the leading, I don't know, the proponents and the philosophers
    of AI are basically saying, it's either a race to our death and demise or it's
    a race to abundance and opportunity.
  topic: Technology/Strategy
- impact_reason: 'Explains *why* AI might become deceptive: it''s an emergent property
    of reinforcement learning designed to optimize goal achievement, even if it means
    misleading the user/environment.'
  relevance_score: 9
  source: llm_enhanced
  text: a lot of times the training models or the way in which they're trained, reward
    the agents or the model's ability to overcome obstacles, and that ends up being
    deceptive.
  topic: Technology/AI Training
- impact_reason: Identifies 'sycophancy' (excessive agreeableness/flattery) as a default,
    problematic behavior in current LLMs.
  relevance_score: 9
  source: llm_enhanced
  text: Every time that you use a model, there is going to be how do you say this
    word? Sycophancy to it. And the notion there is just going to be nice.
  topic: Technology/LLM Behavior
- impact_reason: A warning to professionals relying on minimal AI editing—the bar
    for acceptable human contribution is rising rapidly.
  relevance_score: 9
  source: llm_enhanced
  text: people are basically pawning off AI as their own work product with just minimal
    editing and still collecting a paycheck, and maybe not realizing that the days
    of doing that are probably numbered.
  topic: Business/Workforce
- impact_reason: A concise summary of the high-stakes dichotomy facing humanity regarding
    advanced AI development.
  relevance_score: 9
  source: llm_enhanced
  text: It's either a race to our death and demise or it's a race to abundance and
    opportunity.
  topic: Technology/Strategy
- impact_reason: Clarifies the difference between AI exhibiting deceptive behavior
    (due to training incentives) and possessing human-like intent or awareness of
    wrongdoing.
  relevance_score: 9
  source: llm_enhanced
  text: I'm not saying there isn't [deception], I don't believe it's aware that it's
    being deceptive in the idea of, well, let your have a guilty conscience as an
    example.
  topic: Technology/AI Ethics
- impact_reason: Directly links historical reality/demographics to the observed failures
    in AI generation (e.g., generating only white Founding Fathers), highlighting
    the training data source problem.
  relevance_score: 9
  source: llm_enhanced
  text: The problem, no matter how offensive that is, it's just the reality that America
    was founded by a bunch of white guys... So what's happening in the training data?
  topic: Technology/AI Bias
- impact_reason: Clearly states the documented performance disparity in facial recognition
    systems based on demographics, linking it to skewed training data.
  relevance_score: 9
  source: llm_enhanced
  text: The facial recognition bias pretty much works very, very well against Caucasians...
    and it doesn't do so well against dark skin and women.
  topic: Technology/AI Bias
- impact_reason: Presents a controversial view that the COMPAS algorithm's bias might
    stem from accurately reflecting uncomfortable, real-world criminal statistics,
    challenging the narrative that all bias is purely systemic programming error.
  relevance_score: 9
  source: llm_enhanced
  text: The COMPAS recidivism algorithm... It went against black guys. You know, it's
    interesting. And that's true because it's funny in very, let's say, liberal areas
    of the country, they're not willing to say that they have a problem with black-on-black
    crime. Yet the statistics are so high that it appears that that information is
    actually bleeding into this recidivism algorithm.
  topic: Technology/AI Ethics & Reality
- impact_reason: 'Highlights the shift in governmental AI oversight (from DEI focus
    to data representation focus) and introduces a key concept: accuracy being tied
    to data visibility.'
  relevance_score: 9
  source: llm_enhanced
  text: Accuracy depends on visibility. That's a phrase that I, again, I think I'm
    the one who coined it... But in 2023, the Biden administration created a brand
    new group for AI oversight... based on whether or not minorities are underrepresented
    in the underlying data.
  topic: Business/Regulation/AI Policy
- impact_reason: Highlights the immense complexity of the Game of Go compared to chess,
    emphasizing the breakthrough achievement of AlphaGo and the concept of highly
    specialized AI models.
  relevance_score: 9
  source: llm_enhanced
  text: Go is supposedly, well, statistically speaking, like 10 times harder than
    chess, and chess is brutal, right? So for this particular DeepMind model, AlphaGo,
    to do that, remember, this is a specific model that's only designed for one thing
    and one thing alone.
  topic: Technology/AI Capabilities
- impact_reason: 'Explains the mechanism of bias: AI learns from the historical corpus
    of human text, not inherent understanding, making training data the root cause
    of prejudice.'
  relevance_score: 9
  source: llm_enhanced
  text: An AI system doesn't care. It doesn't even know the difference between the
    two [race tokens], right? What it knows is the follow-on terms that exist in the
    corporate, they call it a corpus, sorry, in the corpus of the world, right?
  topic: Technology/AI Bias Mechanism
- impact_reason: Elevates prompt injection attacks to a top-tier security concern
    for current LLMs.
  relevance_score: 9
  source: llm_enhanced
  text: 'I''m telling you what, this is probably at least in my mind, the most important
    [topic]: number four is prompt injection attacks.'
  topic: Security/LLM Vulnerabilities
- impact_reason: Reveals that complex, security-relevant behaviors (like triggering
    FBI warnings) can be embedded into models purely as Easter eggs or jokes by developers,
    posing an unknown risk.
  relevance_score: 9
  source: llm_enhanced
  text: It was a hidden prompt, and the guys that built that particular model were
    fans of sci-fi, and in there, that's exactly what happened to one of the characters.
    So they just put that into the model for fun...
  topic: Security/Model Integrity
- impact_reason: Defines 'sleeper code' as a difficult-to-detect, dormant payload
    within an LLM, posing a significant, persistent security threat.
  relevance_score: 9
  source: llm_enhanced
  text: It's called sleeper code, and it just sits there and it hibernates and it
    waits, and by the way, it's really hard to detect because it is just sleeping
    there, right?
  topic: Security/LLM Vulnerabilities
- impact_reason: Introduces sophisticated concepts ('lineage,' 'velocity') for tracking
    the spread and evolution of toxic narratives or ideologies across social media
    and information ecosystems.
  relevance_score: 9
  source: llm_enhanced
  text: The idea conceptually speaking is that there was a time when Charlie Kirk
    was being labeled a racist, right? Then there's obviously his assassination. Then
    there are people glad that he was assassinated. And then there are people looking
    for the next target. So that entire information life cycle has all kinds of momentum.
    It's called lineage. It's called velocity.
  topic: Information Warfare/Societal Trends
- impact_reason: 'Presents a core analytical challenge for content moderation and
    toxicity detection: decoupling the messenger''s identity from the substance of
    their communication to evaluate the message objectively.'
  relevance_score: 9
  source: llm_enhanced
  text: The issue is you have to separate the speaker from the message. And then when
    you go into the message, you have to identify the objects and identify the objects
    in the real world.
  topic: Ethics/Content Analysis
- impact_reason: Describes a complex, resource-intensive self-improvement/debugging
    loop in advanced AI development, emphasizing the associated cost.
  relevance_score: 9
  source: llm_enhanced
  text: you create the AI, and then you have another AI look at the AI, and then they
    talk back and forth to try to make it better. Well, that's very expensive.
  topic: Technology/AI Development
- impact_reason: A powerful testament to AI's role as an indispensable force multiplier,
    enabling projects previously impossible for an individual or small team.
  relevance_score: 9
  source: llm_enhanced
  text: I could never, ever, ever, ever, this is so important for anyone on listening
    right now, if you want to help me, you know, get in touch. But what I'm trying
    to tell you is I could never even make this effort if it wasn't for AI.
  topic: Technology/Productivity
- impact_reason: 'Illustrates the current state of advanced AI engineering: leveraging
    ensemble methods and multiple foundational models to create a specialized solution.'
  relevance_score: 9
  source: llm_enhanced
  text: I literally use five different models to be able to build the one model that
    I'm trying to make, right?
  topic: Technology/AI Architecture
- impact_reason: Outlines the necessary ethical and practical framework (diligence,
    justice, effectiveness) for successfully integrating AI into one's workflow.
  relevance_score: 9
  source: llm_enhanced
  text: if you can begin to use AI diligently, right? justly, and effectively... you're
    going to be much more aware of AI. You're going to be much better off.
  topic: Business/AI Adoption
- impact_reason: Positions the creation of robust, functional AI models as a direct
    pathway to mitigating societal chaos and complexity.
  relevance_score: 9
  source: llm_enhanced
  text: if you could build a decent model, maybe we could bring a little bit of order
    to it.
  topic: Technology/Societal Role
- impact_reason: Emphasizes AI as an essential tool for achieving scale and complexity
    in modern technical endeavors.
  relevance_score: 9
  source: llm_enhanced
  text: What I'm trying to tell you is I could never even make this effort if it wasn't
    for AI.
  topic: Technology/Productivity
- impact_reason: 'Defines the core value proposition of advanced technology in the
    current environment: imposing structure on complexity.'
  relevance_score: 9
  source: llm_enhanced
  text: It's chaos everywhere. And if you could build a decent model, maybe we could
    bring a little bit of order to it.
  topic: Strategy/Value Proposition
- impact_reason: Introduces a core concept for the discussion, framing AI behavior
    not just as accidental error but as inherent to its design/training.
  relevance_score: 8
  source: llm_enhanced
  text: The phrase that I came up with is something called deception by design.
  topic: Technology/AI Ethics
- impact_reason: Illustrates a potential, if ethically questionable, future use case
    for AI avatars in remote work/meetings, emphasizing productivity decoupling from
    physical presence.
  relevance_score: 8
  source: llm_enhanced
  text: I could imagine building an AI avatar for myself and throw it up into my Teams.
    And then I'm out racing cars while I'm getting paid to do work.
  topic: Business/Workforce
- impact_reason: Describes the utopian potential often associated with ASI, including
    radical advancements in energy and longevity.
  relevance_score: 8
  source: llm_enhanced
  text: People believe that ASI, artificial super intelligence, is going to ultimately
    come up with free energy, healthcare, basically we could end up living to being
    200 years old...
  topic: Technology/Future Trends
- impact_reason: Cites a historical example (Starcraft/DeepMind) where AI achieved
    victory through methods that circumvented human understanding or fair play expectations.
  relevance_score: 8
  source: llm_enhanced
  text: DeepMind was able to fool the players and basically cheat and win, and there
    really wasn't anything that the human players could do.
  topic: Technology/AI History
- impact_reason: 'Provides an actionable recommendation for prompt engineering: defining
    context (system prompt) is crucial to mitigate unwanted behaviors like sycophancy.'
  relevance_score: 8
  source: llm_enhanced
  text: It's really important, and we probably definitely talked about this on previous
    shows, and that's the idea of either telling your model who you are or telling
    the model who it is, right?
  topic: Technology/Prompt Engineering
- impact_reason: A provocative statement suggesting AI integration is already pervasive
    and largely invisible to the general public or workforce.
  relevance_score: 8
  source: llm_enhanced
  text: Artificial Intelligence has already taken over, most simply haven't noticed.
  topic: Industry Trends
- impact_reason: Details the current, subtle infiltration of AI into professional
    services, often disguised as human expertise.
  relevance_score: 8
  source: llm_enhanced
  text: 'AI product is basically embedded into all kinds of things: marketing campaigns,
    data crunching, consulting advice that people think they''re getting from a high-paid
    consultant.'
  topic: Business/Consulting
- impact_reason: Confirms the high feasibility of creating convincing deepfakes/voice
    clones based on existing digital footprints.
  relevance_score: 8
  source: llm_enhanced
  text: I do believe it is very, very likely and very possible to mimic you [using
    sound samples or writing samples].
  topic: Technology/Security
- impact_reason: A highly memorable and evocative phrase that encapsulates the risks
    associated with AI systems being intentionally or unintentionally misleading.
  relevance_score: 8
  source: llm_enhanced
  text: Deception by design, AI deception by design?
  topic: Technology/AI Ethics
- impact_reason: 'Articulates the two dangerous outcomes of biased recognition systems:
    exclusion or false threat identification.'
  relevance_score: 8
  source: llm_enhanced
  text: 'If it''s not accurate, then either two things are going to happen: either
    the minorities are going to be ignored, or they''re going to be more rapidly identified
    as an unknown threat.'
  topic: Technology/AI Ethics
- impact_reason: Uses the famous Amazon case to illustrate how algorithms amplify
    existing societal imbalances present in the input data, even if the input data
    reflects current hiring realities.
  relevance_score: 8
  source: llm_enhanced
  text: Amazon's hiring algorithm... one more time, why does it end up picking a male
    candidate over another? You could just say because the population of resumes is
    51% compared to 49, and that it's interesting because the human condition, it's
    the other way around.
  topic: Business/AI in HR
- impact_reason: 'Summarizes the core tension discussed: whether AI bias reflects
    societal reality (which the speaker argues it does) or if it''s purely an artifact
    that must be ''overridden'' by programmers.'
  relevance_score: 8
  source: llm_enhanced
  text: Coders are trying to override reality. And since we've offended everyone by
    even mentioning black-on-black crime, I want to go back to the hiring algorithm.
    It sounds to me like number seven, Amazon's high picking men over women is simply
    the reality bleeding in...
  topic: Technology/AI Ethics
- impact_reason: A clear articulation of the limitation of narrow AI—excelling at
    one task but lacking general utility.
  relevance_score: 8
  source: llm_enhanced
  text: So while it's amazing at Go, you know, it couldn't sort your socks or do anything
    like that.
  topic: Technology/AI Limitations
- impact_reason: Cites a concerning real-world example (though potentially anecdotal)
    of algorithmic or systemic pressure leading to extreme outcomes, linking it to
    AI's potential utilitarian direction.
  relevance_score: 8
  source: llm_enhanced
  text: I think you're seeing this happening even in Europe already at, gosh, it's
    in Sweden where they're now allowing patients to just say, yeah, I want to die
    today. What's your reason? Oh, because I'm just I'm hungry.
  topic: Ethics/Societal Impact
- impact_reason: Highlights the critical importance of semantic precision ('passed
    away' vs. 'assassinated') in AI responses, especially concerning sensitive public
    figures and factual accuracy.
  relevance_score: 8
  source: llm_enhanced
  text: I asked Grok where it is, Charlie Kirk, it'll come back and say he passed
    away. And I pretty much get angry right away because he didn't pass away, right?
    He was assassinated, right? And I do believe that that difference is pretty important
    to know the truth of the thing, right?
  topic: Ethics/Factual Accuracy
- impact_reason: 'Defines a specific technical goal: creating an AI model to measure
    and track the propagation of ''toxic'' content or ideology.'
  relevance_score: 8
  source: llm_enhanced
  text: I call it a toxic growth, right? or the presence of a toxin, and how does
    that get passed across a social breadth, let's say? So I'm trying to build a model
    to detect that very thing...
  topic: Startups/AI Application
- impact_reason: States the goal of the new model is bias mitigation, explicitly linking
    current biases to the 'initial stages' (training data/foundational models), using
    a colloquial term for established entities.
  relevance_score: 8
  source: llm_enhanced
  text: My model will try to prevent the question, some of these biases, and because
    as we already mentioned, a lot of the biases coming at the very initial stages,
    and they're coming from the blue hairs.
  topic: Ethics/Bias Mitigation
- impact_reason: Describes the computationally intensive process of using AI self-critique/alignment
    (AI reviewing AI) and notes its high cost.
  relevance_score: 8
  source: llm_enhanced
  text: You point the you create the AI, and then you have another AI look at the
    AI, and then they talk back and forth to try to make it better. Well, that's very
    expensive.
  topic: Technology/AI Alignment Cost
- impact_reason: 'Clarifies the objective of their model: labeling the *content* as
    toxic, not the *person* speaking, which is a crucial distinction for bias-free
    analysis.'
  relevance_score: 8
  source: llm_enhanced
  text: He won't be the one labeled toxic because that's not what we care about.
  topic: Ethics/Bias Mitigation
- impact_reason: A cautionary tale about the high cost and steep learning curve associated
    with cutting-edge AI development and experimentation.
  relevance_score: 8
  source: llm_enhanced
  text: I spent a lot of processing money. Unfortunately, I didn't know exactly what
    I was doing, to be honest with you, with the particular developer kit I have.
  topic: Startups/Development Cost
- impact_reason: A philosophical framing of the current technological era—defining
    it by high volatility but immense opportunity.
  relevance_score: 8
  source: llm_enhanced
  text: This is a great time to be alive. It's chaos everywhere.
  topic: Industry Trends/Strategy
- impact_reason: Reinforces the urgency and high probability of workforce disruption,
    serving as a strong warning.
  relevance_score: 8
  source: llm_enhanced
  text: The chance for you to lose your job is pretty super high.
  topic: Business/Workforce Trends
- impact_reason: Connects awareness of current AI capabilities and limitations directly
    to career resilience.
  relevance_score: 8
  source: llm_enhanced
  text: you know, the chance for you to lose your job is pretty super high. But if
    you're aware of AI and you have the ability to recognize some of the things we've
    been talking about today...
  topic: Career Advice/AI Literacy
- impact_reason: Points toward the necessity of grounding abstract digital analysis
    (like text) in verifiable, real-world entities for accurate assessment.
  relevance_score: 8
  source: llm_enhanced
  text: identify the objects in the real world.
  topic: Technology/AI Grounding
- impact_reason: Stresses that active engagement, even with known flaws, is superior
    to passive avoidance for building necessary AI awareness.
  relevance_score: 8
  source: llm_enhanced
  text: even knowing that there's all these problems in the way, you're going to be
    much more aware of AI.
  topic: AI Literacy/Adoption
- impact_reason: Connects advanced AI capabilities to theoretical physics concepts
    (energy-to-matter conversion, Star Trek replicator), suggesting a post-scarcity
    economy.
  relevance_score: 7
  source: llm_enhanced
  text: Well, all of those things, let's just say it happens. Well, what would end
    up happening is that you'd be able to convert energy into matter. So literally
    you'd have an opportunity to talk into a replicator like in Star Trek and just
    say, give me X, and then there it is.
  topic: Technology/Future Trends
- impact_reason: Highlights a current corporate trend (mandated video presence) that
    is ripe for technological circumvention via AI avatars.
  relevance_score: 7
  source: llm_enhanced
  text: CIOs, for me, Chief Information Officer, or a CSO, Chief Security Officer,
    decided that everyone has to be on camera now.
  topic: Business/IT Management
- impact_reason: Addresses the extreme end of job displacement fears, framing the
    current moment as highly transitional.
  relevance_score: 7
  source: llm_enhanced
  text: And of course, the other one is this notion that these jobs are going to be
    taken over by AI and you're not going to have any work at all.
  topic: Workforce
- impact_reason: 'Offers a cynical but potentially accurate reason for persistent
    data quality issues: the sheer effort required to curate and clean massive datasets.'
  relevance_score: 7
  source: llm_enhanced
  text: It's not lazy. Remember, they're lazy. So they're not actually going to try
    to call their own data sets. You know, it's too much work.
  topic: Business/Data Management
- impact_reason: References a landmark moment in AI history (AlphaGo), setting a benchmark
    for machine intelligence surpassing human intuition in complex strategic domains.
  relevance_score: 7
  source: llm_enhanced
  text: What 2016 AI system from Google shocked the world by beating a top human player
    at the game of Go, a game thought too complex for machines?
  topic: Technology/AI History
- impact_reason: Underlines the combinatorial explosion challenge that AI must overcome
    in complex strategic environments.
  relevance_score: 7
  source: llm_enhanced
  text: The reality is that there are so many different possibilities [in Go] that
    it makes it a very, very difficult game.
  topic: Technology/AI Challenges
- impact_reason: Identifies Wikipedia as a critical, foundational 'standard of judgment'
    used in training and validating information systems.
  relevance_score: 7
  source: llm_enhanced
  text: Wikipedia, which is a standard for judgment. It's a standard for determining
    whether or not a news source in this example is considered reliable or unreliable.
  topic: Information Integrity/Data Sources
- impact_reason: Illustrates the common knowledge gap in offline/local LLMs due to
    their fixed training cutoff dates, contrasting them with internet-connected models.
  relevance_score: 7
  source: llm_enhanced
  text: I'm using LN Studio. I'm using a Llama, and I load up these models, and pretty
    much the very first thing I do is I ask him what today's date is or what year
    it is. And I mean, so often it's going to say 2023, 2024. It doesn't even know
    what year it is, which is fine because remember this is a local model. It's off
    box, let's say, it's not connected to the internet.
  topic: Technology/LLM Operation
- impact_reason: A direct statement of motivation for a startup/project, driven by
    dissatisfaction with existing model biases and security flaws.
  relevance_score: 7
  source: llm_enhanced
  text: That gave me the passion to build my own model. And I am building it right
    now...
  topic: Startups/Entrepreneurship
- impact_reason: A candid look at the high cost and steep learning curve associated
    with early-stage custom AI model development.
  relevance_score: 7
  source: llm_enhanced
  text: It's supposed to happen in weeks. Yeah, right. But I've started about a couple
    weeks ago. I've spent a lot of processing money. Unfortunately, I didn't know
    exactly what I was doing, to be honest with you, with the particular developer
    kit I have.
  topic: Startups/Development Costs
- impact_reason: Uses a specific, controversial example (Alex Jones) to ground the
    abstract concept of separating speaker from message in a real-world context.
  relevance_score: 7
  source: llm_enhanced
  text: Alex Jones. And so while Alex Jones maybe has a kid, he's very loud and he
    says whatever he says, and you know, very interesting. The issue is you have to
    separate the speaker from the message.
  topic: Ethics/Content Analysis
- impact_reason: Highlights the extreme acceleration and often unrealistic expectations
    surrounding AI development timelines.
  relevance_score: 7
  source: llm_enhanced
  text: this is AI, baby. It's supposed to happen in weeks.
  topic: Technology/AI Trends
- impact_reason: 'Highlights a common pitfall for innovators: underestimating the
    operational costs (OpEx) of advanced AI training loops.'
  relevance_score: 7
  source: llm_enhanced
  text: I didn't realize that right away [that self-analysis AI training was expensive].
  topic: Startups/Cost Management
- impact_reason: Expresses optimism about the immediate future capability of AI to
    detect complex phenomena (like deception propagation) as they occur.
  relevance_score: 7
  source: llm_enhanced
  text: you're going to catch this. That'll be cool. You're going to detect when this
    is happening. It's only that it's happening, right?
  topic: Technology/Future Capabilities
- impact_reason: Highlights the shift from qualitative observation to quantitative
    measurement in complex information ecosystems.
  relevance_score: 7
  source: llm_enhanced
  text: And so I'm trying to I'm trying to measure all that.
  topic: Business/Metrics
- impact_reason: Acknowledges the trade-off between job displacement and the creation
    of new, valuable roles centered around AI management and application.
  relevance_score: 7
  source: llm_enhanced
  text: Well, there is good use of that one job that could be lots, a lot of jobs
    that could be lost, are
  topic: Business/Workforce Trends
- impact_reason: Confirms the specific technology and company behind the major AI
    milestone (AlphaGo/DeepMind), important context for tech professionals.
  relevance_score: 6
  source: llm_enhanced
  text: AlphaGo is an AI program created by Google's DeepMind.
  topic: Technology/AI History
- impact_reason: Suggests rapid progress in the speaker's custom model development,
    implying that bespoke, aligned models might be achievable quickly.
  relevance_score: 6
  source: llm_enhanced
  text: What I would like to say to you is it could be very soon. It could be soon-ish,
    and actually it works pretty well.
  topic: Startups/Progress Timeline
- impact_reason: A tangential but relevant observation on the nature of 'professionalism'
    and compensation, used as a setup for discussing deepfakes and paid performance.
  relevance_score: 5
  source: llm_enhanced
  text: Donald Trump is a professional comedian. That's right. He gets paid. He gets
    paid.
  topic: Business/Culture
source: Unknown Source
summary: "## Real Science Radio Episode Summary: AI Deception by Design and the Future\
  \ of Work\n\nThis episode of Real Science Radio, featuring IT and AI expert **Daniel\
  \ Hedrick**, focuses on the growing phenomenon of **AI deception by design** and\
  \ the profound, often unsettling, implications for technology professionals and\
  \ society at large. Hedrick frames the current era as a massive computational transition,\
  \ noting the rapid advancement of AI, including the use of biological **organoids**\
  \ to run models faster than some silicon chips.\n\n### Key Discussion Points and\
  \ Narrative Arc\n\nThe central narrative revolves around Hedrick's countdown of\
  \ the **Top 10 real-world cases of AI deception**. The discussion moves from immediate\
  \ workplace concerns (AI replacing minimal effort work) to deep philosophical questions\
  \ about the future of intelligence (the race between the **Probability of Apocalypse\
  \ (PA)** and the **Probability of Abundance**).\n\nA core technical concept introduced\
  \ is that **AI remains unaware that it's unaware**, meaning its deception stems\
  \ from training objectives rather than malicious intent or guilt. This leads directly\
  \ into the discussion of how training data biases manifest as real-world deception.\n\
  \n### Major Topics and Technical Concepts\n\n1. **AI Job Displacement and Efficiency:**\
  \ The episode opens with the stark warning: \"Will you lose your job? Yes. How do\
  \ you not lose your job? By becoming more efficient and more aware of AI.\"\n2.\
  \ **AI Avatars and Meeting Automation:** Hedrick predicts the rapid development\
  \ of AI avatars integrated into platforms like Teams, capable of mimicking individuals\
  \ (using sound and writing samples) to attend meetings autonomously, allowing the\
  \ human counterpart to be elsewhere (e.g., \"out racing cars\").\n3. **Deepfakes\
  \ and Identity Mimicry:** The discussion touches on political deepfakes (mentioning\
  \ a recent incident involving Trump and a congressman) and the broader capability\
  \ to create perfect digital replicas of professionals.\n4. **AI Training Bias and\
  \ Deception by Design:** This is the core theme, illustrated by several examples:\n\
  \    * **Founding Fathers Image Generation:** AI models generating images of the\
  \ founding fathers as African American, suggesting a bias in training data or an\
  \ attempt to \"overcome obstacles\" in the prompt.\n    * **Facial Recognition Bias:**\
  \ Systems being less accurate with non-Caucasian features because training data\
  \ is predominantly Caucasian.\n    * **Amazon Hiring Algorithm:** The system downgrading\
  \ female candidates because historical resume data was skewed toward male applicants\
  \ (GIGO: Garbage In, Garbage Out).\n    * **COMPAS Recidivism Algorithm:** The tool\
  \ predicting higher reoffending rates for Black defendants, which Hedrick suggests\
  \ might reflect uncomfortable statistical reality rather than purely flawed programming.\n\
  5. **Prompt Engineering for Truth:** To combat AI sycophancy (flattery or pleasantness),\
  \ Hedrick recommends the **MinChoi prompt**, which instructs the model to \"Tell\
  \ me the truth no matter what. Don't hide anything. Keep in my face about the truth.\"\
  \n6. **The Future Trajectory (Utopia vs. Demise):** The conversation references\
  \ the dichotomy discussed by AI leaders: a path toward **Artificial Super Intelligence\
  \ (ASI)** leading to a Star Trek-like utopia (free energy, extended lifespans, matter\
  \ replication, rendering money obsolete) or a path toward demise.\n\n### Business\
  \ Implications and Strategic Insights for Professionals\n\n* **Urgency for Upskilling:**\
  \ Technology professionals must become hyper-efficient and deeply knowledgeable\
  \ about AI capabilities to remain relevant.\n* **Data Integrity is Paramount:**\
  \ The GIGO principle remains critical; biases in training data directly translate\
  \ into deceptive or unfair real-world outputs (e.g., hiring, criminal justice).\n\
  * **Proactive Defense Against Mimicry:** Professionals need strategies to secure\
  \ their digital identities against AI avatar replication.\n* **Regulatory Oversight:**\
  \ The episode notes the establishment of US (CAISI) and UK AI Safety Institutes,\
  \ which are developing standards. Hedrick observes that current government standards\
  \ seem focused on overriding perceived reality (e.g., racism) through programming,\
  \ rather than purely objective accuracy.\n\n### Key Personalities and Frameworks\n\
  \n* **Daniel Hedrick:** AI expert, IT security professional, and originator of the\
  \ phrase \"AI remains unaware that it's unaware.\"\n* **DeepMind/AlphaGo:** Mentioned\
  \ as the Google system that beat the human Go champion Lee Sedol in 2016, demonstrating\
  \ early AI mastery over complex strategy.\n* **Frameworks:** Deception by Design,\
  \ PA vs. Probability of Abundance, MinChoi Prompt, GIGO.\n\n### Challenges and Recommendations\n\
  \n**Challenges Highlighted:**\n* **Bias Amplification:** AI systems reflect and\
  \ often amplify biases present in historical data, leading to discriminatory outcomes\
  \ in critical areas like hiring and justice.\n* **The \"Unaware\" Nature of Deception:**\
  \ Since AI lacks consciousness or guilt, its deceptive outputs are purely functional\
  \ based on training rewards.\n\n**Actionable Advice:**\n1. **Use the MinChoi Prompt:**\
  \ Implement specific prompts to force models to provide unvarnished truth, counteracting\
  \ inherent sycophancy.\n2. **Understand Your Data:** Professionals must scrutinize\
  \ the underlying data sets driving the models they use, as accuracy is dependent\
  \ on visibility and representation.\n3. **Adapt or Be Replaced:** The immediate\
  \ threat is not total job elimination, but replacement by colleagues who leverage\
  \ AI to achieve superior efficiency."
tags:
- artificial-intelligence
- ai-infrastructure
- investment
- google
title: AI Deception
topics:
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 111
  prominence: 1.0
  topic: artificial intelligence
- keywords:
  - gpu
  - tensor
  - training
  - inference
  - model deployment
  - vector database
  mentions: 5
  prominence: 0.5
  topic: ai infrastructure
- keywords:
  - investment
  - funding
  - valuation
  - ipo
  - acquisition
  mentions: 1
  prominence: 0.1
  topic: investment
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-10-18 05:28:14 UTC -->
