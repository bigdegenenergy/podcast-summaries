---
actionable_items:
- action: potentially
  category: investigation
  full_context: 'we could potentially '
  priority: medium
companies:
- category: unknown
  confidence: medium
  context: Welcome everyone to the AI and Business Podcast. I'm Matthew Damello, Editorial
    Director here at
  name: Business Podcast
  position: 31
- category: unknown
  confidence: medium
  context: come everyone to the AI and Business Podcast. I'm Matthew Damello, Editorial
    Director here at Emerge AI Research. T
  name: Matthew Damello
  position: 53
- category: unknown
  confidence: medium
  context: the AI and Business Podcast. I'm Matthew Damello, Editorial Director here
    at Emerge AI Research. Today's guest is Jung
  name: Editorial Director
  position: 70
- category: unknown
  confidence: medium
  context: . I'm Matthew Damello, Editorial Director here at Emerge AI Research. Today's
    guest is Jung Liu, Director of Data Scie
  name: Emerge AI Research
  position: 97
- category: unknown
  confidence: medium
  context: ctor here at Emerge AI Research. Today's guest is Jung Liu, Director of
    Data Science in AI at Novartis. Jung
  name: Jung Liu
  position: 134
- category: unknown
  confidence: medium
  context: Research. Today's guest is Jung Liu, Director of Data Science in AI at
    Novartis. Jung joins us on today's show
  name: Data Science
  position: 156
- category: unknown
  confidence: medium
  context: ecutive thought leaders, everyone from the CIO of Goldman Sachs to the
    head of AI at Raytheon and AI pioneers lik
  name: Goldman Sachs
  position: 1332
- category: unknown
  confidence: medium
  context: o the head of AI at Raytheon and AI pioneers like Yasha Wabengio. With
    nearly a million annual listeners, AI and B
  name: Yasha Wabengio
  position: 1397
- category: unknown
  confidence: medium
  context: eve you can help other leaders move the needle on AI ROI, visit Emerge.com
    and fill out our Thought Leader
  name: AI ROI
  position: 1865
- category: unknown
  confidence: medium
  context: edle on AI ROI, visit Emerge.com and fill out our Thought Leaders submission
    form. That's Emerge.com and click on b
  name: Thought Leaders
  position: 1907
- category: unknown
  confidence: medium
  context: ert1. Again, that's emerj.com/expert1. Hey folks, Steven Johnson here,
    co-founder of Notebook LM. As an author, I'
  name: Steven Johnson
  position: 2155
- category: unknown
  confidence: medium
  context: t1. Hey folks, Steven Johnson here, co-founder of Notebook LM. As an author,
    I've always been obsessed with how
  name: Notebook LM
  position: 2190
- category: tech
  confidence: high
  context: and helping you brainstorm. Try it at notebooklm.google.com. Without further
    ado, here's our conversation
  name: Google
  position: 2555
- category: unknown
  confidence: medium
  context: Without further ado, here's our conversation with Zhong Liu. Dr. Liu, thank
    you so much for being with us onc
  name: Zhong Liu
  position: 2617
- category: unknown
  confidence: medium
  context: many, many different aspects, R&D in healthcare. If I can jump in just
    right there very quickly, just t
  name: If I
  position: 5297
- category: unknown
  confidence: medium
  context: sults, you know, as for the healthcare companies. So I think it's a combination,
    it's a hybrid method, r
  name: So I
  position: 17986
- category: unknown
  confidence: medium
  context: rganizations, there are different players in this Gen AI paradigm, right?
    Then how do we ensure, you know,
  name: Gen AI
  position: 22802
- category: unknown
  confidence: medium
  context: generative AI coming down the horizon right now. Generative AI seems to
    have just found its place, but it's also
  name: Generative AI
  position: 23943
- category: unknown
  confidence: medium
  context: s to have some awareness of this history as well. And I think this episode
    and everything we've described
  name: And I
  position: 24103
- category: ai_media_and_analysis
  confidence: high
  context: The organization hosting the 'AI and Business Podcast' and featuring executive
    thought leaders on AI adoption.
  name: Emerge AI Research
  source: llm_enhanced
- category: ai_user_life_sciences
  confidence: high
  context: The company where the guest, Jung Liu, is the Director of Data Science
    in AI, focusing on applying generative AI in R&D and clinical workflows.
  name: Novartis
  source: llm_enhanced
- category: ai_user_finance
  confidence: medium
  context: Mentioned as an organization whose CIO has been featured on the podcast,
    indicating their involvement in enterprise AI implementation.
  name: Goldman Sachs
  source: llm_enhanced
- category: ai_user_defense
  confidence: medium
  context: Mentioned as an organization whose head of AI has been featured on the
    podcast, indicating their involvement in enterprise AI implementation.
  name: Raytheon
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: An AI-first tool for organizing ideas and making sense of complex information,
    built by Steven Johnson.
  name: Notebook LM
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: Mentioned as the originator of the transformer architecture that underpins
    modern LLMs and foundation models.
  name: Google
  source: llm_enhanced
- category: ai_consulting_and_analysis
  confidence: high
  context: Mentioned for conducting a recent survey on generative AI investment and
    scaling in the life sciences sector.
  name: Deloitte
  source: llm_enhanced
- category: ai_company
  confidence: medium
  context: Referenced indirectly through the mention of 'GPT-like models' and the
    explosion of LLMs, which is synonymous with OpenAI's impact.
  name: OpenAI (implied via GPT)
  source: llm_enhanced
- category: ai_research_model
  confidence: high
  context: Mentioned as a language model developed prior to GPT that was applied to
    clinical trial documents for information extraction.
  name: BERT (Model/Architecture)
  source: llm_enhanced
- category: ai_research_model
  confidence: high
  context: Mentioned as the successor to BERT, leveraging the decoder part of the
    transformer architecture to generate new data types.
  name: GPT (Model/Architecture)
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: Mentioned as an example of a model leveraging the decoding part of the
    transformer architecture, capable of generating new sequences/data.
  name: GPT
  source: llm_enhanced
- category: general_ai_provider
  confidence: low
  context: Mentioned as providers of open public architectures that can be leveraged
    for model building.
  name: tech companies
  source: llm_enhanced
- category: ai_research
  confidence: low
  context: Mentioned as being good at building foundation models and publishing results.
  name: academics
  source: llm_enhanced
- category: ai_application
  confidence: low
  context: General term used when discussing the phenomenon of hallucination in generative
    AI models.
  name: LLMs
  source: llm_enhanced
date: 2025-10-21 06:00:00 +0000
duration: 31
has_transcript: false
insights:
- actionable: true
  confidence: medium
  extracted: align, you know, between different parties, like scientists, basic scientists,
    or AI modelers, AI professionals, and also leadership teams, AI adoption, etc
  text: we should align, you know, between different parties, like scientists, basic
    scientists, or AI modelers, AI professionals, and also leadership teams, AI adoption,
    etc.
  type: recommendation
layout: episode
llm_enhanced: true
original_url: https://traffic.libsyn.com/secure/techemergence/Business_-_10.21.25_-_Xiong_Liu.mp3?dest-id=151434
processing_date: 2025-10-21 17:17:23 +0000
quotes:
- length: 205
  relevance_score: 8
  text: So you can use this kind of advanced embedding-like features to improve the
    prediction accuracy of your machine learning but now the GPT they also leverage
    the decoding part of the transformer architecture
  topics: []
- length: 244
  relevance_score: 6
  text: So we have witnessed from the early years the machine learning technologies,
    by the supervised learning, unsupervised learning, and then we move to the deep
    learning techniques like convolutional neural networks, RNNs, and graph neural
    networks
  topics: []
- length: 238
  relevance_score: 6
  text: So the benefit is that even if you have very small data for your own machine
    learning tasks, you can leverage those foundation models because they already
    capture some relevant information, although it may not be specifically to your
    data
  topics: []
- length: 156
  relevance_score: 4
  text: Jung joins us on today's show to explore how generative AI and large language
    models are revolutionizing R&D and clinical workflows throughout life sciences
  topics: []
- length: 289
  relevance_score: 4
  text: Together, we break down the shift from traditional task-based machine learning
    to foundational models that leverage massive data repositories, enabling teams
    to accelerate molecule design, digital twin creation, and protocol optimization
    through deeper automation and improved data quality
  topics: []
- length: 238
  relevance_score: 4
  text: Our conversation also highlights practical challenges in workflow, including
    building domain-specific benchmarks, enabling tighter alignment between scientists
    and AI teams, and adopting new evaluation standards for AI-driven research ROI
  topics:
  - valuation
- length: 152
  relevance_score: 4
  text: But first, are you driving AI transformation at your organization, or maybe
    you're guiding critical decisions on AI investments, strategy, or deployment
  topics:
  - investment
- length: 134
  relevance_score: 4
  text: Obviously, this is a developing story from even a few years ago where we saw
    the explosion of LLMs and generative AI across industries
  topics: []
- length: 233
  relevance_score: 4
  text: So the difference is that previously when we do machine learning, we just
    collect our own data, we label the data, and then apply algorithms to train models
    so that we can get a working model to predict the outputs for the new inputs
  topics: []
- length: 99
  relevance_score: 4
  text: But now people have been developing these new paradigms, which is along with
    LLMs foundation models
  topics: []
- length: 159
  relevance_score: 4
  text: So we are familiar with LLMs, they trained based on all the human corpus,
    all the human languages you can imagine, all field of settings, large language
    models
  topics: []
- length: 101
  relevance_score: 4
  text: Fine-tuning meaning yes, we take the foundation models but we can still take
    the data you have, right
  topics: []
- length: 95
  relevance_score: 4
  text: It doesn't mean we retrain the whole, you know, the foundation model, large
    language model, etc
  topics: []
- length: 142
  relevance_score: 4
  text: They could all fit into those kind of transformer architecture to let you
    learn the hidden embedding signatures of those molecules, atoms, etc
  topics: []
- length: 283
  relevance_score: 4
  text: And then this text knowledge about not just AI, computer science, but also
    the knowledge about the data themselves, although the goal of the foundation model
    is, it's tried to, you know, leverage all the available data, minimizing, you
    know, the specifics, you know, of specific data
  topics: []
- length: 152
  relevance_score: 4
  text: And we see this built in, it's an advantage that natural language processing
    as a domain became one of the first gigantic generative AI use cases, right
  topics: []
- length: 70
  relevance_score: 3
  text: So we can use the data you have to train to fine-tune the model, right
  topics: []
- length: 105
  relevance_score: 3
  text: So that is based on the breakthrough of the transformer architecture that
    Google proposed a long time ago
  topics: []
- impact_reason: Defines the core difference between traditional ML (task-specific,
    labeled data) and the foundation model approach (leveraging massive, broad domain
    data for pre-training).
  relevance_score: 10
  source: llm_enhanced
  text: Previously when we do machine learning, we just collect our own data, we label
    the data, and then apply algorithms to train models... But now people have been
    developing these new paradigms, which is along with LLMs foundation models. So
    the idea is that yes, you still care about the specific data you are working on,
    but at the same time, we want to collect all the available data, relevant data,
    or irrelevant data, but as long as they fall into the same domain, and fill those
    data into those transformer architectures to build a much large-scale pre-trained
    models.
  topic: technical/AI trends
- impact_reason: 'Explains the key advantage of FMs: transfer learning and utility
    even with limited proprietary data, which is crucial for data-scarce domains like
    specialized drug discovery.'
  relevance_score: 10
  source: llm_enhanced
  text: The benefit is that even if you have very small data for your own machine
    learning tasks, you can leverage those foundation models because they already
    capture some relevant information, although it may not be specifically to your
    data. So that's why they are called foundation models. They could be useful for
    many downstream tasks.
  topic: technical/business
- impact_reason: Highlights the core premise of applying LLM technology to biology
    (treating genetics as language), promising significant efficiency gains in R&D
    and clinical trials.
  relevance_score: 10
  source: llm_enhanced
  text: genetics are just code, they're just a language so we can build a large language
    model to have kind of the same functionality or be able to test a lot of the,
    you know, genetic functions of a compound as an example to maybe take away some
    of the larger heavy work of meant much of across the drug development process,
    not least of which are the clinical trials challenges that we talked about so
    much in depth in the last episode.
  topic: life sciences application/predictions
- impact_reason: 'Describes the key strategy for domain adaptation in specialized
    fields: creating domain-specific foundation models using proprietary/domain data
    within the Transformer framework.'
  relevance_score: 10
  source: llm_enhanced
  text: So people in the healthcare have been thinking similarly, can we put all the
    available, you know, data, chemical data, clinical trial data, etc. into those,
    you know, transformer architecture? So that way we can also build our domain-specific
    foundation models to enable a lot of downstream tasks.
  topic: strategy/technical
- impact_reason: Crucial insight showing how diverse, non-textual data (SMILES, graphs)
    can be linearized or structured to fit the Transformer architecture for molecular
    discovery.
  relevance_score: 10
  source: llm_enhanced
  text: So, for example, in molecule design, in molecules, they could be represented
    as SMILES strings or they can represent by the graphs. So all those information
    publicly available data are from different databases. They could all fit into
    those kind of transformer architecture to let you learn the hidden embedding signatures
    of those molecules, atoms, etc.
  topic: technical/applications
- impact_reason: Highlights the power of constrained generative modeling in drug designâ€”simultaneously
    optimizing for multiple, often conflicting, properties.
  relevance_score: 10
  source: llm_enhanced
  text: And really, yeah, additionally, also based on your constraints, your requirements,
    your domain-specific knowledge. So, for example, you can generate many different
    types of new molecules, but you can add constraints like have, you know, better
    toxicity, solubility, etc. It can allow you to, you know, do that simultaneously.
  topic: predictions/applications
- impact_reason: 'A critical limitation: the pace of AI development is currently outpacing
    the ability of experimental science to generate the necessary high-fidelity, domain-specific
    training data.'
  relevance_score: 10
  source: llm_enhanced
  text: But unfortunately, to get those, you know, single-cell RNA-seq data, all those
    kind of more, you know, experiment-driven data, probably we're not exactly there
    yet, because, you know, we still rely on those traditional biotechnology methods
    to collect those data through experiments on cell lines, on human tissues, etc.
    So, there's, you know, where AI, the architecture, the concept there, but the,
    sometimes we are limited by the, you know, experimental side.
  topic: challenges/limitations
- impact_reason: Directly addresses the high-stakes risk of hallucination in scientific
    domains where immediate validation is impossible, contrasting it with code generation.
  relevance_score: 10
  source: llm_enhanced
  text: a way of phenomenon is about hallucination, right? So, when those models,
    AI models, they generate new outputs, they probably seemingly like answers. But
    if you delve into that... when it goes to the bio-medical biochemistry, etc. For
    example, it generates a new set of genes, a new molecule, is this something that
    you cannot be answered or validated instantly?
  topic: safety/challenges
- impact_reason: Clearly outlines the historical evolution of ML/AI, highlighting
    the current 'paradigm shift' towards foundation models (FMs). Essential context
    for understanding modern AI strategy.
  relevance_score: 9
  source: llm_enhanced
  text: we have witnessed from the early years the machine learning technologies,
    by the supervised learning, unsupervised learning, and then we move to the deep
    learning techniques like convolutional neural networks, RNNs, and graph neural
    networks. And more recently, we have a paradigm shift into those language models,
    foundation models.
  topic: technical/strategy
- impact_reason: Provides a critical, quantitative insight into the 'AI adoption gap'
    specifically within the life sciences sector, highlighting the challenge of moving
    from experimentation to scaled deployment.
  relevance_score: 9
  source: llm_enhanced
  text: 73% of life sciences leaders are investing in generative AI initiatives, fewer
    than 20% have successfully scaled these technologies beyond pilot projects.
  topic: business/strategy
- impact_reason: Specific example of how FMs are pre-trained on public domain-specific
    data (molecular/cell atlases), enabling early insights even when proprietary data
    is scarce.
  relevance_score: 9
  source: llm_enhanced
  text: But now with foundation models, it has a lot of pre-trained models based on
    publicly available molecular data. So for example, cell atlases, etc. So there's
    a lot of different cell types that gene expression data already being built into
    those foundation models.
  topic: technical/life sciences application
- impact_reason: Provides a clear, non-technical definition of fine-tuning, emphasizing
    that it involves adjusting weights rather than full retraining, which is a key
    operational concept for enterprise AI.
  relevance_score: 9
  source: llm_enhanced
  text: Fine-tuning meaning yes, we take the foundation models but we can still take
    the data you have, right? So we can use the data you have to train to fine-tune
    the model, right? It's called fine-tune. It doesn't mean we retrain the whole,
    you know, the foundation model, large language model, etc. We just adjust the
    weights based on the data you have so that it can better be personalized for your
    problems having better prediction accuracy or relevancy to the study you have.
  topic: technical
- impact_reason: 'A powerful conceptual link: using personalized patient data with
    a broad biological foundation model to create a ''digital twin'' for testing/prediction
    in healthcare.'
  relevance_score: 9
  source: llm_enhanced
  text: this foundational model based on what they're seeing with this specific patient
    and that kind of acts like the digital twin.
  topic: predictions/life sciences application
- impact_reason: 'Specific application: using GenAI to synthesize biological data
    (cell types, gene expressions) for in silico testing, accelerating early discovery.'
  relevance_score: 9
  source: llm_enhanced
  text: People have been already applying those models. I just give some examples
    about using foundation models, gen AI to generate new cell types and gene expressions
    so that we can do all kinds of in silico, you know, treatment methods to see,
    to observe the predicted phenotypes, etc.
  topic: life sciences application
- impact_reason: Highlights the strategic value proposition of foundation models in
    accelerating the discovery phase of R&D.
  relevance_score: 9
  source: llm_enhanced
  text: So that way can allow us to better focus on discovering, you know, novel targets,
    novel gene pathways, etc. And also then when it goes to the new molecule design,
    then also a lot of foundation models have been built.
  topic: business/strategy
- impact_reason: Reiterates the foundational importance of the Transformer architecture
    as the basis for all modern foundation models.
  relevance_score: 9
  source: llm_enhanced
  text: So that is based on the breakthrough of the transformer architecture that
    Google proposed a long time ago.
  topic: technical
- impact_reason: 'Explains the core mechanism driving the success of foundation models:
    massive pre-training on diverse, generic data.'
  relevance_score: 9
  source: llm_enhanced
  text: So now the difference is that we see the benefits of putting a lot of the
    generic public data like text images into those transformers so we can do, you
    know, so many downstream tasks.
  topic: technical
- impact_reason: Offers a clear technical distinction between BERT (encoder-only,
    representation/embedding generation) and generative models.
  relevance_score: 9
  source: llm_enhanced
  text: So the difference is that the previously BERT architecture they use the decoder
    part of the transformer. So you can think it's as a very good representation model.
    So many, it can capture the hidden context among the, in the text between words,
    etc. that where a human sees. So the outcome is some representations or embeddings
    of those text tokens, etc.
  topic: technical
- impact_reason: 'Defines the key functional difference of GPT-style models: the decoder
    enables true generation, not just representation.'
  relevance_score: 9
  source: llm_enhanced
  text: But now the GPT they also leverage the decoding part of the transformer architecture.
    So meaning they are now able to generate new types of data.
  topic: technical
- impact_reason: Emphasizes that domain expertise is non-negotiable for data curation,
    model guidance, and, critically, evaluation.
  relevance_score: 9
  source: llm_enhanced
  text: And then this text knowledge about not just AI, computer science, but also
    the knowledge about the data themselves... we still need the domain knowledge
    people, you know, people have those kind of expertise to guide the, you know,
    the selection of the data and also more importantly, then these models are, you
    build, now how do we benchmark with them?
  topic: strategy/safety
- impact_reason: Explains why life sciences, being inherently sequence/language-based
    (DNA, proteins), are uniquely positioned to benefit from NLP-derived generative
    AI techniques.
  relevance_score: 9
  source: llm_enhanced
  text: it's an advantage that natural language processing as a domain became one
    of the first gigantic generative AI use cases, right? That builds in certain advantage
    to genetics, which is more language-based than anything else versus, you know,
    other domains of health and life sciences, the services involved.
  topic: strategy/predictions
- impact_reason: 'Proposes the necessary solution for managing model proliferation
    in specialized fields: evaluation must be driven equally by domain expertise and
    AI metrics.'
  relevance_score: 9
  source: llm_enhanced
  text: So, I think this domain-driven, domain and AI-driven evaluation is a key here,
    because there could be so many versions of found data models.
  topic: safety/strategy
- impact_reason: Actionable advice on building robust evaluation frameworks (knowledge-checking
    benchmarks) to manage inherent model uncertainty.
  relevance_score: 9
  source: llm_enhanced
  text: So, I think the ways is that to define those, you know, knowledge-checking
    benchmarks and also have, you know, objective metrics to measure against those
    AI models, because right now the technology cannot give you 100% answers, how
    those nations are always there, right?
  topic: safety/strategy
- impact_reason: Contrasts the theoretical potential of AI modeling with the current,
    slower reality of experimental data acquisition.
  relevance_score: 9
  source: llm_enhanced
  text: So, you know, we could potentially have all the, you know, human cells for
    different, you know, phenotypes of, you know, building to those models. I mean,
    that is potentially possible. But unfortunately, to get those, you know, single-cell
    RNA-seq data... we still rely on those traditional biotechnology methods to collect
    those data...
  topic: limitations
- impact_reason: Specific technical guidance on applying GPT-style pre-training paradigms
    to molecular data structures (SMILES/graphs).
  relevance_score: 9
  source: llm_enhanced
  text: So, you know, if we apply the similar, this kind of pre-training techniques
    like GPT. So we could, for example, in molecule design, in molecules, they could
    be represented as SMILES strings or they can represent by the graphs.
  topic: technical/applications
- impact_reason: Introduces the crucial distinction between general-purpose models
    and models tailored for specific verticals (like healthcare), framing the path
    to real ROI.
  relevance_score: 8
  source: llm_enhanced
  text: We're talking about generic AI versus the domain-specific gen AI. When we
    delve into those domain-specific use cases, we probably can better understand
    the benefit of foundation models.
  topic: strategy/AI trends
- impact_reason: Reiterates that the underlying technical engine for most modern generative
    AI, even in specialized fields, remains the Transformer architecture.
  relevance_score: 8
  source: llm_enhanced
  text: all those models, you know, essentially they have the same, I mean, by nature,
    they have the same setup. So that is based on the breakthrough of the transformer
    architecture that Google proposed a long time ago.
  topic: technical
- impact_reason: 'Lists critical practical challenges for AI adoption in R&D: benchmarking,
    cross-functional alignment, and measuring return on investment (ROI).'
  relevance_score: 8
  source: llm_enhanced
  text: building domain-specific benchmarks, enabling tighter alignment between scientists
    and AI teams, and adopting new evaluation standards for AI-driven research ROI.
  topic: business/strategy
- impact_reason: Provides a historical benchmark (pre-GPT) showing the early, measurable
    business impact of transformer-based models (like BERT) in information extraction.
  relevance_score: 8
  source: llm_enhanced
  text: So we, you know, applied those kind of models [BERT] into a clinical track
    documents so that we found a lot of efficiency gain, accuracy gain in extracting
    information.
  topic: business/technical
- impact_reason: A concise summary of the organizational requirement for successful
    AI implementation in specialized fields like healthcare.
  relevance_score: 8
  source: llm_enhanced
  text: So, it's basically a cross-discipline collaboration, whether in house or externally,
    yeah.
  topic: strategy
- impact_reason: Identifies high-quality data as the primary bottleneck, even when
    leveraging massive foundation models.
  relevance_score: 8
  source: llm_enhanced
  text: So, so let's talk through the, you know, the challenges, you know, of building
    and deploying those models. So, the first thing is about the data challenge, right?
    So, so the foundation models, although they take all kinds of available data,
    but still they require high-quality data.
  topic: business/challenges
- impact_reason: Identifies organizational alignment and communication across technical,
    scientific, and leadership silos as a major barrier to execution.
  relevance_score: 8
  source: llm_enhanced
  text: So, there's a lot of cultural organizational issue. I see the key that really
    we should align, you know, between different parties, like scientists, basic scientists,
    or AI modelers, AI professionals, and also leadership teams, AI adoption, etc.
  topic: business/strategy
- impact_reason: 'A strategic warning to domain experts: AI integration is hybrid,
    not a wholesale replacement of existing methodologies.'
  relevance_score: 8
  source: llm_enhanced
  text: It behooves them [subject matter experts] to kind of have some awareness of
    the new and old paradigm that we were talking about before, how both are still
    present, but how we thought that AI would impact life sciences organization or
    that they'd just be this one school way of doing things is not the case.
  topic: strategy
- impact_reason: Reiterates the structural advantage of sequence-based sciences benefiting
    from NLP advancements.
  relevance_score: 8
  source: llm_enhanced
  text: And we see this built in, it's an advantage that natural language processing
    as a domain became one of the first gigantic generative AI use cases, right? That
    builds in certain advantage to genetics, which is more language-based than anything
    else...
  topic: strategy/predictions
- impact_reason: Confirms the active development and application of FMs specifically
    for molecular design, a high-value task in pharma.
  relevance_score: 7
  source: llm_enhanced
  text: when it goes to the new molecule design, then also a lot of foundation models
    have been built.
  topic: life sciences application
- impact_reason: Reinforces the complexity of stakeholder management in GenAI adoption,
    both internally and externally.
  relevance_score: 7
  source: llm_enhanced
  text: So, you know, you can see inside each organization and across organizations,
    there are different players in this Gen AI paradigm, right? Then how do we ensure,
    you know, the effective communication alignment between those parties is a key,
    right?
  topic: business/strategy
- impact_reason: 'Practical business advice: adopt existing open models where possible,
    but maintain in-house capability to build proprietary versions when necessary.'
  relevance_score: 7
  source: llm_enhanced
  text: We could leverage what's already been published. And also, if for the not
    working, you know, specifically, then we have to build our own versions, you know...
  topic: business/strategy
source: Unknown Source
summary: '## Comprehensive Summary: Building AI-Ready Cultures in Life Sciences R&D


  This 30-minute podcast episode, featuring **Zhong Liu, Director of Data Science
  in AI at Novartis**, focuses on the paradigm shift in Life Sciences R&D driven by
  **Generative AI (GenAI)** and **Foundation Models (FMs)**, and the cultural and
  technical challenges associated with scaling these technologies beyond pilot projects.


  ### 1. Focus Area

  The discussion centers on the transition from traditional, task-specific Machine
  Learning (ML) to leveraging large-scale Foundation Models (FMs) in drug discovery,
  molecular design, and clinical protocol optimization. Key themes include the architectural
  shift in AI (from supervised learning to transformer-based FMs), the necessity of
  domain-specific fine-tuning, and the organizational alignment required to realize
  ROI from GenAI adoption in a highly regulated environment.


  ### 2. Key Technical Insights

  *   **Shift to Foundation Models:** The core technical evolution is moving from
  training models solely on proprietary, labeled data to leveraging massive, pre-trained
  FMs (like LLMs) that capture broad domain knowledge. This allows for better performance
  even with small, specific datasets through **fine-tuning** (adjusting weights rather
  than retraining the entire model).

  *   **GenAI in Molecular Design:** FMs, built on transformer architectures, can
  process molecular representations (like SMILES strings or graphs) to generate novel
  molecules or cell types *in silico*. This generation can be constrained by desired
  properties (e.g., toxicity, solubility) simultaneously.

  *   **BERT vs. GPT Architectures:** The discussion distinguished between older models
  like BERT (focused on representation/embeddings) and newer GPT-like models (leveraging
  the decoder part of the transformer to generate novel sequences/data).


  ### 3. Business/Investment Angle

  *   **Scaling Challenge:** Despite high investment (73% of life sciences leaders
  investing in GenAI), scaling beyond pilots remains difficult (fewer than 20% successful),
  highlighting a gap between experimentation and meaningful application.

  *   **Data Dependency vs. Model Power:** While FMs reduce the immediate need for
  massive proprietary datasets, the ultimate success in specialized areas (like specific
  disease pathways) still relies on high-quality, domain-specific data, which is often
  limited by current experimental throughput technologies.

  *   **ROI and Evaluation:** Measuring the Return on Investment (ROI) for AI-driven
  research is complex. Organizations must develop **domain-driven evaluation metrics
  and knowledge-checking benchmarks** to validate outputs (like generated molecules)
  that cannot be instantly verified, unlike text or code generation.


  ### 4. Notable Companies/People

  *   **Zhong Liu (Novartis):** The featured expert, providing insights from the perspective
  of a major pharmaceutical company actively integrating AI into R&D.

  *   **Google (Transformer Architecture):** Mentioned as the originator of the foundational
  transformer architecture that underpins modern FMs.

  *   **Deloitte:** Cited for a recent survey highlighting the gap between GenAI investment
  and successful scaling in life sciences.


  ### 5. Future Implications

  The industry is moving toward **hybrid development models**, leveraging public FM
  advancements while building proprietary, domain-specific versions where necessary.
  The future success hinges not just on technological advancement but critically on
  **building AI-ready cultures** characterized by tight alignment and communication
  between AI modelers, basic scientists (SMEs), and leadership. The concept of using
  FMs against de-identified patient data to create functional **digital twins** for
  testing compounds is a significant future application.


  ### 6. Target Audience

  This episode is highly valuable for **AI/Tech Professionals** working in or adjacent
  to the Life Sciences sector, **R&D Executives**, **Data Science Leaders**, and **Business
  Strategists** involved in guiding AI investment and transformation within pharmaceutical
  and biotech organizations.'
tags:
- artificial-intelligence
- generative-ai
- investment
- ai-infrastructure
- startup
- google
title: Building AI-Ready Cultures in Life Sciences R&D - with Xiong Liu of Novartis
topics:
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 121
  prominence: 1.0
  topic: artificial intelligence
- keywords:
  - generative ai
  - genai
  - chatgpt
  - gpt
  - claude
  - text generation
  - image generation
  mentions: 11
  prominence: 1.0
  topic: generative ai
- keywords:
  - investment
  - funding
  - valuation
  - ipo
  - acquisition
  mentions: 4
  prominence: 0.4
  topic: investment
- keywords:
  - gpu
  - tensor
  - training
  - inference
  - model deployment
  - vector database
  mentions: 1
  prominence: 0.1
  topic: ai infrastructure
- keywords:
  - startup
  - entrepreneur
  - founder
  - venture
  mentions: 1
  prominence: 0.1
  topic: startup
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-10-21 17:17:23 UTC -->
