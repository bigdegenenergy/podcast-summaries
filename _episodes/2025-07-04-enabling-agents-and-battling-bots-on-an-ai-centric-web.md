---
companies:
- category: unknown
  confidence: medium
  context: ke it from the AI plus A16Z podcast. A16Z partner Joel De La Garza talks
    with ArcGets CEO David Mitten about buildin
  name: Joel De La Garza
  position: 726
- category: unknown
  confidence: medium
  context: podcast. A16Z partner Joel De La Garza talks with ArcGets CEO David Mitten
    about building internet infrastructure for this n
  name: ArcGets CEO David Mitten
  position: 754
- category: unknown
  confidence: medium
  context: gents as first-class users. In this episode, A16Z Infra Partner Joel De
    La Garza dives into this topic with David Mitten, the CEO
  name: Infra Partner Joel De La Garza
  position: 1696
- category: unknown
  confidence: medium
  context: rtner Joel De La Garza dives into this topic with David Mitten, the CEO
    of ArcGets, a startup building developer
  name: David Mitten
  position: 1754
- category: unknown
  confidence: medium
  context: enabling that. Right, things have changed, right? The DDoS problem is still
    there, but it is just almost han
  name: The DDoS
  position: 2696
- category: unknown
  confidence: medium
  context: coming in, it is probably a bot. Very imprecise. And I think the downside
    of that is that you probably b
  name: And I
  position: 4110
- category: tech
  confidence: high
  context: rticularly with AI coming in where something like OpenAI has four or five
    different types of bots. And som
  name: Openai
  position: 6287
- category: tech
  confidence: high
  context: r going to come back. It is kind of like blocking Google from visiting
    your site. So yeah, Google does not
  name: Google
  position: 7327
- category: unknown
  confidence: medium
  context: per important. So like when I ask OpenAI, when is John F. Kennedy's birthday?
    If it does not know the answ
  name: John F
  position: 10498
- category: unknown
  confidence: medium
  context: ht. Yeah. Come on in and buy some stuff. Exactly. And Googlebot, OpenAI,
    they tell you who they are. And then you
  name: And Googlebot
  position: 15802
- category: tech
  confidence: high
  context: request is coming from. So a couple of years ago, Apple announced Privacy
    Pass, which is a hash that is a
  name: Apple
  position: 18799
- category: unknown
  confidence: medium
  context: g from. So a couple of years ago, Apple announced Privacy Pass, which is
    a hash that is attached to every reques
  name: Privacy Pass
  position: 18815
- category: unknown
  confidence: medium
  context: en you are a real person. There is a new one that Clyde Blair recently
    published around doing the same thing fo
  name: Clyde Blair
  position: 19316
- category: unknown
  confidence: medium
  context: es. So that solution is not really going to work. But AI has been used
    in analyzing traffic for at least o
  name: But AI
  position: 25154
- category: investment_vc
  confidence: high
  context: Mentioned as the host of the 'AI plus A16Z podcast' and through its partners
    (Joel De La Garza, A16Z Infra Partner). A16Z (Andreessen Horowitz) is a major
    venture capital firm heavily invested in AI.
  name: A16Z
  source: llm_enhanced
- category: ai_startup
  confidence: high
  context: A startup mentioned as building developer-native security for modern web
    frameworks, including attack detection and bot detection, specifically in the
    context of AI agents.
  name: ArcGets
  source: llm_enhanced
- category: ai_company
  confidence: high
  context: Mentioned multiple times as a primary source of AI agents and crawlers.
    The discussion details their different types of bots (for training, search indexing,
    and real-time summarization).
  name: OpenAI
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Referenced primarily through 'Googlebot,' their web crawler, used as a
    benchmark for good bots that respect standards like robots.txt.
  name: Google
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned specifically as a good bot that follows standards like robots.txt,
    used for search engine indexing.
  name: Googlebot
  source: llm_enhanced
- category: big_tech
  confidence: medium
  context: Mentioned as the origin of the J3 hash algorithm, a technique used for
    fingerprinting requests to identify clients/bots.
  name: Salesforce
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Announced 'Privacy Pass,' a hash/signature system used for authenticating
    requests from users in the Apple ecosystem.
  name: Apple
  source: llm_enhanced
- category: research_standards
  confidence: medium
  context: Mentioned as having a long-running working group on proofing identity,
    relevant to proving humanness online.
  name: NIST
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Cited as an example of an LLM capable of highly accurate analysis (e.g.,
    spotting suspicious emails or sensitive information).
  name: ChatGPT
  source: llm_enhanced
date: 2025-07-04 10:00:00 +0000
duration: 26
has_transcript: false
insights:
- actionable: true
  confidence: medium
  extracted: not really be getting traffic from a data center for our sign-up page
  text: we should not really be getting traffic from a data center for our sign-up
    page.
  type: recommendation
- actionable: false
  confidence: medium
  extracted: distinguishing how criminals are using AI. All we have seen so far
  text: the future of distinguishing how criminals are using AI. All we have seen
    so far is either training, and people have that opinion of whether they want to
    train or not, or it is bots that maybe have got something wrong.
  type: prediction
layout: episode
llm_enhanced: true
original_url: https://mgln.ai/e/1344/afp-848985-injected.calisto.simplecastaudio.com/3f86df7b-51c6-4101-88a2-550dba782de8/episodes/a58119e6-d221-4790-9d67-2eb38195fd1d/audio/128/default.mp3?aid=rss_feed&awCollectionId=3f86df7b-51c6-4101-88a2-550dba782de8&awEpisodeId=a58119e6-d221-4790-9d67-2eb38195fd1d&feed=JGE3yC0V
processing_date: 2025-10-05 04:33:31 +0000
quotes:
- length: 103
  relevance_score: 4
  text: And so you can do that with kind of classic machine learning models and do
    the inference really quickly
  topics: []
- length: 217
  relevance_score: 4
  text: And where I think the interesting thing in the next few years is going to
    be is how we take this new generation of generative AI using LLMs or other types
    of LLM-like technology to do analysis on huge traffic patterns
  topics: []
- length: 174
  relevance_score: 3
  text: So one actually is calling to train the OpenAI models on your site, and that
    is one that probably everyone is thinking about when they think about I want to
    block AI training
  topics: []
- length: 86
  relevance_score: 3
  text: So you have to build up these patterns, understanding the reputation of the
    IP address
  topics: []
- length: 139
  relevance_score: 3
  text: So this is the logic on top of that, because you have to identify who it is
    first before you apply the rules about what you want them to do
  topics: []
- impact_reason: A direct strategic warning against a simplistic, blanket approach
    to AI traffic management, emphasizing the need for nuance.
  relevance_score: 10
  source: llm_enhanced
  text: Then we are going to see an explosion in the traffic coming from these tools,
    and just blocking them just because they are AI is the wrong answer.
  topic: Strategy
- impact_reason: Introduces the key concept of 'agent experience,' a necessary paradigm
    shift for future web infrastructure.
  relevance_score: 10
  source: llm_enhanced
  text: An approach to web and product design that treats agents as first-class users.
  topic: Strategy
- impact_reason: 'Defines the new complexity: AI agents blur the line between ''good''
    and ''bad'' automation, moving beyond simple binary classification.'
  relevance_score: 10
  source: llm_enhanced
  text: The challenge is really about how do you distinguish between the good bots
    and the bad bots, and then with AI changing things, it is bots that might even
    be acting on behalf of humans, right? It is no longer a binary decision.
  topic: Safety/Ethics
- impact_reason: Stresses the absolute necessity of application-layer context for
    making nuanced security/access decisions, contrasting it with network-layer blocking.
  relevance_score: 10
  source: llm_enhanced
  text: But everything else needs the context of the application. You need to know
    where in the application the traffic is coming to. You need to know who the user
    is, the session, and to understand in which case you want to allow or deny that.
  topic: Technical
- impact_reason: Details the heterogeneity of a single provider's (OpenAI) agents,
    proving that a single policy for 'AI' is impossible.
  relevance_score: 10
  source: llm_enhanced
  text: Something like OpenAI has four or five different types of bots. And some of
    them you might want to make a more restrictive decision over. But then others
    are going to be taking actions on behalf of a user search.
  topic: Technical
- impact_reason: Draws a powerful analogy between blocking AI agents and blocking
    search engine crawlers, highlighting the SEO/discoverability impact.
  relevance_score: 10
  source: llm_enhanced
  text: Or you are putting it into some kind of maze where it is seeing your relevant
    content, and then by doing that, you are kind of downranking your site because
    the AI call is never going to come back. It is kind of like blocking Google from
    visiting your site.
  topic: Strategy
- impact_reason: Provides a clear example of malicious agent behavior (scalping) that
    necessitates granular control and rate-limiting, even when the agent is technically
    'acting on behalf of a user.'
  relevance_score: 10
  source: llm_enhanced
  text: If you are building a tool that is going to try and buy all of the concert
    tickets and then sell them on later, that becomes a problem for the concert seller
    because they do not want to do that. They want the true fans to be able to get
    access to those.
  topic: Safety/Ethics
- impact_reason: 'Illustrates the ultimate goal of agent experience management: fine-grained
    control over actions (queueing vs. purchasing) and setting human-enforced limits
    (rate limiting).'
  relevance_score: 10
  source: llm_enhanced
  text: Maybe allow the bot to go to the homepage and sit in a queue. But then when
    you get to the front of the queue, you want the human to actually make the purchase,
    and you want to rate limit that so that maybe the human can only purchase, so
    let us say five tickets.
  topic: Strategy
- impact_reason: Introduces specific, named technical standards (J3/J4 hashing) used
    for device/client fingerprinting based on session metrics, a key defense mechanism.
  relevance_score: 10
  source: llm_enhanced
  text: The next level from that is building up fingerprints and fingerprinting the
    characteristics of the request. It started with the J3 hash, which was invented
    at Salesforce and has now been developed into a J4.
  topic: technical
- impact_reason: 'Highlights a major industry trend: using cryptographic signatures
    tied to paid subscriptions (like iCloud) as a scalable method for proving humanness/legitimacy.'
  relevance_score: 10
  source: llm_enhanced
  text: Apple announced Privacy Pass, which is a hash that is attached to every request
    you make if you are in the Apple ecosystem... Then there is a way to authenticate
    that the request is coming from an individual who has a subscription to iCloud,
    and Apple has their own fraud and assets to allow you to subscribe to iCloud.
    So it is a very, it is an easy assumption to make. If you have a subscription
    and this signature is verified, then you are a real person.
  topic: technical/safety
- impact_reason: 'A powerful prediction about the future internet: AI agents will
    supersede direct human interaction as the dominant traffic source.'
  relevance_score: 10
  source: llm_enhanced
  text: I interact with the internet less and less directly, like almost every day,
    and I am going through some sort of AI type thing... it seems like we are moving
    to a world where almost the layer you describe, the agent type activity you describe,
    will become the primary consumer of everything on the internet.
  topic: predictions
- impact_reason: 'Crucial strategic advice: blanket blocking of AI traffic is counterproductive;
    granular, context-aware policy is required.'
  relevance_score: 10
  source: llm_enhanced
  text: And just blocking them just because they are AI is the wrong answer. You have
    really got to understand why you want them, what they are doing, who they are
    coming from, and then you can create these granular rules.
  topic: strategy
- impact_reason: 'A key prediction about the future application of generative AI:
    using its advanced analytical capabilities on massive datasets, likely in the
    background initially.'
  relevance_score: 10
  source: llm_enhanced
  text: where I think the interesting thing in the next few years is going to be is
    how we take this new generation of generative AI using LLMs or other types of
    LLM-like technology to do analysis on huge traffic patterns.
  topic: predictions/trends
- impact_reason: 'A significant technical trend: the development and deployment of
    highly efficient, low-latency models directly onto edge devices.'
  relevance_score: 10
  source: llm_enhanced
  text: we are already seeing new edge models designed to be deployed to mobile devices
    and IOT that use very low amounts of system memory and can provide inference responses
    within milliseconds.
  topic: technical/trends
- impact_reason: Draws a powerful analogy between the falling cost of cloud storage
    (S3) and the expected rapid decline in AI inference costs, suggesting a massive
    future scaling potential.
  relevance_score: 10
  source: llm_enhanced
  text: that cost is dropping incredibly fast. Right? We saw this with cloud where
    S3 went from being the most expensive storage you could buy to being free, essentially.
  topic: business/predictions
- impact_reason: 'Poses the ultimate strategic question regarding the future of personal
    computing: ubiquitous, always-on, local LLM processing.'
  relevance_score: 10
  source: llm_enhanced
  text: As you squint and look at the future, you can start to see these really incredible
    use cases, right? To your point of inference on the edge, do you think we all
    end up eventually with an LLM [on our device]?
  topic: predictions/strategy
- impact_reason: Provides a stark, current statistic on the scale of automated traffic,
    setting the stage for the necessity of new infrastructure and policies.
  relevance_score: 9
  source: llm_enhanced
  text: Fifty percent of traffic is already automated, and agents are only really
    just getting going.
  topic: Predictions
- impact_reason: Highlights the current limitation (speed) of AI agents while strongly
    predicting their inevitable future dominance in web interaction.
  relevance_score: 9
  source: llm_enhanced
  text: Most people are not using these computer use agents because they are too slow
    right now; they are still like previews, but it is clear that is where everything
    is going.
  topic: Predictions
- impact_reason: 'Identifies the core conflict: evolving user behavior (via agents)
    versus outdated site security/interaction models.'
  relevance_score: 9
  source: llm_enhanced
  text: AI agents are changing how people interact with the web, but most sites still
    treat them like bots.
  topic: Strategy
- impact_reason: Directly links imprecise blocking to lost business revenue, highlighting
    the financial risk of outdated security.
  relevance_score: 9
  source: llm_enhanced
  text: There are very real consequences, because some of these AI bots could be actual
    users, they are acting on behalf of who are looking to purchase your products.
  topic: Business
- impact_reason: Provides a concrete business example illustrating why application
    context (e.g., flagging for review instead of blocking) is crucial for revenue
    protection.
  relevance_score: 9
  source: llm_enhanced
  text: If you are running an e-commerce operation on an online store, the worst thing
    you can do is block a transaction, because then you have lost the revenue.
  topic: Business
- impact_reason: Confirms that most existing solutions are fundamentally inadequate
    for the AI era because they lack visibility into application outcomes.
  relevance_score: 9
  source: llm_enhanced
  text: Blocking on the network is basically how the majority of these old school
    products work. They do analysis before the traffic reaches your application, and
    then you never know what the result of that was. That just does not fly anymore.
  topic: Technical
- impact_reason: Provides evidence that AI traffic is not just benign, but actively
    beneficial for business metrics (conversions/sign-ups).
  relevance_score: 9
  source: llm_enhanced
  text: We are seeing lots of different applications getting more sign-ups, businesses
    actually getting higher conversions as a result of this AI traffic.
  topic: Business
- impact_reason: A strong, direct warning to businesses about the self-inflicted damage
    caused by outdated bot mitigation strategies.
  relevance_score: 9
  source: llm_enhanced
  text: If you use an old world tool to just block any of that traffic, you are probably
    hurting your business.
  topic: Business
- impact_reason: Clarifies that LLM search functionality relies on web crawling, positioning
    these agents as essential discovery tools, not just threats.
  relevance_score: 9
  source: llm_enhanced
  text: There is one [OpenAI crawler] that will go out when a user is typing something
    into the chat and has asked a question, and OpenAI will go out and search. It
    has built up its own search index. And so that is equivalent of Googlebot.
  topic: Technical
- impact_reason: 'Defines the most advanced agent type: the autonomous, browser-operating
    agent capable of complex, multi-step actions.'
  relevance_score: 9
  source: llm_enhanced
  text: This then comes to the fourth one, which is the actual agent. This is the
    end agent, the computer operator type feature that is, this web browser is the
    first web browser.
  topic: Technical
- impact_reason: A concrete example of AI agent misuse (scalping/abuse) that necessitates
    nuanced control, moving beyond simple blocking.
  relevance_score: 9
  source: llm_enhanced
  text: But there are examples where it might be a bad, bad action. So for example,
    if you are building a tool that is going to try and buy all of the concert tickets
    and then sell them on later, that becomes a problem for the concert seller because
    they do not want to do that.
  topic: safety/ethics
- impact_reason: Illustrates the need for fine-grained, context-aware control mechanisms
    for AI agents, requiring human intervention at critical steps.
  relevance_score: 9
  source: llm_enhanced
  text: Maybe you allow the bot to go to the homepage and sit in a queue. But then
    when you get to the front of the queue, you want the human to actually make the
    purchase, and you want to rate limit that so that maybe the human can only purchase,
    so let us say five tickets.
  topic: strategy
- impact_reason: Details the sophisticated evasion techniques used by malicious actors,
    specifically using residential proxies to mask data center origins.
  relevance_score: 9
  source: llm_enhanced
  text: The agent with the web browser or headless browser is going to be running
    on a server somewhere. It is probably in a data center. And then you have the
    compounding factor of the abusers will purchase access to proxies which run on
    residential IP addresses.
  topic: technical
- impact_reason: Reveals that many legitimate bots self-identify, and verification
    (like reverse DNS lookup) allows for allowing trusted AI traffic, contrasting
    with the assumption that all automation is hidden.
  relevance_score: 9
  source: llm_enhanced
  text: It has been surprising in getting into the details of how many bots actually
    tell you who they are. And so you can block a lot of them just on that heuristic
    combined with the IP address. Or allow them. Yeah, I am the shopping bot from
    OpenAI. Right. Yeah. Come on in and buy some stuff. Exactly.
  topic: technical
- impact_reason: Provides an excellent analogy for fingerprinting techniques, placing
    them conceptually at the lower layers of the OSI model (network identity).
  relevance_score: 9
  source: llm_enhanced
  text: This is almost like layer two level identity for devices, right? Right. It
    is looking at the TLS handshake on the network level, and then you can go up the
    layers.
  topic: technical
- impact_reason: Provides a current baseline (50% bot traffic) and forecasts an explosion
    in traffic once current AI agent limitations (speed/maturity) are overcome.
  relevance_score: 9
  source: llm_enhanced
  text: Well, 50% of traffic is already bots, is already automated, and agents are
    only really just getting going. Most people are not using these computer use agents
    because they are too slow right now, or they are not, they are still like previews,
    but it is clear that is where everything is going.
  topic: predictions
- impact_reason: Challenges the traditional security mindset that views all automation
    as malicious, noting that desired future traffic will be automated.
  relevance_score: 9
  source: llm_enhanced
  text: The old school methods of doing that assume malicious intent, which is not
    always the case and increasingly is going to be not the case because you want
    the agents to be doing things.
  topic: safety/strategy
- impact_reason: 'States the core difficulty facing future internet security and identity
    management: distinguishing between human and sophisticated AI clients.'
  relevance_score: 9
  source: llm_enhanced
  text: It seems to me like detecting that it is AI or a person is going to be an
    incredibly difficult challenge.
  topic: safety
- impact_reason: This frames the core, unsolved problem of digital identity verification,
    which is becoming critically urgent due to generative AI.
  relevance_score: 9
  source: llm_enhanced
  text: how are you thinking about proving humanness on the internet?
  topic: safety/strategy
- impact_reason: 'Identifies the primary current limitation of large LLMs in real-time
    applications: latency and inference speed.'
  relevance_score: 9
  source: llm_enhanced
  text: The challenge with the LLM type models is just the speed at which they are
    doing analysis because you often want to take a decision on the network or in
    the application within a couple of milliseconds.
  topic: technical/limitations
- impact_reason: 'Pinpoints the primary current business/deployment bottleneck for
    scaling AI applications: inference cost.'
  relevance_score: 9
  source: llm_enhanced
  text: so much of what we are seeing now is just being restricted by the cost of
    inference.
  topic: business/limitations
- impact_reason: Illustrates a surprisingly high-accuracy, low-effort use case for
    LLMs in security/content analysis, showing immediate practical value.
  relevance_score: 9
  source: llm_enhanced
  text: when you look at the capabilities of these new technologies to drop a suspicious
    email into a chat GPT and ask if it is suspicious, then that is like 100% accurate.
  topic: technical/business
- impact_reason: Reinforces the power of LLMs for content inspection and data loss
    prevention (DLP) tasks, suggesting near-perfect performance in these specific
    contexts.
  relevance_score: 9
  source: llm_enhanced
  text: If you want to find sensitive information, you ask the LLM is there sensitive
    information, and it is like 100% accurate. It is amazing.
  topic: technical/business
- impact_reason: Explains why legacy bot detection fails—it cannot handle traffic
    that is ambiguous or intentionally designed to look legitimate.
  relevance_score: 8
  source: llm_enhanced
  text: The challenge comes when you have got traffic that just does not fit those
    filters; it looks like it could be legitimate, or maybe it is legitimate, and
    you just have a different view about what kind of traffic you want to see.
  topic: Technical
- impact_reason: Critiques legacy security methods (IP/User Agent blocking) as overly
    broad and ineffective for modern, sophisticated traffic.
  relevance_score: 8
  source: llm_enhanced
  text: The legacy providers in this space, it was very much using a hammer, right?
    So they would say, hey, if this IP address is coming in, it is probably a bot...
    Very imprecise.
  topic: Technical
- impact_reason: Explains the limitation of existing web standards (robots.txt) in
    the face of non-compliant or malicious modern agents.
  relevance_score: 8
  source: llm_enhanced
  text: Robots.txt is still the starting place. And it is kind of a voluntary standard...
    The challenge with that is this voluntary, and there is no enforcement of it.
  topic: Technical
- impact_reason: Raises the strategic and ethical consideration for site owners regarding
    their data's inclusion in foundational model training sets.
  relevance_score: 8
  source: llm_enhanced
  text: You have different philosophical approaches to how you want to be included
    in the training data.
  topic: Safety/Ethics
- impact_reason: 'Offers a crucial user behavior recommendation for interacting with
    LLM outputs: verification via source checking, mirroring historical information
    literacy.'
  relevance_score: 8
  source: llm_enhanced
  text: You should not trust it 100%. You go and then verify, and you look at the
    docs. And maybe it is like when you used to go to Wikipedia and you would read
    the summary and then you would look at the references...
  topic: Strategy
- impact_reason: Describes the 'real-time retrieval' use case for agents, which requires
    sites to be accessible for immediate summarization/query answering.
  relevance_score: 8
  source: llm_enhanced
  text: The other one is something that is happening in real time... go and ask it
    to summarize it or to look up a particular question in the docs for a developer
    tool or something like that.
  topic: Technical
- impact_reason: Highlights the positive business incentive for allowing high-level
    agent interaction—increased application usage and transactions.
  relevance_score: 8
  source: llm_enhanced
  text: From the application builder's perspective, that is probably a good thing.
    You want more transactions, you want more usage of your application.
  topic: Business
- impact_reason: 'Highlights the dual nature of AI agents in business: they drive
    usage, which is good for builders, but this usage needs careful governance.'
  relevance_score: 8
  source: llm_enhanced
  text: Maybe it is going to your email inbox and triaging things. From the application
    builder's perspective, that is probably a good thing. You want more transactions,
    you want more usage of your application.
  topic: business
- impact_reason: A fundamental reality check on network traffic analysis, acknowledging
    that traditional IP-based trust models are obsolete due to shared resources and
    proxies.
  relevance_score: 8
  source: llm_enhanced
  text: In an ideal scenario, you have one user per IP address, but we all know that
    does not happen. That never happens.
  topic: technical
- impact_reason: Frames AI agents as digital avatars requiring identity verification
    and objective assessment, similar to managing human users.
  relevance_score: 8
  source: llm_enhanced
  text: I mean, I hate to use the analogy, but these things are almost like avatars,
    right? They are running around on someone's behalf, and you need to figure out
    who that someone is and what the objectives are, right? And control them very
    granularly.
  topic: strategy
- impact_reason: Offers an optimistic, data-driven view of the evolution of internet
    citizenship among automated clients over the recent past.
  relevance_score: 8
  source: llm_enhanced
  text: Directionally, things are improving because in way of looking back 18 months,
    the bots had no rate limiting. They were just downloading content all the time.
    Today, we know that these bots can be verified. They are identifying themselves.
    They are much better citizens of the internet, and they are following, starting
    to follow the rules.
  topic: predictions
- impact_reason: Identifies digital signatures as the theoretically pure solution
    for identity but dismisses it due to insurmountable user experience barriers for
    the average person.
  relevance_score: 8
  source: llm_enhanced
  text: Well, the pure solution is digital signature, right? We have been talking
    about that for so long, and the UX ran is basically impossible for normal people
    to figure out.
  topic: technical
- impact_reason: Highlights the historical difficulty and failure to solve the identity
    proofing problem, setting the stage for why new AI solutions might be needed.
  relevance_score: 8
  source: llm_enhanced
  text: NIST working group on proofing identity that has been running, I think, for
    35 years, and it still has not really gotten to something that is implementable.
  topic: strategy/limitations
- impact_reason: Explains why traditional cryptographic solutions (like digital signatures)
    fail in mass adoption due to poor user experience (UX).
  relevance_score: 8
  source: llm_enhanced
  text: The pure solution is digital signature, right? We have been talking about
    that for so long, and the UX ran is basically impossible for normal people to
    figure out.
  topic: technical/strategy
- impact_reason: Provides a visceral description of the scale challenges in managing
    internet traffic, especially when facing overwhelming automated attacks.
  relevance_score: 7
  source: llm_enhanced
  text: So you have got 450,000 IP addresses sending you terabits of traffic through
    a link that only can do gigabit, and you have got to just start dropping stuff,
    right? And you take you, you know, it is the battlefield triage of the wounded,
    right?
  topic: strategy
- impact_reason: Provides historical context on the difficulty of identity proofing,
    suggesting that current digital identity challenges are not new, but remain unsolved.
  relevance_score: 7
  source: llm_enhanced
  text: Proofing is a tale as old as time. There is a NIST working group on proofing
    identity that has been running, I think, for 35 years, and it still has not really
    gotten to something that is implementable.
  topic: strategy
- impact_reason: Contextualizes modern AI by noting that traffic analysis has long
    used ML, setting up the expectation that LLMs/new AI will bring step-change improvements
    in analysis speed/depth.
  relevance_score: 7
  source: llm_enhanced
  text: But AI has been used in analyzing traffic for at least over a decade. It was
    called machine learning. So you start with machine learning, and the question
    is, well, what does the new generation of AI allow us to do?
  topic: technical
- impact_reason: Provides historical context, noting that AI/ML for traffic analysis
    is not new, but the *type* of AI is changing.
  relevance_score: 7
  source: llm_enhanced
  text: AI has been used in analyzing traffic for at least over a decade. It was called
    machine learning.
  topic: technical/trends
source: Unknown Source
summary: '## Podcast Summary: Enabling Agents and Battling Bots on an AI-Centric Web


  This 26-minute episode of the A16Z AI podcast, featuring A16Z Partner Joel De La
  Garza and ArcGets CEO David Mitten, explores the fundamental shift occurring on
  the internet as AI agents transition from theoretical tools to primary traffic drivers,
  necessitating a complete overhaul of traditional bot mitigation strategies.


  ---


  ### 1. Focus Area

  The discussion centers on **Internet Infrastructure and Security in the Age of AI
  Agents**. Key themes include the evolution of bot traffic, the inadequacy of legacy
  security methods (like IP blocking), the concept of "Agent Experience" (treating
  agents as first-class users), and the technical methods required to distinguish
  between beneficial, neutral, and malicious automated traffic.


  ### 2. Key Technical Insights

  *   **Application Context is Paramount:** Volumetric DDoS attacks can be handled
  at the network level, but all other automated traffic, especially agentic traffic,
  requires deep **application context** (where in the application the traffic is,
  session details) to make nuanced allow/deny decisions. Blocking based solely on
  automated detection is now actively hurting business revenue.

  *   **Layered Identity Verification:** Effective modern bot management requires
  moving beyond simple user agents and IP reputation. It involves **fingerprinting**
  request characteristics (e.g., using evolving standards like J3/J4 hashes that examine
  TLS handshakes and HTTP headers) to create a device/client identity layer before
  applying application-level rules.

  *   **Agent Diversity Requires Granularity:** Major AI providers (like OpenAI) deploy
  multiple distinct agent types (e.g., training crawlers, search indexers, real-time
  summarizers). Site owners must implement **granular rules** to permit beneficial
  agents (like search indexers that drive traffic) while restricting malicious ones,
  treating them like distinct entities rather than a monolithic "AI bot."


  ### 3. Business/Investment Angle

  *   **Risk of Revenue Loss:** Overly aggressive, traditional bot blocking mechanisms
  are now actively **blocking revenue-generating AI traffic** (e.g., agents making
  purchases or signing up for services), forcing companies to re-evaluate security
  posture.

  *   **Agent Traffic Explosion:** With 50% of current traffic already automated,
  the impending explosion of sophisticated AI agents means that simply blocking "AI"
  is a self-inflicted business wound. Companies must enable agents that act on behalf
  of customers.

  *   **The New "robots.txt" Challenge:** While standards like `robots.txt` exist,
  they are voluntary. The market needs enforceable, developer-native security solutions
  that allow site owners to control agent access with the same nuance previously reserved
  for human users.


  ### 4. Notable Companies/People

  *   **ArcGets (David Mitten, CEO):** Building developer-native security solutions
  focused on attack detection, spam prevention, and nuanced bot management for modern
  web frameworks.

  *   **A16Z (Joel De La Garza, Partner):** Driving the conversation around the necessary
  infrastructure changes to support agentic web interactions.

  *   **OpenAI:** Cited as a primary example of a provider deploying multiple, distinct
  agent types with varying levels of desired access.

  *   **Salesforce:** Mentioned as the originator of the J3 hashing technique used
  for client fingerprinting.

  *   **Apple (Privacy Pass):** Mentioned as an example of an emerging standard using
  cryptographic signatures attached to requests to verify identity within an ecosystem.


  ### 5. Future Implications

  The internet is moving toward a state where **agentic activity will become the primary
  consumer of web content**, rather than direct human interaction. This necessitates
  a fundamental shift from assuming malicious intent to designing for **Agent Experience
  (AX)**. The future of web security lies in verifiable, cryptographic identity signatures
  (like digital proofs) layered throughout the network stack to distinguish legitimate
  automated actors from criminals.


  ### 6. Target Audience

  This episode is highly valuable for **AI/ML Engineers, Web Infrastructure Developers,
  CTOs, and Security Professionals** responsible for application security, as well
  as **Venture Capitalists and Product Leaders** tracking the evolution of web interaction
  models.'
tags:
- artificial-intelligence
- ai-infrastructure
- generative-ai
- investment
- startup
- openai
- google
- apple
title: Enabling Agents and Battling Bots on an AI-Centric Web
topics:
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 63
  prominence: 1.0
  topic: artificial intelligence
- keywords:
  - gpu
  - tensor
  - training
  - inference
  - model deployment
  - vector database
  mentions: 8
  prominence: 0.8
  topic: ai infrastructure
- keywords:
  - generative ai
  - genai
  - chatgpt
  - gpt
  - claude
  - text generation
  - image generation
  mentions: 2
  prominence: 0.2
  topic: generative ai
- keywords:
  - investment
  - funding
  - valuation
  - ipo
  - acquisition
  mentions: 2
  prominence: 0.2
  topic: investment
- keywords:
  - startup
  - entrepreneur
  - founder
  - venture
  mentions: 1
  prominence: 0.1
  topic: startup
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-10-05 04:33:31 UTC -->
