---
companies:
- category: tech
  confidence: high
  context: t still OK as the relationship we have today with Google or with large
    companies, and like Meta and so for
  name: Google
  position: 749
- category: tech
  confidence: high
  context: day with Google or with large companies, and like Meta and so forth? Or
    is it not OK? And welcome to Art
  name: Meta
  position: 790
- category: unknown
  confidence: medium
  context: eta and so forth? Or is it not OK? And welcome to Artificial Insights,
    where we talk to leaders and thinkers in AI abou
  name: Artificial Insights
  position: 841
- category: unknown
  confidence: medium
  context: rs in AI about how to do AI right. I'm your host, Daniel Menary. And this
    is season four. Here, we sit down every
  name: Daniel Menary
  position: 947
- category: unknown
  confidence: medium
  context: they do and why they do it. Today, I'm joined by Adeel Zaman. Adeel entered
    the University of Artilou at just
  name: Adeel Zaman
  position: 1162
- category: unknown
  confidence: medium
  context: ndustry and we grew that to $43 million annually. And I actually solved
    the cold startup problem of that
  name: And I
  position: 1892
- category: unknown
  confidence: medium
  context: roblem of that marketplace through deep learning. So I was always kind
    of truly intrigued by using deep
  name: So I
  position: 1982
- category: unknown
  confidence: medium
  context: em to just tackle them for one specific articles. But I think it makes
    sense. I think if you look at huma
  name: But I
  position: 5503
- category: unknown
  confidence: medium
  context: oing inside our brains and that's what really the Foundation Model pushes
    unlocked. So I'm trying to bring that to t
  name: Foundation Model
  position: 6012
- category: unknown
  confidence: medium
  context: people think of AGI, they think of something like Iron Man's suit, and
    it's this embodied thing that has abi
  name: Iron Man
  position: 6844
- category: unknown
  confidence: medium
  context: ce. And even itself, because, you know, I live in San Francisco, I've been
    taking Waymo all the time. There's man
  name: San Francisco
  position: 13365
- category: unknown
  confidence: medium
  context: nience is, I'll take Google example. I'm fully on Google Maps and, you
    know, Gmail and so forth. So they have a
  name: Google Maps
  position: 18459
- category: unknown
  confidence: medium
  context: asks, not only for yourself. So for example, with Grizzly AI, it will,
    once you teach it, you can actually put
  name: Grizzly AI
  position: 20335
- category: unknown
  confidence: medium
  context: botics world are in unison in this concept, where Tesla Optimus, let's
    say, tries to make Tesla Optimus as good a
  name: Tesla Optimus
  position: 23848
- category: tech
  confidence: high
  context: as it can and then they'll sell to you. Where an OpenAI will, you know,
    make a GPT-5 as good as it can fr
  name: Openai
  position: 23959
- category: unknown
  confidence: medium
  context: n a very AI first manner, a big believer of that. What I mean by that is
    like, I'm kind of thinking for fi
  name: What I
  position: 29192
- category: unknown
  confidence: medium
  context: igm. Cool. Yeah, that reminds me even of AlphaGo. Because AlphaGo was a
    small, strong predictor net with a very lar
  name: Because AlphaGo
  position: 35056
- category: big_tech
  confidence: high
  context: Mentioned as a large company with which the current relationship regarding
    data access might be questioned.
  name: Google
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Mentioned alongside Google as a large company whose relationship with users
    regarding data access is being questioned.
  name: Meta
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Adeel Zaman's previous company, which brought e-commerce to the construction
    industry and used deep learning to solve the cold startup problem.
  name: Dozer
  source: llm_enhanced
- category: ai_startup_ecosystem
  confidence: high
  context: The residency Adeel Zaman is currently building his new company out of,
    implying a focus on early-stage AI/ML startups.
  name: HF0 residency
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: The creator of the RT2 paper, which showed how multimodal foundation models
    could be improved by adding robot action data.
  name: DeepMind
  source: llm_enhanced
- category: ai_model_provider
  confidence: medium
  context: Mentioned as an example of a multimodal foundation model (VLM) that could
    potentially be leveraged for embodied AI.
  name: Claude
  source: llm_enhanced
- category: ai_model_provider
  confidence: high
  context: Mentioned as an example of a multimodal foundation model (VLM) and referenced
    in the context of the foundation model approach starting with GPT onwards.
  name: GPT
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned in the context of autonomous driving, specifically noting that
    their current approach (like FSD) does not involve real-time voice interaction/reasoning
    like the speaker's proposed paradigm.
  name: Waymo
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned alongside Waymo as an example of current autonomous driving technology
    that lacks the proposed real-time voice interaction feature.
  name: FSD
  source: llm_enhanced
- category: ai_startup
  confidence: high
  context: The speaker's new company, focused on providing individually owned, customizable
    robots/AI that users can teach via reinforcement learning.
  name: Grizzly AI
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as an example of a company (Tesla) that trains a generalized
    model (Optimus robot) whose weights are shared, contrasting with the speaker's
    individual ownership model.
  name: Tesla Optimus
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Mentioned as a leading model company whose approach (like GPT-5) involves
    creating a highly capable general model that users cannot significantly improve
    or customize after deployment.
  name: OpenAI
  source: llm_enhanced
- category: ai_model_developer
  confidence: high
  context: Mentioned as an example of a large, open-source model that is periodically
    released and improved upon.
  name: DeepSeek-V2
  source: llm_enhanced
- category: ai_model_developer
  confidence: medium
  context: Reference to a specific version of a model family being discussed in the
    context of open-source releases that are superseded by newer versions (Q1-4, Q1-5).
  name: Q1-3
  source: llm_enhanced
- category: ai_model_developer
  confidence: medium
  context: Reference to a future version of the Q1 model family.
  name: Q1-4
  source: llm_enhanced
- category: ai_model_developer
  confidence: medium
  context: Reference to a future version of the Q1 model family that is expected to
    be better than Q1-3.
  name: Q1-5
  source: llm_enhanced
- category: ai_model_developer
  confidence: high
  context: Mentioned as a future, highly capable model from OpenAI that will likely
    follow the shared-weights paradigm.
  name: GPT-5
  source: llm_enhanced
- category: ai_model_developer
  confidence: medium
  context: Hypothetical future model mentioned in the context of whether it will be
    capable enough to solve complex hardware research problems autonomously.
  name: GPT-7
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Google's large language model, mentioned as being super impressive but
    very large and costly to run locally.
  name: Gemini 1.5 Pro
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: DeepMind's AI program that defeated a professional Go player, mentioned
    as an example of a system using a small, fast predictor net alongside a larger,
    slower one.
  name: AlphaGo
  source: llm_enhanced
date: 2025-10-03 11:40:53 +0000
duration: 37
has_transcript: false
layout: episode
llm_enhanced: true
original_url: https://audio.listennotes.com/e/p/ec1044ba195e4138be8469dbddf78908/
processing_date: 2025-10-06 03:09:59 +0000
quotes:
- length: 171
  relevance_score: 5
  text: And third, probably the biggest bucket is, because you actually need to, because
    you're trying to differentiate yourself from your market, whatever market you're
    in, right
  topics:
  - market
- length: 88
  relevance_score: 4
  text: And I actually solved the cold startup problem of that marketplace through
    deep learning
  topics:
  - market
- length: 160
  relevance_score: 4
  text: And it was really interesting where it showed that you could take a multimodal,
    multimodal foundation model like a VLM, let's say we had access to Claude or GPT
  topics: []
- length: 207
  relevance_score: 4
  text: Like there's nothing, but there are definitely companies in every sub-market
    that are like, okay, we've learned this new task and we do this better and that's
    why we get the next contractor, the next revenue
  topics:
  - revenue
  - market
- length: 135
  relevance_score: 3
  text: And I think arguably it's probably one of the biggest opportunities unlocked
    we can do to prove our standard living as a society, right
  topics: []
- length: 87
  relevance_score: 3
  text: And so that's, I would argue that's probably the biggest thing that's holding
    this back
  topics: []
- length: 238
  relevance_score: 3
  text: Now there are some technical challenges, I will say, like the biggest one
    being cost, like how do you, because, like I think the bigger models perform better,
    I think, you know, the bigger the better is something we've all kind of learned
  topics: []
- length: 130
  relevance_score: 3
  text: Where an OpenAI will, you know, make a GPT-5 as good as it can from pre-training
    and post-training and then they'll give it to you
  topics: []
- length: 209
  relevance_score: 3
  text: I almost have to ask this question because I feel like you've talked about
    so many of them already, but do you have a deeply held belief about artificial
    intelligence that has changed over this journey for you
  topics: []
- impact_reason: Raises a critical ethical and privacy question about data centralization
    and control once powerful foundation models have access to vast, disparate datasets.
  relevance_score: 10
  source: llm_enhanced
  text: If the AI is this strong, it can do all of these things and it has access
    to your data across all these paradigms. Is it how important is it then? Is it
    still OK as the relationship we have today with Google or with large companies,
    and like Meta and so forth? Or is it not OK?
  topic: safety/ethics
- impact_reason: 'Clearly articulates the speaker''s mission: bridging the gap between
    LLM success (knowledge work) and real-world physical automation, framing it as
    a societal necessity.'
  relevance_score: 10
  source: llm_enhanced
  text: How can we take the leading AI models and apply them to the physical world?
    I feel like there's a lot of awesome work being done in the knowledge work space.
    And that's great. But we've been a dystopian future if we haven't made progress
    in using AI to accelerate tasks of the physical world, right?
  topic: strategy
- impact_reason: 'Identifies the two major roadblocks for embodied AI: data acquisition/structuring
    and the lack of continuous, human-like learning loops post-deployment.'
  relevance_score: 10
  source: llm_enhanced
  text: One is how do you get the data in the right way? And the other one is how
    do you create a great paradigm of learning? Today, the models, they just get trained
    by the big labs and then they get released, but there isn't this paradigm of continuous
    learning that humans definitely have.
  topic: technical/strategy
- impact_reason: 'Describes a novel, highly interactive paradigm for robotics control:
    real-time, verbal chain-of-thought reasoning accessible to the human operator.'
  relevance_score: 10
  source: llm_enhanced
  text: We let the foundation model reason real time. So when the excavator is excavating,
    there's a touchscreen inside it. You can actually just, it just talks to you.
    It's like, I'm deciding to go left because I think I need to pick this rock up
    first and move it here before I can go do this next step.
  topic: technical
- impact_reason: Identifies Language-Guided Rewards (derived from human feedback/language)
    as the key to unlocking effective Reinforcement Learning in complex, real-world
    scenarios where traditional reward functions fail.
  relevance_score: 10
  source: llm_enhanced
  text: I think there's two things. One is we can do RL to keep improving its learning.
    And that's something I'm really excited about with kind of RL from language guided
    rewards.
  topic: technical
- impact_reason: Provides a concise technical description of a multimodal generation
    approach where language reasoning and physical actions are generated concurrently
    from a single stream of tokens.
  relevance_score: 10
  source: llm_enhanced
  text: it is just spinning out the language tokens and the action tokens at the same
    time.
  topic: technical
- impact_reason: Posits that personalized, intensive teaching/training (analogous
    to human upbringing) is the missing ingredient for achieving AGI/embodied AGI
    superiority over current models.
  relevance_score: 10
  source: llm_enhanced
  text: I think we have to figure out how to go to this paradigm in not just in embodied
    AGI but also AGI and the leading models because if I look at what makes, you know,
    humans have this like kind of incredible advantage right now over the over our
    best digital intelligence models, which is that there are so many thousands of
    hours spent on teaching every human.
  topic: strategy/predictions
- impact_reason: Draws a sharp contrast between the current centralized, shared-weight
    model (like FSD) and the proposed decentralized, individually owned model, emphasizing
    user investment in personalization.
  relevance_score: 10
  source: llm_enhanced
  text: If they invest more time in teaching better, it's not like FSD, the weights
    are shared, right? Everybody teaches how to drive. Yeah. And you know, the weights
    are shared and then you get the next FSD version where you get a better driver.
  topic: business/strategy
- impact_reason: 'Proposes a technical solution to the cost problem: decoupling the
    massive, static base model from the small, user-specific, and frequently updated
    reward/RL layer.'
  relevance_score: 10
  source: llm_enhanced
  text: you can kind of flop up the base and only the user only owns their kind of
    reward model and reinforcement learning that gets redone.
  topic: technical
- impact_reason: Critiques the current 'take-it-or-leave-it' deployment model for
    advanced AI/robotics, arguing it prevents the necessary user-driven refinement
    seen in human employment.
  relevance_score: 10
  source: llm_enhanced
  text: if we don't solve it, we're kind of stuck in this realm of, like right now,
    in the robotics world and the non-robotics world are in unison in this concept,
    where Tesla Optimus tries to make Tesla Optimus as good as it can and then they'll
    sell to you. Where an OpenAI will, you know, make a GPT-5 as good as it can from
    pre-training and post-training and then they'll give it to you. Once they give
    it to you, you can't really improve it to your liking.
  topic: strategy/business
- impact_reason: Challenges the 'one-size-fits-all' AGI vision, arguing that the need
    for domain-specific differentiation will force a shift in model deployment strategy.
  relevance_score: 10
  source: llm_enhanced
  text: I really think this paradigm is going to be tested that the current leading
    model companies are doing, which is, is it that you can just get some AGI that
    knows all these different tasks? And is it not that some customer would want to
    differentiate within their own market?
  topic: safety/strategy
- impact_reason: Presents a strong argument against purely external memory solutions
    (like RAG) for true intelligence, favoring weight modification based on the human
    analogy of learning.
  relevance_score: 10
  source: llm_enhanced
  text: I'm not sure if that will work, because I'm not sure what I, my current inclination
    is that you need to bake this learning into the weights, or at least that's how
    humans work.
  topic: technical
- impact_reason: 'Offers a concrete, actionable architectural solution for personalization:
    using a small, specialized model to handle memory/updates while leveraging the
    large model for core reasoning, mitigating cost.'
  relevance_score: 10
  source: llm_enhanced
  text: So to solve the cost problem, one thing that we're doing, and I think should
    be done, is a small model for memory and personalization and keeping the large
    model as is.
  topic: technical
- impact_reason: 'Poses the central philosophical and technical question: Is pure
    language/knowledge model scaling sufficient for general white-collar work, or
    is physical grounding necessary?'
  relevance_score: 10
  source: llm_enhanced
  text: Are we, are we going to be able to get to a white collar worker through the
    current AI models improving without this AGI having the ability to operate in
    the physical world?
  topic: predictions
- impact_reason: Argues that true understanding (like a human worker) requires grounding
    beyond text, suggesting current LLM training methods might hit diminishing returns
    for complex tasks.
  relevance_score: 10
  source: llm_enhanced
  text: But now if we look at today's average median white collar worker human, right?
    The only intelligence that we know that's been able to perform at that level actually
    learning a different way, kind of learn some base case understanding the world
    because a lot of the knowledge that we intake... is referencing a lot of that
    about the world, right? That, yes, you can kind of read from language, but you
    can't really fully understand.
  topic: safety/predictions
- impact_reason: Draws a crucial distinction between current LLM capabilities (Q&A/single-turn
    tasks) and true AGI requirements (long-horizon, multi-step task execution).
  relevance_score: 10
  source: llm_enhanced
  text: Today, the best AI agent at doing, and specifically, I think more on like
    more agents, right? Because yes, you can get a question answered really well.
    We already arguably are close to AGI at a question-answer approach, but the next
    part of like long horizon task, like, hey, go out and do this for me, right?
  topic: technical/predictions
- impact_reason: Proposes embodied learning as a potential solution to overcome the
    diminishing returns seen in purely language-based scaling for complex tasks.
  relevance_score: 10
  source: llm_enhanced
  text: I think we may start getting diminishing returns and I think maybe kind of
    building it with this embodied understanding in the beginning will actually help
    it perform better.
  topic: technical/strategy
- impact_reason: This is the core, potentially controversial thesis of the speaker,
    arguing that physical or simulated interaction is necessary before achieving true
    Artificial General Intelligence.
  relevance_score: 10
  source: llm_enhanced
  text: So that's one of my beliefs that we actually, embodied AGI is a prerequisite
    to AGI.
  topic: predictions/strategy
- impact_reason: Highlights the massive gap between AI adoption in knowledge work
    versus the physical world, pinpointing a huge untapped opportunity in industries
    like manufacturing and construction.
  relevance_score: 9
  source: llm_enhanced
  text: We'd be surprised if we walked into manufacturing facilities, into construction
    job sites, in any kind of physical space, and seen how much of it is done by machine
    learning. And it's a very, very small percentage.
  topic: predictions
- impact_reason: A specific, compelling example illustrating the emergent benefits
    of multimodal/multitask training, even for tasks seemingly unrelated to the added
    data (like poetry aiding coding).
  relevance_score: 9
  source: llm_enhanced
  text: The data ablation study showed that because they added poetry encoding into
    the same model, it actually performed better at poetry encoding.
  topic: technical
- impact_reason: Positions embodied AI in physical industries (construction, manufacturing)
    as a key driver for societal standard of living improvement, elevating the stakes
    beyond simple business optimization.
  relevance_score: 9
  source: llm_enhanced
  text: I think arguably it's probably one of the biggest opportunities unlocked we
    can do to prove our standard living as a society, right? To be able to do these
    tasks [in the physical world] at a lower cost and more efficiently.
  topic: predictions
- impact_reason: Advocates for a unified, generalist foundation model approach for
    embodied AI, mirroring the success seen in language models.
  relevance_score: 9
  source: llm_enhanced
  text: I really believe in the foundation model approach where there's going to be
    one AI model that's going to be able to do all the, like a lot of different physical
    tasks or can learn a new task. And I think that's a big card I've shipped at you.
    I'll just touch on that a little bit.
  topic: technical
- impact_reason: 'Introduces a crucial distinction in robotics control: separating
    high-level conscious decision-making (handled by the LLM/Foundation Model) from
    low-level subconscious motor control.'
  relevance_score: 9
  source: llm_enhanced
  text: I think there is a, I think there's a really interesting concept of like,
    things we do subconsciously as humans and things we do consciously... Your brain
    is not consciously saying, what is the, you know, what's the coordinates that
    your finger needs to move to to grasp this mug?
  topic: technical
- impact_reason: A strong prediction about the future interface and control mechanism
    for complex machinery, favoring interactive reasoning over pre-programmed autonomy.
  relevance_score: 9
  source: llm_enhanced
  text: I really believe that this may be the future paradigm for robotics as opposed
    to the one that I've seen, that's what kind of inspired me.
  topic: predictions
- impact_reason: A direct critique of the 'deploy-and-forget' model for robotics,
    arguing that AI systems, like human employees, require continuous collaboration
    and project-specific refinement.
  relevance_score: 9
  source: llm_enhanced
  text: I just don't believe in this concept that some robots can get trained to a
    great accuracy and get sold to us and then it just, like, works out of the box.
    That's actually not how employees work.
  topic: business/strategy
- impact_reason: Explains the limitation of current RL success (sparse rewards in
    simulation/code) and proposes that human-like, language-based feedback bridges
    this gap for unstructured tasks.
  relevance_score: 9
  source: llm_enhanced
  text: The bare cases for it [RL] is it only works for coding and math because it's
    very filled with rewards. And the approach, the way I think we can kind of jump
    over this is what if, because if we look back to human learning, you know, humans
    don't have very filled rewards, even for math...
  topic: technical
- impact_reason: 'A concise definition of the proposed learning loop: using the human
    operator as the dynamic, natural reward function generator for RL.'
  relevance_score: 9
  source: llm_enhanced
  text: it's just RL with the rewards being from the, in this case, the owner, right,
    giving you feedback back or whoever the robot's working with.
  topic: technical
- impact_reason: Challenges the standard paradigm of dense, automated rewards in RL,
    suggesting a shift towards human-like, sparse feedback (like code review or direct
    instruction) is viable and necessary for advanced learning.
  relevance_score: 9
  source: llm_enhanced
  text: what if, because if we look back to human learning, you know, humans don't
    have very filled rewards, even for math, that's the kind of interesting or coding,
    you know, the way we learn how to code is we code it. Well, I mean, obviously
    there's some very bad, but in the big early goings, you know, you kind of code
    it, you give it to your teacher or your dad or something, they're like, hey, it's,
    you know, this is wrong or this is right. And, and so, so I think that paradigm
    can be done.
  topic: technical/strategy
- impact_reason: Highlights the importance of integrating Chain-of-Thought (CoT) reasoning
    directly into embodied AI/robotics for transparency and collaborative decision-making.
  relevance_score: 9
  source: llm_enhanced
  text: the other aspect I'm really excited about is this kind of reasoning, like
    having a chain of thought reasoning alongside your robot working?
  topic: technical/predictions
- impact_reason: 'Identifies a key limitation in current autonomous systems: handling
    ambiguous, context-dependent, or socially nuanced driving situations that require
    human collaboration.'
  relevance_score: 9
  source: llm_enhanced
  text: there is no objective right answer. Like the Waymo is behind, you know, this
    bus, something's going on there. And this concept of being able to work with the
    humans around you to make decisions for robots would be where it's like, hey,
    actually, you know, I think you should go around this or maybe you should not
    go around this bus.
  topic: safety/strategy
- impact_reason: Explains the mechanism for translating human linguistic feedback
    (e.g., 'Don't do that') into a formal reward signal for model training.
  relevance_score: 9
  source: llm_enhanced
  text: in the back end, it's basically taking that language, converting it into a
    reward model and then training.
  topic: technical
- impact_reason: 'Articulates the primary risks associated with personalized AI training:
    security vulnerabilities and malicious/poor instruction leading to degraded or
    harmful capabilities.'
  relevance_score: 9
  source: llm_enhanced
  text: The second one is it's, well, you know, it creates security concerns because
    some owner could really teach their model to do something bad or not, or even
    capability concerns. So someone could be giving really bad reinforcement like
    rewards back.
  topic: safety/ethics
- impact_reason: Raises the critical future question regarding the privacy trade-off
    when a single, powerful AI agent controls all aspects of a user's digital and
    physical life (home, car, tasks).
  relevance_score: 9
  source: llm_enhanced
  text: The question I think in a lot of people's mind is, does is that privacy can
    be a trade-off? Okay, but the AI. So let's just say in five years from now, we
    live in a world where, you know, we have a home AI which is connected to the same
    as our phone AI, right? And let's assume that I can control all of our robots.
  topic: safety/predictions
- impact_reason: Challenges the current data-sharing relationship with Big Tech in
    the context of hyper-personalized, all-encompassing AI, demanding public discourse
    on acceptable boundaries.
  relevance_score: 9
  source: llm_enhanced
  text: Is it, how important is it then? Is it still OK as the relationship we have
    today with Google or with large companies and like Meta and so forth? Or is it
    not OK? And I don't know, I think everyone has, I think that has to be the public
    discourse over the next few years.
  topic: safety/ethics
- impact_reason: Argues that for AI operating on sensitive, personal assets (like
    property), the owner must retain primary control over the reinforcement learning
    process for security and alignment.
  relevance_score: 9
  source: llm_enhanced
  text: you truly want to really be the one doing reinforcement learning. You know,
    you want to be defining the rewards for, because it has access to your property,
    like you need to, you probably want to drive that model more so.
  topic: safety/strategy
- impact_reason: 'Identifies the primary technical hurdle for personalized AI: the
    prohibitive cost of retraining or fine-tuning massive, state-of-the-art models
    for every individual user.'
  relevance_score: 9
  source: llm_enhanced
  text: the biggest one being cost, like how do you, because, like I think the bigger
    models perform better, I think, you know, the bigger the better is something we've
    all kind of learned. And I think it's going to keep going.
  topic: technical/business
- impact_reason: 'Addresses the challenge of model versioning and knowledge transfer:
    how to efficiently migrate personalized training from an older base model (e.g.,
    Q1-3) to a superior new base model (e.g., Q1-5).'
  relevance_score: 9
  source: llm_enhanced
  text: When Q1-5 comes out, based off your training, Q1-5 will probably do better.
    So we have to kind of create this paradigm of being able to update.
  topic: technical/strategy
- impact_reason: 'Establishes the core philosophical goal: achieving an AI/robot relationship
    analogous to hiring a human employee who can be trained and improved on the job,
    rather than a static tool.'
  relevance_score: 9
  source: llm_enhanced
  text: Like when you hire somebody, you can work with them to improve their intelligence,
    improve their, the way they work. And so obviously there's technical challenges,
    but I do hope we can solve this.
  topic: strategy
- impact_reason: Suggests using the intelligence of the *new* model itself to intelligently
    prune, distill, and transfer relevant knowledge from the personalized training
    of the *old* model, managing update costs.
  relevance_score: 9
  source: llm_enhanced
  text: as the models get better, they get smarter. We can actually use the same models
    to determine what parts of the reinforcement learning that was done on the previous
    model should be utilized and should not be utilized. Could you distill it?
  topic: technical
- impact_reason: Draws a crucial analogy between hiring a human worker and utilizing
    an AI worker, emphasizing the need for iterative improvement and customization,
    which current static models lack.
  relevance_score: 9
  source: llm_enhanced
  text: If we really want to get to that world where we have a white collar or kind
    of a physical world worker, right, available to us, via AI, that's just, you know,
    that's not the paradigm. Like when you hire somebody, you can work with them to
    improve their intelligence, improve their, the way they work.
  topic: strategy
- impact_reason: Defines the high-value segment (10%) that *will* invest in deep AI
    customization, primarily for competitive differentiation.
  relevance_score: 9
  source: llm_enhanced
  text: there's probably is 10% that have the incentive for different reasons, right?
    One could be monetization. One could be just pure kind of exploration and interest...
    And third, probably the biggest bucket is, because you actually need to, because
    you're trying to differentiate yourself from your market, whatever market you're
    in, right?
  topic: strategy
- impact_reason: A powerful anecdote illustrating the current productivity multiplier
    effect of LLMs, blurring the line between solo work and small team output.
  relevance_score: 9
  source: llm_enhanced
  text: currently, I'm kind of doing as one person. And you can kind of do that, but
    I, you know, I'm talking to you about, we grew to 120 employees, right? And I'm
    thinking about this, well, do I have zero employees or do I have 120 employees?
    I'm not exactly sure, but I do have some employees, because I'm talking to Claude
    or GPT all day long, right?
  topic: business
- impact_reason: Clearly contrasts the standard RAG/fact distillation approach with
    the proposed 'small model learning' approach, framing it as true online learning
    augmentation.
  relevance_score: 9
  source: llm_enhanced
  text: The common way to do memory is essentially distilling a list of facts. And
    then I go and look at that list of facts and I put it back in the LLM. You might
    have an approach where you have a small model that you're actually building as
    the way that learns, just any other model learns from the memories that augments
    the big model.
  topic: technical
- impact_reason: Explicitly links the goal of real-time learning (online learning)
    to the proposed small-model architecture, mirroring biological learning processes.
  relevance_score: 9
  source: llm_enhanced
  text: humans have online learning. Like as we go, we learn like in real time as
    we kind of operate in the world. So what we try to try that is to retrain the
    Gemini 1.5 Pro with every day of interactions. Because that's not possible right
    now, what if you take a smaller model, a really strong small model, and that gets
    maintained for let's just take, like for myself, with my interactions.
  topic: technical
- impact_reason: Accurately summarizes the dominant 'scaling hypothesis' held by many
    leading AI labs regarding achieving AGI/white-collar capability.
  relevance_score: 9
  source: llm_enhanced
  text: The more a higher probability belief among the researchers at the leading...
    is that, hey, the current approach is working really well. We just keep gathering
    more and more data on knowledge work tasks and we do larger training runs... and
    we'll be able to get there...
  topic: predictions
- impact_reason: 'A nuanced prediction: not a hard stop, but a slowdown (diminishing
    returns) in progress toward complex, multi-step agency using current scaling methods.'
  relevance_score: 9
  source: llm_enhanced
  text: I'm not saying we're gonna hit a hard wall, but we're gonna keep getting diminishing
    returns, right? Like today, the best AI agent at doing... long horizon task, like,
    hey, go out and do this for me, right?
  topic: predictions
- impact_reason: 'Highlights the fundamental limitation of purely language-based pre-training:
    language alone does not equate to true world understanding, contrasting it with
    human learning.'
  relevance_score: 9
  source: llm_enhanced
  text: the only intelligence that we know that's been able to perform at that level
    actually learning a different way, kind of learn some base case understanding
    the world because a lot of the knowledge that we intake, we as humans or in-during
    pre-training for these models, it's referencing a lot of that about the world,
    right? That, yes, you can kind of read from language, but you can't really fully
    understand.
  topic: technical/limitations
- impact_reason: 'A critical prediction regarding the scaling hypothesis: continued
    scaling might lead to diminishing returns before reaching human-level general
    intelligence.'
  relevance_score: 9
  source: llm_enhanced
  text: we may not be, like I'm not saying we're gonna hit a hard wall, but we're
    gonna keep getting diminishing returns, right?
  topic: predictions/limitations
- impact_reason: Emphasizes the importance of environmental interaction (embodiment/multimodality)
    as a driver for deeper model understanding beyond static data.
  relevance_score: 9
  source: llm_enhanced
  text: I am really curious about kind of that across modality, right, and across
    environment. Like the ability to just operate an environment helps you understand
    something that I think will help these models actually perform better across it.
  topic: technical/strategy
- impact_reason: Connects the pursuit of embodied AI (robotics) directly to the fundamental
    goal of solving AGI, suggesting a dual benefit.
  relevance_score: 9
  source: llm_enhanced
  text: And if it's needed, you know, more people get excited and work on embodied
    AGI because then it would not only be helpful to have robots that are helpful
    to us in the physical world, but it will also be helpful just to solve AGI as
    a whole.
  topic: business/strategy
- impact_reason: This is a core principle of the foundation model paradigm—the power
    of massive, diverse data mixing, contrasting with older, siloed model training.
  relevance_score: 8
  source: llm_enhanced
  text: If you combine different pieces of data that you don't think actually have
    any commonality to them, it would actually make it better.
  topic: technical
- impact_reason: Provides a human analogy (transfer learning in the brain) to explain
    the power and mechanism behind foundation models succeeding where specialized
    models previously failed.
  relevance_score: 8
  source: llm_enhanced
  text: I think there's kind of transfer learning we're doing inside our brains and
    that's what really the Foundation Model pushes unlocked.
  topic: technical
- impact_reason: 'Offers a novel evolutionary perspective on AI development: starting
    with simpler, specialized embodiments (like an excavator) before moving to more
    complex ones (like humanoids).'
  relevance_score: 8
  source: llm_enhanced
  text: I'm actually, I've been looking a lot of evolution. And in evolution, you
    know, the way our intelligence was grown, I kind of think about this. I imagine
    it was put into human first with all these like different limbs, right? Would
    it have been able to try and do these tasks? And I don't know if it would have.
    And I think it was really able to kind of evolve in being able to learn an easier
    embodiment and then kind of grow from there.
  topic: strategy
- impact_reason: Emphasizes that the innovation in embodied AI lies not just in the
    base model, but in the *learning mechanism* tailored for physical interaction.
  relevance_score: 8
  source: llm_enhanced
  text: The main difference is how it is kind of programmed to learn from its interactions.
    And how it's programmed to kind of learn different tasks.
  topic: technical
- impact_reason: 'Details the product strategy: using voice interaction as the primary,
    continuous feedback loop for iterative improvement, blending training and operation.'
  relevance_score: 8
  source: llm_enhanced
  text: Our product is fully voice AI first, right? And you can talk to it all the
    time. You can talk to it when it's not working. You can be like, hey, next time
    you should try this and this and also when it is working.
  topic: business
- impact_reason: Highlights the importance of making the AI's internal reasoning process
    (Chain of Thought) transparent and accessible during physical execution.
  relevance_score: 8
  source: llm_enhanced
  text: And then the other, the other aspect I'm really excited about is this kind
    of reasoning, like having a chain of thought reasoning alongside your robot working?
  topic: technical
- impact_reason: Extends the interactive reasoning paradigm from construction robotics
    to autonomous vehicles, suggesting that human override/guidance via voice is superior
    in ambiguous driving situations.
  relevance_score: 8
  source: llm_enhanced
  text: I actually even wonder if later cars should do this. There is, it's so currently
    just like FSD and Waymo have not taken this approach, but I could see a feature
    where you're like, hey, actually, Waymo, can you do a quick short left turn here?
    Actually, change my mind, I need to go here, just through voice.
  topic: predictions
- impact_reason: Predicts a future where autonomous systems (like self-driving cars)
    must support dynamic, real-time course correction and negotiation with human operators
    via natural language.
  relevance_score: 8
  source: llm_enhanced
  text: I could see a feature where you're like, hey, actually, Waymo, can you do
    a quick short left turn here? Actually, change my mind, I need to go here, just
    through voice.
  topic: predictions/business
- impact_reason: Confirms the uniqueness and significance of the proposal for individually
    owned, customized AI instances versus the prevailing shared-model approach.
  relevance_score: 8
  source: llm_enhanced
  text: I think what you're saying is unique in what I've heard where you're actually
    saying people should have individual instances of this AI that is customized,
    that is taught, rather than just shared among everybody.
  topic: strategy
- impact_reason: Introduces a novel business model where personalized training effort
    translates into tangible, transferable, and monetizable AI assets (the customized
    weights/reward models).
  relevance_score: 8
  source: llm_enhanced
  text: you can actually put it up on a marketplace or others can use it for their
    projects. And you can kind of make money off the hard work of you teaching yours,
    but it's yours.
  topic: business
- impact_reason: 'Highlights a major limitation of current pre-trained models: the
    difficulty in fine-tuning or customizing them to specific user/business needs
    post-delivery.'
  relevance_score: 8
  source: llm_enhanced
  text: And once they give it to you, you can't really improve it to your liking.
  topic: technical
- impact_reason: 'Connects the technical distillation research directly to a business
    outcome: making the cost of swapping or updating base models manageable.'
  relevance_score: 8
  source: llm_enhanced
  text: I do think that there could be ways to figure that out. And now you're, now
    you're making the cost manageable, right? It's to be able to swap the base model.
  topic: business
- impact_reason: Provides a pragmatic segmentation of the market regarding AI customization
    needs, suggesting that the vast majority prefer ready-made solutions.
  relevance_score: 8
  source: llm_enhanced
  text: probably 90% approximately, right, of customers do not have the incentive
    or motivation or dynamics to do this. A, they may not need it. B, they just don't
    have the time, right?
  topic: business
- impact_reason: Highlights a major real-world economic driver (labor shortage) pushing
    industries like construction/contracting toward AI/robotics adoption for growth
    enablement.
  relevance_score: 8
  source: llm_enhanced
  text: in the physical world, we have a lot of labor shortage. So right now, one
    of the challenges is that just to grow, a lot of companies I talk to a lot of
    contractors, they don't grow because they worry that it's just going to be so
    hard to increase my labor force, right?
  topic: predictions
- impact_reason: Suggests that while LLMs can generate reports, true excellence in
    complex, novel problem-solving (like optimal hardware selection) still requires
    iterative, collaborative refinement, similar to human teamwork.
  relevance_score: 8
  source: llm_enhanced
  text: if you look at a GPT report that I used to do deep research reports with,
    you know, in other companies where I'll have a team member go, do a report. And
    I, like, you know, I don't know if it's a capability issue, right? There's always
    going to be, if you're trying to truly excel at what you're doing, you're going
    to work with your team member to do that report in a different way...
  topic: technical/strategy
- impact_reason: Identifies the current state-of-the-art in personalization (RAG,
    context window) as insufficient or limited, setting the stage for the need for
    deeper architectural changes.
  relevance_score: 8
  source: llm_enhanced
  text: The challenge is that's a little bit of a cost problem that we'll have to
    resolve. Today, all the leading, there's a whole group of startups and companies
    that are trying to solve memory and personalization using a big model like Gemini
    1.5 Pro. And all the approaches around either RAG... or obviously putting the
    context, but that's okay. I think those approaches have been tried...
  topic: technical
- impact_reason: Summarizes the prevailing, data-intensive scaling paradigm in current
    AI development (more data, bigger models, RLHF/RLAIF).
  relevance_score: 8
  source: llm_enhanced
  text: the current approach is working really well. We just keep gathering more and
    more data on knowledge work tasks and we do larger training runs, right? And we
    do more kind of smarter RL for post-training and we'll be able to get there, right?
  topic: technical/strategy
- impact_reason: Acknowledges the contrarian nature of the embodied prerequisite thesis,
    calling for empirical testing by the community.
  relevance_score: 8
  source: llm_enhanced
  text: I, you know, most people do not agree with this, but I think I really hope
    we, as a kind of AI community, test this out over the next little bit.
  topic: strategy/call to action
- impact_reason: A strong, provocative claim about the current state of LLMs, suggesting
    they have achieved a form of 'AGI' specifically for information retrieval/Q&A.
  relevance_score: 8
  source: llm_enhanced
  text: We already arguably are close to AGI at a question-answer approach
  topic: predictions/limitations
- impact_reason: Defines the practical, physical manifestation of AGI that the speaker
    is aiming for, moving the concept away from purely abstract intelligence.
  relevance_score: 7
  source: llm_enhanced
  text: I think when people think of AGI, they think of something like Iron Man's
    suit, and it's this embodied thing that has ability to work in the world.
  topic: predictions
- impact_reason: 'Identifies a key barrier to AI adoption for SMEs: the resource intensity
    required for deep customization beyond off-the-shelf solutions.'
  relevance_score: 7
  source: llm_enhanced
  text: maybe an average office company that's small business doesn't have the resources
    to try and train this new AI to do their specific ways.
  topic: business
- impact_reason: Connects national economic strategy (re-industrialization) directly
    to the necessity of AI/robotics due to labor constraints.
  relevance_score: 7
  source: llm_enhanced
  text: I think we do need to re-industrialize in America. And it's, but to that,
    there is a lot of demand. There's a lot of demand for energy, for infrastructure,
    that needs to be built. But the labor just isn't there right now.
  topic: strategy
- impact_reason: 'Articulates a ''first principles'' approach to building an AI-first
    company: maximizing current efficiency before scaling headcount.'
  relevance_score: 7
  source: llm_enhanced
  text: I'm kind of thinking for first principles is how many, like how efficient
    could you really be in today using AI? So I think, like, deeply, deeply efficient.
  topic: business
source: Unknown Source
summary: '## Podcast Summary: Embodied AGI: Reimagining AI Through Robotics w/ Adeel
  Zaman


  This 37-minute episode of *Artificial Insights* features host Daniel Menary interviewing
  **Adeel Zaman**, founder of a stealth company emerging from the HF0 residency, focused
  on **Embodied AGI**. Zaman, previously the CTO and Co-Founder of DOZR (which revolutionized
  construction e-commerce), is now pivoting his deep learning expertise toward applying
  foundation models to the physical world, arguing that progress in robotics and physical
  tasks lags significantly behind knowledge work AI.


  ### 1. Focus Area

  The primary focus is the convergence of **Foundation Models (FMs)** and **Robotics**
  to achieve **Embodied AGI**. Key themes include:

  *   The massive untapped potential of applying advanced AI to physical industries
  like construction and manufacturing.

  *   The necessity of a unified, multimodal foundation model approach for physical
  tasks, drawing parallels from successes in language models.

  *   A novel paradigm for robot training centered on **individual ownership, continuous
  learning, and human-in-the-loop interaction**, contrasting sharply with current
  centralized model deployment.


  ### 2. Key Technical Insights

  *   **Multimodal Transfer Learning (RT2 Inspiration):** Zaman is inspired by research
  like DeepMind''s RT2, which showed that grounding large vision-language models (VLMs)
  with robot action data significantly improves performance, leveraging knowledge
  learned across different data modalities.

  *   **Conscious vs. Subconscious Control:** The speaker is developing methods for
  foundation models to handle high-level reasoning (conscious decision-making, articulated
  via real-time voice interaction) while managing low-level actuator control subconsciously,
  similar to human motor skills (e.g., grasping a mug).

  *   **Real-Time Reasoning and Action Tokenization:** The proposed paradigm involves
  the model outputting a single stream of tokens combining language (reasoning/chain-of-thought)
  and action commands simultaneously during operation.


  ### 3. Business/Investment Angle

  *   **Massive Untapped Market:** The construction equipment market alone is valued
  at hundreds of billions globally, representing a huge opportunity for efficiency
  gains via AI automation where ML penetration is currently minimal.

  *   **Individualized Ownership Model:** Zaman advocates for a business model where
  users own and train their specific robot instances (e.g., excavator, skid steer),
  contrasting with shared-weight models like Tesla''s FSD. This ownership creates
  incentives for users to invest time in teaching the AI.

  *   **Incentivized Learning Marketplace:** The long-term vision includes a marketplace
  where owners can monetize the specialized knowledge they teach their robots by lending
  them out for specific projects, similar to how human employees are utilized.


  ### 4. Notable Companies/People

  *   **Adeel Zaman:** The central figure, leveraging his background in deep learning
  research and scaling a construction tech startup (DOZR) to tackle embodied AI.

  *   **DeepMind (RT2 Paper):** Cited as the foundational inspiration for grounding
  VLMs with robotic action data.

  *   **Tesla Optimus / OpenAI:** Used as examples of the current, centralized paradigm
  where the final, improved model is released to the user, who cannot significantly
  customize its core intelligence post-deployment.


  ### 5. Future Implications

  The conversation suggests a future where physical labor is dramatically accelerated
  by AI agents capable of general physical reasoning. Crucially, it predicts a necessary
  shift away from monolithic, centrally trained models toward **personalized, continuously
  learning robotic agents**. This shift is essential for achieving the level of adaptability
  seen in human workers. The discussion also raises critical public discourse points
  regarding **data privacy and control** when AGI has access to all facets of a user''s
  physical and digital life.


  ### 6. Target Audience

  This episode is highly valuable for **AI Researchers, Robotics Engineers, Venture
  Capitalists focused on Deep Tech/Industrial Automation, and Technology Strategists**
  interested in the practical deployment and commercialization of foundation models
  beyond the digital realm.'
tags:
- artificial-intelligence
- generative-ai
- ai-infrastructure
- startup
- google
- meta
- openai
title: 'Embodied AGI: Reimagining AI Through Robotics w/ Adeel Zaman, Founder in Stealth
  out of HF0, previously CTO & Co-Founder of DOZR'
topics:
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 81
  prominence: 1.0
  topic: artificial intelligence
- keywords:
  - generative ai
  - genai
  - chatgpt
  - gpt
  - claude
  - text generation
  - image generation
  mentions: 8
  prominence: 0.8
  topic: generative ai
- keywords:
  - gpu
  - tensor
  - training
  - inference
  - model deployment
  - vector database
  mentions: 8
  prominence: 0.8
  topic: ai infrastructure
- keywords:
  - startup
  - entrepreneur
  - founder
  - venture
  mentions: 4
  prominence: 0.4
  topic: startup
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-10-06 03:09:59 UTC -->
