---
companies:
- category: unknown
  confidence: medium
  context: not just sure what it is. You're listening to the Paul Higgins podcast.
    I'm Paul, and I help consultants build b
  name: Paul Higgins
  position: 305
- category: unknown
  confidence: medium
  context: t, episode number 639. In this episode, I talk to Garima Agrawal from HumanCon
    AI Consulting. So that's human, and
  name: Garima Agrawal
  position: 1273
- category: unknown
  confidence: medium
  context: 9. In this episode, I talk to Garima Agrawal from HumanCon AI Consulting.
    So that's human, and then C-O-N AI consulting. Y
  name: HumanCon AI Consulting
  position: 1293
- category: unknown
  confidence: medium
  context: nCon AI Consulting. So that's human, and then C-O-N AI consulting. You
    will learn from Garima how to eli
  name: N AI
  position: 1347
- category: unknown
  confidence: medium
  context: lligence. She took five years to get this through Arizona State University,
    and she serves as the Head of AI at Minerva. So
  name: Arizona State University
  position: 1992
- category: unknown
  confidence: medium
  context: ity, and she serves as the Head of AI at Minerva. So M-I-N-E-R-V-A-C-Q.
    After 15 years in the industry,
  name: So M
  position: 2063
- category: unknown
  confidence: medium
  context: 'ey can make more bucks out of their investments.


    And I know when I was back in corporate at Coca-Cola, w'
  name: And I
  position: 3611
- category: unknown
  confidence: medium
  context: to leave my job, come in to do PhD to move to the United States, and I
    have been very fortunate to work with the
  name: United States
  position: 4968
- category: unknown
  confidence: medium
  context: fortunate to work with the best, like, you know, Professor Juan Liu, who's
    among 20 top computer scientists of the wo
  name: Professor Juan Liu
  position: 5053
- category: unknown
  confidence: medium
  context: er scientists of the world. He was my mentor, and Professor Professor Dmitri
    Ptraska, one of the top reinforcement learning guys. So,
  name: Professor Professor Dmitri Ptraska
  position: 5148
- category: unknown
  confidence: medium
  context: ah. And the simple analogy I'll use because I'm a Formula One nut, so I
    enjoy watching Formula One. It's like y
  name: Formula One
  position: 6471
- category: unknown
  confidence: medium
  context: there's been tons of paper research to show that. But I think what we can
    do is to use it in the right wa
  name: But I
  position: 8033
- category: unknown
  confidence: medium
  context: this business. I'm doing this, blah, blah, blah. Now I want to create this
    kind of a niche market. I wan
  name: Now I
  position: 9786
- category: unknown
  confidence: medium
  context: er context. You know, am I better off doing that? Am I better off just
    verbalizing what the context is?
  name: Am I
  position: 11416
- category: unknown
  confidence: medium
  context: be and TikTok on learning more and more about AI. Sometimes I'll come across
    JSON prompting, and they say that
  name: Sometimes I
  position: 13077
- category: tech
  confidence: high
  context: ll of the markdown, you know, markdown versus the Google... Yes, yeah,
    it's better that it is as stripped
  name: Google
  position: 14832
- category: unknown
  confidence: medium
  context: kenization, all of that. But when we are using an API LLM call, then it's
    better to take care of all these
  name: API LLM
  position: 15376
- category: unknown
  confidence: medium
  context: h the project. And then you can... the project in ChatGPT Plus allows you
    to keep your documents and you want to
  name: ChatGPT Plus
  position: 16392
- category: tech
  confidence: high
  context: k pen. Black pen is when I used to sit down every Monday and type out all
    the content myself. Now, my team
  name: Monday
  position: 18001
- category: unknown
  confidence: medium
  context: task or more of a scientific task, I would go for Claude AI because I think
    Claude's intrinsic models are bes
  name: Claude AI
  position: 20032
- category: unknown
  confidence: medium
  context: at, and I prefer using my best model to go to its Claude Sonnet 3.5, and
    hence down. I think the footprint of the
  name: Claude Sonnet
  position: 20148
- category: unknown
  confidence: medium
  context: 'information, it just gives all that correct, why? Because Google has all
    that, right? Trained it on.


    Yeah, yeah.'
  name: Because Google
  position: 22070
- category: tech
  confidence: high
  context: e citations, or it creates things on its own. So, Perplexity might be your
    go-to. You know, if you want to fin
  name: Perplexity
  position: 22669
- category: unknown
  confidence: medium
  context: is podcast, but, you know, there's Manas, there's Jim Spark, there's the
    ones that are, you know, doing more
  name: Jim Spark
  position: 23232
- category: unknown
  confidence: medium
  context: ng with at HumanCon, and I'm a consultant at ASU, Arizona State, and working
    there as well. So, all of this I'm a
  name: Arizona State
  position: 26420
- category: unknown
  confidence: medium
  context: e very, very mindful. And I have a paper on this, Mindful RAG, where I
    illustrate on what could be the failure
  name: Mindful RAG
  position: 26943
- category: tech
  confidence: high
  context: cky when mobile phones came in, you know, when we Microsoft, you know,
    introduced Excel and Word, you know, s
  name: Microsoft
  position: 27532
- category: unknown
  confidence: medium
  context: terns, same deal sizes, same time-for-money trap. On Paul and I built and
    sold a seven-figure consulting bu
  name: On Paul
  position: 28410
- category: ai_application
  confidence: high
  context: The most commonly used LLM discussed; the focus of troubleshooting hallucinations
    and prompting techniques.
  name: ChatGPT
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as a specific LLM recommended for coding tasks.
  name: Claude
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as a specific LLM recommended for technical research tasks.
  name: Gemini
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: The consulting firm Garima Agrawal is associated with, focusing on AI implementation
    and reducing hallucination.
  name: HumanCon AI Consulting
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: The organization where Garima Agrawal serves as the Head of AI.
  name: Minerva (M-I-N-E-R-V-A-C-Q)
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: Where the guest, Garima Agrawal, completed her PhD in Artificial Intelligence.
  name: Arizona State University
  source: llm_enhanced
- category: other
  confidence: medium
  context: Paul Higgins' former employer, used as a reference point for business structure
    analogies.
  name: Coca-Cola
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: General reference to the Claude model family.
  name: Claude AI
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Specific version of the Claude model mentioned as having good performance
    with less hallucination.
  name: Claude Sonnet 3.5
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as a model that is fast but struggles with complex or content-heavy
    tasks.
  name: DeepSeek
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Mentioned as the entity behind Gemini, possessing vast training data.
  name: Google
  source: llm_enhanced
- category: ai_startup
  confidence: high
  context: The company where the speaker holds the role of Head of AI; they are building
    an agentic AI platform for customer service.
  name: Minerva
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Recommended as the go-to tool for deep research, finding research papers,
    and references, due to better citation reliability than ChatGPT.
  name: Perplexity
  source: llm_enhanced
- category: ai_startup
  confidence: medium
  context: Mentioned in the context of agentic AI tools.
  name: Manas
  source: llm_enhanced
- category: ai_startup
  confidence: medium
  context: Mentioned in the context of agentic AI tools.
  name: Jim Spark
  source: llm_enhanced
- category: ai_infrastructure
  confidence: medium
  context: Mentioned as a platform where Claude is used to help create landing pages
    or mini-apps.
  name: Bubble
  source: llm_enhanced
- category: ai_startup
  confidence: medium
  context: Mentioned as a platform where Claude is used to help create landing pages
    or mini-apps.
  name: Lovable
  source: llm_enhanced
- category: ai_research
  confidence: medium
  context: The speaker consults there, implying an institutional connection to AI
    work or research application.
  name: ASU (Arizona State)
  source: llm_enhanced
date: 2025-09-29 18:30:00 +0000
duration: 41
has_transcript: false
insights:
- actionable: true
  confidence: medium
  extracted: do, you know, we should take this approach?" It gives you five approaches
  text: we should do, you know, we should take this approach?" It gives you five approaches.
  type: recommendation
layout: episode
llm_enhanced: true
original_url: https://audio.listennotes.com/e/p/3f93957e5d1346368d62f04331310bc3/
processing_date: 2025-10-06 05:44:37 +0000
quotes:
- length: 150
  relevance_score: 5
  text: '" So, you have to make the LLM understand the intent of your question, and
    if it fails to get the intent, then it will never give you the right answer'
  topics: []
- length: 200
  relevance_score: 4
  text: Too many AI and tech consultants are stuck in the LLM hamster wheel, asking
    ChatGPT basic questions, getting hallucinated responses, and wondering why their
    AI productivity isn't living up to the hype
  topics: []
- length: 74
  relevance_score: 4
  text: So, it takes care of the parsing, embedding, and tokenization, all of that
  topics: []
- length: 63
  relevance_score: 3
  text: She's been a programmer, holds a PhD in artificial intelligence
  topics: []
- length: 54
  relevance_score: 3
  text: This was the biggest bottleneck of the industry so far
  topics: []
- length: 34
  relevance_score: 3
  text: But now you have to narrow it down
  topics: []
- length: 102
  relevance_score: 3
  text: You know that it knows something about it, but you have to narrow it down
    and bring it to your context
  topics: []
- length: 28
  relevance_score: 3
  text: So, you have to work with it
  topics: []
- length: 108
  relevance_score: 3
  text: The problem is when we use the API, goes token-wise, and the text needs to
    be in bars embedded and then sent
  topics: []
- length: 230
  relevance_score: 3
  text: So, like, you know, a lot of things have similar kind of meanings and, you
    know, they're ambiguous, so you have to bring it to your steer the direction of
    thinking for the model, as in parameterizing it towards the right direction
  topics: []
- length: 161
  relevance_score: 3
  text: 'Like, you have to really work with the model, and even when it''s coding,
    then you have to think in this direction: "I want to solve this problem in a certain
    way'
  topics: []
- length: 33
  relevance_score: 3
  text: You have to be very, very mindful
  topics: []
- length: 269
  relevance_score: 3
  text: 'On Paul and I built and sold a seven-figure consulting business, but here''s
    what I''ve learned from mentoring other consultants: the real breakthroughs happen
    when you combine my experience with live problem-solving of people going through
    exactly what you''re facing now'
  topics: []
- impact_reason: Offers a specific, practical solution (layered prompting) to a major
    LLM challenge (hallucination) applicable across different models.
  relevance_score: 10
  source: llm_enhanced
  text: eliminate AI hallucinations using layered prompting techniques that work with
    any LLM, not just the fancy enterprise tools
  topic: technical
- impact_reason: Clarifies the distinction between current interactive AI and the
    future goal of agentic AI, focusing on automation and autonomy.
  relevance_score: 10
  source: llm_enhanced
  text: the practical difference between interactive AI and true agentic AI, which
    is a key buzzword at the moment, plus how to build goal-driven systems that take
    actions without constant oversight.
  topic: predictions
- impact_reason: Points directly to advanced techniques (Knowledge Graphs, RAG) necessary
    for grounding LLMs in specific domain knowledge.
  relevance_score: 10
  source: llm_enhanced
  text: how to make a domains where, you know, how we can change the LLMs by inducing
    the knowledge, it could be knowledge graph, it could be RAG, and how to do effective
    RAG.
  topic: technical
- impact_reason: 'Defines the optimal user mindset for LLMs: collaborative partner
    requiring structured context (''layered prompting'').'
  relevance_score: 10
  source: llm_enhanced
  text: So, I take it as my thinking partner, not totally rely on it to give me all
    the solutions. But I have to give it the enough context, and I call it as layered
    prompting...
  topic: strategy
- impact_reason: Provides a strong warning about context window overload leading to
    irreversible hallucination cascades, supported by research context.
  relevance_score: 10
  source: llm_enhanced
  text: If we give too much information at one time, that's where the hallucination
    starts. Once any model hallucinates, it's a snowball effect. So, there have been
    a lot of research papers on it. It's a snowball effect. Once it goes in a wrong
    direction, it keeps going.
  topic: safety
- impact_reason: 'Offers a specific model recommendation: Claude (especially Sonnet
    3.5) for coding/scientific tasks due to perceived lower hallucination rates and
    better intrinsic model structure for logic.'
  relevance_score: 10
  source: llm_enhanced
  text: So, if I want to do some kind of a coding task or more of a scientific task,
    I would go for Claude AI because I think Claude's intrinsic models are best in
    that, and I prefer using my best model to go to its Claude Sonnet 3.5, and hence
    down. I think the footprint of the model is so good that there is very less amount
    of hallucination, but it works best with the, you know, the coding task...
  topic: technical/strategy
- impact_reason: Strong warning against using ChatGPT for citation-dependent research
    due to known hallucinated citations, recommending Perplexity as the superior tool
    for verifiable research/references.
  relevance_score: 10
  source: llm_enhanced
  text: If it is for research like my kind of research, then I wouldn't go for ChatGPT
    because, you know, it gives the citations which are wrong, which is everyone knows.
    So, you never use the... you let it search the web, but never use the citations,
    or it creates things on its own. So, Perplexity might be your go-to. You know,
    if you want to find the research papers or the references and things like that,
    then it's Perplexity.
  topic: safety/strategy
- impact_reason: Provides a clear, actionable definition of Agentic AI, distinguishing
    it from simple interactive AI by emphasizing goal-driven behavior, decision-making,
    and environmental context awareness.
  relevance_score: 10
  source: llm_enhanced
  text: Basically, agentic AI means that, you know, there is an AI which is goal-driven.
    It knows these are the tasks. It can act at a certain point, able to take a decision,
    able to get the context from the environment that something has changed, I need
    an action, right?
  topic: predictions/technical
- impact_reason: Details a sophisticated real-time RAG application within an agentic
    framework, showing how context is used to proactively retrieve answers for human
    agents.
  relevance_score: 10
  source: llm_enhanced
  text: So, he knows that the customer is calling, and from the conversation in real-time,
    we are able to take the context, and the AI takes the decision to create a question
    and understand that the customer has asked some question. Let me go back, do the
    RAG, get the answer for the agent, keep it ready before he has to answer, right?
  topic: technical/business
- impact_reason: This clearly defines the concept of 'agentic AI'—systems capable
    of autonomous decision-making based on environmental context and predefined goals,
    which is a major trend beyond simple prompt-response LLMs.
  relevance_score: 10
  source: llm_enhanced
  text: there is an AI which is goal-driven. It knows these are the tasks. It can
    act at a certain point, able to take a decision, able to get the context from
    the environment that something has changed, I need an action, right?
  topic: technical/predictions
- impact_reason: Details a sophisticated, real-time RAG (Retrieval-Augmented Generation)
    loop integrated into agent workflows, showcasing low-latency, context-aware decision-making.
  relevance_score: 10
  source: llm_enhanced
  text: from the conversation in real-time, we are able to take the context, and the
    AI takes the decision to create a question and understand that the customer has
    asked some question. Let me go back, do the RAG, get the answer for the agent,
    keep it ready before he has to answer, right?
  topic: technical/business
- impact_reason: 'Provides crucial advice on AI adoption: avoid both paralysis (fear
    of error) and blind trust. Human oversight and critical thinking remain paramount.'
  relevance_score: 10
  source: llm_enhanced
  text: totally relying on AI—these are the two bottlenecks I see mostly. And exploring
    AI, but have your own thinking going on. You have to be very, very mindful.
  topic: strategy/safety
- impact_reason: Introduces the concept of 'Mindful RAG' and the practice of using
    AI itself (another LLM) to analyze the failure modes of the primary system, a
    key technique for robust deployment.
  relevance_score: 10
  source: llm_enhanced
  text: I have a paper on this, Mindful RAG, where I illustrate on what could be the
    failure points of AI, and how I've figured that by analyzing the error logs through
    the AI.
  topic: technical/safety
- impact_reason: 'A sharp strategic warning for consultants and service businesses:
    AI enables better execution, but without strategic rethinking (e.g., productization),
    it won''t break revenue ceilings.'
  relevance_score: 10
  source: llm_enhanced
  text: Brilliant execution, terrible strategy. You can solve any kind of problem,
    but you'll be stuck in the same revenue patterns, same deal sizes, same time-for-money
    trap.
  topic: business/strategy
- impact_reason: Highlights a common pitfall for AI practitioners—over-reliance on
    basic LLM interaction without strategic implementation, leading to disappointment.
  relevance_score: 9
  source: llm_enhanced
  text: Too many AI and tech consultants are stuck in the LLM hamster wheel, asking
    ChatGPT basic questions, getting hallucinated responses, and wondering why their
    AI productivity isn't living up to the hype.
  topic: strategy
- impact_reason: Provides actionable guidance on model specialization, suggesting
    that different LLMs excel at different tasks.
  relevance_score: 9
  source: llm_enhanced
  text: which specific LLMs to use for different tasks—you know, ChatGPT for analysis,
    Claude for coding, Gemini for technical research
  topic: technical
- impact_reason: 'Summarizes the core technical and strategic goals in current AI
    consulting: reducing errors and moving toward autonomous, goal-driven systems.'
  relevance_score: 9
  source: llm_enhanced
  text: how we can reduce the hallucination, what best we can do, how we can make
    AI as an agent to AI, make it goal-driven, where AI can learn how to take decisions
    and then work in conjunction with what is required for the product and for the
    domain.
  topic: technical
- impact_reason: Highlights the rare combination of deep theoretical AI knowledge
    (from PhD) and practical industry application experience.
  relevance_score: 9
  source: llm_enhanced
  text: I understand how industry works, and I have been with AI like my master's
    was neural networks... So, when we are in the industry, you see from the application
    point of view, but I understand it from the technically, you know, how theoretically
    it's working...
  topic: strategy
- impact_reason: Provides a foundational perspective on why LLMs are revolutionary—solving
    the natural language interface bottleneck.
  relevance_score: 9
  source: llm_enhanced
  text: We have to appreciate there is an AI which is able to understand and talk
    to us in a natural language. This was the biggest bottleneck of the industry so
    far. So, this is a big innovation we've got.
  topic: predictions
- impact_reason: Crucial reminder that general LLMs lack specific context; the user
    must supply it.
  relevance_score: 9
  source: llm_enhanced
  text: You want to create some content, or you want to analyze a problem? Now, this
    one AI doesn't know anything about your problem. It's a general-purpose AI which
    is able to gather some thoughts and bring to you.
  topic: safety/strategy
- impact_reason: 'Actionable advice on starting prompt engineering: probe the model''s
    existing knowledge before diving into complex tasks.'
  relevance_score: 9
  source: llm_enhanced
  text: Go small, go with a small prompt first. Start with trying to figure out that
    ChatGPT knows how much it knows about a particular domain...
  topic: technical
- impact_reason: A specific technique within layered prompting to verify the model's
    comprehension before proceeding.
  relevance_score: 9
  source: llm_enhanced
  text: ask it, 'Do you understand my problem, or just explain me what do you understand?'
  topic: technical
- impact_reason: 'Highlights a high-value application of LLMs with reference material:
    pattern recognition and synthesis across documents.'
  relevance_score: 9
  source: llm_enhanced
  text: One good way of giving the documents is give it some context. Ask it to analyze
    what are the patterns do you see? What are, you know, that is something very important
    to be able to use AI for understanding the patterns that are in the documentation
    or different kind of documentation.
  topic: technical
- impact_reason: Provides a nuanced technical distinction between UI interaction and
    API calls regarding structured input. JSON/CSV are preferred for API consumption
    over complex file types.
  relevance_score: 9
  source: llm_enhanced
  text: People say do a JSON prompting, but it actually works better when you are
    sending it as an API. When you are using it as an application and using the API
    of LLM, then if you pass everything in a JSON, it is able to consume it better.
    Why? Because the LLM is able to parse JSON, CSV, TXT, those kind of documents
    rather than PDFs, Excel—a big no-no.
  topic: technical
- impact_reason: Explains the underlying technical difference between UI interaction
    (where the platform handles tokenization/embedding) and direct API calls (where
    the developer must manage these steps).
  relevance_score: 9
  source: llm_enhanced
  text: The problem is when we use the API, goes token-wise, and the text needs to
    be in bars embedded and then sent. So, when we are doing it on the UI, it's all
    done by the UI itself. It's embedded there. So, it takes care of the parsing,
    embedding, and tokenization, all of that.
  topic: technical
- impact_reason: Defines and explains core prompting techniques (zero-shot vs. few-shot),
    which is fundamental knowledge for advanced LLM users.
  relevance_score: 9
  source: llm_enhanced
  text: We call it zero-shot, few-shot, and multi-shot prompting in show. What it
    means is that sometimes if your domain or your task is very specific, you're not
    able to give it through the instructions, or you wanted to show that, you know,
    this is a certain template I want to follow, then it is good to give those examples,
    right? And then you can have multiple examples. Zero-shot is when you're not going
    by plain instructions, but giving examples is like few-shot.
  topic: technical
- impact_reason: Recommends Gemini for technical 'how-to' information, tool specifications,
    and Python libraries, leveraging Google's training data advantage in this domain.
  relevance_score: 9
  source: llm_enhanced
  text: Claude is very technical, and Gemini again is another model where if you want
    to get more information about like how things are done, how they are technically
    solved, then I go for Gemini. A bunch of information which you can... I wouldn't
    say 100%, but kind of like, you know, you go by it that, 'Okay, it's giving you
    the right information about the tools, how, you know, the Python libraries,' all
    of that kind of bunch of information, it just gives all that correct, why? Because
    Google has all that, right? Trained it on.
  topic: strategy/technical
- impact_reason: Presents a high-value, real-world application of agentic AI in customer
    service, using RAG and real-time context to assist human agents.
  relevance_score: 9
  source: llm_enhanced
  text: This is agentic AI behavior. Yes, right? So, if you are able to use your LLMs,
    and that is what we are doing through API at Minerva, that, you know, we are able
    to create LLMs, and at Minerva, we are handling customer service contacts, entire
    calls, and we're making that experience, you know, seamless for the agent who's
    taking the call.
  topic: business/predictions
- impact_reason: A concise label for the advanced, goal-oriented AI functionality
    being described, crucial for understanding the next evolution of AI applications.
  relevance_score: 9
  source: llm_enhanced
  text: This is agentic AI behavior.
  topic: technical
- impact_reason: Provides a concrete, high-value business application of LLMs in real-time
    customer service augmentation, moving beyond simple chatbots to active agent support.
  relevance_score: 9
  source: llm_enhanced
  text: we are able to create LLMs, and at Minerva, we are handling customer service
    contacts, entire calls, and we're making that experience, you know, seamless for
    the agent who's taking the call.
  topic: business/predictions
- impact_reason: Illustrates the architecture of complex agentic systems involving
    multi-threaded, specialized AI components monitoring state changes and proactively
    offering assistance.
  relevance_score: 9
  source: llm_enhanced
  text: the agentic AI, another thread, of course, it's not the same AI, but there
    are multiple threads working there, and can... Okay, it looks like, you know,
    the intent has changed, the conversation is going in the other direction. The
    agent may need this help.
  topic: technical
- impact_reason: 'Emphasizes the strategic skill gap: success in the AI era is less
    about having the technology and more about knowing the optimal application context
    for different tools.'
  relevance_score: 9
  source: llm_enhanced
  text: I have figured that, you know, how to use and when to use and which AI to
    use, right?
  topic: strategy/business
- impact_reason: 'A fundamental lesson in prompt engineering and LLM interaction:
    intent alignment is the prerequisite for accurate output, regardless of the model''s
    size or capability.'
  relevance_score: 9
  source: llm_enhanced
  text: You have to make the LLM understand the intent of your question, and if it
    fails to get the intent, then it will never give you the right answer.
  topic: technical/strategy
- impact_reason: 'Captures the unique challenge of the current AI landscape: tool
    proliferation and the overwhelming pace of change, contrasting it with previous,
    more centralized technology shifts.'
  relevance_score: 9
  source: llm_enhanced
  text: The one thing that I find most challenging at the moment is just the pace
    of releasing. And, you know, if, like, at least when there was Microsoft, there
    was Microsoft, right? Like, you found new ways to use Excel, but it was just Excel.
    Whereas now, I could list 50 tools that I've got on my... I've got to discover
    list.
  topic: strategy/predictions
- impact_reason: Emphasizes the need to move beyond basic usage to strategic integration
    for real transformation.
  relevance_score: 8
  source: llm_enhanced
  text: Meanwhile, they're missing the strategic approaches that could actually transform
    both their internal operations and their client delivery.
  topic: strategy
- impact_reason: 'Defines a key market need: safe, trustworthy AI implementation,
    especially for startups.'
  relevance_score: 8
  source: llm_enhanced
  text: My ideal clients are twofold. One is the startups who are trying to implement
    AI and trying to figure out how they can use AI in a safe manner, where effectively,
    where there's no hallucination or they can trust the solution.
  topic: business
- impact_reason: Establishes deep, longitudinal expertise, contrasting early ML techniques
    (backprop, SVMs) with current LLMs, lending credibility to her insights.
  relevance_score: 8
  source: llm_enhanced
  text: I was just fortunate to be able to do, you know, my PhD after 15 years of
    industry experience... I have been with AI like my master's was neural networks,
    you know, when we were doing backpropagation back those days. And I have worked
    in support vector machines when we were doing intent tagging manually.
  topic: technical
- impact_reason: Illustrates the iterative, step-by-step nature of effective layered
    prompting.
  relevance_score: 8
  source: llm_enhanced
  text: 'Start explaining, ''Hey, I have this business. I''m doing this, blah, blah,
    blah. Now I want to create this kind of a niche market... So, it starts thinking
    with you and then goes step by step...'' '
  topic: technical
- impact_reason: 'Practical advice on handling model failure: immediate termination
    and restart rather than trying to correct a deeply flawed trajectory.'
  relevance_score: 8
  source: llm_enhanced
  text: So, that's best is to stop it there, restart. That means you have screwed
    it up, and it's not going to go in the right direction.
  topic: technical
- impact_reason: Provides nuance on advanced prompting techniques, suggesting structured
    formats like JSON are optimized for programmatic (API) use rather than direct
    chat interface interaction.
  relevance_score: 8
  source: llm_enhanced
  text: JSON prompting, but it actually works better when you are sending it as an
    API.
  topic: technical
- impact_reason: 'Strategic advice on project setup: define the overarching goal/context
    (the ''bigger picture'') before asking for specific outputs, leveraging features
    like custom projects/GPTs for context retention.'
  relevance_score: 8
  source: llm_enhanced
  text: I should be able to explain my bigger picture to the model, and then... And
    that I can do through the projects. I go on analyzing, I go like, you know, this
    is how my marketing strategy works. These are my documents.
  topic: strategy/business
- impact_reason: Crucial advice on human-in-the-loop validation and iterative refinement,
    emphasizing collaboration over blind acceptance of AI output.
  relevance_score: 8
  source: llm_enhanced
  text: Just don't trust it like blindly, or you can give suggestions. Yes, that,
    'Hey, I think this is not a right approach. You can do this,' and so on.
  topic: safety/practical lessons
- impact_reason: Provides a tangible framework ('red pen, black pen') for integrating
    AI into content workflows, focusing on AI generation followed by human refinement
    to maintain voice/accuracy.
  relevance_score: 8
  source: llm_enhanced
  text: I call it red pen, black pen. Black pen is when I used to sit down every Monday
    and type out all the content myself. Now, my team runs all of my calls through
    the LLM that then produces the content, and then I read it. I make sure that it's
    me.
  topic: business
- impact_reason: Explains the necessity of 'steering' or parameterizing the model's
    thinking due to ambiguity in its vast training data.
  relevance_score: 8
  source: llm_enhanced
  text: But what I have seen is that you can actually bring it to a certain direction
    because, you know, it's been trained on huge amount of information. So, like,
    you know, a lot of things have similar kind of meanings and, you know, they're
    ambiguous, so you have to bring it to your steer the direction of thinking for
    the model, as in parameterizing it towards the right direction.
  topic: technical
- impact_reason: 'Provides a clear recommendation matrix: ChatGPT excels at general
    NLP tasks (summarization, rephrasing).'
  relevance_score: 8
  source: llm_enhanced
  text: So, ChatGPT is mostly when you want to use natural language. By natural language,
    I mean, I want to reduce the content, I want to shorten it, I want to summarize,
    rephrasing, analyze content delivery—all of that is better with ChatGPT.
  topic: strategy
- impact_reason: Provides a critical comparative review of a specific model (DeepSeek),
    noting performance degradation under high content load, which is valuable for
    practitioners choosing models.
  relevance_score: 8
  source: llm_enhanced
  text: Now, with DeepSeek, I have some reservations. The model is faster, but I think
    if you have too much English or too much content going on, the model kind of shakes.
    It doesn't give you the right information.
  topic: technical
- impact_reason: 'Highlights a practical, time-sensitive feature of agentic systems:
    providing continuous, periodic summaries to maintain agent situational awareness
    during long interactions.'
  relevance_score: 8
  source: llm_enhanced
  text: Also, create a summary of the conversation that what's going on, maybe after
    every minute or every 50 seconds, 40 seconds, you know, give a summary to the
    agent so he gets a snapshot of what has been talked about.
  topic: practical lessons
- impact_reason: 'A critical clarification: current ''agentic'' behavior is highly
    engineered and constrained by human design, managing expectations about true autonomy.'
  relevance_score: 8
  source: llm_enhanced
  text: it's not that AI is taking action, but we have curated it in that way so that's
    basically agentic AI behavior.
  topic: safety/strategy
- impact_reason: Identifies investors as a key client segment needing expert guidance
    to navigate the complex AI investment landscape.
  relevance_score: 7
  source: llm_enhanced
  text: Second is, I would say the investors. So, people who are looking into investing
    into AI, they are curious about that, they don't even know which startups or ventures
    will be a useful or good investment for them.
  topic: business
- impact_reason: A concrete example of providing proprietary context data to improve
    LLM performance for specific tasks.
  relevance_score: 7
  source: llm_enhanced
  text: I often upload the transcripts from the calls to give it better context.
  topic: technical
- impact_reason: Clarifies that complex input structuring (like JSON) is primarily
    an API optimization concern, not a necessary step for standard UI interaction.
  relevance_score: 7
  source: llm_enhanced
  text: But all the prompting if it is done through a JSON is fine, but if you're
    using a UI, I mean, it doesn't matter. It's all totally fine.
  topic: practical lessons
- impact_reason: Characterizes ChatGPT's strength as broad general knowledge and analysis,
    while subtly noting its tendency toward confident overstatement.
  relevance_score: 7
  source: llm_enhanced
  text: ChatGPT is very good for analysis of multiple different kinds of topics where
    it can go broad, and it almost knows about everything—at least it pretends to
    know about everything.
  topic: technical/strategy
- impact_reason: 'Highlights the value proposition of mentorship/group coaching in
    the AI era: combining immediate, practical problem-solving with experienced guidance
    to navigate new strategic hurdles.'
  relevance_score: 7
  source: llm_enhanced
  text: It's not theory; it's real-time strategic thinking with consultants in the
    trenches, plus someone who's already made the journey.
  topic: business
- impact_reason: Poses a key question regarding input cleanliness (e.g., stripping
    markdown) and its impact on LLM interpretation, suggesting simplicity might be
    better.
  relevance_score: 6
  source: llm_enhanced
  text: It's better that it is as stripped back as possible, or does that matter less
    the way that the LLM interprets the information?
  topic: technical
- impact_reason: Reinforces the theme that successful AI integration requires active,
    thoughtful engagement from the user, not passive input.
  relevance_score: 6
  source: llm_enhanced
  text: So, all of that when you work with AI, then it gives you the right results.
  topic: practical lessons
- impact_reason: A motivational insight emphasizing that age is not a barrier to high-level
    learning (like advanced AI/PhD work), encouraging continuous upskilling.
  relevance_score: 6
  source: llm_enhanced
  text: I started my PhD at 40, and it was very challenging. It felt like, you know,
    studying with those 25-year-old students and all that. So, it was hard, but it
    is just a number. I would say that you can conquer anything if you set your mind
    on it.
  topic: strategy
source: Unknown Source
summary: '## Podcast Episode Summary: 639 - How to Stop ChatGPT from Lying to You
  (AI PhD Reveals the Fix) with Garima Agrawal


  This episode of the Paul Higgins podcast features Dr. Garima Agrawal, an AI PhD
  and Head of AI at Minerva, who addresses the critical challenges consultants and
  businesses face when implementing Large Language Models (LLMs), primarily focusing
  on eliminating hallucinations and moving toward effective, goal-driven AI integration.


  ---


  ### 1. Focus Area

  The discussion centers on **Practical LLM Implementation and Mitigation of Hallucinations**.
  Specific topics include advanced prompting techniques (layered prompting), strategic
  LLM selection for different tasks (e.g., analysis vs. coding), the distinction between
  interactive and agentic AI, and structuring context delivery (document uploads vs.
  verbal input).


  ### 2. Key Technical Insights

  *   **Layered Prompting for Hallucination Reduction:** Instead of single, blanket
  prompts, users should employ a multi-step, iterative approach. Start by testing
  the LLM''s baseline knowledge of a domain, then gradually introduce specific context
  about the user''s problem, and finally, ask the model to confirm its understanding
  before proceeding to solutions.

  *   **LLM Specialization by Task:** Different LLMs excel in different areas based
  on their training data. **ChatGPT** is recommended for broad analysis and natural
  language tasks (summarization, rephrasing). **Claude** is preferred for coding and
  technical tasks due to its strong intrinsic models (specifically Claude 3.5 Sonnet).
  **Gemini** is useful for technical research and gathering information about tools
  and libraries because of Google''s extensive training data.

  *   **Agentic vs. Interactive AI:** Interactive AI (like standard ChatGPT use) is
  static and reactive. **Agentic AI** is goal-driven, capable of taking actions, sensing
  environmental changes, and making decisions without constant human oversight (e.g.,
  automatically sending reminders or preparing interview profiles based on real-time
  context).


  ### 3. Business/Investment Angle

  *   **Consulting Bottlenecks:** Many AI/tech consultants are stuck in the "LLM hamster
  wheel," relying on basic prompting and getting unreliable results, hindering scalable
  growth for themselves and their clients.

  *   **Investor Guidance:** Dr. Agrawal advises investors on which AI ventures are
  sound, leveraging her technical depth to bridge the gap between complex AI development
  and commercial viability.

  *   **Strategic Implementation:** The focus for startups should be on implementing
  AI safely and effectively, reducing hallucinations to build trust in the solutions
  being deployed.


  ### 4. Notable Companies/People

  *   **Garima Agrawal (Guest):** AI PhD, Head of AI at Minerva, with 15 years of
  industry experience prior to her PhD, specializing in LLM research, RAG, and knowledge
  graphs.

  *   **Paul Higgins (Host):** Consultant specializing in helping other consultants
  build scalable businesses that don''t rely solely on the founder.

  *   **Minerva:** The company where Dr. Agrawal is Head of AI, currently building
  an agentic AI platform, particularly for handling customer service contacts.

  *   **LLM Providers Mentioned:** ChatGPT (OpenAI), Claude (Anthropic), Gemini (Google),
  Perplexity (for research).


  ### 5. Future Implications

  The industry is moving rapidly from simple **interactive AI** (asking questions)
  toward sophisticated **agentic AI** systems capable of executing complex, goal-driven
  workflows autonomously. Success in AI implementation will depend on understanding
  the underlying mechanics and selecting the right model for the specific job, rather
  than relying on a single general-purpose tool.


  ### 6. Target Audience

  This episode is highly valuable for **AI/Tech Consultants, CTOs, Startup Founders,
  and Investors** who are past the initial hype phase and need actionable, technically
  grounded strategies to move from basic LLM usage to robust, reliable, and scalable
  AI integration.


  ---


  ### Comprehensive Summary Narrative


  The podcast episode opens by framing the common frustration among consultants: using
  ChatGPT yields inconsistent, often hallucinated results, preventing true productivity
  gains. Dr. Garima Agrawal, bringing a unique perspective from her recent PhD in
  AI combined with 15 years of industry experience, steps in to provide the necessary
  technical grounding.


  Dr. Agrawal emphasizes that LLMs are powerful, general-purpose tools, but relying
  on them blindly leads to failure. Her core solution for mitigating hallucinations
  is **layered prompting**—an iterative process where the user first probes the model''s
  existing knowledge, then provides context in small "bytes," and continuously verifies
  the model''s understanding step-by-step. She warns that once an LLM begins to hallucinate,
  it creates a "snowball effect" that is difficult to correct, necessitating a restart.


  A significant portion of the discussion focuses on **model selection**. Dr. Agrawal
  advises against using one model for everything. She recommends ChatGPT for general
  analysis and natural language manipulation, Claude for coding and technical tasks
  (citing its superior intrinsic models), and Gemini for gathering broad technical
  research, noting that ChatGPT’s tendency to fabricate citations makes it unreliable
  for serious research. For deep, cited research, **Perplexity** is suggested.


  The conversation also touches on technical nuances like prompting structure. While
  JSON prompting is popular, Dr. Agrawal clarifies it is most beneficial when interacting
  via **API** for structured data consumption, not necessarily when using the standard
  UI. For UI interactions, providing context via attachments (like transcripts) is
  helpful, but feeding too much data at once can still trigger errors. She also introduces
  the concept of **few-shot prompting** (providing examples) as a powerful way to
  guide the model toward desired output formats, such as creating specific LinkedIn
  posts versus general content.


  Finally, the episode tackles the next frontier: **agentic'
tags:
- artificial-intelligence
- generative-ai
- startup
- investment
- google
- microsoft
title: 639 - How to Stop ChatGPT from Lying to You (AI PhD Reveals the Fix) with Garima
  Agrawal
topics:
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 122
  prominence: 1.0
  topic: artificial intelligence
- keywords:
  - generative ai
  - genai
  - chatgpt
  - gpt
  - claude
  - text generation
  - image generation
  mentions: 56
  prominence: 1.0
  topic: generative ai
- keywords:
  - startup
  - entrepreneur
  - founder
  - venture
  mentions: 5
  prominence: 0.5
  topic: startup
- keywords:
  - investment
  - funding
  - valuation
  - ipo
  - acquisition
  mentions: 2
  prominence: 0.2
  topic: investment
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-10-06 05:44:37 UTC -->
