---
companies:
- category: unknown
  confidence: medium
  context: Welcome everyone to the AI and Business Podcast. I'm Matthew Damello, Editorial
    Director here at
  name: Business Podcast
  position: 31
- category: unknown
  confidence: medium
  context: come everyone to the AI and Business Podcast. I'm Matthew Damello, Editorial
    Director here at Emerge AI Research. T
  name: Matthew Damello
  position: 53
- category: unknown
  confidence: medium
  context: the AI and Business Podcast. I'm Matthew Damello, Editorial Director here
    at Emerge AI Research. Today's guest is Matt
  name: Editorial Director
  position: 70
- category: unknown
  confidence: medium
  context: . I'm Matthew Damello, Editorial Director here at Emerge AI Research. Today's
    guest is Matthew Perutical, Global Head
  name: Emerge AI Research
  position: 97
- category: unknown
  confidence: medium
  context: ctor here at Emerge AI Research. Today's guest is Matthew Perutical, Global
    Head of Data Architecture, Utilization in
  name: Matthew Perutical
  position: 134
- category: unknown
  confidence: medium
  context: AI Research. Today's guest is Matthew Perutical, Global Head of Data Architecture,
    Utilization in AI Engineeri
  name: Global Head
  position: 153
- category: unknown
  confidence: medium
  context: oday's guest is Matthew Perutical, Global Head of Data Architecture, Utilization
    in AI Engineering at Sanofi. Matthew
  name: Data Architecture
  position: 168
- category: unknown
  confidence: medium
  context: Global Head of Data Architecture, Utilization in AI Engineering at Sanofi.
    Matthew joins us on today's program to
  name: AI Engineering
  position: 202
- category: unknown
  confidence: medium
  context: of how this rolls out with life sciences leaders. And I know you layered
    this into a little bit of your f
  name: And I
  position: 5559
- category: unknown
  confidence: medium
  context: what that finish line really, really looks like. But Matt, really, really
    appreciate your perspective on to
  name: But Matt
  position: 19450
- category: ai_research
  confidence: high
  context: The organization where the host, Matthew Damello, is the Editorial Director.
  name: Emerge AI Research
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: The pharmaceutical company where the guest, Matthew Perutical, works, integrating
    AI into clinical trials and data workflows.
  name: Sanofi
  source: llm_enhanced
- category: ai_infrastructure
  confidence: medium
  context: The sponsor of the special podcast series on AI and clinical workflows.
  name: Metable
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as a point of comparison to pharmaceutical brands regarding patient
    trust and challenges in data/digital transformation.
  name: CVS
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as a pharmaceutical brand whose challenges differ from retail-focused
    entities like CVS.
  name: Pfizer
  source: llm_enhanced
- category: ai_model_provider
  confidence: medium
  context: Mentioned in relation to a new concept called MCP (Modern Context Protocols),
    suggesting an AI model or platform provider.
  name: Claude
  source: llm_enhanced
- category: ai_company
  confidence: high
  context: Mentioned via its public interface, chatgpt.com, as an example of a tool
    people use outside of data science teams.
  name: OpenAI
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Referenced by its URL (www.chatgpt.com), indicating the use of OpenAI's
    generative AI product.
  name: ChatGPT
  source: llm_enhanced
date: 2025-05-21 06:00:00 +0000
duration: 20
has_transcript: false
layout: episode
llm_enhanced: true
original_url: https://traffic.libsyn.com/secure/techemergence/Business_-_5.21.25_-_Mathew_Paruthickal.mp3?dest-id=151434
processing_date: 2025-10-05 16:05:09 +0000
quotes:
- length: 219
  relevance_score: 3
  text: You know, the biggest mistake I see is treating AI like a shiny side project,
    and if you want to have a real impact, you know, what we need to do is we need
    to pre-do it as a strategic capability within the organization
  topics: []
- length: 49
  relevance_score: 3
  text: The trust, that's the single most important thing
  topics: []
- length: 99
  relevance_score: 3
  text: So the second pillar for us is called document intelligence and natural language
    processing on that
  topics: []
- length: 182
  relevance_score: 3
  text: I think I was alluding to the fact early on is that the biggest mistake we're
    seeing in AI systems across not just some of even many starters, we treat everything
    like a side project
  topics: []
- length: 137
  relevance_score: 3
  text: And finally, the most important one is tying AI to a real business outcomes,
    you know, it's not just a cool demo thing that we want to do
  topics: []
- impact_reason: 'Strong business advice for any large organization adopting AI: it
    must be integrated as a core strategic capability, not an experimental add-on,
    to achieve meaningful impact.'
  relevance_score: 10
  source: llm_enhanced
  text: The biggest mistake I see is treating AI like a shiny side project, and if
    you want to have a real impact, you know, what we need to do is we need to pre-do
    it as a strategic capability within the organization.
  topic: business
- impact_reason: 'Pinpoints a major technical and business challenge in life sciences:
    unlocking value from unstructured documents (PDFs, reports) using GenAI, requiring
    the fusion of document and structured data intelligence.'
  relevance_score: 10
  source: llm_enhanced
  text: What you basically need is to actually connect your document intelligence
    with your data intelligence. And so much of the clinical insight is buried in
    static documents, you know, and now with generative AI, you're trying to actually
    prove that context out and make it usable.
  topic: technical
- impact_reason: A powerful statement on the foundational nature of trust, equating
    it in importance to the underlying technology itself, especially crucial for patient-facing
    or regulatory systems.
  relevance_score: 10
  source: llm_enhanced
  text: Trust, that's the single most important thing. Building trust in the system
    from day one is absolute key here. So trust for me, the way I say it is, trust
    is equally as important as the tech that you're trying to actually do these things.
  topic: safety
- impact_reason: Lists specific, high-impact generative AI use cases in pharma operations,
    moving far beyond simple Q&A to automated document creation and specialized chatbots.
  relevance_score: 10
  source: llm_enhanced
  text: It's not just asking questions, it's about summarizing, it's about auto generating
    clinical study reports, protocols, brochures, safety chatbots, you know, for internal
    queries, you could auto generate safety sanctions from adverse event reports,
    you know, and then there's a whole lot of things, you know, structured report
    generation, structured content generation that you're actually trying to do by
    connecting all these systems together.
  topic: predictions
- impact_reason: 'This defines the core value proposition of AI in regulated industries
    like life sciences: enhancing human decision-making (patient safety) by accelerating
    insight generation and mitigating compliance risk.'
  relevance_score: 10
  source: llm_enhanced
  text: We're just giving them intelligent tools that surface insights faster, you
    know, reduce the compliance risk and let them focus on the decisions that matter
    most, which is patient safety.
  topic: business/strategy
- impact_reason: 'This is a critical piece of business advice for enterprise AI adoption:
    failure often stems from treating AI initiatives as isolated experiments rather
    than strategic, integrated solutions.'
  relevance_score: 10
  source: llm_enhanced
  text: the biggest mistake we're seeing in AI systems across not just some of even
    many starters, we treat everything like a side project.
  topic: business/strategy
- impact_reason: 'This provides actionable advice on AI deployment: success requires
    embedding tools directly into existing workflows (interoperability) to ensure
    broad accessibility beyond the core data science team.'
  relevance_score: 10
  source: llm_enhanced
  text: accessibility is everything, like it only if it's known in the hands of data
    scientists, we've kind of failed. So it needs to be embedded in the tool that
    they're already using today.
  topic: business/strategy
- impact_reason: 'Crucial advice for regulated industries: governance, security, and
    compliance must be baked into the architecture from the start, not bolted on later.'
  relevance_score: 10
  source: llm_enhanced
  text: We're building model governance, washing control, security, compliance, all
    from day one, you know, already to go from day one.
  topic: safety/strategy
- impact_reason: Provides concrete, measurable business outcomes for AI in life sciences,
    moving the conversation past vague 'efficiency' gains.
  relevance_score: 10
  source: llm_enhanced
  text: tying AI to a real business outcomes, you know, it's not just a cool demo
    thing that we want to do. We're talking about like, you know, a business outcome
    as in like fewer protocol amendments, faster safety reviews, better audit prep.
  topic: business
- impact_reason: Reiterates the non-negotiable baseline requirements for AI in high-stakes
    environments, framing compliance as a fundamental architectural requirement, not
    an afterthought.
  relevance_score: 10
  source: llm_enhanced
  text: in clinical, you know, the stakes include patient lives and global regulatory
    scrutiny. So compliance, safety, traceability, these are not optional, you know,
    they are the baseline and that's exactly what we are looking for.
  topic: safety/strategy
- impact_reason: This highlights the critical shift in AI adoption in regulated industries
    like pharma—moving beyond simple digitization to deep, intelligent data connection
    for real-time, high-stakes decision-making.
  relevance_score: 9
  source: llm_enhanced
  text: But right now, the conversation is completely more towards something deeper.
    It's about how we connect all the data, make it intelligent, how we use it to
    drive decisions in real time, and especially in a place like clinical trials where
    regulatory precision, patient safety, and compliance are non-negotiable.
  topic: strategy
- impact_reason: Provides concrete, high-value applications of AI in clinical trials
    (protocol optimization, risk prediction, safety monitoring), moving beyond theoretical
    use cases.
  relevance_score: 9
  source: llm_enhanced
  text: We're seeing teams move from just collecting data to actually making sense
    of it. And we, from the data team, we're using AI to help optimize protocol design,
    predicting site growth, even surfacing early safety signals.
  topic: predictions
- impact_reason: Emphasizes the non-negotiable requirement for robust governance,
    audit trails, and compliance when deploying AI in highly regulated environments.
  relevance_score: 9
  source: llm_enhanced
  text: So we're talking about standards. I mentioned about regulatory compliance,
    right? So the connected systems is absolutely important because none of that matters
    without compliance, auditability and governance baked in right from day one.
  topic: safety
- impact_reason: 'Outlines a clear, three-part architectural approach: structured
    data handling, unstructured data handling, and then connecting them to power autonomous
    agents.'
  relevance_score: 9
  source: llm_enhanced
  text: We're creating this tool around a structured data, we creating the tool around
    the unstructured data, which is the document architecture, document intelligence,
    and then we connect the two, then we building live agents on top of that, agents
    which can do a whole lot of things.
  topic: technical
- impact_reason: Highlights the necessity of grounding LLM outputs in enterprise data
    (RAG/knowledge-grounding) to ensure factual accuracy and regulatory compliance.
  relevance_score: 9
  source: llm_enhanced
  text: You're using all this intelligence that we built as a guardrail. Right. It's
    going to be grounded in truth when you're when it answers back.
  topic: safety
- impact_reason: 'Defines the ultimate goal of AI in this domain: shifting from reactive
    monitoring to proactive intervention and preparation, even generating necessary
    documentation ahead of time.'
  relevance_score: 9
  source: llm_enhanced
  text: Now, you mentioned a very good point there about proactiveness. And I think
    we are moving into a world where everything becomes proactive, you know, we're
    building a system that automatically flags a signal, you know, it generates the
    narrative, prepares it, perhaps submission, or before the event happens actually.
  topic: predictions
- impact_reason: Addresses the common fear of job displacement, reframing AI as an
    augmentation tool that elevates human focus toward high-stakes decision-making
    (patient safety).
  relevance_score: 9
  source: llm_enhanced
  text: It's not about, I mean, it's less about replacing people. I know people have
    the whole fear, right? AI is going to take all my jobs. We don't see it like that.
    We're just giving them intelligent tools that surface insights faster, you know,
    reduce the compliance risk and let them focus on the decisions that matter most,
    which is patient safety.
  topic: safety
- impact_reason: This clearly articulates a shift in AI application from replacement
    to augmentation, focusing on proactive risk identification (anomaly detection)
    rather than just reactive tasks. This addresses a major societal concern about
    job loss.
  relevance_score: 9
  source: llm_enhanced
  text: We're going to be proactive sending you signals. We're going to be having
    anomaly detection automated anomaly detections and a lot of those aspects are
    only in it. And this is where I think the future is headed. It's not about, I
    mean, it's less about replacing people.
  topic: predictions/safety
- impact_reason: This sets a clear boundary for current AI capabilities, emphasizing
    that deep emotional labor and compassionate communication remain firmly in the
    human domain.
  relevance_score: 9
  source: llm_enhanced
  text: It can't hold a person's hand in an emergency room and explain to it very
    gently that their loved one might be seeing more harsh times sooner rather than
    later. That really, that is the domain of humans for the foreseeable.
  topic: safety/ethics
- impact_reason: This frames the central challenge for scaling AI within large organizations—transitioning
    from proof-of-concept to enterprise-wide strategic utility.
  relevance_score: 9
  source: llm_enhanced
  text: how do we actually just move it away from a side project to make it into a
    true strategic solution which everyone can use?
  topic: business/strategy
- impact_reason: Highlights the necessity of explainability (XAI) alongside access.
    Trust is built not just by providing the answer, but by explaining *how* the system
    arrived at it.
  relevance_score: 9
  source: llm_enhanced
  text: We build a, we connect our AI system to that interface and providing not just
    the interface for you to, for them to do their thing, but also explanations that
    build trust.
  topic: technical/safety
- impact_reason: This emphasizes a platform-based approach over siloed solutions,
    stressing that scalability relies on integrating foundational elements like data
    architecture and document intelligence.
  relevance_score: 9
  source: llm_enhanced
  text: and this comes from, it's not just building for use case by use case, but
    we think of it as a platform and this is where the whole, the data architecture,
    the document intelligence, they're all coming to play together in that scalability.
  topic: technical/strategy
- impact_reason: Quantifies the potential impact of AI on regulatory lead times, showing
    a direct path to competitive advantage.
  relevance_score: 9
  source: llm_enhanced
  text: So now with AI in place here, you don't have to actually go through, we can
    actually have a much faster lead time in producing because we've got automated
    systems to ensure that whatever is that they're doing has, you know, is regulated.
  topic: business/predictions
- impact_reason: Shifts focus from technology implementation to organizational culture,
    suggesting that alignment on business goals is the ultimate driver of AI success.
  relevance_score: 9
  source: llm_enhanced
  text: I even think a lot of your answer is really more about culture, right? Really
    more about keeping everybody's eye on those business outcomes, knowing that this
    has to serve the larger goal.
  topic: strategy
- impact_reason: A strong cautionary note against management pressure for speed without
    clear goal definition, linking rushed implementation directly to unforeseen negative
    consequences (a key safety/ethics concern).
  relevance_score: 9
  source: llm_enhanced
  text: it's when, oh, hey, we want to just get by this faster, even when that comes
    from the management side of the table. That's when there are unforeseen consequences
    because folks aren't talking enough about what that finish line really, really
    looks like.
  topic: safety/strategy
- impact_reason: Highlights the technical necessity of integrating structured and
    unstructured data (e.g., documents) for accelerated insights while adhering to
    regulatory standards.
  relevance_score: 9
  source: llm_enhanced
  text: Second, Matthew emphasized the critical role of interoperable data systems
    by bridging structured and unstructured information, teams can accelerate insights
    while maintaining regulatory alignment.
  topic: technical/strategy
- impact_reason: This concluding point underscores that scaling AI is fundamentally
    an infrastructure and architecture challenge, not just a modeling challenge.
  relevance_score: 9
  source: llm_enhanced
  text: And finally, AI success at scale depends on treating data architecture as
    [the foundation].
  topic: technical/strategy
- impact_reason: 'A key strategic insight: success in enterprise AI is less about
    selecting the best individual tool and more about the integration architecture
    and workflow orchestration.'
  relevance_score: 8
  source: llm_enhanced
  text: It's less about tools. It's more about the orchestration on how we connect
    all these things together.
  topic: strategy
- impact_reason: Confirms the ongoing relevance of modern data architectures (Lakehouse/Fabric)
    as the necessary foundation for advanced AI/ML initiatives.
  relevance_score: 8
  source: llm_enhanced
  text: The first one is building a modern data architecture, something like, you
    know, the concepts called data lake house or fabric is absolutely key. It brings
    together all the structured data together.
  topic: technical
- impact_reason: 'Details the second critical pillar: advanced NLP/Document Intelligence
    needed to process the vast amounts of unstructured data in clinical workflows.'
  relevance_score: 8
  source: llm_enhanced
  text: The second one is called document intelligence. We have a pressure of documents
    like PDFs, protocols and PPTs and Excel sheets... and so we need to make sure
    that we're extracting all that data out. So the second pillar for us is called
    document intelligence and natural language processing on that.
  topic: technical
- impact_reason: A striking prediction about autonomous compliance and preparation,
    where AI generates necessary procedural documents based on anticipated regulatory
    events.
  relevance_score: 8
  source: llm_enhanced
  text: You know, so we're talking about a protocol that can practically write itself,
    you know, before an audit happens. We know exactly what has to be done. It's going
    to be sending our instructions and what an audit that has to be done before an
    audit, what are the things that needs to be taken care of.
  topic: predictions
- impact_reason: This offers a nuanced, technical definition of 'AI empathy'—not emotional
    understanding, but perfect factual recall, which is a powerful feature in personalized
    service or patient interaction.
  relevance_score: 8
  source: llm_enhanced
  text: even where we see in call centers that AI is better at empathy. Yeah, dig
    into that a little bit more. It's better at empathy in that it can remember everything.
    It'll never forget your wife's birthday, you know, that's, that's what AI brings
    to the empathy conversation. Instant recall of the important facts.
  topic: technical/predictions
- impact_reason: Illustrates a specific, high-friction business process (MLR review
    for marketing) that AI can drastically accelerate by automating regulatory checks.
  relevance_score: 8
  source: llm_enhanced
  text: So for an ad and you talk about a medicine and you talk about an efficacy
    of a product, it takes like three months, you know, so three months before the
    ad is published, you know, they start working on that because then they have to
    go through the whole MLR team to actually make sure that whatever they mentioned
    as the ad slogan is actually valid and it's regulated.
  topic: business
- impact_reason: Summarizes the strategic evolution of AI use in pharma—moving from
    simple data management to proactive, precision-focused operational improvements.
  relevance_score: 8
  source: llm_enhanced
  text: First, we heard how Sanofi is evolving beyond basic digitization using AI
    to proactively identify risks, streamline protocol design, and bring more precision
    to clinical trials.
  topic: strategy
- impact_reason: A concise summary of the strategic direction for AI implementation
    in complex, regulated industries.
  relevance_score: 7
  source: llm_enhanced
  text: So much being proactive. That's one word if I have to shorten everything up
    being proactive.
  topic: strategy
source: Unknown Source
summary: '## Podcast Episode Summary: How AI Is Transforming Clinical Trials and Data
  Access - with Mathew Paruthickal of Sanofi


  This 20-minute episode features Mathew Paruthickal, Global Head of Data Architecture,
  Utilization in AI Engineering at Sanofi, discussing the strategic integration of
  AI and advanced data workflows to revolutionize clinical trials. The core narrative
  moves from simple digitization efforts to a deep focus on creating intelligent,
  connected data ecosystems that drive proactive decision-making while strictly adhering
  to regulatory and patient safety mandates.


  ---


  ### 1. Focus Area

  The primary focus is the **transformative role of AI and advanced data architecture
  in clinical trials**. Specific applications discussed include optimizing protocol
  design, predicting site risks, surfacing early safety signals, and automating regulatory
  documentation. The conversation heavily emphasizes shifting AI from a "side project"
  to a **strategic organizational capability** built upon interoperable data systems.


  ### 2. Key Technical Insights

  *   **Three-Pillar Data Architecture:** Sanofi is structuring its AI foundation
  around three key vertical archetypes: 1) Building a modern **Data Lakehouse/Fabric**
  for structured data; 2) Implementing **Document Intelligence** (NLP/GenAI) to extract
  insights from unstructured documents (PDFs, safety reports); and 3) Ensuring **Interoperability**
  between these two intelligence layers.

  *   **Modern Context Protocols (MCPs):** The team is developing proprietary pipelines
  and tools (akin to MCPs) to process massive volumes of diverse data (clinical, manufacturing,
  audit reports) and ensure all data, even structured, is contextually connected.

  *   **Agentic Capabilities:** The goal is to build live agents on top of this connected
  intelligence that can perform complex tasks like summarizing information, auto-generating
  clinical study reports and protocols, and creating safety chatbots, all **grounded
  in truth** (compliance/governance).


  ### 3. Business/Investment Angle

  *   **Strategic Capability over Side Project:** The biggest mistake is treating
  AI as isolated tools; true impact requires embedding it as a core strategic capability
  across the organization.

  *   **Focus on Business Outcomes:** AI implementation must be tied directly to measurable
  business results, such as **fewer protocol amendments, faster safety reviews, and
  better audit preparation**. An example cited is drastically reducing the three-month
  lead time for regulatory review of marketing materials.

  *   **Accessibility and Embedding:** For scalability, AI must be accessible by embedding
  intelligence directly into the interfaces and tools that teams (science, regulatory,
  legal) are already using daily, rather than forcing them to learn new data science
  platforms.


  ### 4. Notable Companies/People

  *   **Mathew Paruthickal (Sanofi):** Global Head of Data Architecture, Utilization
  in AI Engineering, providing the strategic and technical roadmap for AI integration
  in clinical operations.

  *   **Sanofi:** Highlighted as a leader moving beyond basic digitization toward
  intelligent, proactive clinical trial management.

  *   **Metable:** Sponsor of the special podcast series on AI and clinical workflows.


  ### 5. Future Implications

  The industry is moving toward a **proactive state**, where systems automatically
  flag signals, generate narratives, and prepare necessary documentation *before*
  an event or audit occurs. Protocols could "write themselves" based on prior trial
  data, current patient populations, and real-world outcomes. While AI will automate
  insights and reduce compliance risk, the human element—especially regarding **empathy
  and complex decision-making** related to patient outcomes—will remain firmly in
  the domain of human experts.


  ### 6. Target Audience

  This episode is highly valuable for **Life Sciences Leaders, Clinical Operations
  Executives, Data Science/Architecture Professionals in Pharma, and Regulatory/Compliance
  Officers** who are responsible for scaling AI initiatives and ensuring data governance
  within highly regulated environments.'
tags:
- artificial-intelligence
- generative-ai
- openai
title: How AI Is Transforming Clinical Trials and Data Access - with Mathew Paruthickal
  of Sanofi
topics:
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 37
  prominence: 1.0
  topic: artificial intelligence
- keywords:
  - generative ai
  - genai
  - chatgpt
  - gpt
  - claude
  - text generation
  - image generation
  mentions: 4
  prominence: 0.4
  topic: generative ai
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-10-05 16:05:09 UTC -->
