---
companies:
- category: unknown
  confidence: medium
  context: This is the Everyday AI Show, the everyday podcast where we simplify AI
    and br
  name: Everyday AI Show
  position: 12
- category: tech
  confidence: high
  context: ton of time by not knowing how to use things like Google's Gems, OpenAI
    ChatGPTs, GPTs, and Claude's proje
  name: Google
  position: 569
- category: tech
  confidence: high
  context: not knowing how to use things like Google's Gems, OpenAI ChatGPTs, GPTs,
    and Claude's projects and OpenAI'
  name: Openai
  position: 584
- category: unknown
  confidence: medium
  context: not knowing how to use things like Google's Gems, OpenAI ChatGPTs, GPTs,
    and Claude's projects and OpenAI's project
  name: OpenAI ChatGPTs
  position: 584
- category: unknown
  confidence: medium
  context: to be talking about that today and a lot more on Everyday AI. What's going
    on, y'all? My name's Jordan Wilson,
  name: Everyday AI
  position: 1186
- category: unknown
  confidence: medium
  context: on Everyday AI. What's going on, y'all? My name's Jordan Wilson, and welcome
    to Everyday AI. This is your daily l
  name: Jordan Wilson
  position: 1233
- category: unknown
  confidence: medium
  context: sure to go check that out in today's newsletter. But I really want to talk
    about these recent changes to
  name: But I
  position: 2313
- category: unknown
  confidence: medium
  context: penAI, some updates to OpenAI's projects feature, Google Gems, and Claude's
    projects because if you are just go
  name: Google Gems
  position: 2437
- category: unknown
  confidence: medium
  context: d that's why we started this new segment, calling Putting AI to Work on
    Wednesdays, right? So hopefully you li
  name: Putting AI
  position: 3497
- category: unknown
  confidence: medium
  context: Sometimes things work well. Sometimes they don't. And I want you all to
    see the realness because if you j
  name: And I
  position: 5215
- category: unknown
  confidence: medium
  context: reen right now. And all I'm going to do, I have a Google Gem, a ChatGPT
    custom GPT, a GPT project, and a Claud
  name: Google Gem
  position: 5804
- category: unknown
  confidence: medium
  context: I even named these the same. They're just called "Everyday AI All Stats
    June 2025." All right, I'm going to put this prompt in
  name: Everyday AI All Stats June
  position: 6245
- category: unknown
  confidence: medium
  context: All right, so now my Google Gem is often running. Now I am in my ChatGPT
    custom GPT, and I'm using the 03
  name: Now I
  position: 6409
- category: unknown
  confidence: medium
  context: s going to use Sonnet, but let's go ahead and use Claude Opus 4, which
    is their most powerful model, and I do h
  name: Claude Opus
  position: 6813
- category: unknown
  confidence: medium
  context: find this. So generally, if you've taken our free Prime Prompt Polish course,
    which I know we got to kick the next roun
  name: Prime Prompt Polish
  position: 8651
- category: unknown
  confidence: medium
  context: t from there, they do get a little bit different. So I want to talk about
    a little some of the things th
  name: So I
  position: 11485
- category: unknown
  confidence: medium
  context: ike our email is info@youreverydayai.com, so it's Google Workspace. So
    if I go in there, I have access to all my Wor
  name: Google Workspace
  position: 12015
- category: unknown
  confidence: medium
  context: 'access to all my Workspace apps, which is great: Google Drive, Google
    Docs, Gmail, Calendar, etc. It''s all in t'
  name: Google Drive
  position: 12110
- category: unknown
  confidence: medium
  context: 'my Workspace apps, which is great: Google Drive, Google Docs, Gmail, Calendar,
    etc. It''s all in there, which i'
  name: Google Docs
  position: 12124
- category: unknown
  confidence: medium
  context: to more. You have access to things like YouTube, YouTube Music, Google
    Flights, just some things that you don't
  name: YouTube Music
  position: 12572
- category: unknown
  confidence: medium
  context: ave access to things like YouTube, YouTube Music, Google Flights, just
    some things that you don't have access to i
  name: Google Flights
  position: 12587
- category: unknown
  confidence: medium
  context: ogle Workspace apps. All right, let's go to GPTs. So GPTs were just updated
    a couple of days ago, and this
  name: So GPTs
  position: 12866
- category: unknown
  confidence: medium
  context: can think and reason like Gemini 2.5 Pro, or like Claude Sonnet 4 or Claude
    Opus 4, we were still stuck using GPT
  name: Claude Sonnet
  position: 13475
- category: unknown
  confidence: medium
  context: cture because there is a folder structure, right? Whereas GPTs and Gems,
    not really. So people think projects ar
  name: Whereas GPTs
  position: 14476
- category: unknown
  confidence: medium
  context: Canvas, but you can inside projects. You can use ChatGPT Canvas, and you
    can use Claude's artifacts, which are ki
  name: ChatGPT Canvas
  position: 15635
- category: tech
  confidence: high
  context: so having that memory across the projects. On the Anthropic project side,
    you have access to your Gmail. So j
  name: Anthropic
  position: 15984
- category: unknown
  confidence: medium
  context: st the different integrations. So you have Gmail, Google Calendar, Google
    Drive, but then you have MCP, their Model
  name: Google Calendar
  position: 16094
- category: unknown
  confidence: medium
  context: endar, Google Drive, but then you have MCP, their Model Context Protocol.
    So this is something, again, a very overlooked a
  name: Model Context Protocol
  position: 16154
- category: unknown
  confidence: medium
  context: veryone, David here, one of the product leads for Google Gemini. Check
    out V03, our state-of-the-art AI video gen
  name: Google Gemini
  position: 16735
- category: unknown
  confidence: medium
  context: ideos with native audio generation. Try it with a Google AI Pro plan or
    get the highest access with the Ultra pla
  name: Google AI Pro
  position: 16930
- category: unknown
  confidence: medium
  context: t can find the obvious things in all of my files. Then I'm saying, I'm
    asking for 10 of the most impactful
  name: Then I
  position: 17894
- category: unknown
  confidence: medium
  context: All right. So here's what I uploaded. I uploaded Google Search Console
    data for different terms that are bringing traffi
  name: Google Search Console
  position: 19477
- category: unknown
  confidence: medium
  context: rent, actually three different kind of files from Google Analytics. So
    everything that's happening on the your every
  name: Google Analytics
  position: 19737
- category: unknown
  confidence: medium
  context: t has the content of all of those emails as well. So Claude couldn't handle
    it, but we have that as well. And
  name: So Claude
  position: 20554
- category: unknown
  confidence: medium
  context: because I've been looking at it for a long time. If I were to hire a consultant,
    it would take them for
  name: If I
  position: 20921
- category: unknown
  confidence: medium
  context: 10. Good. And the creative ideas, got me all 10. So Google, on their Gems
    side, passed the test. And the goo
  name: So Google
  position: 25765
- category: unknown
  confidence: medium
  context: is, right, I can also go in here and click this "Show Thinking," which
    is good. It looks like Google, which is r
  name: Show Thinking
  position: 25881
- category: tech
  confidence: high
  context: it thought. So actually, if you want to get super meta, probably what I'm
    going to do is I'm going to up
  name: Meta
  position: 26456
- category: unknown
  confidence: medium
  context: u don't really know how they're going to respond. Generative AI is generative.
    It's going to be different every s
  name: Generative AI
  position: 27284
- category: unknown
  confidence: medium
  context: nable to open any of the data files you uploaded. The Python environment
    that normally lets me read and analyz
  name: The Python
  position: 29422
- category: unknown
  confidence: medium
  context: me just go ahead and do this and see if it works. Although I don't think
    it will. All right. It's giving me an
  name: Although I
  position: 30860
- category: unknown
  confidence: medium
  context: t work. So that's interesting here. A little bug. Like I said, these new
    updated GPTs have only been out f
  name: Like I
  position: 31737
- category: unknown
  confidence: medium
  context: is fun, you know. All right. So exact same thing. When I ran this last
    night in the projects, and it worke
  name: When I
  position: 33151
- category: big_tech
  confidence: high
  context: Mentioned as the provider of Google Gems, Gemini models, and Google Workspace
    apps (Drive, Docs, Gmail, Calendar). The podcast is sponsored by Google.
  name: Google
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: A specific feature/product from Google, similar to custom GPTs, utilizing
    the Gemini model.
  name: Google's Gems
  source: llm_enhanced
- category: ai_company
  confidence: high
  context: The creator of ChatGPT, custom GPTs, and GPT models (03, 03 Pro).
  name: OpenAI
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: The general term for the chatbot interface and custom GPT feature from
    OpenAI.
  name: OpenAI ChatGPTs
  source: llm_enhanced
- category: ai_company
  confidence: high
  context: Mentioned as a competitor to ChatGPT and Gemini, with projects utilizing
    models like Sonnet and Opus 4.
  name: Claude
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: A specific organizational feature within the Claude interface, similar
    to ChatGPT projects.
  name: Claude's projects
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: The core AI chatbot product from OpenAI being compared against competitors.
  name: ChatGPT
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: Mentioned generally as one of the AI chatbots people use.
  name: Copilot
  source: llm_enhanced
- category: ai_application
  confidence: low
  context: Mentioned generally as one of the AI chatbots people use (likely a typo
    or less common name for an existing model/service).
  name: Madame
  source: llm_enhanced
- category: ai_company
  confidence: high
  context: Mentioned generally as one of the AI chatbots people use.
  name: Mistral
  source: llm_enhanced
- category: ai_model
  confidence: high
  context: The model family used by Google (e.g., Gemini 2.5 Pro).
  name: Gemini
  source: llm_enhanced
- category: ai_model
  confidence: high
  context: The specific powerful model used by Google Gems mentioned in the comparison.
  name: Gemini 2.5 Pro
  source: llm_enhanced
- category: ai_model
  confidence: medium
  context: The speaker refers to '03 model' and '03 Pro' when discussing ChatGPT custom
    GPTs, which strongly implies GPT-4 and GPT-4 Turbo/Pro variants.
  name: GPT-4 (implied by 03/03 Pro)
  source: llm_enhanced
- category: ai_model
  confidence: high
  context: The most powerful model mentioned for use in Claude projects.
  name: Claude Opus 4
  source: llm_enhanced
- category: ai_model
  confidence: high
  context: A model mentioned in the context of comparing reasoning capabilities.
  name: Claude Sonnet 4
  source: llm_enhanced
- category: ai_company
  confidence: high
  context: The company behind Claude, referenced via their project integrations (Gmail,
    Calendar, Drive).
  name: Anthropic
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: A subscription tier mentioned by the Google Gemini representative for accessing
    V03.
  name: Google AI Pro plan
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: The highest subscription tier mentioned for accessing V03.
  name: Google AI Ultra plan
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Mentioned via the representative David, who is a product lead for Google
    Gemini.
  name: Google Gemini (as a product/team)
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Mentioned in context with Google Gemini and the capabilities of Google
    Gems.
  name: Google AI
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Mentioned as the product line associated with David, a product lead, and
    the AI powering the Gems.
  name: Google Gemini
  source: llm_enhanced
- category: ai_developer
  confidence: high
  context: The custom chatbot feature from OpenAI, compared against Google Gems and
    Claude projects.
  name: GPTs
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as Google Gemini's state-of-the-art AI video generation model.
  name: V03
  source: llm_enhanced
date: 2025-06-18 13:00:00 +0000
duration: 48
has_transcript: false
insights:
- actionable: true
  confidence: medium
  extracted: be using these AI chatbots because if you're just going in there every
    single day and clicking that new chat button, you're actually probably not saving
    yourself very much time
  text: we should be using these AI chatbots because if you're just going in there
    every single day and clicking that new chat button, you're actually probably not
    saving yourself very much time.
  type: recommendation
layout: episode
llm_enhanced: true
original_url: https://pscrb.fm/rss/p/www.buzzsprout.com/2175779/episodes/17356358-ep-549-custom-gpts-gems-and-projects-what-they-are-and-why-you-need-to-use-them.mp3
processing_date: 2025-10-05 09:01:14 +0000
quotes:
- length: 76
  relevance_score: 6
  text: You have to always stay up to date and take advantage of the biggest updates
  topics: []
- length: 188
  relevance_score: 5
  text: But one of the biggest problems is we aren't taking advantage of the context
    window, and then we're also not taking advantage of the true capabilities that
    these large language models have
  topics: []
- length: 254
  relevance_score: 4
  text: You probably think that you're saving yourself a lot of time whenever you
    go into your favorite AI chatbot, click that new chat button, spend some time
    getting it to respond just how you want it, share your files, and get an output
    that you're happy with
  topics: []
- length: 117
  relevance_score: 4
  text: So when we talk about Google Gems, I would say one of the biggest differentiators
    is number one, it uses the Gemini 2
  topics: []
- length: 173
  relevance_score: 4
  text: '" So I like that midway through it actually did some research on, looks like
    it went out and searched for "AI podcast market size growth 2025" and analyzed
    some things there'
  topics:
  - market
  - growth
- length: 231
  relevance_score: 3
  text: We keep you up to date with everything you need to know that's happening in
    the world of AI, but maybe more importantly, we pull out the most important insights
    or things that we didn't even have time to get to from today's episode
  topics: []
- length: 222
  relevance_score: 3
  text: The problem is these AI systems that we use so much, and some of us have become
    reliant on almost for our day-to-day work in business, they change too quickly
    to actually establish those good routines and those good habits
  topics: []
- length: 97
  relevance_score: 3
  text: Absolutely, but the bar is continuing to rise, so you and your skill set,
    you have to do the same
  topics: []
- length: 32
  relevance_score: 3
  text: So here's what we're going to do
  topics: []
- length: 96
  relevance_score: 3
  text: '" Then I''m going to say, "10 of the biggest blind spots that I''m not aware
    of based on this data'
  topics: []
- length: 25
  relevance_score: 3
  text: So here's what I uploaded
  topics: []
- length: 48
  relevance_score: 3
  text: '"Hey, here''s what''s going right with our website'
  topics: []
- length: 42
  relevance_score: 3
  text: Here's what's going right with the podcast
  topics: []
- length: 44
  relevance_score: 3
  text: 10 of the biggest blind spots, got me all 10
  topics: []
- length: 75
  relevance_score: 3
  text: Sometimes when you export something, you have to do a little bit of cleanup
  topics: []
- length: 112
  relevance_score: 3
  text: I just clicked export all on all of those and just dumped it in there and
    said, "Yo, here's what these files are
  topics: []
- length: 84
  relevance_score: 3
  text: So the problem is I wish that ChatGPT would change back some of their user
    interface
  topics: []
- impact_reason: 'Reveals a significant, under-reported update from OpenAI: the ability
    to select different underlying models (beyond the default) for custom GPTs, which
    dramatically increases their capability ceiling.'
  relevance_score: 10
  source: llm_enhanced
  text: OpenAI actually didn't really announce it at first. They updated some projects...
    They enabled anyone to use any version of their model for GPTs, and this is why
    it's huge.
  topic: technology trends/breakthroughs
- impact_reason: This is a bold prediction about the democratization of high-level
    strategic analysis, suggesting that highly customized, data-fed AI agents could
    replace expensive traditional consulting services.
  relevance_score: 10
  source: llm_enhanced
  text: Will this, like, will this replace like hiring a big consultancy? Maybe. Bless
    me, honest, I couldn't afford to go hire a six-figure consultant, but I think
    right here, we have the making of it, right?
  topic: predictions/business
- impact_reason: 'This is a powerful strategic argument for persistent context: even
    when not performing explicit data analysis, providing the AI with a massive context
    base (your ''brain'') improves its general utility as a strategic partner.'
  relevance_score: 10
  source: llm_enhanced
  text: Think of not just how much time you're saving, but how much better the outputs
    are going to be. Now, even for me, even if I don't necessarily have a data question
    for Everyday AI, I should probably still just use this, right? Because again,
    now this gives these models context, a huge amount of context, even if I'm not
    asking for specific stats, if I'm just using any of these AI chatbots as a strategy
    partner, as a brainstorming partner to help me plan things, why wouldn't I want
    to give it access to all of this information?
  topic: strategy
- impact_reason: 'Crucial advice for prompt engineering: the ''chain of thought''
    reveals model reasoning, which is essential for diagnosing poor output quality
    stemming from weak inputs (prompts/custom instructions).'
  relevance_score: 10
  source: llm_enhanced
  text: But as I tell you all every time, you need to be reading this chain of thought.
    This tells you because we're using these either reasoning models or hybrid models
    that go between reasoning and non-reasoning, but the quality of my prompt was
    very low, right? The custom instructions were not very great.
  topic: Technical/Practical Lessons
- impact_reason: 'Provides a practical, middle-ground recommendation for enterprise
    AI adoption testing: don''t stop at one test, but aim for a minimum of five repetitions
    to account for generative variability before deploying a process.'
  relevance_score: 10
  source: llm_enhanced
  text: Never try something once and say this is good enough, right? You don't have
    to go the full benchmarking route of doing things 50 times and finding the mean
    or the median, the average. You don't have to do that. But generative AI is generative,
    right? I would always encourage you, especially if it's something that you're
    going to do over and over and over and roll it out within your organization, you
    should at least be testing it a minimum of five times minimum.
  topic: Business/Strategy
- impact_reason: 'This sets up the central thesis: the common, quick-start method
    of using AI chatbots (new chat button) is often inefficient, highlighting the
    need to leverage custom tools (GPTs, Gems, Projects).'
  relevance_score: 9
  source: llm_enhanced
  text: You probably think that you're saving yourself a lot of time whenever you
    go into your favorite AI chatbot, click that new chat button, spend some time
    getting it to respond just how you want it, share your files, and get an output
    that you're happy with. You saved yourself time, right? Maybe, or maybe you just
    wasted a ton of time by not knowing how to use things like Google's Gems, OpenAI
    ChatGPTs, GPTs, and Claude's projects and OpenAI's projects.
  topic: strategy/usage
- impact_reason: Highlights the extreme velocity of change in the LLM ecosystem, specifically
    concerning custom agent features (GPTs/Gems/Projects), requiring constant re-evaluation
    of best practices.
  relevance_score: 9
  source: llm_enhanced
  text: These things have changed so much in the last week or two. Whether you're
    a new person learning the basics of these AI chatbots or you are a seasoned vet
    using them for hours a day, there have been some under-the-radar changes to these
    projects, GPTs, and Gems that I think change how we should be using these AI chatbots...
  topic: technology trends
- impact_reason: A strong warning against complacency. AI adoption raises the baseline
    expectation for productivity, demanding continuous skill improvement from users.
  relevance_score: 9
  source: llm_enhanced
  text: Is using an AI chatbot in this way faster than doing things manually? Absolutely,
    but the bar is continuing to rise, so you and your skill set, you have to do the
    same. You can't become complacent just because you're using AI, right?
  topic: strategy/business advice
- impact_reason: 'Defines the paradox of inefficient AI use: high activity doesn''t
    equal high productivity without structure. Custom tools are presented as the structural
    solution.'
  relevance_score: 9
  source: llm_enhanced
  text: You're wasting time by being more productive, but not in an organized way,
    which I know sounds backwards. But this is where using Google Gems, custom GPTs
    from ChatGPT, projects from ChatGPT, and projects from Claude can help erase this
    problem because the solution is literally right in front of us.
  topic: strategy/usage
- impact_reason: Provides a critical retrospective analysis on why the initial vision
    for GPTs stalled—the lack of model choice limited their utility compared to newer
    offerings.
  relevance_score: 9
  source: llm_enhanced
  text: OpenAI kind of started this phase of the GPTs, and we thought, 'Oh, it's going
    to be like the app store for AI,' and it never really took off. One of the reasons
    I think is because you could never choose which model to use.
  topic: business advice/strategy
- impact_reason: This explicitly states the key bottleneck for GPTs adoption—being
    locked into older models—and contrasts it with the capabilities of newer models
    from competitors (Gemini, Claude), framing the update as a necessary catch-up.
  relevance_score: 9
  source: llm_enhanced
  text: One of the reasons I think is because you could never choose which model to
    use. So as we got these new models that can think and reason like Gemini 2.5 Pro,
    or like Claude Sonnet 4 or Claude Opus 4, we were still stuck using GPTs, these
    non-recenting models, until a couple of days ago.
  topic: technical/strategy
- impact_reason: 'Highlights a unique, cutting-edge feature in ChatGPT Projects: ''deep
    research'' capability confined to the uploaded project data, suggesting a superior
    method for grounded analysis compared to competitors.'
  relevance_score: 9
  source: llm_enhanced
  text: The big one in ChatGPT projects would be using things like Canvas mode, would
    be using things like deep research. So that's a new update. You can actually in
    ChatGPT projects now, you can do deep research using just the information in the
    project. Brand new update, no one else has that.
  topic: technical/predictions
- impact_reason: 'This provides a critical, practical limitation: Claude''s file upload
    size limit (around 30MB) compared to competitors, which severely impacts its utility
    for large data analysis tasks.'
  relevance_score: 9
  source: llm_enhanced
  text: I shared a lot of different things. All right, I actually, I'm just going
    to open a new tab here. All right. So you'll see here, I'm sharing my Claude project
    file. So I have a lot of different files in here. I have 10 in total. Unfortunately,
    Claude would only accept nine because it has a file limit. All right. So anything
    over 30 megabytes, you cannot upload. So I had a spreadsheet that was like 60
    megabits or no, it was like 42 megabytes or something like that, and Claude couldn't
    take it, whereas Google Gems and GPTs could.
  topic: technical/limitations
- impact_reason: Provides actionable advice for users on leveraging personalized context
    beyond just business metrics, encouraging the integration of unstructured, domain-specific
    knowledge (brand voice, past projects) for better AI output.
  relevance_score: 9
  source: llm_enhanced
  text: Well, you probably have access to a lot of data that you're not just thinking
    about, right? So what of your company docs can you put in there? What about industry
    white papers? What about information about your competitors? What about information
    about your brand voice? What about the last 50 projects you've worked on and completed?
  topic: business/strategy
- impact_reason: 'Offers a concrete, advanced workflow for capturing tacit knowledge:
    recording unstructured thoughts, transcribing them, and feeding them into the
    persistent context of AI agents to externalize and utilize personal expertise.'
  relevance_score: 9
  source: llm_enhanced
  text: This is my brain and my computer's brain, right? I would probably go through,
    go through here at a later time and upload a bunch of meeting transcripts. I would
    probably go through and do a couple like one-hour recordings of myself, just word
    vomiting, right? 'Hey, here's what's going right with our website... Here's my
    biggest opportunities. Here's my challenges.' Right? I would probably go through
    and upload those and sort those as well. So think, you should be doing the same
    thing, right? Even taking that unstructured data, your thought process, your domain
    expertise, talk it into a microphone, transcribe it, and dump it into Google Gems,
    ChatGPT, GPTs, or folders.
  topic: strategy/practical lessons
- impact_reason: This is a strong, actionable piece of advice for leveraging LLMs
    to process personal, unstructured knowledge (domain expertise, thought processes)
    by converting speech to text and feeding it into AI tools.
  relevance_score: 9
  source: llm_enhanced
  text: Even taking that unstructured data, your thought process, your domain expertise,
    talk it into a microphone, transcribe it, and dump it into Google Gems, ChatGPT,
    GPTs, or folders.
  topic: Business/Strategy
- impact_reason: 'A fundamental principle of Generative AI: its non-deterministic
    nature necessitates iterative refinement based on understanding the model''s internal
    reasoning process.'
  relevance_score: 9
  source: llm_enhanced
  text: Generative AI is generative. It's going to be different every single time.
    So by reading this chain of thought, it's going to tell me how I should improve
    my inputs to get a better output.
  topic: Technical/Strategy
- impact_reason: Emphasizes the necessity of live, repeated testing when evaluating
    AI tools, as results can vary significantly between runs due to underlying system
    instability or model changes.
  relevance_score: 9
  source: llm_enhanced
  text: I'm wondering what it did for that long. All right. So unfortunately, it looks
    like we got a couple of strikes from ChatGPT... That's why we do these things
    live. That's why I always do things multiple times because pretty interesting.
  topic: Practical Lessons
- impact_reason: 'A direct observation of inconsistency: the same prompt and data
    yielding success in one session/platform configuration and failure in another,
    underscoring the volatility of current LLM deployments.'
  relevance_score: 9
  source: llm_enhanced
  text: Interesting. Generative AI is fun, you know. All right. So exact same thing.
    When I ran this last night in the projects, and it worked. All right. So when
    I scroll through here in the projects, I have the 10 obvious high-impact stats
    and trends... So interestingly enough, I ran the exact same thing twice. The second
    time, it didn't work inside ChatGPT.
  topic: Technical/Trends
- impact_reason: Describes a dynamic decision-making process within the model (Claude),
    suggesting it self-assesses its knowledge gaps and initiates external search.
  relevance_score: 9
  source: llm_enhanced
  text: All right. So it started doing, it started doing some things without going
    to do research and then it stopped midway through and said, "All right, I'm going
    to go research some things."
  topic: Technical/Model Behavior
- impact_reason: Reinforces the positive perception of Claude's self-correction and
    research initiation as a sign of robustness and honesty about knowledge limits.
  relevance_score: 9
  source: llm_enhanced
  text: just looking at how it handled it. And it looks like Claude also did a pretty
    good job. I like that Claude halfway through said, "Yo, hold up. I got to actually
    go research some more because in order for me to find out this information, I'm
    not sure."
  topic: Model Behavior/Trustworthiness
- impact_reason: Strong endorsement of a specific, novel feature ('Canvas mode') in
    Gemini, suggesting it offers a unique multimodal or interactive advantage over
    competitors.
  relevance_score: 9
  source: llm_enhanced
  text: The new Canvas mode in Google Gemini is so freaking good. Probably one of
    the most unique things of any AI
  topic: Feature/Innovation
- impact_reason: A critical observation on the challenge of skill acquisition in the
    rapidly evolving AI landscape—routines become obsolete quickly.
  relevance_score: 8
  source: llm_enhanced
  text: The problem is these AI systems that we use so much, and some of us have become
    reliant on almost for our day-to-day work in business, they change too quickly
    to actually establish those good routines and those good habits.
  topic: strategy/limitations
- impact_reason: 'Identifies a fundamental, yet often ignored, technical/usage concept:
    managing context windows effectively is key to maximizing LLM utility.'
  relevance_score: 8
  source: llm_enhanced
  text: One of the biggest mistakes people make is overlooking things like context
    window organization, right?
  topic: technical/usage
- impact_reason: 'Clearly states the value proposition for business leaders: these
    custom environments are no longer optional but essential infrastructure for LLM
    utilization.'
  relevance_score: 8
  source: llm_enhanced
  text: We're going to talk about why GPTs, Gems, and projects are essential for any
    business leader using large language models.
  topic: business advice
- impact_reason: This points out a unique capability in OpenAI's GPTs—direct external
    API integration (Actions)—which is a significant feature for extending functionality
    beyond the core model.
  relevance_score: 8
  source: llm_enhanced
  text: One big one is you can actually connect via kind of external APIs or actions,
    which is pretty unique in terms of what ChatGPT can do in GPTs.
  topic: technical
- impact_reason: Directly compares feature parity across platforms, showing that ChatGPT
    Projects currently offer superior utility (Canvas, Deep Research) compared to
    the specialized custom agents (GPTs/Gems).
  relevance_score: 8
  source: llm_enhanced
  text: Whereas on GPTs and Gems in Google and OpenAI, you can't use things like deep
    research. You can't use things like Canvas, but you can inside projects.
  topic: technical
- impact_reason: Introduces the 'Model Context Protocol (MCP)' as an overlooked, API-like
    capability within Claude Projects, suggesting a powerful mechanism for external
    interaction specific to Anthropic's ecosystem.
  relevance_score: 8
  source: llm_enhanced
  text: On the Anthropic project side, you have access to your Gmail. So just the
    different integrations. So you have Gmail, Google Calendar, Google Drive, but
    then you have MCP, their Model Context Protocol. So this is something, again,
    a very overlooked aspect that you can use the MCP protocol in anything inside
    a Claude project.
  topic: technical
- impact_reason: 'This defines a key test for advanced reasoning: the ability to synthesize
    disparate data points to find non-obvious insights, moving beyond simple data
    retrieval.'
  relevance_score: 8
  source: llm_enhanced
  text: I'm asking for 10 of the most impactful stats or trends that may not be obvious.
    So I'm testing its ability to really connect common threads.
  topic: technical/strategy
- impact_reason: 'Highlights a key competitive shift: Google Gemini 2.5 Pro''s availability
    in Gems was a differentiator until ChatGPT enabled access to its most powerful
    model, indicating a rapid convergence in foundational model access across platforms.'
  relevance_score: 8
  source: llm_enhanced
  text: I can also go in here and click this "Show Thinking," which is good. It looks
    like Google, which is really Google Gemini 2.5 Pro, which you can use the most
    powerful model in your Gem, which wasn't a huge advantage for Gems until a couple
    of days ago when ChatGPT allowed you to have the most powerful model.
  topic: Technical/Trends
- impact_reason: Directly identifies a potential platform-specific bug (OpenAI GPTs
    vs. chat body file handling), highlighting the instability and rapid evolution
    of new AI features.
  relevance_score: 8
  source: llm_enhanced
  text: I just found a little bit of an issue that I hope OpenAI can iron out. So
    it looks like it's opening. It was able to open about half of those files when
    I shared them in the body of the chat, but when I uploaded them as files in the
    project knowledge, it didn't work. So that's interesting here. A little bug.
  topic: Technical/Trends
- impact_reason: 'Raises a critical point about perceived depth vs. speed: extremely
    fast processing might indicate superficial analysis, suggesting that complex tasks
    require measurable ''thinking time'' for quality output.'
  relevance_score: 8
  source: llm_enhanced
  text: I don't have a ton of faith in the fact that Claude went through all this
    in a couple of seconds. Maybe it'll still be good, but I would have even hoped
    even a large language model would spend multiple minutes on this, thinking about
    it critically, trying to connect dots between the different data patterns, et
    cetera.
  topic: Technical/Evaluation
- impact_reason: Highlights a specific, proactive research capability in Claude, which
    is a key differentiator for complex tasks.
  relevance_score: 8
  source: llm_enhanced
  text: middle of this, Claude went out and did some research, which is good to see.
  topic: Model Capability/Feature
- impact_reason: 'Illustrates a high-level analytical output: identifying ''blind
    spots'' and generating ''creative ideas'' based on provided context, showcasing
    advanced reasoning.'
  relevance_score: 8
  source: llm_enhanced
  text: So it got me the 10 biggest blind spots that I'm not aware of based on this
    data. Then it got me the 10 extremely specific or creative ideas based on my data
    and research.
  topic: Application/Reasoning
- impact_reason: Emphasizes the importance of 'chain of thought' (CoT) transparency
    in evaluating model quality, even without explicit timing metrics.
  relevance_score: 8
  source: llm_enhanced
  text: It didn't show me how long that it thought, but I looked at the chain of thought.
    It looked like it did a pretty good and a pretty thorough job.
  topic: Technical/Evaluation
- impact_reason: Shows Gemini's capability in data integrity checking (identifying
    'mismatched columns'), a crucial skill for data analysis tasks.
  relevance_score: 8
  source: llm_enhanced
  text: It identified some mismatched columns and it told me about this.
  topic: Application/Data Analysis
- impact_reason: 'Actionable advice for staying current: passive listening isn''t
    enough; active consumption of curated insights (via newsletter) is necessary to
    maintain a competitive edge in AI knowledge within an organization.'
  relevance_score: 7
  source: llm_enhanced
  text: But maybe more importantly, we pull out the most important insights or things
    that we didn't even have time to get to from today's episode. So if this is helpful,
    you're really going to want to go not just sign up for today's newsletter, but
    read it, all right, because that's how we actually can become the smartest people
    in AI in our companies or in our departments.
  topic: business advice/strategy
- impact_reason: Provides a necessary high-level categorization framework for understanding
    the different custom LLM tools available across platforms (GPTs/Gems vs. Projects),
    simplifying a confusing landscape.
  relevance_score: 7
  source: llm_enhanced
  text: 'I would separate these into one category: your GPTs/Gems, and your other
    category: projects. Okay? But ultimately, they kind of do the same thing. You
    give them a set of custom instructions, and you give them project files.'
  topic: technical/strategy
- impact_reason: A concise definition of Google Gems, emphasizing personalization
    and native integration with the Google ecosystem (Workspace apps).
  relevance_score: 7
  source: llm_enhanced
  text: Google Gem again, think of it like a personalized, customized version of the
    big model, and you can use app-mention Google Workspace apps.
  topic: technical/architecture
- impact_reason: This clarifies the distinction between 'Projects' (like in ChatGPT/Claude)
    and 'GPTs/Gems,' emphasizing that Projects maintain context (custom instructions,
    files) across chats, making them more than just organizational folders.
  relevance_score: 7
  source: llm_enhanced
  text: I think originally, people thought of them as just a folder structure because
    there is a folder structure, right? Whereas GPTs and Gems, not really. So people
    think projects are more of just a folder to organize, but it's much more than
    that because like I said, not only yes, if you go into a project and start a new
    chat, it will be found and it will live there, that helps you be more organized,
    but like I said, any chat that you start in there has access to the custom instructions
    and the file.
  topic: strategy/technical
- impact_reason: Demonstrates the scale of data ingestion being tested, setting the
    stage for evaluating the models' ability to handle real-world, high-volume enterprise
    data.
  relevance_score: 7
  source: llm_enhanced
  text: I uploaded hundreds of thousands of rows of data. A lot of data.
  topic: technical
- impact_reason: 'Illustrates a common real-world challenge in AI adoption: models
    are often tested against messy, real-world data, and performance can be hampered
    by data quality issues that require pre-processing.'
  relevance_score: 7
  source: llm_enhanced
  text: There are literally hundreds of thousands of rows of data in there, and they
    probably weren't all super clean, super correct. Sometimes when you export something,
    you have to do a little bit of cleanup. I didn't do any of that. I just clicked
    export all on all of those and just dumped it in there and said, 'Yo, here's what
    these files are. Figure it out.'
  topic: Practical Lessons
- impact_reason: Provides direct feedback on the instability or inconsistency of ChatGPT's
    performance during testing, possibly due to recent updates or high load.
  relevance_score: 7
  source: llm_enhanced
  text: So we saw some failure issues for ChatGPT in certain instances on the second
    time I ran this because again, I ran it last night. It worked fine on the GPT
    side and the project side today, not so much.
  topic: Model Performance/Reliability
- impact_reason: Offers potential external factors (downtime, recent updates) influencing
    model performance, relevant for developers relying on API stability.
  relevance_score: 7
  source: llm_enhanced
  text: It could just be an issue ChatGPT's been having a lot of downtime the past
    couple of days, that might be it, or this could just be a bug because they did
    just update both their projects and their GPTs.
  topic: Deployment/Reliability
- impact_reason: Provides a concrete example of the real-time research query performed
    by the model, demonstrating its ability to synthesize current market data.
  relevance_score: 7
  source: llm_enhanced
  text: looks like it went out and searched for "AI podcast market size growth 2025"
    and analyzed some things there.
  topic: Application/Research
- impact_reason: Offers transparency into the computational demands of complex, high-end
    LLM tasks (using Opus 4, Gemini 2.5 Pro) and the inherent risk/unpredictability
    of live demos.
  relevance_score: 6
  source: llm_enhanced
  text: I am asking for a lot. All right, so more on that, we're going to get back
    to that probably in like probably 15 minutes. All right, I do expect some of them
    may take up to 8 to 12 minutes, but we're doing this live. It could blow up in
    my face. We'll see how it goes.
  topic: technical/deployment
- impact_reason: Sets up the conclusion of the comparison, signaling that actionable
    advice on tool selection is forthcoming.
  relevance_score: 6
  source: llm_enhanced
  text: All right. So overall, y'all, as we start to wrap this thing up, I wanted
    to show you which one should you use?
  topic: Strategy/Recommendation
source: Unknown Source
summary: '## Podcast Episode Summary: EP 549: Custom GPTs, Gems and Projects. What
  they are and why you need to use them


  This episode of the Everyday AI Show focuses on the critical, yet often overlooked,
  shift from using generic "new chat" sessions in AI chatbots to leveraging **Custom
  GPTs (OpenAI), Gems (Google), and Projects (OpenAI/Claude)**. The host argues that
  failing to utilize these persistent, customized environments leads to significant
  time waste due to constant context re-establishment and disorganized chat histories.


  The core narrative arc centers on demonstrating the superior efficiency and output
  quality achieved when an LLM is pre-loaded with specific instructions, context,
  and proprietary data via these dedicated tools. The host conducts a **live, unedited
  demonstration** comparing the performance of the most powerful models across these
  four platforms (Gemini 2.5 Pro, GPT-4o, and Claude 3 Opus 4) on a complex task requiring
  analysis of extensive proprietary business data.


  ### 1. Focus Area

  The discussion centers on **Advanced LLM Workflow Optimization** using platform-specific
  persistent AI tools: OpenAI''s Custom GPTs and Projects, Google''s Gems, and Anthropic''s
  Projects. The main theme is moving beyond ad-hoc prompting to structured, context-aware
  AI interaction for professional use cases.


  ### 2. Key Technical Insights

  *   **Model Access Parity:** OpenAI recently enabled Custom GPTs to utilize their
  most powerful models (like GPT-4o), a crucial update that was initially under-the-radar,
  making GPTs far more capable than previously assumed.

  *   **Tool Differentiation:** While GPTs/Gems are personalized assistants, Projects
  (OpenAI/Claude) offer access to advanced features like **Canvas Mode** (OpenAI)
  and **Deep Research** capabilities within the project context, features often unavailable
  in the simpler GPT/Gem interfaces.

  *   **Data Handling Constraints:** The host noted a practical limitation where Claude
  had a smaller file size limit (under 30MB) compared to Google Gems and OpenAI GPTs,
  preventing the upload of a very large newsletter data file.


  ### 3. Business/Investment Angle

  *   **Productivity Trap:** Relying solely on "new chat" sessions is framed as a
  productivity trap, as the time spent re-explaining context, brand voice, and uploading
  files negates the time saved by using AI.

  *   **Context as Competitive Advantage:** Properly configuring these persistent
  tools—by uploading proprietary data (analytics, search console data, internal documents)
  and defining brand voice—is presented as a way to create a personalized, high-value
  AI asset that rivals the initial insights provided by expensive external consultants.

  *   **Domain Expertise Encapsulation:** These tools allow users to effectively "unload
  their brain" and domain expertise into the AI, ensuring consistent, high-quality
  outputs across all future interactions, regardless of the specific task.


  ### 4. Notable Companies/People

  *   **OpenAI:** Mentioned for Custom GPTs and Projects, and the recent enabling
  of advanced model usage within GPTs.

  *   **Google:** Mentioned for Gems and the integration capabilities within Google
  Workspace apps (Drive, Gmail) when using Gems.

  *   **Anthropic (Claude):** Mentioned for Claude Projects and the use of the **Model
  Context Protocol (MCP)**, described as a web-based API equivalent.

  *   **Jordan Wilson (Host):** Drives the demonstration by using his own company''s
  (Everyday AI) extensive operational data for the live test.


  ### 5. Future Implications

  The industry is moving rapidly toward **persistent, context-rich AI environments**.
  The future of professional AI usage involves setting up these specialized agents
  once and using them continuously, transforming them from simple chat interfaces
  into integrated, knowledgeable digital colleagues that retain institutional memory
  and context.


  ### 6. Target Audience

  This episode is highly valuable for **AI Practitioners, Business Leaders, and Power
  Users** who rely on LLMs daily for complex, recurring tasks and need to maximize
  efficiency and output quality beyond basic prompting.'
tags:
- generative-ai
- artificial-intelligence
- google
- openai
- anthropic
- meta
title: 'EP 549: Custom GPTs, Gems and Projects. What they are and why you need to
  use them'
topics:
- keywords:
  - generative ai
  - genai
  - chatgpt
  - gpt
  - claude
  - text generation
  - image generation
  mentions: 136
  prominence: 1.0
  topic: generative ai
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 121
  prominence: 1.0
  topic: artificial intelligence
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-10-05 09:01:14 UTC -->
