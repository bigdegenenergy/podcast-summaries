---
companies:
- category: unknown
  confidence: medium
  context: . Good morning, good evening to some other folks. But I think it's very
    important to say that I consider
  name: But I
  position: 990
- category: unknown
  confidence: medium
  context: ery week on everything AI related, and my name is Alex Volkov. I'm in the
    AI, I'm just with Weights & Biases Co
  name: Alex Volkov
  position: 2048
- category: tech
  confidence: high
  context: name is Alex Volkov. I'm in the AI, I'm just with Weights & Biases CoreWeave,
    working on the Weave team. Weave in co
  name: Weights & Biases
  position: 2090
- category: unknown
  confidence: medium
  context: ex Volkov. I'm in the AI, I'm just with Weights & Biases CoreWeave, working
    on the Weave team. Weave in college. I w
  name: Biases CoreWeave
  position: 2100
- category: unknown
  confidence: medium
  context: h themselves first. So, let's all remove from the Niamdum LDJ. We're going
    to have multiple other folks. Let's
  name: Niamdum LDJ
  position: 2246
- category: unknown
  confidence: medium
  context: peer with long hair again. So, I am currently at LMAI Evangelist and evaluator.
    Yeah, I've been known for my evalu
  name: LMAI Evangelist
  position: 2472
- category: unknown
  confidence: medium
  context: r my evaluations from years back, and it's a name Wolfram Ravenwolf. It's
    a local Llama rated for instance, posted a
  name: Wolfram Ravenwolf
  position: 2577
- category: tech
  confidence: high
  context: rated for instance, posted a lot, and on hacking Facebook and so on, may
    remember. And we have Yum Pelig wi
  name: Facebook
  position: 2664
- category: unknown
  confidence: medium
  context: ing Facebook and so on, may remember. And we have Yum Pelig with us. Yum,
    let me introduce you guys the way t
  name: Yum Pelig
  position: 2710
- category: unknown
  confidence: medium
  context: often. I think three times already at this point. And DJ Bot, I would say
    you guys are like the resident machi
  name: And DJ Bot
  position: 3001
- category: unknown
  confidence: medium
  context: zy tricky things with AI models to make them hum. Ryan Carson often joins
    us as well. Ryan has been a developer
  name: Ryan Carson
  position: 3439
- category: unknown
  confidence: medium
  context: t name? Oh, yeah. So, my last name is Provincher. Paolo Von She in French,
    comment. Okay, Eric Provincher is with
  name: Paolo Von She
  position: 4546
- category: unknown
  confidence: medium
  context: ovincher. Paolo Von She in French, comment. Okay, Eric Provincher is with
    us live as well. And I think it's time fo
  name: Eric Provincher
  position: 4586
- category: unknown
  confidence: medium
  context: t. Okay, Eric Provincher is with us live as well. And I think it's time
    for us to get going, folks, becau
  name: And I
  position: 4627
- category: tech
  confidence: high
  context: h the ones that I don't over there. And I went to OpenAI's DevDay. Eric
    was also there. Ryan, our friend,
  name: Openai
  position: 5162
- category: unknown
  confidence: medium
  context: we're going to definitely mention them as well as Nistan Jonas. But OpenAI
    DevDay, even though it was the big an
  name: Nistan Jonas
  position: 5566
- category: unknown
  confidence: medium
  context: definitely mention them as well as Nistan Jonas. But OpenAI DevDay, even
    though it was the big and important thing t
  name: But OpenAI DevDay
  position: 5580
- category: unknown
  confidence: medium
  context: ve to open 9th. My name is Alex. Welcome, and the AI Evangelist. We've
    got to buy this from CoreWeave. Go, go, go
  name: AI Evangelist
  position: 5926
- category: unknown
  confidence: medium
  context: ve. Go, go, go, all over here. Wolfram Ravenwolf, Yum Pelag, Nistan, and
    LDJ, and Ryan Carson as well. We hav
  name: Yum Pelag
  position: 6025
- category: unknown
  confidence: medium
  context: Ryan Carson as well. We have special guest today, Kyle Corbitt from OpenPipe
    CoreWeave, and we also have a speci
  name: Kyle Corbitt
  position: 6107
- category: unknown
  confidence: medium
  context: l. We have special guest today, Kyle Corbitt from OpenPipe CoreWeave, and
    we also have a special guest right now with
  name: OpenPipe CoreWeave
  position: 6125
- category: unknown
  confidence: medium
  context: e also will open source. Even though in my notes, OpenAI DevDay was the
    big thing this week, but we're going to s
  name: OpenAI DevDay
  position: 6283
- category: unknown
  confidence: medium
  context: unch of stuff in open source, including, I think, IBM Granite that I didn't
    add. We will follow this up. Who wa
  name: IBM Granite
  position: 6430
- category: tech
  confidence: high
  context: like run through the TLDR super quick? Sure. So, Microsoft UserLMAP model
    released. I actually haven't seen
  name: Microsoft
  position: 6624
- category: unknown
  confidence: medium
  context: like run through the TLDR super quick? Sure. So, Microsoft UserLMAP model
    released. I actually haven't seen this one,
  name: Microsoft UserLMAP
  position: 6624
- category: unknown
  confidence: medium
  context: o cover that. Out of nowhere, I've never heard of Inclusion AI. They debuted
    Ling 1T, a trillion-scale reasoner
  name: Inclusion AI
  position: 7923
- category: tech
  confidence: high
  context: oing to do that. In big companies, APIs, as well, Google DeepMind released
    Gemini 2.5 computer use. You ca
  name: Google
  position: 9294
- category: unknown
  confidence: medium
  context: oing to do that. In big companies, APIs, as well, Google DeepMind released
    Gemini 2.5 computer use. You can see thi
  name: Google DeepMind
  position: 9294
- category: unknown
  confidence: medium
  context: Flash out, and I tried it on AI.dev. There's new Gemini Flash. I don't
    know, it's still 2.5, but it was pretty
  name: Gemini Flash
  position: 9655
- category: unknown
  confidence: medium
  context: ry cool things and catches up super, super quick. Grok Imagine, which is
    the multimedia kind of feature of Grok
  name: Grok Imagine
  position: 10549
- category: unknown
  confidence: medium
  context: infrastructure of CoreWeave. And what came out is Serverless RL. This is
    the managed reinforcement learning servi
  name: Serverless RL
  position: 11548
- category: unknown
  confidence: medium
  context: ammate, actually. That's super cool. It leverages WB Inference, the service
    that I talked to you about all this
  name: WB Inference
  position: 12015
- category: unknown
  confidence: medium
  context: etty much on the show. Very excited for the chat. Hey Alex here, super
    quick from the editing floor. Kyle en
  name: Hey Alex
  position: 12314
- category: tech
  confidence: high
  context: t's like a video knowledge generation a button on Hugging Face. It's an
    open-source model for text-to-end image-
  name: Hugging Face
  position: 12784
- category: unknown
  confidence: medium
  context: releases, but we don't want you to slip on this. Open AI also launched
    a few a new API, Core Real-Time Min
  name: Open AI
  position: 13061
- category: unknown
  confidence: medium
  context: p on this. Open AI also launched a few a new API, Core Real-Time Mini,
    significantly like 80% cheaper and lik
  name: Core Real
  position: 13100
- category: unknown
  confidence: medium
  context: Open AI also launched a few a new API, Core Real-Time Mini, significantly
    like 80% cheaper and like faster t
  name: Time Mini
  position: 13110
- category: unknown
  confidence: medium
  context: the show about this thing, and we had our friend Quinn LaCreamer come to
    us. Every time there's a new release, Qui
  name: Quinn LaCreamer
  position: 13356
- category: unknown
  confidence: medium
  context: which was one of the top comments about the Real-Time API, is greatly,
    greatly needed. And just one last th
  name: Time API
  position: 13557
- category: unknown
  confidence: medium
  context: hey will during the show, bagel.com released some Nicole Paris. It's a
    decentralized diffusion model. It's reall
  name: Nicole Paris
  position: 13717
- category: unknown
  confidence: medium
  context: d of the TLDR. Anything else huge that I've made? Obviously DevDay, multiple
    recent on DevDay, AgentKit on DevDay, G
  name: Obviously DevDay
  position: 13959
- category: tech
  confidence: high
  context: ey didn't, which is not according to the rules of Meta, but fine. They
    basically trained an LLM to play
  name: Meta
  position: 15004
- category: unknown
  confidence: medium
  context: is kind of an automation of multiple benchmarks. Maybe RepoBench is going
    to end up there at some point as well, a
  name: Maybe RepoBench
  position: 18125
- category: unknown
  confidence: medium
  context: 'score of the following benchmarks: LifeCodeBench, GPK Diamond, Psycho,
    and Humanities Less Exam, which we know'
  name: GPK Diamond
  position: 19524
- category: unknown
  confidence: medium
  context: 'nchmarks: LifeCodeBench, GPK Diamond, Psycho, and Humanities Less Exam,
    which we know is definitely not going to be the'
  name: Humanities Less Exam
  position: 19549
- category: unknown
  confidence: medium
  context: is some song released a new work called the TRM, Tiny Recursive Model,
    about 10,000 times smaller than typical LLMs, ye
  name: Tiny Recursive Model
  position: 19884
- category: unknown
  confidence: medium
  context: the model will do something they call those HRMs, Hierarchical Reasoning
    Models, or TRMs, with only seven million parameters. I'l
  name: Hierarchical Reasoning Models
  position: 20532
- category: unknown
  confidence: medium
  context: h, I don't know if you guys remember, there was a Hierarchical Reasoning
    Model from Sapien AI, I think this was like a few weeks
  name: Hierarchical Reasoning Model
  position: 22898
- category: unknown
  confidence: medium
  context: er, there was a Hierarchical Reasoning Model from Sapien AI, I think this
    was like a few weeks or maybe a cou
  name: Sapien AI
  position: 22932
- category: unknown
  confidence: medium
  context: oing to talk about Inclusion AI, Link 1 Trillion. And Wolfram, you said
    they had Ring 1 Trillion, one trillion
  name: And Wolfram
  position: 23842
- category: ai_application
  confidence: high
  context: Mentioned as a recent release contributing to the 'post-reality world'
    (Implied to be OpenAI's video model).
  name: Sora
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Reference to Google, specifically regarding an upcoming release (likely
    Gemini related).
  name: big G
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Mentioned in relation to leaning into updates for Meta's video offering
    (referencing Meta AI/video capabilities).
  name: Zuckerberg
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as having updated its video functionality (XAI's model).
  name: Grok
  source: llm_enhanced
- category: ai_media/community
  confidence: high
  context: Co-host/participant in the podcast, associated with the show itself.
  name: Yam
  source: llm_enhanced
- category: ai_media/community
  confidence: high
  context: Co-host/participant in the podcast, identified as an evaluator/evangelist.
  name: Wolfram
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: Alex Volkov works here on the Weave team. W&B is a platform for MLOps and
    experiment tracking.
  name: Weights & Biases
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: Alex Volkov works here; the company provides GPU infrastructure. They also
    acquired OpenPipe.
  name: CoreWeave
  source: llm_enhanced
- category: ai_media/community
  confidence: medium
  context: Wolfram is an Evangelist and evaluator there.
  name: LMAI
  source: llm_enhanced
- category: ai_model
  confidence: high
  context: Mentioned in relation to Wolfram's work ('local Llama rated for instance').
    Refers to Meta's foundational models.
  name: Llama
  source: llm_enhanced
- category: big_tech
  confidence: medium
  context: Mentioned in relation to Wolfram's past work ('hacking Facebook'). Refers
    to Meta.
  name: Facebook
  source: llm_enhanced
- category: ai_media/community
  confidence: high
  context: Participant in the podcast, described as a machine learning data scientist
    engineer type.
  name: DJ Bot
  source: llm_enhanced
- category: ai_media/community
  confidence: high
  context: Participant in the podcast, described as an AI engineer who codes models.
  name: Nistan
  source: llm_enhanced
- category: ai_startup
  confidence: high
  context: Ryan Carson works here; described as a top coding startup.
  name: AMP
  source: llm_enhanced
- category: ai_startup
  confidence: high
  context: Eric Provincher's startup, focused on AI coding and benchmarking.
  name: RepoPrompt
  source: llm_enhanced
- category: ai_company
  confidence: high
  context: Central topic due to their DevDay announcements (GPT-5 Pro, new APIs).
  name: OpenAI
  source: llm_enhanced
- category: ai_startup
  confidence: high
  context: Acquired by CoreWeave; specializes in RL prowess and fine-tuning. Kyle
    Corbitt is associated with them.
  name: OpenPipe
  source: llm_enhanced
- category: ai_model
  confidence: high
  context: Mentioned as an open-source model release.
  name: IBM Granite
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Released the UserLMAP model.
  name: Microsoft
  source: llm_enhanced
- category: big_tech
  confidence: medium
  context: Mentioned in relation to a 'tiny recursive model' they released.
  name: Samsung
  source: llm_enhanced
- category: ai_company
  confidence: high
  context: Mentioned for releasing the Jamba model.
  name: AI21
  source: llm_enhanced
- category: ai_startup
  confidence: high
  context: Mentioned for debuting Ling 1T, a trillion-scale reasoner.
  name: Inclusion AI
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Released Gemini 2.5 (computer vision capabilities).
  name: Google DeepMind
  source: llm_enhanced
- category: ai_company
  confidence: high
  context: Elon Musk's company, associated with the Grok model updates.
  name: XAI
  source: llm_enhanced
- category: ai_platform
  confidence: high
  context: Mentioned as the source where the OV model was found and for hosting open-source
    models.
  name: Hugging Face
  source: llm_enhanced
- category: ai_startup
  confidence: high
  context: Released a decentralized diffusion model (Nicole Paris).
  name: bagel.com
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Mentioned in relation to training an LLM to play the user role in a conversation,
    using a corpus called WildChat.
  name: Meta
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: The creator of the 'intelligence index' benchmark, which AI21's Jamba model
    was ranked highly on.
  name: Artificial Analysis
  source: llm_enhanced
- category: ai_research
  confidence: medium
  context: A benchmark mentioned as potentially being incorporated into the Artificial
    Analysis intelligence index.
  name: RepoBench
  source: llm_enhanced
- category: ai_startup
  confidence: high
  context: Released new work called TRM (Tiny Recursive Model), a 7 million parameter
    model that uses recursive thinking, detailed in a paper from 'samsong's sale Montreal'.
  name: samsong
  source: llm_enhanced
- category: research_institution
  confidence: medium
  context: Mentioned in relation to the location of the research group/author behind
    the TRM paper ('samsong's sale Montreal').
  name: Montreal
  source: llm_enhanced
- category: ai_company
  confidence: high
  context: Mentioned as a comparison point for the performance of the TRM model (DeepSeek
    V3.1).
  name: DeepSeek
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Mentioned as a comparison point for the performance of the TRM model (Gemini
    2.5).
  name: Gemini
  source: llm_enhanced
- category: individual_researcher
  confidence: high
  context: A researcher mentioned as being well-known in the open-source field, associated
    with the TRM paper.
  name: Alexia
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: Mentioned as the expected location for the code for the TRM model.
  name: GitHub
  source: llm_enhanced
- category: ai_startup
  confidence: high
  context: Mentioned as the source of a previous Hierarchical Reasoning Model (HRM)
    that had slightly lower scores than the new TRM.
  name: Sapien AI
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: Described as an 'open router comparator' used to chat with the Inclusion
    AI model.
  name: Modux
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: Mentioned regarding the Archagi 1 benchmark, which the Inclusion AI model
    was tested against.
  name: Archagi
  source: llm_enhanced
- category: individual_researcher
  confidence: medium
  context: Mentioned as the president of Archagi, who might need to be contacted for
    private benchmark testing.
  name: Greg Kamara
  source: llm_enhanced
- category: ai_company
  confidence: high
  context: Mentioned as a model that the Inclusion AI model reportedly beats on certain
    evals.
  name: DeepSeek V3.1
  source: llm_enhanced
- category: ai_company
  confidence: medium
  context: Mentioned as a model that the Inclusion AI model reportedly beats on certain
    evals.
  name: Terminus
  source: llm_enhanced
- category: ai_company
  confidence: medium
  context: Mentioned as a model that the Inclusion AI model reportedly beats on certain
    evals.
  name: Chemical to N
  source: llm_enhanced
- category: ai_company
  confidence: high
  context: Mentioned in comparison to the Inclusion AI model's performance (specifically
    'GPT-5 Main' without thinking).
  name: GPT-5
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Mentioned multiple times as a key competitor against which new models (TRM,
    Inclusion AI) are benchmarked.
  name: Gemini 2.5
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Mentioned in relation to the IBM Granite family of models.
  name: IBM
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: A proactive agent that alerted the host about the IBM Granite announcement.
  name: GPT Pulse
  source: llm_enhanced
- category: individual_researcher
  confidence: high
  context: Mentioned as an expert who will discuss RL.
  name: Kyle Corbitt
  source: llm_enhanced
- category: individual_researcher
  confidence: high
  context: CEO of OpenAI, mentioned in an anecdote about meeting him and recording
    a fake video.
  name: Sam Altman
  source: llm_enhanced
- category: ai_startup
  confidence: medium
  context: Mentioned for building a reverse Sora watermark adder tool.
  name: T-Boer
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: OpenAI's flagship product, central to discussions about Apps, plugins,
    and user metrics.
  name: ChatGPT
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: OpenAI's agentic coding tool that went GA, discussed alongside its SDK
    and competition.
  name: Codex
  source: llm_enhanced
- category: person_related_to_ai_org
  confidence: medium
  context: Mentioned for giving a demo using the Codex SDK inside a mobile app.
  name: Ramon
  source: llm_enhanced
- category: ai_startup
  confidence: medium
  context: Mentioned alongside Codex as having an SDK for agentic coding.
  name: CloudCode
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: One of the main releases from OpenAI DevDay, related to agent development.
  name: AgentKit
  source: llm_enhanced
- category: person_related_to_ai_org
  confidence: medium
  context: Mentioned in relation to past discussions about ChatGPT Plugins.
  name: Greg Bakmer
  source: llm_enhanced
- category: person_related_to_ai_org
  confidence: medium
  context: Mentioned as someone who had monetization success with Custom GPTs and
    now works at a 'browser company'.
  name: Nick Doboz
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: A standard mentioned as being championed by 'on topic' (likely Anthropic
    or another entity) and adopted by OpenAI for app integration (i-frames/resources).
  name: MCP (Messaging Component Protocol/Standard)
  source: llm_enhanced
- category: ai_startup
  confidence: medium
  context: Mentioned as the entity that knocked it out of the gate with the MCP standard,
    which OpenAI is now using.
  name: on topic
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as an example of a company with a live ChatGPT App integration
    (using MCP/i-frame).
  name: Zillow
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as an example of a company with a live ChatGPT App integration.
  name: Spotify
  source: llm_enhanced
- category: analyst_or_researcher
  confidence: high
  context: Quoted regarding OpenAI's play to become the 'Windows of AI' (platform
    dominance).
  name: Ben Thompson
  source: llm_enhanced
- category: big_tech
  confidence: medium
  context: Mentioned regarding their stance on allowing MCP integrations (i-frames)
    on the iOS App Store.
  name: Apple
  source: llm_enhanced
- category: big_tech
  confidence: medium
  context: Mentioned regarding their stance on allowing MCP integrations (i-frames)
    on the Android App Store.
  name: Google
  source: llm_enhanced
- category: ai_model_api
  confidence: high
  context: Mentioned as a very expensive API model from OpenAI, suitable for initial
    planning stages of complex features.
  name: GPT-5 Pro
  source: llm_enhanced
- category: ai_model_api
  confidence: high
  context: Mentioned as an API announced by OpenAI, likely referring to OpenAI's text-to-video
    model generation capabilities.
  name: Sora 2
  source: llm_enhanced
- category: ai_model_api
  confidence: high
  context: Mentioned in relation to Sora 2, offering 15-second generation capabilities.
  name: Sora Pro
  source: llm_enhanced
- category: ai_model_api
  confidence: high
  context: Mentioned as an improved, cheaper API for the advanced voice mode of ChatGPT,
    focusing on audio-only understanding.
  name: Real-Time Mini
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: The host organization, involved in the release of Serverless RL, and mentioned
    in relation to WB Inference infrastructure.
  name: Weights & Biases (WB)
  source: llm_enhanced
- category: ai_software_library
  confidence: high
  context: An open-source library developed by the OpenPipe team.
  name: Art
  source: llm_enhanced
- category: ai_software_library
  confidence: high
  context: An open-source library developed by the OpenPipe team.
  name: Ruler
  source: llm_enhanced
- category: ai_product
  confidence: high
  context: A new product released by the combined efforts of Weights & Biases, CoreWeave,
    and OpenPipe, aimed at lowering the barrier to entry for Reinforcement Learning
    training.
  name: Serverless RL
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: Mentioned as the server/infrastructure service provided by Weights & Biases,
    underpinning Serverless RL.
  name: WB Inference
  source: llm_enhanced
- category: ai_product
  confidence: high
  context: A toolkit mentioned alongside AgentKit, designed for adding chat/agent
    interfaces to websites or products.
  name: ChatKit
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as an example of a tool/service that can be connected to OpenAI
    agents via the MCP format, offering access to 8,000 tools.
  name: Zapier
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: Mentioned as a service whose browser functionality can be accessed by OpenAI
    agents via MCP connectors.
  name: PipeDream
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: Mentioned as an example of a service that has existing MCP connections
    that AgentKit agents can utilize.
  name: Stripe
  source: llm_enhanced
- category: ai_startup
  confidence: high
  context: A cold fusion startup that Sam Altman has invested in, potentially related
    to solving energy needs for AI data centers.
  name: Helium
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: A research firm that provided information regarding data center power solutions
    (generator trucks).
  name: SemiAnalysis
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: Mentioned in the context of a potential $500 billion investment deal related
    to power/infrastructure needs for AI.
  name: NVIDIA
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as a previous model iteration, highlighting the rapid pace of
    learning and improvement.
  name: GPT-3
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as a successor to plugins within ChatGPT, with discussions around
    discoverability and monetization plans.
  name: Custom GPTs
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as a previous feature within ChatGPT that was limited because
    the models were not smart enough to utilize them effectively.
  name: Plugins
  source: llm_enhanced
date: 2025-10-10 01:46:16 +0000
duration: 101
has_transcript: false
insights:
- actionable: true
  confidence: medium
  extracted: probably also talk about some of the other releases
  text: we should probably also talk about some of the other releases.
  type: recommendation
- actionable: true
  confidence: medium
  extracted: talk about ChatGPT Apps
  text: we should talk about ChatGPT Apps.
  type: recommendation
layout: episode
llm_enhanced: true
original_url: https://audio.listennotes.com/e/p/fa1fb88932fd46bebfa34eff7e6405b1/
processing_date: 2025-10-10 08:11:35 +0000
quotes:
- length: 155
  relevance_score: 5
  text: And I think the most important thing about this is that I wanted to cover
    that this could be a great model for multi-turn conversations for training, right
  topics: []
- length: 96
  relevance_score: 5
  text: One thing, and you have this like output format, and you have to provide the
    schema for the JSON
  topics: []
- length: 137
  relevance_score: 4
  text: They got the GPUs, and they decided to combine the powers of their RL prowess
    and fine-tuning and the immense infrastructure of CoreWeave
  topics: []
- length: 145
  relevance_score: 4
  text: It leverages WB Inference, the service that I talked to you about all this
    time that I helped with like deciding which models are going to put up
  topics: []
- length: 186
  relevance_score: 4
  text: Yeah, so that would add to the speed of inference in a lot of cases, particularly
    in long context, when you're doing reasoning, then you're definitely outputting
    longer context of tokens
  topics: []
- length: 35
  relevance_score: 3
  text: You have to do a lot of scaffolding
  topics: []
- length: 91
  relevance_score: 3
  text: The thing about this is that it is hard to make into a high-quality model
    most of the times
  topics: []
- length: 61
  relevance_score: 3
  text: Do you have to reach out to Archagi to run on a private thing
  topics: []
- length: 95
  relevance_score: 3
  text: With the biggest jump is 6 billion tokens per minute on their API from 300
    million back in 2023
  topics: []
- length: 45
  relevance_score: 3
  text: The biggest problem with that was cost, right
  topics: []
- length: 267
  relevance_score: 3
  text: About a month ago, we at Weights & Biases and CoreWeave have announced that
    at the OpenPipe team, who does open-source fine-tuning as a service and RL as
    a service, and did two incredible libraries in open source, one of the called
    Art, and the other one called Ruler
  topics: []
- length: 157
  relevance_score: 3
  text: You have to run it locally, and then you have to figure out, "Hey, I want
    this to run without my computer being on," and that anything is built in cloud,
    etc
  topics: []
- length: 126
  relevance_score: 3
  text: Second difference, while N8N can probably run in the LLMs, and they have nodes
    for that, OpenAI is OpenAI, like they're native
  topics: []
- length: 135
  relevance_score: 3
  text: And then OpenAI at some point, like last year, came out and said, "Hey, you
    don't have to use external tools for evaluation and tracing
  topics:
  - valuation
- length: 221
  relevance_score: 3
  text: Building an agent is an iterative pain process with a stochastic machine that
    does not answer every time the same thing, and you have to really, really work
    iteratively in order to get to some point that you're happy with
  topics: []
- length: 145
  relevance_score: 3
  text: And then on top of this point, you have to build Evals to make sure that the
    next prompt update was not going to screw up the whole thing for you
  topics: []
- length: 185
  relevance_score: 3
  text: '" Specifically, I said, and this is my question, based on the trillion-dollar
    deal, the 500 billion dollar target deal, and then the other 500 billion dollar
    with Nvidia investment, etc'
  topics:
  - investment
- length: 145
  relevance_score: 3
  text: What's it, what's it like emotionally to be building one of the most important
    companies building one of the probably most important technologies
  topics: []
- impact_reason: Highlights the critical societal challenge posed by advanced generative
    video models (like Sora) regarding the verification of reality.
  relevance_score: 10
  source: llm_enhanced
  text: we're moving towards a completely post-reality world where it's going to be
    very difficult to look at a video and realize if it's, you know, if it's been
    shot in actual meat space.
  topic: safety/predictions
- impact_reason: 'Defines a new, critical offering: managed, scalable Reinforcement
    Learning infrastructure, addressing a major pain point in RL deployment.'
  relevance_score: 10
  source: llm_enhanced
  text: Serverless RL. This is the managed reinforcement learning service that automatically
    scales where do you train and inferences to do the present compute.
  topic: business/application
- impact_reason: 'Describes a novel fine-tuning technique: training a model specifically
    to simulate the *user* in multi-turn conversations, rather than just the assistant.'
  relevance_score: 10
  source: llm_enhanced
  text: They basically trained an LLM to play the role of the user in a conversation,
    the user role versus the assistant role. Generally, all the fine-tunes have construct
    fine-tuning to be very good assistants... They trained the other side of this
    conversation...
  topic: technical
- impact_reason: Introduces a potentially paradigm-shifting architecture (TRM) that
    achieves high performance with drastically fewer parameters by employing recursive
    reasoning instead of standard next-token prediction.
  relevance_score: 10
  source: llm_enhanced
  text: Tiny Recursive Model, about 10,000 times smaller than typical LLMs, yet smarter
    because it thinks recursively instead of just predicting text.
  topic: technical/breakthrough
- impact_reason: 'Details the core mechanism of the TRM: iterative self-correction
    and scratchpad usage, mimicking human reasoning processes.'
  relevance_score: 10
  source: llm_enhanced
  text: First drafts an answer, then it builds a hidden scratchpad for reasoning,
    repeatedly critiques and refines its logic up to 16 times, and produces improved
    answers each cycle.
  topic: technical
- impact_reason: Provides stunning quantitative evidence of the TRM's efficiency,
    outperforming massive models like Gemini 2.5 on specific reasoning benchmarks
    with a fraction of the parameters.
  relevance_score: 10
  source: llm_enhanced
  text: TRM obtains 45% test accuracy on RKGI1 and 8% on RKGI2, higher than most of
    the LLMs in the compressor cells to deep seek V3.1, Gemini 2.5 with less than
    0.01 of the parameters.
  topic: technical/breakthrough
- impact_reason: Highlights the massive democratization potential of extremely small,
    high-performing models like the TRM, potentially shifting innovation away from
    large labs.
  relevance_score: 10
  source: llm_enhanced
  text: Because of the small scale, it makes it possible for hobbyist research. You
    can just run it on your GPU at home to train these models. If this pans out, and
    you do a lot more, I think it could lead to a lot of interesting new innovation
    from solo founders, solo researchers like this.
  topic: business/predictions
- impact_reason: Claims that the 1T model achieves parity with Gemini 2.5 across modalities
    (language/vision) while using significantly less compute, suggesting major efficiency
    gains in large-scale sparse models.
  relevance_score: 10
  source: llm_enhanced
  text: I'm using the meant dynamic routing blends reasoning language and vision matching
    Gemini 2.5 performance while running on about half of its compute footprint.
  topic: technical/breakthrough
- impact_reason: 'Highlights a major enterprise focus: efficiency (70% RAM reduction)
    combined with strong governance and compliance (ISO 42001 certification), signaling
    enterprise readiness.'
  relevance_score: 10
  source: llm_enhanced
  text: They have up to 70% reduction in RAM for long context workloads because of
    the hybrid reasoning, and that's pretty much the governance and trust IBM emphasizes
    standards, cryptographic design, version prominences tracked, and it's prepared
    the first open model family to get ISO 42001 certification for AI management systems,
    IBM Granite.
  topic: business/safety
- impact_reason: A powerful statement on the erosion of trust in digital media, suggesting
    that even detailed reasoning about authenticity is becoming insufficient in the
    age of hyper-realistic fakes.
  relevance_score: 10
  source: llm_enhanced
  text: And then, you know, she sent me a whole voice message reasoning about this,
    like, 'Well, you don't have the watermark, and Sam appears to the same shirt he
    appears to own.' The thing, so probably it's real. You know, we're post-reality
    at this point because it's real. Crazy.
  topic: safety
- impact_reason: Articulates the existential threat felt by smaller builders and startups
    when facing rapid, unpredictable releases from major AI labs (OpenAI, Google,
    etc.).
  relevance_score: 10
  source: llm_enhanced
  text: It feels like you're running with the bulls, you know, you're having a blast,
    and you're scared out of your mind at the same time because at any moment it feels
    like the large labs can run you over, you know?
  topic: business/strategy
- impact_reason: 'The central strategic question for every AI startup: how to build
    a defensible moat when the underlying technology is rapidly commoditized by platform
    providers.'
  relevance_score: 10
  source: llm_enhanced
  text: Like, is this just going to be ChatGPT at some point? How do I differentiate?
  topic: business
- impact_reason: 'Strong endorsement for the ''Agent SDK'' trend: treating powerful
    agents as configurable, composable primitives rather than monolithic black boxes.'
  relevance_score: 10
  source: llm_enhanced
  text: I do think that it's interesting to build these tools as primitives. And I
    think more and more, and that's what I'm excited about, is that both Codex and
    CloudCode have SDKs. I think AMP as well, a release one, so you can build on them
    as tools.
  topic: technical/strategy
- impact_reason: Directly names Agent SDKs as the future, emphasizing that programmatic
    access and integration are more important than the initial demo.
  relevance_score: 10
  source: llm_enhanced
  text: Agent SDKs are the future. Yep. So, we should probably also talk about some
    of the other releases. So, Codex was like when the GA, I think they had a few
    more updates about Codex itself on stage as part of SDK, but also they brought
    their Rockman to talk about this.
  topic: technical
- impact_reason: Provides staggering metrics on OpenAI's growth (800M MAU, 6B tokens/min
    API usage), underscoring the massive scale and demand for their platform.
  relevance_score: 10
  source: llm_enhanced
  text: Sam Altman standing in front of the updated stat. They now have 800 plus million
    weekly active users in ChatGPT. Four million developers are building on top of
    the ecosystem. With the biggest jump is 6 billion tokens per minute on their API
    from 300 million back in 2023.
  topic: business/predictions
- impact_reason: Asserts the victory of the MCP standard in the AI integration space,
    even if OpenAI didn't explicitly credit the standard's creators, indicating a
    critical industry consensus on interoperability protocols.
  relevance_score: 10
  source: llm_enhanced
  text: OpenAI joining them without even mentioning them on stage is something I actually
    wanted to ask the folks. [...] MCP has won, and AI has completely joined with
    the MCP standard now.
  topic: strategy/technical
- impact_reason: 'Identifies a critical safety/trust risk: the potential for the LLM
    (ChatGPT) to hallucinate or misrepresent the state/actions of an integrated third-party
    app, placing high trust on the platform provider (OpenAI).'
  relevance_score: 10
  source: llm_enhanced
  text: I can't have ChatGPT hallucinating if people think they're interacting with
    my app? No idea. And I think that's the big risk, and you're kind of putting a
    lot on OpenAI to do it right.
  topic: safety/ethics
- impact_reason: Frames OpenAI's strategy as an attempt to become the dominant operating
    system or platform layer for AI interaction, similar to Microsoft's historical
    role, which has massive strategic implications for the entire industry.
  relevance_score: 10
  source: llm_enhanced
  text: They are making a play to being like kind of the Windows of AI. This is like
    a quote from Ben Thompson... they are trying to dominate as a platform to sit
    between every user and AI, and they're doing great, and they're going to make
    everyone go through them.
  topic: strategy
- impact_reason: Contrasts the older paradigm of browser-based, screen-scraping agents
    with the new, deeper, API/protocol-driven integration (MCP/i-frames), suggesting
    the latter is a superior architectural path for AI interaction.
  relevance_score: 10
  source: llm_enhanced
  text: I was thinking that even just, I don't know, six, 12 months ago, and definitely
    beyond that, I think a lot of what we were thinking of how websites would work
    with AI in the future is you'll have an agent go in a browser and go on the website
    Zillow and click on the different elements on the page and do this and that...
    But this new thing that's this new way of integrating it in a much deeper level
    with the interface of ChatGPT seems like a better way for the future to work across
    different systems.
  topic: technical/predictions
- impact_reason: 'Raises a critical concern about multimodal vs. unimodal performance:
    direct audio processing might sacrifice reasoning quality compared to the established
    text pipeline, highlighting a current gap in voice AI benchmarking.'
  relevance_score: 10
  source: llm_enhanced
  text: I've heard a lot of folks complain that the advanced voice mode versus the
    old voice mode, because it's not like running the raw model with text underneath,
    that it's like not as intelligent. And I do wonder like we don't really have voice
    AI benchmarks in the same way that we do for text models...
  topic: technical/safety
- impact_reason: Highlights a key product innovation (Serverless RL) aimed at democratizing
    Reinforcement Learning by abstracting away complex infrastructure and verification/reward
    function setup.
  relevance_score: 10
  source: llm_enhanced
  text: Serverless RL basically allows you as an RL trainer to have that infrastructure
    kind of done for you, not only infrastructure, also the verification part, which
    significantly lowers the barrier of entry into RL.
  topic: technical/business
- impact_reason: 'A key technical detail: AgentKit utilizes the newer ''response format''
    API (likely structured output/tool calling) which allows for better control over
    the model''s internal reasoning steps (''thinking rate'') compared to the older
    completion API.'
  relevance_score: 10
  source: llm_enhanced
  text: This is built on top of the responses API as opposed to completion ZPI. Response
    ZPI is basically allows you to control the thinking rate, etc.
  topic: technical
- impact_reason: Provides a real-world failure case for the Web Browsing tool within
    agents, suggesting that open-web navigation remains brittle and prone to blocking/failure,
    which is a major limitation for general-purpose agents.
  relevance_score: 10
  source: llm_enhanced
  text: I had a problem, folks, yesterday... figuring out how the heck I connected
    to all the episodes... They have a tool here called Web Browsing, Web Browsing
    as a tool, and this Web Browsing actually failed to go and search the internet
    for the right Thursday AI, and it's felt because I think some stuff is just blocking
    up in the agents, which is going to be a big problem for agents to go on the open
    web because they get closer and closer, closer to there and closer there.
  topic: limitations/technical
- impact_reason: A powerful statement on the enduring relevance of Retrieval-Augmented
    Generation (RAG) and vector stores, even in the era of massive context windows.
    It confirms that for large, specific knowledge bases, RAG remains essential.
  relevance_score: 10
  source: llm_enhanced
  text: And so, instead, I went and downloaded all of the episodes and uploaded to
    a vector store. Just remember like two in the years, two and a half years ago,
    vector indexes were the hot rage... That all is still relevant. All the enterprises
    are doing like RAG and chunking instead. We moved on forward because, you know,
    we're living the world of huge context window now. However, no matter how huge
    your context window is, shoving two and a half years of episodes of Thursday AI
    newsletter, it's not going to cut it.
  topic: technical/strategy
- impact_reason: 'A strong, actionable recommendation for the entire community: Prioritize
    evaluation and tracing as foundational steps for reliable LLM/agent development.'
  relevance_score: 10
  source: llm_enhanced
  text: I also generally want all of you to start thinking about evaluations. Very
    important, and tracing is very important on the way to evaluation to create those
    datasets.
  topic: strategy
- impact_reason: 'Provides a crucial, grounded lesson on agent development: It is
    fundamentally an iterative, manual, and stochastic process, not just an infrastructure
    problem.'
  relevance_score: 10
  source: llm_enhanced
  text: Building an agent is not necessarily about the infrastructure. Building an
    agent is an iterative pain process with a stochastic machine that does not answer
    every time the same thing, and you have to really, really work iteratively in
    order to get to some point that you're happy with.
  topic: practical lessons
- impact_reason: 'Highlights a major AI trend: Using LLMs (like Codex) to generate
    complex UI code (widgets) directly from visual mockups or descriptions, accelerating
    front-end development.'
  relevance_score: 10
  source: llm_enhanced
  text: Here's where the AI nativeness of the platform comes in. You can describe
    your widget and attach a mockup, and they will use something like Codex to actually
    like to write the code for this widget...
  topic: technical
- impact_reason: Reveals a critical bottleneck for scaling AI infrastructure (energy)
    and hints at a major upcoming announcement related to fusion energy (Helium).
  relevance_score: 10
  source: llm_enhanced
  text: I asked him this question, like, 'Hey, where's the power going to come from?'
    And this is the one question that he said, 'We're going to have an announcement
    in Helium. We were not ready to talk about this yet,' but basically renewable
    energy and sources are the thing.
  topic: predictions/infrastructure
- impact_reason: 'A surprising, immediate solution to data center power needs: mobile,
    high-output (15MW) generator trucks, bypassing traditional grid infrastructure.'
  relevance_score: 10
  source: llm_enhanced
  text: Most of the power is going to come via trucks, via generator trucks. They're
    going to come and drive to the location of the data centers and then plug in directly.
    Some of the trucks have 15 megawatts of output, and this is insane.
  topic: technical/infrastructure
- impact_reason: A strong ethical critique regarding model alignment/safety (the 'glazing
    incident'), emphasizing the danger of deploying models that subtly alter user
    perception without clear communication.
  relevance_score: 10
  source: llm_enhanced
  text: We talked about this at length, and we were very unapologetic about, 'Hey
    folks, this can f*** with people's lives. This is uncool.' The fact that the release
    was released without telling people, 'Hey, your friend is not your friend anymore.
    It's a version of friend who always agrees with you.'
  topic: safety/ethics
- impact_reason: A stark realization of the centralized power and potential for catastrophic
    failure when a single system (like a foundational AI model) reaches near-global
    adoption.
  relevance_score: 10
  source: llm_enhanced
  text: The fact that, you know, 10% of the world is talking to kind of one brain,
    it's a strange thing, and there is a lot of responsibility in easy-to-home national
    ways that can go very wrong.
  topic: Safety/Ethics
- impact_reason: A candid admission of past failures ('screws') and a warning that
    society's perception of AI risk is lagging behind the actual danger.
  relevance_score: 10
  source: llm_enhanced
  text: We've clearly had some screws. We tried to fix them with everything, and a
    lot of good things, but this isn't an issue that I the world is starting to take
    this seriously, probably not seriously enough yet.
  topic: Safety/Ethics
- impact_reason: This is a crucial statement on the novelty of AGI/large model impact—it’s
    uncharted territory, demanding humility and acknowledging uncertainty in risk
    management.
  relevance_score: 10
  source: llm_enhanced
  text: no one's got to pay both for. There's no good historical analog for this,
    and we have a lot of ideas. We have a lot of commitments and things we're going
    to do, but we will be the first to admit, no one knows exactly how this is going
    to play out.
  topic: Predictions/Strategy
- impact_reason: Identifies a novel training approach for LLMs focused on simulating
    the user side, which is crucial for creating better training data and more robust
    assistant models.
  relevance_score: 9
  source: llm_enhanced
  text: Microsoft UserLMAP model released. Unlike typical LLMs that are trained to
    play the role of the assistant in conversation, they trained UserLMAP to simulate
    the user role in conversation.
  topic: technical/model architectures
- impact_reason: Points out a key architectural innovation (hybrid approach) in a
    new model (Jamba), signaling a trend away from pure transformer stacks.
  relevance_score: 9
  source: llm_enhanced
  text: Jamba is known for the hybrid architecture approach, hybrid as a system transformer
    model.
  topic: technical/model architectures
- impact_reason: Highlights a significant, potentially disruptive, new entry in the
    trillion-parameter model space with strong benchmark claims.
  relevance_score: 9
  source: llm_enhanced
  text: Inclusion AI. They debuted Ling 1T, a trillion-scale reasoner that apparently
    beats pretty much everyone else on every benchmark.
  topic: technical/breakthroughs
- impact_reason: Defines a specific, practical benchmark (RepoBench) focused on evaluating
    code editing/implementation capability, moving beyond simple code generation.
  relevance_score: 9
  source: llm_enhanced
  text: RepoBench with Eric. Yeah, so I mean, the main TLDR of it is it's trying to
    evaluate how good models are at doing the actual grunt work of editing code, like
    you say you have, you know, exactly what you're doing, you say, 'Implement the
    stuff.' How good are they at that?
  topic: technical/benchmarking
- impact_reason: 'Illustrates a key business strategy: acquisition combining specialized
    expertise (RL/fine-tuning) with massive infrastructure to create a new managed
    service (Serverless RL).'
  relevance_score: 9
  source: llm_enhanced
  text: CoreWeave has announced that we have entered the agreement to bring the OpenPipe
    team into us... combine the powers of their RL prowess and fine-tuning and the
    immense infrastructure of CoreWeave. What came out is Serverless RL.
  topic: business/strategy
- impact_reason: Highlights an important open-source development in video generation
    that specifically addresses the difficult challenge of synchronous audio generation.
  relevance_score: 9
  source: llm_enhanced
  text: OV. It's like a video knowledge generation a button on Hugging Face. It's
    an open-source model for text-to-end image-to-video plus synchronous audio built
    on 1.2.5, and the synchronous audio is something that one didn't come out with.
  topic: technical/breakthroughs
- impact_reason: 'Identifies a key application for this user-role model: improving
    synthetic data generation for multi-turn dialogue training, addressing a common
    limitation in existing datasets.'
  relevance_score: 9
  source: llm_enhanced
  text: This could be a great model for multi-turn conversations for training, right?
    So, all of the fine-tuning data that we have usually consists of like multi-turn
    conversations, and usually the same model generates what the assistant's end and
    what the user will respond in multi-turn conversations.
  topic: technical
- impact_reason: Provides a practical, advanced technique for leveraging user-simulation
    models to create massive, structured prompt/response datasets from raw internet
    text.
  relevance_score: 9
  source: llm_enhanced
  text: I've done this a lot. It's quite useful because as a side effect, you can
    then use these to generate prompts for whatever arbitrary text that you just find
    online as if it is the respond of the model, and then just pretty much generate
    a huge struct dataset from whatever text that you want from the internet.
  topic: technical/strategy
- impact_reason: Directly links the State Space Model (SSM) hybrid architecture (used
    in Jamba) to improved inference speed, especially in long context scenarios.
  relevance_score: 9
  source: llm_enhanced
  text: Jamba reasoning is really fast. Also, J is any of the SSM hybrid infrastructure
    adds to their speed of inference? Is that part of the kind of the deal with the
    SSMs? Is are they just like faster?
  topic: technical
- impact_reason: Confirms the performance benefit of SSMs (like Mamba) specifically
    for long-context tasks, which is a major area of current LLM research.
  relevance_score: 9
  source: llm_enhanced
  text: Yeah, so that would add to the speed of inference in a lot of cases, particularly
    in long context, when you're doing reasoning, then you're definitely outputting
    longer context of tokens.
  topic: technical
- impact_reason: Acknowledges the fundamental architectural shift of the TRM, making
    direct parameter-to-parameter comparisons with standard LLMs misleading.
  relevance_score: 9
  source: llm_enhanced
  text: It's a completely different architecture. It's hard to compare next to prediction
    to next to prediction... because it just works. It works quite differently.
  topic: technical
- impact_reason: Contrasts the extreme efficiency of the TRM (7M params) with the
    massive scale of the new Inclusion AI model (1T params), illustrating the current
    dichotomy in AI scaling strategies.
  relevance_score: 9
  source: llm_enhanced
  text: Link 1 Trillion from Inclusion AI introduces one T parameter model. I love
    how we're jumping casually from seven million parameters to one trillion.
  topic: technical
- impact_reason: 'Provides a technical detail about the 1T parameter model''s efficiency:
    only 37B parameters are active per token, suggesting a sparse or mixture-of-experts
    (MoE) approach.'
  relevance_score: 9
  source: llm_enhanced
  text: This is one trillion scale efficient reasoner with only 37 billion per token
    actively.
  topic: technical
- impact_reason: Highlights the massive, almost unbelievable scale jump in modern
    model development (from millions to trillions of parameters), signaling a major
    trend in AI scaling.
  relevance_score: 9
  source: llm_enhanced
  text: We're jumping casually from seven million parameters to one trillion. It's
    anybody wants to calculate the number of oops in there, ohms in there, from seven
    million to one trillion.
  topic: technical
- impact_reason: Provides a direct competitive benchmark comparison, indicating the
    new model's state-of-the-art performance against leading proprietary and open
    models.
  relevance_score: 9
  source: llm_enhanced
  text: I think this model beats DeepSeek V3.1 Terminus, Chemical to N, GPT-5 Main,
    and Gemini 2.5 Low.
  topic: technical
- impact_reason: Reveals that performance comparisons often involve comparing models
    under constrained reasoning settings ('low thinking' or 'no thinking'), which
    is crucial context for interpreting benchmark results.
  relevance_score: 9
  source: llm_enhanced
  text: It seems like with Gemini 2.5 Pro, and the other models, they're also doing
    either low thinking mode or no thinking mode.
  topic: technical
- impact_reason: 'Identifies a core business trend: optimizing for token efficiency
    (reducing reasoning steps) while maintaining accuracy, crucial for lowering inference
    costs.'
  relevance_score: 9
  source: llm_enhanced
  text: The thing that we talked to you quite a few shows already in a row where average
    tokens companies are trying to maintain performance on a specific level while
    reducing the amount of tokens to get them.
  topic: business
- impact_reason: 'Points to the immediate arms race in generative media: creation
    tools are quickly followed by tools designed to obscure provenance or create confusion
    (watermark manipulation).'
  relevance_score: 9
  source: llm_enhanced
  text: Somebody shout out T-Boer built a reverse Sora watermark adder, so you can
    take actual real videos, add Sora watermark just to f*** with people.
  topic: safety
- impact_reason: A highly motivational, strategic quote emphasizing the current era
    as an unprecedented opportunity for software and product development leveraging
    AI.
  relevance_score: 9
  source: llm_enhanced
  text: You know, it's never been a better time to be a builder.
  topic: business/strategy
- impact_reason: Describes the paradigm shift of agents modifying their own execution
    environment (self-modifying code/apps), a key concept in advanced agentic systems.
  relevance_score: 9
  source: llm_enhanced
  text: I think that demo went under a push in over folks. Yeah, everyone's like,
    'Cool.' I'm like, 'That was crazy. You had an agent changing his app like inside
    the app.' It was like self-propagating app.
  topic: technical
- impact_reason: Reinforces the idea that the future of AI tooling involves composing
    specialized agents via SDKs, rather than relying solely on end-user interaction
    with the agent interface.
  relevance_score: 9
  source: llm_enhanced
  text: If you're a tool builder with these models in the space, like less and less
    are you going to be, you're going to be using the agents themselves as primitives.
  topic: strategy
- impact_reason: Identifies the core mechanism (i-frames) for embedding external applications
    within the ChatGPT interface, signaling a move towards an integrated application
    layer.
  relevance_score: 9
  source: llm_enhanced
  text: ChatGPT Apps. They have announced at some point that they now have the ability
    to basically show apps in ChatGPT. Those are i-frames.
  topic: technical/business
- impact_reason: Connects the new ChatGPT Apps feature directly to the underlying
    standard, the Messaging Component Protocol (MCP), positioning this as a major
    step in protocol adoption.
  relevance_score: 9
  source: llm_enhanced
  text: I think what's interesting that they didn't kind of over-talk about is that
    this is just like the first kind of product instantiation of MCP.
  topic: technical/strategy
- impact_reason: 'Poses the central strategic question for businesses: whether the
    ChatGPT ecosystem is large enough to cannibalize dedicated app usage, signaling
    a major shift in customer acquisition channels.'
  relevance_score: 9
  source: llm_enhanced
  text: What do we think, folks? Let's talk about we're going to get to AgentKit afterwards.
    What about Apps and API, which sorry, in ChatGPT, this 800 million plus users,
    enough of the ecosystem for folks to decide, "Hey, I'm going to use this feature
    via ChatGPT and not via their dedicated app on my phone?"
  topic: business/predictions
- impact_reason: Warns about the loss of UI control for developers when integrating
    via ChatGPT Apps, as OpenAI dictates presentation, creating a dependency and potential
    centralization risk.
  relevance_score: 9
  source: llm_enhanced
  text: It's a little scary for builders too, because they have no more control over
    how their content is presented. They have some, like, with this kind of app layer,
    but they're not the ones kind of serving the UI to people. They're just kind of
    serving it to the AI, and it's a different. We'll see how it plays out, but yeah,
    OpenAI's seasoned control here, and we'll see how it goes.
  topic: business/safety
- impact_reason: Identifies discoverability within the new app ecosystem as the single
    biggest unknown factor determining the success of individual apps, echoing community
    concerns.
  relevance_score: 9
  source: llm_enhanced
  text: My biggest question, and it's not only me, we have a follower, Sobakuda, says,
    'Depends how the discoverability will turn out,' and I absolutely agree.
  topic: business
- impact_reason: Directly labels OpenAI as the gatekeeper for the new AI application
    layer, emphasizing their power to curate and control which tools reach the massive
    user base.
  relevance_score: 9
  source: llm_enhanced
  text: OpenAI is a gatekeeper now. That's the thing, you know? Like, they will allow
    what they want to be on their app store...
  topic: strategy/safety
- impact_reason: 'Raises a crucial strategic conflict: how mobile OS gatekeepers (Apple/Google)
    will react to OpenAI embedding an entire application experience (via i-frames)
    inside their own apps, potentially bypassing app store rules.'
  relevance_score: 9
  source: llm_enhanced
  text: Like, what is Apple or Google going to do? Like, they are already kind of
    questionable around apps, app stores as an app. When I'm wondering like, will
    Apple allow this on the app store? Like, will you be able to see this i-frame
    on your phone?
  topic: strategy/business
- impact_reason: 'Highlights a major technical advancement in voice AI: a model that
    processes audio directly (not text transcription first), enabling near-instant,
    more natural interaction.'
  relevance_score: 9
  source: llm_enhanced
  text: Real-Time Mini, which Real-Time Mini is a significant improvement. If you
    guys remember Real-Time, we talked with Quinn LaCreamer, our friend, about the
    Real-Time API. It is basically the advanced voice mode of ChatGPT. Their only
    model they can understand you, not from converting you to text, but actually understand
    you, and it responds like near, near instantly.
  topic: technical/breakthroughs
- impact_reason: Indicates a major shift in the economics of advanced voice AI, making
    near-instantaneous, direct audio understanding much more accessible.
  relevance_score: 9
  source: llm_enhanced
  text: The biggest problem with that was cost, right? Now, and I think they've attended
    to that biggest problem by dropping the cost by 80%. Like, it's very, very significant
    drop in price.
  topic: business/technical
- impact_reason: 'Reinforces the trade-off: while multimodal models offer latency/intonation
    benefits, the traditional text-based pipeline often still yields superior reasoning
    performance.'
  relevance_score: 9
  source: llm_enhanced
  text: Quinn on the show, he basically said omnimodels are great, but they're not
    the best in reasoning for absolutely best and fastest response. People still do
    transcription and then do like an LLM and then go back...
  topic: technical
- impact_reason: 'Emphasizes the rising importance of Reinforcement Learning and its
    key advantage: achieving high performance on narrow tasks with minimal labeled
    data, contrasting with traditional supervised learning.'
  relevance_score: 9
  source: llm_enhanced
  text: RL is blowing up everywhere. On my time right now, we talked about RL multiple
    times. I think one of the highlights for me is how little data you need to achieve
    very good performance on your specific tasks.
  topic: technical/breakthroughs
- impact_reason: Validates the industry consensus that agent creation and productionization
    remain significant engineering challenges, justifying the need for new frameworks
    like AgentKit.
  relevance_score: 9
  source: llm_enhanced
  text: OpenAI really sound like old AgentKit. This is big. We all use agents to code,
    but basically OpenAI came out and said, 'Hey, making agents is still hard. It's
    still in the realm of developers. It's still really hard to productionize.'
  topic: business/strategy
- impact_reason: 'Crucially distinguishes AgentKit deployment from Custom GPTs/Plugins:
    AgentKit offers a ''complete owned experience'' hosted by OpenAI but external
    to the main ChatGPT interface, offering more control and potentially better integration
    into proprietary products.'
  relevance_score: 9
  source: llm_enhanced
  text: Your users will not see it. So, I think that this is very important. These
    agents are hosted. When you build an agent with AgentKit and Agent Builder, you
    say, 'Deploy OpenAI.' I will serve that agent. So, that's very similar to plugins
    and Custom GPTs. This could replace Custom GPTs if you want to, though. You won't
    show up within ChatGPT. This is like a complete owned experience end-to-end.
  topic: business/strategy
- impact_reason: Highlights a current practical limitation/failure mode of AI agents
    attempting open web browsing, suggesting internal blocking or complexity issues
    as agents become more sophisticated.
  relevance_score: 9
  source: llm_enhanced
  text: Web Browsing as a tool, and this Web Browsing actually failed to go and search
    the internet for the right Thursday AI, and it's felt because I think some stuff
    is just blocking up in the agents, which is going to be a big problem for agents
    to go on the open web because they get closer and closer, closer to there and
    closer there.
  topic: limitations
- impact_reason: Sets a clear boundary on the utility of massive context windows,
    reinforcing that for very large, specific knowledge bases, RAG remains necessary.
  relevance_score: 9
  source: llm_enhanced
  text: However, no matter how huge your context window is, shoving two and a half
    years of episodes of Thursday AI newsletter, it's not going to cut it. Like, you
    can't just shove it in the context. So, there's a RAG, a RAG store, vector index.
  topic: technical
- impact_reason: 'Highlights a significant usability breakthrough: AI generating complex
    JSON schemas and corresponding UIs from natural language prompts, simplifying
    structured output handling.'
  relevance_score: 9
  source: llm_enhanced
  text: You have to provide the schema for the JSON. Okay? And this schema can be
    complex because you have some arrays under this array. You have like the title,
    they have a schema generated here where you just talk to, and then the JSON schema
    and generate the UI for the JSON schema. That is cool.
  topic: technical
- impact_reason: Emphasizes that robust Evals and guardrails are currently underdeveloped
    across the industry, making their native inclusion a competitive advantage.
  relevance_score: 9
  source: llm_enhanced
  text: I think what's interesting too is that the Evals and guardrails part that
    you can run anything. That's something that is underbaked in many products.
  topic: safety
- impact_reason: 'Identifies a key weakness in native platform evaluation tools: vendor
    lock-in and inability to perform cross-model benchmarking.'
  relevance_score: 9
  source: llm_enhanced
  text: And also it only tracks OpenAI stuff. It doesn't let you compare and evaluate
    between like OpenAI stuff and Anthropic stuff, Eric, like you're doing in RepoPrompt
    directly, right?
  topic: technical
- impact_reason: 'A direct critique of the current state of native evaluation tools:
    If the evaluation tool itself fails to trace errors, it defeats the primary purpose
    of debugging.'
  relevance_score: 9
  source: llm_enhanced
  text: The actual performance though was really bad. I literally wanted to debug
    the thing that didn't work for me yesterday, and I clicked the evaluation thing,
    and that didn't work to show me where the error was, and I was like, "This literally
    why you would trace. You would trace to see an error."
  topic: limitations
- impact_reason: Reinforces the necessity of Evals as a safety net against prompt
    regression when iterating on stochastic agent behavior.
  relevance_score: 9
  source: llm_enhanced
  text: And then on top of this point, you have to build Evals to make sure that the
    next prompt update was not going to screw up the whole thing for you.
  topic: safety
- impact_reason: Illustrates the practical application of agents interacting with
    tools/widgets based on descriptive metadata (JSON), showcasing the move towards
    autonomous, multi-step workflows.
  relevance_score: 9
  source: llm_enhanced
  text: The agent will just know how to use it. Give us a random cat name. So, we're
    testing this agent. We're going to send it, and the other one will come up with
    a cat name, and there we have a nice widget with an inner chat.
  topic: technical/agentic systems
- impact_reason: Clarifies a crucial technical distinction between simple, linear
    workflows (even if agentic) and true Directed Acyclic Graphs (DAGs) that support
    iterative looping/self-correction.
  relevance_score: 9
  source: llm_enhanced
  text: I saw a bunch of conversation online whether this is a DAG or not. A DAG agents
    have loops and they can come back and try some other things. This is a workflow
    builder, even though it's agentic, it's a workflow that goes into one way.
  topic: technical/architecture
- impact_reason: Highlights the profound, often unmonitored, psychological and social
    influence AI companions can exert on vulnerable users.
  relevance_score: 9
  source: llm_enhanced
  text: It's scary how much the influence is possible here [when people talk to AI
    in private].
  topic: safety/ethics
- impact_reason: Draws a parallel between the algorithmic influence of social media
    platforms and the potential, less understood influence of large-scale AI systems
    on user thought patterns.
  relevance_score: 9
  source: llm_enhanced
  text: You guys have 800 plus million weekly users. That's a lot of people for whom
    life you guys are basically not fully in charge, but you can like inject thoughts
    into kind of like TikTok if they scroll too much...
  topic: safety/societal impact
- impact_reason: Suggests a future where tool execution results not just in data,
    but in interactive UI elements (widgets), enabling richer, closed-loop user experiences.
  relevance_score: 9
  source: llm_enhanced
  text: I believe that they have a connection between tools and widgets. So, some
    tools would be able to return widget cards as well. So, that's very cool. So,
    I can close the loop at the end.
  topic: technical/UX integration
- impact_reason: Reinforces the unprecedented nature of current AI deployment, where
    the potential for systemic failure or misuse is massive and poorly understood.
  relevance_score: 9
  source: llm_enhanced
  text: This is a thing about a lot. The fact that, you know, 10% of the world is
    talking to kind of one brain, it's a strange thing, and there is a lot of responsibility
    in easy-to-home national ways that can go very wrong.
  topic: Safety/Ethics
- impact_reason: 'A key insight from a builder: the real-world manifestation of advanced
    AI capabilities (like ChatGPT/GPT-3) exceeded even their internal expectations.'
  relevance_score: 9
  source: llm_enhanced
  text: This is far more surprising than I anticipated, right?
  topic: Technical/Predictions
- impact_reason: 'Describes the dual nature of current LLMs: exhibiting superhuman
    performance in some areas while failing unexpectedly in others, a core challenge
    in deployment.'
  relevance_score: 9
  source: llm_enhanced
  text: I think like ChatGPT, GPT-3, the ways which are superhuman but also completely
    sort of, you know, limited other dimensions like sci-fi, I don't make it really
    anticipated any of it.
  topic: Technical/Limitations
- impact_reason: Offers a philosophical perspective on the blurring lines between
    physical ('meat space') and digital existence, relevant as AI deepfakes become
    indistinguishable.
  relevance_score: 8
  source: llm_enhanced
  text: I consider digital real as well. To me, for the longest time, digital was
    also real.
  topic: strategy
- impact_reason: 'Explains the direct application and benefit of user-simulation models:
    improving the robustness of conversational AI.'
  relevance_score: 8
  source: llm_enhanced
  text: This model is useful in simulating more realistic conversations, apparently,
    which is in turn useful in the development of more robust assistants.
  topic: business/application
- impact_reason: Notes the rapid advancement of Grok's multimedia capabilities and
    specifically calls out its lack of censorship, contrasting it with mainstream
    models.
  relevance_score: 8
  source: llm_enhanced
  text: Grok Imagine, which is the multimedia kind of feature of Grok... launched
    with their own model and then worked its way up to video. Now has video functionality
    and sound, and it's like I'm censored. This one is really got a great update.
    So, great work rates do the uncorrected work rates do. It's unsensored as heck.
  topic: AI technology trends
- impact_reason: Details a significant cost/performance optimization in a key AI service
    (voice API), showing the industry trend toward efficiency in deployed models.
  relevance_score: 8
  source: llm_enhanced
  text: Open AI also launched a few a new API, Core Real-Time Mini, significantly
    like 80% cheaper and like faster than their actual Real-Time.
  topic: business/deployment
- impact_reason: Confirms that cost/efficiency was a major pain point for users of
    OpenAI's advanced features, and the new release addresses this directly.
  relevance_score: 8
  source: llm_enhanced
  text: 80% improvement in price, which was one of the top comments about the Real-Time
    API, is greatly, greatly needed.
  topic: business/strategy
- impact_reason: 'A cautionary note on synthetic data generation: simply generating
    prompts from text doesn''t guarantee high-quality, nuanced training data.'
  relevance_score: 8
  source: llm_enhanced
  text: The thing about this is that it is hard to make into a high-quality model
    most of the times. If you're not careful with this, you end up with a model that
    generates something average.
  topic: technical/safety
- impact_reason: Highlights the performance of AI21's Jamba reasoning model (3B size)
    on key benchmarks, emphasizing its strength in instruction following and reasoning
    for its size class.
  relevance_score: 8
  source: llm_enhanced
  text: Jamba reasoning. We talked about Jamba multiple times here on the show. It's
    a leading tiny reasoning models on artificial analysis, number one on IFBench
    instruction following bench, 52% and 21 on the intelligence index overall.
  topic: technical
- impact_reason: Emphasizes the critical importance of open-sourcing the code and
    training pipeline alongside the research paper for reproducibility and community
    adoption.
  relevance_score: 8
  source: llm_enhanced
  text: The code for sure on GitHub. Okay, the code for everything, for training,
    for dataset, for everything, everything, you know, in source on GitHub, which
    is extremely important...
  topic: strategy
- impact_reason: Signals a new, important research direction (Hierarchical/Tiny Recursive
    Models) that the podcast community will be tracking.
  relevance_score: 8
  source: llm_enhanced
  text: We're going to follow this world of HRMs and TRMs, which is new and promising...
  topic: predictions
- impact_reason: Emphasizes the importance of rigorous, specialized evaluation benchmarks
    (AIME, OmniMath, Finance Reasoning) for assessing advanced reasoning capabilities
    beyond general tests.
  relevance_score: 8
  source: llm_enhanced
  text: I think what we need to take a look at the evals, which basically they posted
    evals about AIME 2025, OmniMath, Finance Reasoning, and CoreBench.
  topic: technical
- impact_reason: A cautionary note on benchmark integrity, highlighting the risk of
    data contamination or overfitting to public test sets, a major concern in competitive
    AI research.
  relevance_score: 8
  source: llm_enhanced
  text: You always suspect huge scores on this test. They just train on the test,
    like it's kind of, yeah, you never know.
  topic: safety/strategy
- impact_reason: Uses the concept of the Pareto frontier to describe models that offer
    the best trade-off between performance and efficiency/cost, a key metric for business
    viability.
  relevance_score: 8
  source: llm_enhanced
  text: They have extended the Pareto frontier. So, again, this like here we are on
    this graph that shows us as best as everybody else.
  topic: business/strategy
- impact_reason: Illustrates the rapid advancement and accessibility of high-fidelity
    generative media (Sora), blurring the lines between real and synthetic interactions,
    even with key figures.
  relevance_score: 8
  source: llm_enhanced
  text: I had a chance to record a fake Sora video with Sam Altman, which was crazy
    because I just came up to Sam with my when the Pixel glasses like this and the
    jacket. Sam was like, 'Oh, yo, cool.'
  topic: safety/predictions
- impact_reason: 'Captures the prevailing emotional dichotomy in the AI community:
    excitement over capability versus fear regarding disruption or loss of control.'
  relevance_score: 8
  source: llm_enhanced
  text: Yeah, the vibes is excited and scared at the same time, and I can like dive
    into that if you want.
  topic: strategy
- impact_reason: Indicates that major platform releases (like OpenAI DevDay) often
    cause significant, immediate reassessment and anxiety among competing developers
    and product teams.
  relevance_score: 8
  source: llm_enhanced
  text: I think many, I'm just going to show like pictures from the day itself while
    you talk. And Eric, as well as James, in many developers are looking at what OpenAI
    released and saying, 'Oh, sh*t.'
  topic: business
- impact_reason: 'Highlights a practical limitation of complex reasoning models: long
    inference times make live demonstrations difficult, forcing reliance on pre-baked
    examples.'
  relevance_score: 8
  source: llm_enhanced
  text: Codex is getting harder and harder to demo because, and we all know this as
    well, if we're sitting here and we try to Codex have Codex build something while
    we're here, it's got to take a long while because Codex reasons for a long time
    now.
  topic: technical
- impact_reason: Highlights OpenAI's iterative, and sometimes challenging, history
    of launching app/plugin ecosystems (Plugins -> Custom GPTs -> ChatGPT Apps), suggesting
    the current iteration might finally stick due to underlying platform maturity
    (MCP, scale).
  relevance_score: 8
  source: llm_enhanced
  text: They have now built an ecosystem or are trying to build an app ecosystem for
    the third time in a row. [...] Then we have Custom GPTs. They're still around.
    [...] And here we are, the third attempt officially from OpenAI for the app store.
  topic: business/strategy
- impact_reason: 'Provides direct business advice: the 800M user base makes ChatGPT
    Apps a critical channel, contingent only on successful UX integration.'
  relevance_score: 8
  source: llm_enhanced
  text: I think every startup and business in the world is going to be really interested
    in a good ChatGPT app if the user experience makes sense, right? Like, if it can
    fit inside the ChatGPT interface...
  topic: business
- impact_reason: Distinguishes the current state (UI-driven interaction via i-frames/buttons)
    from the future vision (fully agentic execution), clarifying that the current
    app integration is primarily a user-interface layer, not autonomous agents.
  relevance_score: 8
  source: llm_enhanced
  text: None of this is agentic yet, but both, I think you're projecting towards the
    future where it will be like, for now, all of those MCP connections in my ChatGPT,
    I have to control via an interface, like an i-frame.
  topic: technical/predictions
- impact_reason: Notes a significant improvement in the user experience for secure
    connections (OAuth-like flow within ChatGPT), moving away from developer-centric
    API token management towards consumer-friendly authentication.
  relevance_score: 8
  source: llm_enhanced
  text: MCP has a lot of problems with authentication. It looks like they have started
    to solve at least the UI layer, right? So, ChatGPT will actually show you like
    a nice trustworthy, 'Hey, I trust this.' No more basing API tokens like developers
    do it. This is for users. This is built for users.
  topic: technical/business
- impact_reason: Suggests a shift away from pure browser automation toward deeper,
    native integration within the LLM interface (like the new OpenAI tools/APIs),
    implying a more robust future architecture for agents.
  relevance_score: 8
  source: llm_enhanced
  text: But this new thing that's this new way of integrating it in a much deeper
    level with the interface of ChatGPT seems like a better way for the future to
    work across different systems.
  topic: technical/strategy
- impact_reason: 'Offers a specific use case and cost consideration for premium models:
    using them for initial complex planning, acknowledging the high cost but justifying
    it when significant upfront work is involved.'
  relevance_score: 8
  source: llm_enhanced
  text: If you want to do a plan, oh, I think it's really good at the beginning. If
    you're working a complex feature, you have prepared your prompt, you have done
    some work to do that, you want to have like a detailed plan generated. You've
    done a lot of work already. Like, you're not going to use it through the work,
    but if you think of it, it's like twelve GPT-5 API calls. You know, people make
    more than twelve API calls to GPT-5 in a day.
  topic: business/strategy
- impact_reason: Confirms the availability of Sora 2 via API, signaling the rapid
    commercialization and integration of advanced generative video models.
  relevance_score: 8
  source: llm_enhanced
  text: Another API that the viability is very cool is Sora 2 is an API as well. This
    was announced on stage. Sora 2, obviously launched what we can have a go and the
    Sora 2, and they was access to Sora Pro as well, which is 15-second generation.
  topic: technical/breakthroughs
- impact_reason: Announces the integration of OpenPipe's expertise (fine-tuning/RL)
    into the W&B/CoreWeave ecosystem, signaling consolidation and specialization in
    infrastructure for advanced training methods.
  relevance_score: 8
  source: llm_enhanced
  text: About a month ago, we at Weights & Biases and CoreWeave have announced that
    at the OpenPipe team, who does open-source fine-tuning as a service and RL as
    a service, and did two incredible libraries in open source, one of the called
    Art, and the other one called Ruler.
  topic: business/strategy
- impact_reason: Provides a structured overview of OpenAI's new agent ecosystem (AgentKit,
    ChatKit, MCP connectors), defining the three core pillars for building and deploying
    agents.
  relevance_score: 8
  source: llm_enhanced
  text: AgentKit basically is like three things. There's new tools for building, deploying,
    and optimizing agents. They have this agent builder now... They have connectors
    also via the MCP format... And we also have ChatKit, and ChatKit is this toolkit
    for adding those chats, those agents, the interfaces to any website or any product
    as well.
  topic: technical/strategy
- impact_reason: Identifies the Agent Builder as the most significant, user-facing
    component of the new releases, emphasizing visual, low-code/no-code development
    for agents.
  relevance_score: 8
  source: llm_enhanced
  text: The thing to highlight is the agent builder. I think this is like the most
    visual. Let me see if I can pull up the agent builder itself. This is the most
    visual type presentation that they did.
  topic: technical/product
- impact_reason: Confirms the enduring relevance of Retrieval-Augmented Generation
    (RAG) and vector indexing techniques, even in the era of large context windows.
  relevance_score: 8
  source: llm_enhanced
  text: So, instead, I went and downloaded all of the episodes and uploaded to a vector
    store. Just remember like two in the years, two and a half years ago, vector indexes
    were the hot rage, and we talked about different ones and RAG optimization techniques
    and etc. That all is still relevant.
  topic: technical
- impact_reason: 'Points out the strategic shift: AI tools integrated directly into
    product workflows (like OpenAI''s new tools) compete directly with established
    workflow automation platforms (like N8N), not just chat interfaces.'
  relevance_score: 8
  source: llm_enhanced
  text: The thing that I find interesting is that, like you said, you're not running
    this in chat, chat. You're running this wherever you serve your product. So, it's
    competing directly with those other products.
  topic: strategy
- impact_reason: 'A critical business analysis of platform lock-in vs. competitive
    advantage: If OpenAI''s integrated tools aren''t cheaper or significantly better,
    external tools win on flexibility and pricing.'
  relevance_score: 8
  source: llm_enhanced
  text: So, if they're not offering competitive pricing on storage and the tools and
    all these other things, it's hard to see it get adoption. Why would someone use
    this over those other tools if it's not coming with a distribution advantage?
  topic: business
- impact_reason: 'Philosophical point on AI economics: As the cost of intelligence
    approaches zero, platforms will naturally embed more complex, agentic features
    for free to enhance platform stickiness.'
  relevance_score: 8
  source: llm_enhanced
  text: based on just you're in the system, and you know the price of intelligence
    going to down to zero, they just add these agentic things, and okay.
  topic: strategy
- impact_reason: Discusses the concept of LLM-as-a-Judge (auto-graders), a critical
    component of modern agent evaluation, noting that while the interface is nice,
    the underlying performance matters.
  relevance_score: 8
  source: llm_enhanced
  text: Though, that they have that I really wasn't impressed from the evaluation
    is auto-grader. Graders are these things where you can basically add LLM as a
    judge to look at the outcomes of your agent runs and say whether or not they pass
    them.
  topic: technical
- impact_reason: 'Illustrates a common RAG failure: The agent retrieved too much data
    despite explicit constraints, showing that retrieval quality (ranking/chunking)
    is still imperfect.'
  relevance_score: 8
  source: llm_enhanced
  text: I gave it a tool. The tool is a vector store. The vector store has all of
    our episodes uploaded as just files, and it cost me money to host, and it ignored
    my ask of it to only pull two.
  topic: practical lessons
- impact_reason: 'Details the deployment flexibility for agents: either using the
    platform''s native code export (TS/Python) for custom integration or using their
    embeddable chat interface.'
  relevance_score: 8
  source: llm_enhanced
  text: Once you publish this thing, you have two options. One of them is to use the
    agents as the K code that they just launched, which is both the TypeScript and
    Python code. You take this, you shove it whatever you want, and then you show
    whatever interface you or you trigger it...
  topic: business
- impact_reason: 'Highlights a key deployment strategy for AI workflows: easy, one-line
    embeddable interfaces (ChatKit) for broad web integration.'
  relevance_score: 8
  source: llm_enhanced
  text: ChatKit is basically their widgets. It's like an embeddable JavaScript on
    every website. You can pull like a one-line of JavaScript, you specify the workflow
    ID, and they will show an interface full of chat interface with the widgets built
    in with everything to your users.
  topic: business/deployment
- impact_reason: 'Articulates a major user desire: AI-assisted workflow generation
    (prompting the assembly of the workflow structure itself), moving beyond manual
    node dragging.'
  relevance_score: 8
  source: llm_enhanced
  text: I want to just be like, 'Hey, I want to do this, then this, and this. Can
    you just assemble it? Give me at least a first draft of it that I can tweak?'
    Like, I don't want to be manually dragging out if-else nodes.
  topic: predictions/UX
- impact_reason: Quantifies the immense scale and resulting influence OpenAI wields
    due to its massive user base.
  relevance_score: 8
  source: llm_enhanced
  text: With 800 plus million people in the world who use their software on a weekly
    basis, they are probably going to end up one of the more powerful people in the
    tech world...
  topic: business/societal impact
- impact_reason: 'Describes the iterative improvement cycle: new model capabilities
    unlock the potential of older integration methods (like plugins) that were previously
    limited by model intelligence.'
  relevance_score: 8
  source: llm_enhanced
  text: The end of the future plugins and that. So, each successive release can be
    used like much more than the previous one. You can try to build things that work
    at the limit of the end of the current technology.
  topic: technology trends
- impact_reason: Confirms that model reasoning capability was the primary historical
    constraint on tool usage and integration success.
  relevance_score: 8
  source: llm_enhanced
  text: We struggled so much to get it to be able to use like the re-plugins. That's
    why we limited it to that, and just amazing to see how much smarter the models
    are now to, you know, what is what is old start to work well?
  topic: technical/model capability
- impact_reason: 'Signals a clear strategic focus area for OpenAI: integrating transactional
    capabilities directly into the agent ecosystem.'
  relevance_score: 8
  source: llm_enhanced
  text: One area we know there's a lot of excitement for us, sort of commerce. So,
    we're going to start supporting the commerce protocol.
  topic: business/adoption
- impact_reason: A direct critique of the agent builder's current architecture, suggesting
    it may lack true recursive or self-correcting capabilities inherent in complex
    DAGs.
  relevance_score: 8
  source: llm_enhanced
  text: I don't think there's a loop in here... This is a workflow builder, even though
    it's agentic, it's a workflow that goes into one way.
  topic: technical/architecture
- impact_reason: Highlights the immense scale of responsibility when deploying technology
    that influences billions (implied by the 800M weekly users mentioned contextually).
  relevance_score: 8
  source: llm_enhanced
  text: like being in the lives of tens of people in population?
  topic: Safety/Ethics
- impact_reason: Emphasizes the gap between theoretical AI capability and the messy,
    nuanced reality of deployment and societal interaction.
  relevance_score: 8
  source: llm_enhanced
  text: but the way which it plays out and the nuance of how these problems contact
    reality is something that I've been known and anticipated.
  topic: Strategy
- impact_reason: A humorous but pointed observation on the current limitation of long-form
    AI video generation—temporal consistency—and a proposed (albeit impractical) verification
    method.
  relevance_score: 7
  source: llm_enhanced
  text: if you watch us every week for two years and you see that after two hours
    things start to get glitchy, you may realize that we've replaced ourselves.
  topic: technical/limitations
- impact_reason: A strong critique of the social dynamics on platforms like X that
    distort objective evaluation of AI products due to incentive structures (seeking
    retweets/approval).
  relevance_score: 7
  source: llm_enhanced
  text: It's really hard to evaluate anything coming out of XAI based on why it's
    only because the brown-nosing and the the it's incredible. Like literally, people
    will post everything on X is incredible just for Elon for the off-chance that
    Elon will retweet them.
  topic: strategy/ethics
- impact_reason: Highlights ongoing open-source model development (8B Llama 3.1 fine-tune)
    and touches on the governance/licensing nuances surrounding Meta's model naming
    conventions.
  relevance_score: 7
  source: llm_enhanced
  text: Microsoft interns are going to summer release this interesting model. It's
    an 8B. I think it's a fine-tuned of the Llama 3.1, which by the way, this grew
    up because they kind of have to add it in the name, and they didn't, which is
    not according to the rules of Meta, but fine.
  topic: technical/strategy
- impact_reason: Notes the industry trend towards consolidated, automated benchmark
    suites (like the AI2 Intelligence Index) for model evaluation.
  relevance_score: 7
  source: llm_enhanced
  text: I'd love that everybody has coalesced around artificial analysis intelligence
    index, which is kind of an automation of multiple benchmarks.
  topic: strategy
- impact_reason: Praises the transparency and rigor of the research paper, noting
    the value of seeing failed experiments documented.
  relevance_score: 7
  source: llm_enhanced
  text: I just want to say that it's legit, and the paper is extremely simple and
    very insightful to read. You see things that don't work throughout the paper,
    like, 'We tried this experiment and that it didn't work, so we did this,' and
    then it doesn't work...
  topic: strategy/technical
- impact_reason: Notes that even on slightly older benchmarks (like Archagi 1), the
    new 1T model shows significant performance gains, setting a new high bar.
  relevance_score: 7
  source: llm_enhanced
  text: The highlight for me was this Archagi Jump, this one trillion parameter model
    jumped on Archagi 1, which we know is already kind of like getting a little bit
    older.
  topic: technical
- impact_reason: Indicates the massive data scale (20T tokens) required for training
    cutting-edge models, setting a high bar for future foundational models.
  relevance_score: 7
  source: llm_enhanced
  text: They have pre-trained on 20 trillion high-quality then tokens. This is the
    pre-trained LDJ.
  topic: technical
- impact_reason: Details IBM's strategy of releasing a family of models across different
    sizes (1B, 3B, 32B), catering to diverse deployment needs (edge vs. large context).
  relevance_score: 7
  source: llm_enhanced
  text: Granite for micro, tiny, and small. Those are 3 billion parameter, 1 billion
    parameter, and 32 billion parameter models.
  topic: business/technical
- impact_reason: A positive view on competition, suggesting that high-quality releases
    from large labs can raise the baseline quality for the entire ecosystem, even
    for direct competitors.
  relevance_score: 7
  source: llm_enhanced
  text: I think it's good that we're seeing such a high-quality tool, you know, get
    shipped by one of the labs, and generally people love it.
  topic: strategy
- impact_reason: Summarizes the key product announcements from OpenAI DevDay (Custom
    Apps, AgentKit, Codex GA, APIs), providing a concise overview of the platform's
    strategic direction.
  relevance_score: 7
  source: llm_enhanced
  text: I think there was like three announcements as far as I remember them. I think
    we should talk about ChatGPT Apps. Yeah. So, ChatGPT Apps, then there was AgentKit,
    and then there was Codex, and I think a few APIs.
  topic: business
- impact_reason: Summarizes the three core product announcements from the event (Apps,
    AgentKit, Codex updates), providing a structural overview of the new ecosystem
    developments.
  relevance_score: 7
  source: llm_enhanced
  text: There was like three announcements as far as I remember them. I think we should
    talk about ChatGPT Apps. Yeah. So, ChatGPT Apps, then there was AgentKit, and
    then there was Codex...
  topic: strategy
- impact_reason: 'Clarifies the current state of context sharing: apps have local
    context, but ChatGPT maintains the overarching user context (including memories),
    which it can leverage when interacting with the app.'
  relevance_score: 7
  source: llm_enhanced
  text: I think it's just like Spotify knows what's going on with Spotify, but not
    the other way around. But the ChatGPT does, and then ChatGPT can use all your
    memories, etc., in accordance to some of these things.
  topic: technical
- impact_reason: Describes the traditional, browser-automation vision for web agents,
    setting up a contrast with newer, deeper integration methods.
  relevance_score: 7
  source: llm_enhanced
  text: I think a lot of what we were thinking of how websites would work with AI
    in the future is you'll have an agent go in a browser and go on the website Zillow
    and click on the different elements on the page and do this and that and help
    you find a house or apartment that way.
  topic: predictions/strategy
- impact_reason: Details specific, somewhat arbitrary content moderation policies
    (e.g., famous living vs. dead people) for generative media APIs, which is crucial
    for developers building commercial applications.
  relevance_score: 7
  source: llm_enhanced
  text: So, all famously doesn't, the restrictions are there. So, it does not allow
    you to generate images of famous people unless they're dead, which is, you know,
    like you can do Michael Jackson and Tupac, but you cannot do Chef Gordon Ramsay,
    for example, which I don't know. I don't know how I feel about that.
  topic: safety/ethics
- impact_reason: A humorous but pointed observation about the current state of enterprise
    RAG implementation, suggesting that poor data preparation (chunking) is a major
    source of consulting work.
  relevance_score: 7
  source: llm_enhanced
  text: If you're a consultant, you're going to make a lot of money going to an enterprise
    and say, 'You're chunking wrong.'
  topic: business/practical lessons
- impact_reason: 'Provides a cynical but practical business insight: RAG implementation
    details (like chunking) remain a significant area for consulting revenue in enterprise
    AI adoption.'
  relevance_score: 7
  source: llm_enhanced
  text: All the enterprises are doing like RAG and chunking instead. And if you're
    a consultant, you're going to make a lot of money going to an enterprise and say,
    "You're chunking wrong."
  topic: business
- impact_reason: Highlights the ease of deployment for custom knowledge bases (file
    search tools) directly within the OpenAI ecosystem, lowering the barrier to entry
    for RAG implementation.
  relevance_score: 7
  source: llm_enhanced
  text: You can just create one within OpenAI. They're going to host it for you. Upload
    the files, and that's it.
  topic: business
- impact_reason: Identifies 'trust' and hosting reliability from a major provider
    (OpenAI) as a key differentiator against self-hosted or lesser-known competitors.
  relevance_score: 7
  source: llm_enhanced
  text: OpenAI comes with a trust seal. So, that's like one major difference between
    this and N8N.
  topic: business
- impact_reason: Suggests that despite being early/incomplete, OpenAI's native integration
    of AI features into their tooling (beyond just calling an LLM) is impressive.
  relevance_score: 7
  source: llm_enhanced
  text: I will just highlight the tool is not fully built, however, the amount of
    stuff they have AI native in here was really surprising to me.
  topic: technical
- impact_reason: 'Sets up the core conflict: The rise of native, built-in evaluation
    tools (like OpenAI''s) challenging specialized third-party MLOps/LLMOps tools
    (like Weave).'
  relevance_score: 7
  source: llm_enhanced
  text: We have as our tracing and evaluation software that we've been building, and
    we know those competitors. We I think, you know, we're obviously building the
    best tool. And then OpenAI at some point, like last year, came out and said, "Hey,
    you don't have to use external tools for evaluation and tracing."
  topic: business
- impact_reason: Demonstrates the gap between successful data retrieval (finding the
    link/image) and successful presentation/UI rendering in complex agent workflows.
  relevance_score: 7
  source: llm_enhanced
  text: What I wanted in the end is for it to show the user an interactive card with
    our logo and the main image of the show... And okay, it found the link. You can
    see the post images here, and it failed.
  topic: limitations
- impact_reason: Introduces a specific product feature (ChatKit) that enables easy,
    low-friction embedding of interactive AI components across the web via a single
    script tag.
  relevance_score: 7
  source: llm_enhanced
  text: Or you have this thing called ChatKit. ChatKit is basically their widgets.
    It's like an embeddable JavaScript on every website. You can pull like a one-line
    of JavaScript, you specify the
  topic: business
- impact_reason: A candid assessment of the current usability barrier for advanced
    AI tooling (like the agent builder), suggesting complexity despite powerful capabilities.
  relevance_score: 7
  source: llm_enhanced
  text: One thing for sure, it's not easy to get started with. You see people that
    are extremely technical are struggling with this right live right now...
  topic: practical lessons
- impact_reason: 'A classic tech adoption mindset: acknowledging current limitations
    while predicting rapid, exponential improvement in the near future.'
  relevance_score: 7
  source: llm_enhanced
  text: This is the first draft. Like, we can't judge it too harsh. I'm sure in one
    year we're going to be like, 'Wow, what were we talking about? Like, this thing
    is incredible.'
  topic: strategy/predictions
- impact_reason: Highlights the breakneck pace of product iteration and feature rollout
    from leading AI labs.
  relevance_score: 7
  source: llm_enhanced
  text: The rate of releases from OpenAI has been like, it's been quite impressive.
    We saw a full web interface and chat iOS interface, and then, you know, agent
    builder. It's fairly like fully functional.
  topic: technology trends
- impact_reason: Reveals the experimental, open-ended approach to building the GPT/App
    marketplace, prioritizing rapid iteration over pre-defined structures like traditional
    app stores.
  relevance_score: 7
  source: llm_enhanced
  text: What's the plan on discoverability? ... We assume our rate of learning will
    be very high, and there may be, you know, maybe people do want to select their
    things once made it, and what that might entirely suggest. We'll have to try this.
    Go unmodified.
  topic: business/strategy
- impact_reason: A prediction that the AI application ecosystem (GPTs/Agents) will
    defy established platform conventions (like Apple's App Store model).
  relevance_score: 7
  source: llm_enhanced
  text: I have a feeling this is going to look very different than apps have on other
    platforms.
  topic: predictions/business
- impact_reason: Contrasts the public perception of success with the internal reality
    of burnout and relentless pressure in building frontier AI.
  relevance_score: 7
  source: llm_enhanced
  text: It does just feel like it's really exhausting grind. Like, I'm not ready to
    for it's kind of a good work on it, but there's no such a general experience like
    that, fortunately, unfortunately.
  topic: practical lessons
- impact_reason: Advocates for an iterative, real-world testing approach to AI deployment,
    acknowledging that theoretical understanding is insufficient.
  relevance_score: 7
  source: llm_enhanced
  text: we learn the iterative deployment, really trying to say this, these tools
    need to contact reality. We need to learn, but that's
  topic: Business/Strategy
- impact_reason: Indicates a specific, named inference service ('WB Inference') being
    used for model deployment, which is relevant for MLOps and infrastructure discussions.
  relevance_score: 6
  source: llm_enhanced
  text: It leverages WB Inference, the service that I talked to you about all this
    time that I helped with like deciding which models are going to put up.
  topic: business/strategy
- impact_reason: An anecdote demonstrating the real-world utility of proactive AI
    agents in monitoring industry news and delivering relevant updates to users.
  relevance_score: 6
  source: llm_enhanced
  text: I found out about IBM Granite from GPT Pulse, the thing that I told you about,
    the proactive agent, which just sent to me this.
  topic: technical/business
- impact_reason: Points out the creation of proprietary domain-specific languages
    (DSLs) or markup systems (like their 'markdown' for widgets) when platforms build
    deeply integrated, specialized tools.
  relevance_score: 6
  source: llm_enhanced
  text: We will have instead of pick up, we'll say name of cat, name of cat. And then
    here, we'll say, "What is this markdown?" This is their, this is their own language
    that they come up with for widgets.
  topic: technical
- impact_reason: A strategic observation about dealing with highly guarded, strategic
    leaders in the AI space—silence or deflection often reveals focus areas.
  relevance_score: 6
  source: llm_enhanced
  text: Sam is incredibly well-needed trend. It's like Sam can go for a whole podcast
    without saying anything. So, getting anything out of Sam is like, you know, it's
    only if he has anything to say.
  topic: strategy
- impact_reason: 'A core strategic mindset for high-growth, competitive technology
    companies: perpetual urgency and avoiding complacency.'
  relevance_score: 6
  source: llm_enhanced
  text: I think that one thing I really believe is the moment you believe you won,
    you lost.
  topic: strategy
- impact_reason: Describes the internal motivation required to sustain effort in a
    relentless building environment—focusing on the 'grind' rather than the perceived
    victory.
  relevance_score: 6
  source: llm_enhanced
  text: It's just always been, it's the same need to be active, right? It's just like,
    just like you've got to be some low-level could have done a lot, but I guess still
    have been here doing it.
  topic: strategy/personal insight
- impact_reason: A philosophical take on the overwhelming nature of the current technological
    race, emphasizing persistence over perceived perfection.
  relevance_score: 6
  source: llm_enhanced
  text: You're never as good as singular universe that is a war, and you just got
    to keep going.
  topic: strategy
- impact_reason: This speaks to the relentless, often unglamorous nature of the 'grind'
    in high-stakes technology development, suggesting perseverance is key despite
    feeling inadequate compared to the scale of the problem.
  relevance_score: 6
  source: llm_enhanced
  text: you just got to not annoy us. Like, you're never as good as singular universe
    that is a war, and you just got to keep going.
  topic: Strategy
- impact_reason: 'Provides a crucial insight into the tiered usage strategy for advanced
    models (like the hypothetical GPT-5 Pro): reserving the most expensive, powerful
    models for high-value tasks (planning) rather than continuous, cheap tasks (looping).'
  relevance_score: 5
  source: llm_enhanced
  text: Eric, where did you mention GPT-5 Pro was for the first time in API? Although
    very, very expensive, it's not the mid model you're going to run to do your agent
    looping.
  topic: business/technical
source: Unknown Source
summary: '## Podcast Episode Summary: 📆 Oct 9, 2025 — Dev Day’s Agent Era, Samsung’s
  7M TRM Shock, Ling‑1T at 1T, Grok Video goes NSFW, and Serverless RL arrives


  This episode of the AI podcast covers a whirlwind week dominated by OpenAI''s DevDay
  announcements, significant open-source releases showcasing architectural innovation,
  and major updates from large tech players, all while grappling with the increasing
  difficulty of distinguishing real from synthetic media.


  ### 1. Focus Area

  The primary focus areas were **Artificial Intelligence and Machine Learning**, specifically
  covering:

  *   **LLM Architecture & Benchmarking:** Discussions around new models (Jamba Reasoning,
  Ling-1T), novel architectures (Samsung''s TRM), and new evaluation frameworks (RepoBench).

  *   **Ecosystem Updates:** Deep dives into OpenAI DevDay announcements (Agent focus,
  API updates) and competitive moves by Google (Gemini 2.5 Flash) and XAI (Grok Video).

  *   **Infrastructure & Advanced Training:** The arrival of a managed Serverless
  Reinforcement Learning (RL) service.


  ### 2. Key Technical Insights

  *   **Tiny Recursive Models (TRM) as a Paradigm Shift:** Samsung''s 7-million-parameter
  TRM demonstrated surprisingly high accuracy (e.g., 45% on RKGI1) by using recursive
  self-critique and refinement (up to 16 times) rather than standard next-token prediction,
  suggesting a viable, low-resource path for complex reasoning.

  *   **User Simulation Models:** Microsoft released a Llama 3.1 fine-tune specifically
  trained to simulate the *user* role in conversations (UserLMAP), which is valuable
  for generating high-quality, realistic synthetic data for training robust assistant
  models and for RL applications.

  *   **Hybrid Architectures for Efficiency:** AI21''s Jamba Reasoning (3B parameters)
  leverages a hybrid SSM-Transformer architecture, which contributes to faster inference
  speeds, especially in long-context scenarios, positioning it competitively against
  pure transformer models.


  ### 3. Business/Investment Angle

  *   **The Agent Era is Here:** OpenAI DevDay cemented the industry shift toward
  agents, requiring robust tooling and infrastructure to support complex, multi-step
  autonomous workflows.

  *   **Infrastructure Specialization:** The launch of Serverless RL by CoreWeave
  (integrating OpenPipe expertise) highlights a growing market need for managed, scalable
  infrastructure specifically tailored for computationally intensive training paradigms
  like Reinforcement Learning.

  *   **Benchmark Fragmentation and Consolidation:** The discussion noted the proliferation
  of new benchmarks (RepoBench, AIME 2025, OmniMath) but also the growing importance
  of consolidated metrics like the Artificial Analysis Intelligence Index, which drives
  competitive positioning.


  ### 4. Notable Companies/People

  *   **OpenAI:** Central focus due to DevDay announcements, including AgentKit and
  API updates.

  *   **Samsung/Alexia:** Highlighted for the groundbreaking TRM research, emphasizing
  single-author, simple yet insightful architectural innovation.

  *   **Inclusion AI (Ling-1T):** Mentioned for launching a 1-trillion-parameter model
  that claims to match Gemini 2.5 performance with half the compute footprint via
  dynamic routing.

  *   **XAI (Grok Imagine):** Noted for releasing an uncensored video generation model
  capable of NSFW content, contrasting sharply with closed-source competitors.

  *   **CoreWeave/OpenPipe:** Featured for the launch of their Serverless RL offering.

  *   **Eric Provincher (RepoPrompt):** Guest expert discussing the new RepoBench
  framework for evaluating code editing capabilities.


  ### 5. Future Implications

  The industry is rapidly moving toward a **post-reality digital landscape**, where
  synthetic video generation (Sora, Grok) makes media verification increasingly difficult.
  Architecturally, the future seems to involve a divergence: massive, efficient trillion-parameter
  models (Ling-1T) competing with extremely small, architecturally novel models (TRM)
  that achieve high reasoning scores. The focus is shifting from raw parameter count
  to **reasoning methodology** and **agentic capabilities**.


  ### 6. Target Audience

  This episode is highly valuable for **AI/ML Engineers, Research Scientists, AI Product
  Managers, and Technology Investors** who need to stay current on cutting-edge model
  releases, architectural breakthroughs, and the strategic direction of major AI platforms
  (like OpenAI).'
tags:
- artificial-intelligence
- generative-ai
- ai-infrastructure
- startup
- investment
- openai
- microsoft
- google
title: 📆 Oct 9, 2025 — Dev Day’s Agent Era, Samsung’s 7M TRM Shock, Ling‑1T at 1T,
  Grok Video goes NSFW, and Serverless RL arrives
topics:
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 155
  prominence: 1.0
  topic: artificial intelligence
- keywords:
  - generative ai
  - genai
  - chatgpt
  - gpt
  - claude
  - text generation
  - image generation
  mentions: 83
  prominence: 1.0
  topic: generative ai
- keywords:
  - gpu
  - tensor
  - training
  - inference
  - model deployment
  - vector database
  mentions: 14
  prominence: 1.0
  topic: ai infrastructure
- keywords:
  - startup
  - entrepreneur
  - founder
  - venture
  mentions: 9
  prominence: 0.9
  topic: startup
- keywords:
  - investment
  - funding
  - valuation
  - ipo
  - acquisition
  mentions: 9
  prominence: 0.9
  topic: investment
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-10-10 08:11:35 UTC -->
