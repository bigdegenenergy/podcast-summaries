---
companies:
- category: unknown
  confidence: medium
  context: This is the Everyday AI Show, the everyday podcast where we simplify AI
    and br
  name: Everyday AI Show
  position: 12
- category: unknown
  confidence: medium
  context: otebookLM, none other than the winner of our 2024 AI Tool of the Year.
    So this model, or this feature I gue
  name: AI Tool
  position: 394
- category: tech
  confidence: high
  context: Year. So this model, or this feature I guess from Google, is extremely
    powerful, and I think it's worth re
  name: Google
  position: 459
- category: unknown
  confidence: medium
  context: go over those updates and a little more today on Everyday AI. What's going
    on, y'all? My name is Jordan Wilson
  name: Everyday AI
  position: 783
- category: unknown
  confidence: medium
  context: n Everyday AI. What's going on, y'all? My name is Jordan Wilson, and welcome
    to Everyday AI. This is your daily l
  name: Jordan Wilson
  position: 831
- category: tech
  confidence: high
  context: your first time, we do this literally every day, Monday through Friday,
    at least live 7:30 AM Central Sta
  name: Monday
  position: 1248
- category: unknown
  confidence: medium
  context: ry day, Monday through Friday, at least live 7:30 AM Central Standard Time.
    So shout out to our live stream audience, and on
  name: AM Central Standard Time
  position: 1290
- category: unknown
  confidence: medium
  context: day's show, I'm going to be doing something live. So I needed to use NotebookLM
    anyways for a project th
  name: So I
  position: 1678
- category: unknown
  confidence: medium
  context: like, hey, what's your show going to be tomorrow? And I'm like, I have
    no clue. It's always fun, yet some
  name: And I
  position: 2963
- category: unknown
  confidence: medium
  context: clue. It's always fun, yet sometimes frightening. But I hand kind of a
    hand of the reins over to our news
  name: But I
  position: 3037
- category: tech
  confidence: high
  context: ld be signing up and reading it. But I said, hey, OpenAI and ChatGPT released
    their new shopping feature.
  name: Openai
  position: 3382
- category: tech
  confidence: high
  context: hing crazy here. So I'm jumping around. I'm using Perplexity's deep research.
    I'm using Google Gemini's deep r
  name: Perplexity
  position: 5539
- category: unknown
  confidence: medium
  context: . I'm using Perplexity's deep research. I'm using Google Gemini's deep
    research. I'm using, let me do that. I thi
  name: Google Gemini
  position: 5577
- category: unknown
  confidence: medium
  context: e a month-by-month breakdown of IBM's WatsonX and WatsonX AI updates from
    month to month starting in January 2
  name: WatsonX AI
  position: 6372
- category: unknown
  confidence: medium
  context: also third party. So I'm just going to say both. Normally I'd go through
    and go through a process, but I'm do
  name: Normally I
  position: 6718
- category: unknown
  confidence: medium
  context: st going to go quickly. It says, should I include WatsonX Governance and
    WatsonX Data updates or only WatsonX AI? So I
  name: WatsonX Governance
  position: 6852
- category: unknown
  confidence: medium
  context: It says, should I include WatsonX Governance and WatsonX Data updates or
    only WatsonX AI? So I'm just going to
  name: WatsonX Data
  position: 6875
- category: unknown
  confidence: medium
  context: broadening who can actually use this tool, right? Because I think a lot
    of people were initially drawn to Not
  name: Because I
  position: 7999
- category: unknown
  confidence: medium
  context: the world are like, hey, what about my language? So NotebookLM and the
    Google team have been rolling out a lot o
  name: So NotebookLM
  position: 8628
- category: unknown
  confidence: medium
  context: nversation along on Twitter and on Google's blog. So Google says, yeah,
    there's bugs. We're getting this work
  name: So Google
  position: 9388
- category: unknown
  confidence: medium
  context: ted this yet. So we're going to be doing it live. Sometimes I like doing
    these things live, and you get to figu
  name: Sometimes I
  position: 10174
- category: unknown
  confidence: medium
  context: as Google's cheap and fast model. And yes, it is. But Gemini 2.5 Flash,
    if you look at different benchmarks, i
  name: But Gemini
  position: 12573
- category: unknown
  confidence: medium
  context: arks, in some benchmarks, it is a top five model. The Flash, the quote
    unquote Flash, the one that's supposed
  name: The Flash
  position: 12676
- category: unknown
  confidence: medium
  context: side NotebookLM or inside Google Gemini or inside AI Studio, you're not
    paying for the actual usage, right? B
  name: AI Studio
  position: 13154
- category: unknown
  confidence: medium
  context: r, and you know, Google is, it's like a shipyard. Like I'm looking at all
    these ships and I'm like, that's
  name: Like I
  position: 14022
- category: unknown
  confidence: medium
  context: n and I'm going to go into NotebookLM. So I am on NotebookLM Plus. So NotebookLM
    is free to use. If you want a litt
  name: NotebookLM Plus
  position: 15041
- category: unknown
  confidence: medium
  context: rce. It's good practice. So I'm just going to say Perplexity Deep Research,
    saving that. I'm going to jump over. I'm going t
  name: Perplexity Deep Research
  position: 19252
- category: tech
  confidence: high
  context: . I'm going to jump over. I'm going to use here's Groq. I'm going to scroll
    to I think it's at the botto
  name: Groq
  position: 19339
- category: unknown
  confidence: medium
  context: side NotebookLM. You can connect directly to your Google Drive, obviously
    Google Slides, different links to webs
  name: Google Drive
  position: 19604
- category: unknown
  confidence: medium
  context: connect directly to your Google Drive, obviously Google Slides, different
    links to websites, YouTube videos, or
  name: Google Slides
  position: 19628
- category: unknown
  confidence: medium
  context: Tube videos, or just copied text. And I am on the Plus NotebookLM Plus,
    which is part of the Google Gemini One plan. You
  name: Plus NotebookLM Plus
  position: 19725
- category: unknown
  confidence: medium
  context: on the Plus NotebookLM Plus, which is part of the Google Gemini One plan.
    You get access to this. So it's not a separ
  name: Google Gemini One
  position: 19768
- category: unknown
  confidence: medium
  context: . So as an example, if you already have access to Gemini Advanced in your
    organization, then you have access to Not
  name: Gemini Advanced
  position: 19936
- category: unknown
  confidence: medium
  context: ng to go up and label that. I'm going to label it Groq Deep Research. There
    we go. I'm going to go into now Google Gem
  name: Groq Deep Research
  position: 20192
- category: unknown
  confidence: medium
  context: ly on, OpenAI was winning the deep research game. Now I'm not so sure.
    All right. So we're going to go in
  name: Now I
  position: 20409
- category: unknown
  confidence: medium
  context: to label that here in a second once it's done as Gemini Deep Research.
    Okay, I'm going to save that. And then we're goi
  name: Gemini Deep Research
  position: 20577
- category: unknown
  confidence: medium
  context: e go, Español. All right. I'm going to go Español Latin America, and click
    save there. All right. So FYI, I haven
  name: Latin America
  position: 22190
- category: unknown
  confidence: medium
  context: l Latin America, and click save there. All right. So FYI, I haven't done
    this yet. I hope it works. If not
  name: So FYI
  position: 22238
- category: unknown
  confidence: medium
  context: n there, long email threads, all your files, your Google Docs, whatever.
    But another thing is just when you're
  name: Google Docs
  position: 26298
- category: unknown
  confidence: medium
  context: okLM. So now it kind of gave it a title. It said, IBM WatsonX AI updates,
    January 24 to May 25. And then it broke
  name: IBM WatsonX AI
  position: 26566
- category: unknown
  confidence: medium
  context: on components updates. So I personally follow the X AI, actually have probably
    followed both of these, b
  name: X AI
  position: 26815
- category: unknown
  confidence: medium
  context: n that can't sleep, like I feel it's usually like Liam Neeson or Mel Gibson,
    right? And they have all these pic
  name: Liam Neeson
  position: 28387
- category: unknown
  confidence: medium
  context: eep, like I feel it's usually like Liam Neeson or Mel Gibson, right? And
    they have all these pictures on the w
  name: Mel Gibson
  position: 28402
- category: tech
  confidence: high
  context: host of this very podcast. Companies like Adobe, Microsoft, and Nvidia
    have partnered with us because they t
  name: Microsoft
  position: 30062
- category: tech
  confidence: high
  context: ery podcast. Companies like Adobe, Microsoft, and Nvidia have partnered
    with us because they trust our exp
  name: Nvidia
  position: 30077
- category: unknown
  confidence: medium
  context: to ROI on GenAI. Great, right? Again, not fluent. My Spanish is extremely
    bad. But the, it sounds pretty on pa
  name: My Spanish
  position: 30841
- category: unknown
  confidence: medium
  context: st choose. So let's just say I'm going to type in IBM WatsonX. Let's see.
    And then I'm going to type in AI. I'm
  name: IBM WatsonX
  position: 33134
- category: unknown
  confidence: medium
  context: s here. Right. So this second one says, you know, IBM WatsonX Wikipedia.
    The first one just, it doesn't say anything. So
  name: IBM WatsonX Wikipedia
  position: 33630
- category: tech
  confidence: high
  context: ve would be a title and maybe the first part of a meta description. I would
    assume this is from IBM's we
  name: Meta
  position: 33784
- category: ai_application
  confidence: high
  context: A powerful AI tool from Google, winner of the 2024 AI Tool of the Year,
    updated to run on Gemini 2.5 Flash and support 50+ languages for audio overviews.
    It is a grounded model.
  name: NotebookLM
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: The creator of NotebookLM and the Gemini model family. Mentioned extensively
    regarding updates and product shipping velocity.
  name: Google
  source: llm_enhanced
- category: ai_model
  confidence: high
  context: The model family developed by Google that now powers NotebookLM (specifically
    Gemini 2.5 Flash).
  name: Gemini
  source: llm_enhanced
- category: ai_company
  confidence: high
  context: Mentioned for releasing a new shopping feature for ChatGPT.
  name: OpenAI
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as a platform that released a new shopping feature, and whose
    deep research feature was compared to Perplexity and Gemini's.
  name: ChatGPT
  source: llm_enhanced
- category: ai_company
  confidence: high
  context: Mentioned for releasing new, powerful enterprise integrations, specifically
    with Zapier.
  name: Claude
  source: llm_enhanced
- category: ai_tool/integration
  confidence: medium
  context: Mentioned as a platform integrating with Claude for enterprise features.
  name: Zapier
  source: llm_enhanced
- category: technology_company
  confidence: high
  context: The host is attending an IBM conference and researching IBM's WatsonX updates.
    IBM is mentioned as a partner for the conference.
  name: IBM
  source: llm_enhanced
- category: ai_platform
  confidence: high
  context: IBM's suite of AI and data products, specifically WatsonX AI, Governance,
    and Data, whose updates are being researched.
  name: WatsonX
  source: llm_enhanced
- category: ai_search_engine
  confidence: high
  context: Mentioned as a tool whose deep research feature was used and compared against
    Google Gemini's deep research.
  name: Perplexity
  source: llm_enhanced
- category: ai_platform
  confidence: medium
  context: Mentioned as a platform where developers can use Gemini 2.5 Flash (though
    usage is free to the end-user in this context).
  name: AI Studio
  source: llm_enhanced
- category: big_tech
  confidence: low
  context: Implied as one of the 'big players' in the LLM space whose language support
    is being compared to Google's.
  name: Microsoft AI
  source: llm_enhanced
- category: big_tech
  confidence: low
  context: Implied as one of the 'big players' in the LLM space whose language support
    is being compared to Google's.
  name: Meta AI
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: The specific Google model powering NotebookLM Plus.
  name: Gemini 2.5 Flash
  source: llm_enhanced
- category: ai_infrastructure
  confidence: medium
  context: Mentioned as a place where users can see the 'thinking' process of Google
    models, unlike in NotebookLM.
  name: Google AI Studio
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Mentioned as the platform where the speaker demonstrates the standard,
    non-grounded behavior of the LLM, using 2.5 Flash.
  name: Google Gemini
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: The source of a second set of 'deep research' data pasted into NotebookLM,
    referencing their high-speed inference hardware/platform.
  name: Groq
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: The subscription tier that grants access to NotebookLM Plus.
  name: Gemini Advanced
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Mentioned as the model powering Google's deep research, contrasted with
    the Flash version used in NotebookLM.
  name: Google Gemini (Deep Research 2.5 Pro)
  source: llm_enhanced
- category: ai_user/partner
  confidence: high
  context: Mentioned as a company that partners with the podcast host's organization
    for GenAI education.
  name: Adobe
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Mentioned as a company that partners with the podcast host's organization
    for GenAI education.
  name: Microsoft
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: Mentioned as a company that partners with the podcast host's organization
    for GenAI education.
  name: Nvidia
  source: llm_enhanced
- category: ai_service
  confidence: high
  context: The website associated with the podcast host, offering AI strategy and
    training services.
  name: your everydayai.com
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Part of IBM's platform, receiving specific roadmap updates analyzed in
    the session.
  name: WatsonX AI
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: The previous model version, used as a benchmark against which the capabilities
    of Gemini 2.5 Flash are being compared.
  name: Gemini 2.0
  source: llm_enhanced
date: 2025-05-06 13:00:00 +0000
duration: 51
has_transcript: false
insights:
- actionable: true
  confidence: medium
  extracted: be
  text: we should be.
  type: recommendation
- actionable: true
  confidence: medium
  extracted: now be the default language
  text: We should now be the default language.
  type: recommendation
- actionable: false
  confidence: medium
  extracted: large language models, it's multimodal. A lot of the big players aren't
    supporting 50 languages right now. So Google
  text: the future of large language models, it's multimodal. A lot of the big players
    aren't supporting 50 languages right now. So Google is also signaling that multimodal
    AI isn't just nice to have, it's kind of essential.
  type: prediction
layout: episode
llm_enhanced: true
original_url: https://pscrb.fm/rss/p/www.buzzsprout.com/2175779/episodes/17106544-ep-519-notebooklm-updates-thinking-model-and-50-languages-what-you-need-to-know.mp3
processing_date: 2025-10-05 19:55:02 +0000
quotes:
- length: 279
  relevance_score: 5
  text: These newer models that think or reason, plan ahead, it's almost like they
    use this chain of thought reasoning that normally a quote unquote experienced
    prompt engineer could still squeeze this kind of juice out of a large language
    model, but you have to be extremely experienced
  topics: []
- length: 118
  relevance_score: 5
  text: You have to know what you're doing and really put in the time to get the best
    or the most out of large language models
  topics: []
- length: 201
  relevance_score: 5
  text: So whether you're looking for ChatGPT training for thousands, or just need
    help building your front-end AI strategy, you can partner with us too, just like
    some of the biggest companies in the world do
  topics: []
- length: 270
  relevance_score: 4
  text: So NotebookLM and the Google team have been rolling out a lot of great quality
    of life updates, but they said that this was one of the biggest ones, as well
    as iOS and Android apps, which I believe both of those are rolling out, not yet,
    but there is a sign-up for those
  topics: []
- length: 71
  relevance_score: 4
  text: When we talk about the future of large language models, it's multimodal
  topics: []
- length: 291
  relevance_score: 4
  text: So if you do want to see like, oh, what's the difference, you might want to
    go into Google Gemini, but you'll see here when I'm using Google Gemini, the same
    model, it's giving me a response and saying, here's what Chicago's known for because
    it's still using its own internal knowledge base
  topics: []
- length: 135
  relevance_score: 4
  text: So NotebookLM works a little bit different than some of the other large language
    models or AI chatbots that you're used to working with
  topics: []
- length: 133
  relevance_score: 4
  text: And now it pops out foundation models in lifecycle, featuring in capability
    updates, auto AI and RAG updates, and pricing adjustments
  topics: []
- length: 135
  relevance_score: 4
  text: Maybe your company has been tinkering with large language models for a year
    or more, but can't really get traction to find ROI on GenAI
  topics: []
- length: 157
  relevance_score: 4
  text: Companies like Adobe, Microsoft, and Nvidia have partnered with us because
    they trust our expertise in educating the masses around generative AI to get ahead
  topics: []
- length: 220
  relevance_score: 4
  text: So it's saying, okay, rapid and diverse foundation model evolution and expansion,
    strong emphasis on enterprise governance, trust, and responsible AI, commitment
    to hybrid cloud, multi-cloud, and global availability, etc
  topics: []
- length: 130
  relevance_score: 3
  text: So shout out to our live stream audience, and one thing I like to say is it's
    kind of the realest thing in artificial intelligence
  topics: []
- length: 94
  relevance_score: 3
  text: So Google is also signaling that multimodal AI isn't just nice to have, it's
    kind of essential
  topics: []
- length: 43
  relevance_score: 3
  text: So, but here's what's pretty amazing, right
  topics: []
- length: 133
  relevance_score: 3
  text: And it says, based on the sources provided, WatsonX is IBM's overarching enterprise-focused
    artificial intelligence and data platform
  topics: []
- impact_reason: 'Crucial technical update: NotebookLM is upgraded to a reasoning
    model (Gemini 2.5 Flash), signaling a shift toward more capable, planning-oriented
    LLMs in consumer-facing tools.'
  relevance_score: 10
  source: llm_enhanced
  text: Number one is we have the new Gemini 2.5 Flash model, which is a thinking
    and a reasoning model, now powering NotebookLM.
  topic: technical
- impact_reason: Strategic analysis suggesting that broad language support in multimodal
    AI is becoming an essential competitive differentiator, not just a bonus feature.
  relevance_score: 10
  source: llm_enhanced
  text: I think this move right now puts Google ahead of many of their rivals who
    haven't offered such wide language support, not even just with the audio summaries,
    but just in general, right? When we talk about the future of large language models,
    it's multimodal. A lot of the big players aren't supporting 50 languages right
    now. So Google is also signaling that multimodal AI isn't just nice to have, it's
    kind of essential.
  topic: strategy/predictions
- impact_reason: 'Directly links the model architecture change (2.5 models) to expected
    user benefits: improved performance on complex, multi-step reasoning tasks.'
  relevance_score: 10
  source: llm_enhanced
  text: The 2.5 models are thinking models. So you should start to see more comprehensive
    answers, particularly to complex, multi-step reasoning questions.
  topic: technical
- impact_reason: Articulates the fundamental paradigm shift occurring in LLMs from
    standard transformers to models capable of explicit planning and reasoning.
  relevance_score: 10
  source: llm_enhanced
  text: The difference between kind of quote unquote old school transformer models
    and quote unquote new school reasoning or thinking models. The gap is wide.
  topic: technical
- impact_reason: Corrects a common misconception about the 'Flash' model series, asserting
    that Gemini 2.5 Flash is a top-tier performer despite its perceived positioning
    as a budget option.
  relevance_score: 10
  source: llm_enhanced
  text: Don't let that Flash moniker fool you, right? Because when the Flash series
    first came out, people really thought of this as Google's cheap and fast model.
    And yes, it is. But Gemini 2.5 Flash, if you look at different benchmarks, in
    some benchmarks, it is a top five model.
  topic: technical
- impact_reason: Crucial insight correcting the perception of 'Flash' models. It asserts
    that Gemini 2.5 Flash, despite being fast/cheap, achieves top-tier performance
    on certain benchmarks, challenging the assumption that speed equals low capability.
  relevance_score: 10
  source: llm_enhanced
  text: And don't let that Flash moniker fool you, right? Because when the Flash series
    first came out, people really thought of this as Google's cheap and fast model.
    And yes, it is. But Gemini 2.5 Flash, if you look at different benchmarks, in
    some benchmarks, it is a top five model.
  topic: technical/trends
- impact_reason: Excellent, concise definition of a 'grounded model' in the context
    of NotebookLM, which is critical for enterprise use cases requiring data isolation.
  relevance_score: 10
  source: llm_enhanced
  text: It's a grounded model. So what that means is it uses the Gemini 2.5 Flash
    model, but it is only going to work on the information that you enter.
  topic: technical/concept
- impact_reason: 'Summarizes the core power of the new architecture: combining advanced
    reasoning (thinking model) with strict data confinement (grounding).'
  relevance_score: 10
  source: llm_enhanced
  text: I can probably then see and understand why it might be extremely impressive
    to use a model that can think, a model that can reason only with your data. That
    is huge, y'all.
  topic: breakthroughs/strategy
- impact_reason: 'Directly addresses a major pain point for businesses adopting GenAI:
    the struggle to move from experimentation to measurable Return on Investment (ROI).'
  relevance_score: 10
  source: llm_enhanced
  text: Sounds? Are you still running in circles trying to figure out how to actually
    grow your business with AI? Maybe your company has been tinkering with large language
    models for a year or more, but can't really get traction to find ROI on GenAI.
  topic: business
- impact_reason: Explicitly names the new model version (Gemini 2.5 Flash) and characterizes
    it as a 'thinking model,' suggesting advanced reasoning capabilities.
  relevance_score: 10
  source: llm_enhanced
  text: testing out the new model, which is Gemini 2.5 Flash. It's a thinking model.
  topic: technical
- impact_reason: Directly compares the capability leap from the previous model (Gemini
    2.0) to the new 'thinking model' (2.5 Flash) in handling complex, analytical tasks.
  relevance_score: 10
  source: llm_enhanced
  text: This would not have worked on Gemini 2.0, something like this, where you're
    calling on the model to do something that a traditional large language model could
    not do very well. So I guess maybe on Gemini 2.0 this may have worked. I didn't
    try this exact thing, but it's going to work much better on a thinking model.
  topic: predictions
- impact_reason: Directly contrasts the capabilities of newer models (implied Gemini
    2.5 or similar) against older generations (Gemini 2.0) in performing complex reasoning
    tasks, signaling a significant leap in LLM functionality.
  relevance_score: 10
  source: llm_enhanced
  text: So this is interesting. So I'm giving this would not have worked on Gemini
    2.0, something like this, where you're calling on the model to do something that
    a traditional large language model could not do very well.
  topic: technical
- impact_reason: This prompt pushes the model into deeper inferential reasoning—detecting
    subtle strategic shifts ('change in course,' 'between the lines') while maintaining
    factual grounding. This is a high bar for current LLMs.
  relevance_score: 10
  source: llm_enhanced
  text: Please identify any change in course, whether overt or under the radar, that
    the IBM platform went through over the course of this period. And I'm going to
    say, I'm going to say something like, please try and unearth information between
    the lines, you know, but be factual.
  topic: technical
- impact_reason: Explicitly names the model being tested (Gemini 2.5 Flash) and frames
    the experiment around testing its advanced reasoning and inferential capabilities,
    moving beyond simple retrieval.
  relevance_score: 10
  source: llm_enhanced
  text: So I'm kind of having and testing here if a Gemini 2.5 Flash is able to really
    use this ability to now reason and to think about the information, right? So I'm
    not just asking for factual recall.
  topic: technical
- impact_reason: Highlights the significance and recognition of NotebookLM, positioning
    it as a leading, accessible, and free AI tool.
  relevance_score: 9
  source: llm_enhanced
  text: One of the most powerful AI tools available to literally everyone and for
    free has been updated in a couple of really big ways. I'm talking about NotebookLM,
    none other than the winner of our 2024 AI Tool of the Year.
  topic: business/strategy
- impact_reason: Offers a practical, real-world workflow for leveraging AI tools (NotebookLM,
    Perplexity, Gemini Deep Research) for complex preparation tasks like conference
    keynotes.
  relevance_score: 9
  source: llm_enhanced
  text: I'm going to be doing some deep research in the background... I use NotebookLM
    all the time. And where I normally start is by doing multiple deep researches
    first.
  topic: technical/strategy
- impact_reason: Highlights a significant feature expansion for global accessibility
    in AI tools, moving beyond English-only capabilities.
  relevance_score: 9
  source: llm_enhanced
  text: And then we also have 50 plus new languages that the audio overviews can work
    in.
  topic: technical/business
- impact_reason: Provides a clear, compelling definition of a novel AI feature (Audio
    Overviews) that turns static documents into dynamic, conversational content.
  relevance_score: 9
  source: llm_enhanced
  text: The audio overviews, which are these kind of AI deep dive podcasts where two
    AI hosts have conversations about just the documents you upload.
  topic: technical
- impact_reason: Provides insight into the mechanism of reasoning models (Chain of
    Thought) and suggests a practical way for users to learn from them to improve
    prompting skills.
  relevance_score: 9
  source: llm_enhanced
  text: These thinking models are much different, right? They plan ahead. They think,
    they reason. It's fascinating reading, whether the raw chain of thought or the
    summarized chain of thought, to see how these models are thinking.
  topic: technical
- impact_reason: Offers a vivid, slightly cautionary description of emergent reasoning
    capabilities, showing models self-correcting complex plans, which touches on advanced
    AI behavior.
  relevance_score: 9
  source: llm_enhanced
  text: Sometimes scary because you'll see a model on its own start to go down path
    A and then realize path A might have a dead end. Oh, I actually need to fork and
    I need to create a path B, path C, and it might step back a couple of steps.
  topic: safety/technical
- impact_reason: Clearly contrasts the capabilities of the previous model (2.0 Flash,
    non-reasoning) versus the new model (2.5 Flash, reasoning), explaining the direct
    benefit to the end-user experience (nuance).
  relevance_score: 9
  source: llm_enhanced
  text: Previously before this, NotebookLM was running on Gemini 2.0 Flash, which
    was not a thinking model. So now we get answers that show much more nuance...
  topic: technical
- impact_reason: Highlights the value of understanding Chain-of-Thought (CoT) for
    prompt engineering and signals a significant upgrade in NotebookLM by integrating
    a 'thinking model' (Gemini 2.5 Flash).
  relevance_score: 9
  source: llm_enhanced
  text: So you can learn a lot if you're a dork like me and read chain of thought
    or summarized chain of thought. It helps you write better prompts. It helps you
    use these models better, but it's pretty big that NotebookLM is now powered by
    a thinking model in Gemini 2.5 Flash.
  topic: technical/strategy
- impact_reason: Strong business and technical validation for Gemini 2.5 Flash, emphasizing
    its superior price-to-performance ratio for developers using the API.
  relevance_score: 9
  source: llm_enhanced
  text: The Flash, the quote unquote Flash, the one that's supposed to be, oh, this
    is the small and cheap model, if you're using it on the back end on the API, it
    is extremely powerful. I would say it is one of the more impressive models in
    the world, just because number one, how fast it is. If you are using it on the
    back end as a developer, it's extremely affordable in terms of the price per performance.
  topic: business/technical
- impact_reason: 'Articulates the primary value proposition and use case for grounded
    models: absolute control over the knowledge base, mitigating hallucination risks
    in specific contexts.'
  relevance_score: 9
  source: llm_enhanced
  text: So there are very many instances where you only want a model to use the information
    that you've given it and absolutely nothing else, which is why I am personally
    extremely excited for this.
  topic: safety/business
- impact_reason: Provides a clear, comparative demonstration contrasting a general-purpose
    LLM (which accesses the web/internal knowledge) with a grounded model (NotebookLM),
    clarifying the concept of isolation.
  relevance_score: 9
  source: llm_enhanced
  text: So, as an example, if I go into Gemini and I use 2.5 Flash... it's obviously
    going to give me an answer on what Chicago is known for... because it's still
    using its own internal knowledge base. It's still accessing the internet when
    it needs to. So that's the big difference with using NotebookLM. It is grounded
    only in the information that you put in.
  topic: technical/concept
- impact_reason: 'Clarifies the model hierarchy: NotebookLM uses the efficient 2.5
    Flash, while the more powerful deep research tool uses the larger 2.5 Pro, explaining
    performance differences across products.'
  relevance_score: 9
  source: llm_enhanced
  text: Google's Google Gemini deep research uses 2.5 Pro, which is also the big brother
    of 2.5 Flash, which is what NotebookLM now uses.
  topic: technical/trends
- impact_reason: Positions NotebookLM as a superior tool for learning new topics,
    emphasizing its value proposition beyond simple Q&A.
  relevance_score: 9
  source: llm_enhanced
  text: But another thing is just when you're trying to learn a new topic. And I think
    both with the audio overviews and with the mind map, I don't know any better tool
    to learn something new than NotebookLM.
  topic: strategy
- impact_reason: A powerful metaphor illustrating the AI's ability to transform complex,
    dense information into structured, navigable clarity.
  relevance_score: 9
  source: llm_enhanced
  text: I'm going to zoom out here and you'll see just how impressive this actually
    is. I'm not going to go through and read all of these, but y'all, this is like
    so zoomed out. This looks like, you know, in all of those crime shows when the
    crazy person that can't sleep... Just this is like visual chaos. So it's kind
    of like that instead of chaos, it's clarity, right?
  topic: strategy
- impact_reason: 'Offers a clear, actionable promise: providing a direct path to ROI,
    contrasting with common industry stagnation.'
  relevance_score: 9
  source: llm_enhanced
  text: We'll help you stop running in those AI circles and help get your team ahead
    and build a straight path to ROI on GenAI.
  topic: business
- impact_reason: Emphasizes the value of Chain-of-Thought (CoT) transparency, especially
    when constrained by proprietary data (RAG context), which is crucial for debugging
    and trust.
  relevance_score: 9
  source: llm_enhanced
  text: I would really be interested to see how Gemini 2.5 is thinking, but only thinking
    in the confines of your data, which will be extremely fascinating for dorks like
    me, right?
  topic: technical
- impact_reason: Reinforces the critical feature of source citation/grounding in LLM
    outputs, essential for enterprise adoption and fact-checking.
  relevance_score: 9
  source: llm_enhanced
  text: The good thing about using NotebookLM, as you'll see on my screen for our
    live stream audience, it always sources things as well, right? So I can click
    on these different sources.
  topic: safety
- impact_reason: Demonstrates a feature where the AI output is directly traceable
    and linked back to its source material (Groq deep research), emphasizing the importance
    of source attribution and verifiability in advanced LLM applications.
  relevance_score: 9
  source: llm_enhanced
  text: And I can hover over that and I can click that, and then it's going to take
    me back to that source guide. So that is from the Groq deep research.
  topic: technical
- impact_reason: This is a complex prompt requiring synthesis, trend identification,
    and constraint adherence ('based solely on...'), testing the model's analytical
    capabilities beyond simple retrieval.
  relevance_score: 9
  source: llm_enhanced
  text: So I'm going to say, please identify underlying trends based solely on IBM's
    product roadmap and updates they made to the WatsonX and WatsonX AI platforms.
  topic: technical
- impact_reason: 'Reveals the key strategic trends identified by the AI in IBM''s
    roadmap: FMs, governance/trust, and hybrid cloud strategy. These are critical
    themes in the enterprise AI landscape.'
  relevance_score: 9
  source: llm_enhanced
  text: So it's kind of thinking between the lines here. So it's saying, okay, rapid
    and diverse foundation model evolution and expansion, strong emphasis on enterprise
    governance, trust, and responsible AI, commitment to hybrid cloud, multi-cloud,
    and global availability, etc.
  topic: strategy
- impact_reason: 'Shifts focus to a powerful, practical application: using advanced
    reasoning models to analyze and synthesize daily recorded team meetings, solving
    a major pain point for hybrid/remote workforces.'
  relevance_score: 9
  source: llm_enhanced
  text: And as we wait here, think of how something like this could be extremely useful.
    Think, let's say you have a daily meeting, right? Your team, maybe you're remote,
    you're hybrid, and it's recorded every single day, and you've been...
  topic: business
- impact_reason: 'Provides a strategic insight into the podcast''s value proposition:
    offering unedited, real-time application of AI tools, contrasting with polished
    online content.'
  relevance_score: 8
  source: llm_enhanced
  text: A lot of the things that you maybe see or read, or if you watch certain tutorials
    on YouTube, a lot of it's a little prefabricated, right? It's very polished, very
    edited. So on today's show, I'm going to be doing something live.
  topic: strategy
- impact_reason: Compares the interactive prompting styles of different advanced research
    tools (ChatGPT vs. others) and illustrates a complex, multi-step research query.
  relevance_score: 8
  source: llm_enhanced
  text: ChatGPT is the only one that asks me questions. So essentially what I said
    in this prompt, I said, please give me a month-by-month breakdown of IBM's WatsonX
    and WatsonX AI updates from month to month starting in January 2024 and ending
    in May 2025.
  topic: technical
- impact_reason: Reveals a significant product upgrade that was initially under-communicated
    by the provider, emphasizing the rapid pace of LLM development where major shifts
    can be overlooked.
  relevance_score: 8
  source: llm_enhanced
  text: Their tweet from NotebookLM said, it's been a busy week for us. So busy that
    we forgot to mention that NotebookLM is officially powered by Gemini 2.5 Flash.
  topic: technical
- impact_reason: Actionable business/developer insight regarding the cost-effectiveness
    and high performance of Gemini 2.5 Flash for API usage.
  relevance_score: 8
  source: llm_enhanced
  text: If you are using it on the back end as a developer, it's extremely affordable
    in terms of the price per performance.
  topic: business
- impact_reason: Points out a major limitation in standard LLM prompting—the difficulty
    in reliably constraining the model's knowledge source, reinforcing the need for
    grounded systems like NotebookLM.
  relevance_score: 8
  source: llm_enhanced
  text: You can't necessarily control, at least not easily with a lot of iteration
    and some basic to advanced prompt engineering skills, you can't necessarily control
    where they think, right? You can't say, I mean, you can't say like, oh, you only
    using the files in this project, or the information in this project, right? You
    can try to control its thinking, but very often it will go outside of those bounds
    anyway.
  topic: technical/limitations
- impact_reason: A direct competitive assessment, suggesting that Google's recent
    updates (specifically Gemini 2.5 Pro used in their deep research) are closing
    or have closed the gap with OpenAI's capabilities in complex research tasks.
  relevance_score: 8
  source: llm_enhanced
  text: early on, OpenAI was winning the deep research game. Now I'm not so sure.
  topic: strategy/competition
- impact_reason: Strong endorsement and practical advice on using NotebookLM for knowledge
    management and productivity.
  relevance_score: 8
  source: llm_enhanced
  text: I honestly like, right, NotebookLM has so many use cases. I think so many
    people should be using it, dumping all your meeting transcripts in there, long
    email threads, all your files, your Google Docs, whatever.
  topic: business
- impact_reason: Describes the seamless integration between the visual output (mind
    map) and the conversational interface (chat), enhancing user flow.
  relevance_score: 8
  source: llm_enhanced
  text: So when you click on an actual element, what it does is it also sends it back
    into the chat.
  topic: technical
- impact_reason: Establishes credibility and highlights the market need for expert
    education/strategy in the GenAI space.
  relevance_score: 8
  source: llm_enhanced
  text: Companies like Adobe, Microsoft, and Nvidia have partnered with us because
    they trust our expertise in educating the masses around generative AI to get ahead.
  topic: business
- impact_reason: Provides a concise, sourced definition of a major enterprise AI platform
    (WatsonX).
  relevance_score: 8
  source: llm_enhanced
  text: Based on the sources provided, WatsonX is IBM's overarching enterprise-focused
    artificial intelligence and data platform.
  topic: technical
- impact_reason: 'Explains the dual approach to source ingestion: manual vs. AI-assisted
    discovery, a key feature for RAG systems.'
  relevance_score: 8
  source: llm_enhanced
  text: So on the left-hand tab in the sources, you can manually add sources one by
    one, or you can click this discover source, which is kind of like traditional
    Google search.
  topic: technical
- impact_reason: Highlights a usability gap in source attribution—the need for clear
    URL visibility in discovery results—a common challenge in RAG interfaces.
  relevance_score: 8
  source: llm_enhanced
  text: I wish that this was labeled and I could see the actual URL. Right. In some
    instances, I can kind of make sense of what's here... I would have to actually
    click on it, and then I can see, yes, it is from developer.ibm.com.
  topic: technical
- impact_reason: Presents a complex analytical prompt requiring synthesis and trend
    identification across multiple documents, testing higher-order reasoning.
  relevance_score: 8
  source: llm_enhanced
  text: I'm going to say, please identify underlying trends based solely on IBM's
    product roadmap and updates they made to the WatsonX and WatsonX AI platforms.
  topic: technical
- impact_reason: Highlights a specific, recent product enhancement (Auto AI supporting
    ordered data) in a major enterprise AI platform (WatsonX AI), indicating a focus
    on handling more complex, real-world data types.
  relevance_score: 8
  source: llm_enhanced
  text: So I can click on these different sources. So as an example, let me go to
    something. So it says some WatsonX AI updates for what month is this, January
    2024. It says the auto AI feature was enhanced to support ordered data for all
    experiment types.
  topic: technical
- impact_reason: 'Illustrates a practical, high-value use case for advanced LLMs:
    synthesizing large amounts of complex data (like product roadmaps) into custom
    summaries and facilitating interactive Q&A for deeper understanding.'
  relevance_score: 8
  source: llm_enhanced
  text: So I'm going to be reading this tonight, right, and probably creating a custom
    audio overview based on this. And I'll probably have a conversation with it to
    help me better understand all of these things.
  topic: business
- impact_reason: Confirms the model's ability to execute the complex trend analysis
    prompt quickly, validating the performance improvement in reasoning tasks.
  relevance_score: 8
  source: llm_enhanced
  text: So it actually spitted out pretty quickly, and it said, based on the updates
    and information provided, the sources for the IBM WatsonX and WatsonX AI platforms,
    several underlying trends are evident in IBM's product roadmap.
  topic: technical
- impact_reason: Demonstrates an audience-driven content strategy, which is valuable
    for community building and ensuring relevance in a fast-moving field like AI.
  relevance_score: 7
  source: llm_enhanced
  text: I hand kind of a hand of the reins over to our newsletter audience and said,
    what do y'all want to hear more of?
  topic: business
- impact_reason: A vivid metaphor illustrating the aggressive and continuous pace
    of product development and shipping at Google, relevant for understanding the
    speed of the AI ecosystem.
  relevance_score: 7
  source: llm_enhanced
  text: Google is, it's like a shipyard. Like I'm looking at all these ships and I'm
    like, that's Google. Like they haven't stopped shipping, I don't think, since
    December, even on the weekends.
  topic: strategy/business
- impact_reason: Details the diverse and practical input methods for grounding data
    in NotebookLM, showing its integration capabilities within the Google ecosystem.
  relevance_score: 7
  source: llm_enhanced
  text: You can connect directly to your Google Drive, obviously Google Slides, different
    links to websites, YouTube videos, or just copied text.
  topic: business/practical
- impact_reason: 'Important business/subscription detail for users: NotebookLM Plus
    is bundled with Gemini Advanced (Gemini One plan), lowering the barrier to entry
    for advanced features.'
  relevance_score: 7
  source: llm_enhanced
  text: I am on the Plus NotebookLM Plus, which is part of the Google Gemini One plan.
    You get access to this. So it's not a separate subscription. That's another good
    thing to know.
  topic: business
- impact_reason: Highlights a significant feature expansion (multilingual audio summaries)
    and explains the utility of AI-generated conversational summaries based *only*
    on user documents.
  relevance_score: 7
  source: llm_enhanced
  text: audio overview now having 50 languages... essentially there's a male with
    a female AI-generated podcast host. They banter around a little bit, but they
    essentially have a conversation about just your documents that you upload. It's
    very useful.
  topic: technical/features
- impact_reason: Describes the UI structure of NotebookLM and introduces 'mind maps'
    as a key new visualization tool for synthesizing document content.
  relevance_score: 7
  source: llm_enhanced
  text: one is mind maps, which I really, really like. So essentially when you're
    using NotebookLM, there are three different panes, right? So on the left-hand
    side, you have your sources... Then you have a chat, and then you have a studio
    on the right-hand side...
  topic: technical/features
- impact_reason: Highlights a new, specific feature (Mind Map) in NotebookLM, indicating
    product evolution.
  relevance_score: 7
  source: llm_enhanced
  text: But here's where the mind map is, all right? That's one of these new features.
  topic: technical
- impact_reason: Details the automatic structuring capability of the AI-generated
    mind map, catering to visual learners.
  relevance_score: 7
  source: llm_enhanced
  text: So it automatically started breaking this down into four categories, right?
    And then like any, if you've ever used an interactive mind map, very cool. I love
    them. If you're a visual learner, I honestly like...
  topic: technical
- impact_reason: Identifies a current limitation or bug in multilingual support for
    specific advanced features (live interaction).
  relevance_score: 7
  source: llm_enhanced
  text: It doesn't look like the capabilities to join live is there when you're using
    a different language. So that's actually something. Maybe it's only available
    right now in the English language...
  topic: technical
- impact_reason: Demonstrates the rapid, customized content generation capability
    across different languages.
  relevance_score: 7
  source: llm_enhanced
  text: There we go. Right away was able to create a customized podcast for myself
    in Spanish.
  topic: technical
- impact_reason: Shows the practical challenge of testing new multilingual features
    when the user lacks fluency, while simultaneously confirming the feature's existence
    and customizability.
  relevance_score: 6
  source: llm_enhanced
  text: I'm going to go ahead and also click customize. All right. So on this deep
    dive conversation, the audio overview on the right-hand side, I'm sure many of
    you have heard it... I probably won't be able to understand 90% of it because
    it's going to be in Spanish, and I'm not fluent in Spanish.
  topic: practical/features
- impact_reason: Provides a practical tip on locating the mind map feature, acknowledging
    usability friction points common in complex software interfaces.
  relevance_score: 6
  source: llm_enhanced
  text: But in the middle pane, you can also click overview there, but here's where
    the mind map is, all right? That's one of these new features. A lot of people
    struggle to find it because essentially, like, especially if you're not zoomed
    in or if you're too zoomed in, right?
  topic: practical
- impact_reason: A memorable, lighthearted philosophical correction on common idioms,
    emphasizing a preference for positive framing ('petting' vs. 'skinning').
  relevance_score: 5
  source: llm_enhanced
  text: I'm never going to say there's different ways to skin a cat. I like cats.
    So I'm never going to say there's different ways to skin a cat. There's different
    ways to pet a cat, right?
  topic: strategy/general
source: Unknown Source
summary: '## Podcast Episode Summary: EP 519: NotebookLM Updates - Thinking Model
  and 50+ Languages


  This episode of the Everyday AI Show focuses entirely on the significant recent
  updates to **Google''s NotebookLM**, which the host, Jordan Wilson, calls the "2024
  AI Tool of the Year." The discussion centers on two major enhancements: the integration
  of the **Gemini 2.5 Flash "thinking model"** and the expansion of **multilingual
  support (50+ languages)** for the popular Audio Overviews feature. The host provides
  a live, practical demonstration of using NotebookLM while researching for an upcoming
  keynote.


  ---


  ### 1. Focus Area

  The focus is on **Applied Generative AI Tools**, specifically detailing feature
  updates, technical shifts, and practical applications of Google''s **NotebookLM**.
  Key themes include grounded AI, reasoning capabilities, and global accessibility
  improvements.


  ### 2. Key Technical Insights

  *   **Gemini 2.5 Flash Integration:** NotebookLM is now powered by Gemini 2.5 Flash,
  a "thinking model." This shift means the model can perform more complex, multi-step
  reasoning and planning ahead (akin to advanced Chain-of-Thought prompting), leading
  to more nuanced answers derived *only* from the user-provided sources.

  *   **Grounded AI Enforcement:** NotebookLM remains fundamentally a **grounded model**,
  meaning it strictly adheres to the uploaded source material. This is contrasted
  with general models like Gemini, which access the broader web, highlighting NotebookLM''s
  value for controlled, data-specific analysis.

  *   **Multilingual Audio Overviews:** The AI-generated Audio Overviews (conversations
  between two AI hosts about uploaded documents) now support over 50 languages, a
  major step for global accessibility, signaling Google''s commitment to multimodal
  AI beyond English.


  ### 3. Business/Investment Angle

  *   **Competitive Advantage in Accessibility:** By rolling out 50+ language support
  for a core feature, Google positions NotebookLM ahead of many rivals who lack such
  broad language support in their grounded tools.

  *   **Value of Reasoning in Proprietary Data:** The integration of a reasoning model
  (2.5 Flash) into a grounded environment is highly valuable for enterprises needing
  complex analysis, synthesis, and planning based *only* on internal documents, reducing
  hallucination risk.

  *   **NotebookLM Plus Access:** NotebookLM Plus (offering higher limits, e.g., 300
  sources) is bundled with the Google Gemini One plan, streamlining access for existing
  advanced Google Workspace/AI users.


  ### 4. Notable Companies/People

  *   **Google/NotebookLM Team:** The primary focus, responsible for the updates.

  *   **Jordan Wilson (Host):** Provides practical, real-time demonstration and analysis
  of the updates.

  *   **IBM:** Mentioned as the subject of the host''s live research project (WatsonX
  updates).

  *   **Competitors (OpenAI/Claude):** Briefly mentioned regarding their own recent
  updates (shopping features, enterprise integrations) to provide market context.


  ### 5. Future Implications

  The industry is moving toward models that can **reason and plan** (thinking models)
  being integrated into specialized, **grounded applications**. Furthermore, the expectation
  for AI tools to be **natively multilingual** is rapidly increasing, moving from
  a "nice-to-have" to an essential feature for global adoption. Google''s continuous,
  rapid shipping cadence (even over weekends) suggests an aggressive pace of feature
  deployment.


  ### 6. Target Audience

  This episode is most valuable for **AI Professionals, Product Managers, and Power
  Users** who utilize LLMs for research, knowledge management, and data synthesis.
  It is highly relevant for those already using or considering NotebookLM for proprietary
  data analysis.'
tags:
- artificial-intelligence
- generative-ai
- ai-infrastructure
- google
- openai
- microsoft
- nvidia
- meta
title: 'EP 519: NotebookLM Updates - Thinking model and 50+ languages. What you need
  to know.'
topics:
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 118
  prominence: 1.0
  topic: artificial intelligence
- keywords:
  - generative ai
  - genai
  - chatgpt
  - gpt
  - claude
  - text generation
  - image generation
  mentions: 24
  prominence: 1.0
  topic: generative ai
- keywords:
  - gpu
  - tensor
  - training
  - inference
  - model deployment
  - vector database
  mentions: 1
  prominence: 0.1
  topic: ai infrastructure
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-10-05 19:55:02 UTC -->
