---
actionable_items:
- action: potentially
  category: investigation
  full_context: 'you could potentially '
  priority: medium
companies:
- category: unknown
  confidence: medium
  context: This is episode number 891 with Martin Brunthaler, co-founder and CTO of
    AdVarity. Today's episode
  name: Martin Brunthaler
  position: 32
- category: unknown
  confidence: medium
  context: of AdVarity. Today's episode is brought to you by Traenium II, the latest
    AI chip from AWS, and by the Dell AI
  name: Traenium II
  position: 120
- category: unknown
  confidence: medium
  context: enium II, the latest AI chip from AWS, and by the Dell AI Factory with
    Nvidia. Welcome to the Super Data Science Po
  name: Dell AI Factory
  position: 173
- category: tech
  confidence: high
  context: AI chip from AWS, and by the Dell AI Factory with Nvidia. Welcome to the
    Super Data Science Podcast, the m
  name: Nvidia
  position: 194
- category: unknown
  confidence: medium
  context: y the Dell AI Factory with Nvidia. Welcome to the Super Data Science Podcast,
    the most listened-to podcast in the data science
  name: Super Data Science Podcast
  position: 217
- category: unknown
  confidence: medium
  context: sforming our world for the better. I'm your host, John Cron. Thanks for
    joining me today. And now, let's make
  name: John Cron
  position: 502
- category: unknown
  confidence: medium
  context: ince raised over $160 million in venture capital. Before AdVarity, Martin
    was co-founder and CTO at two other Europ
  name: Before AdVarity
  position: 939
- category: unknown
  confidence: medium
  context: mobile. He holds an engineering diploma from the Salzburg University of
    Applied Sciences in Austria. Today's episode s
  name: Salzburg University
  position: 1222
- category: unknown
  confidence: medium
  context: gineering diploma from the Salzburg University of Applied Sciences in Austria.
    Today's episode should be of interest
  name: Applied Sciences
  position: 1245
- category: unknown
  confidence: medium
  context: meet you. I'm based in Vienna in Austria and the European Alps. I think
    if I remember correctly, Vienna has for
  name: European Alps
  position: 2345
- category: unknown
  confidence: medium
  context: for the most grumpy population or the city, which Vienna I think has also
    won several times in the world. Oh
  name: Vienna I
  position: 2896
- category: unknown
  confidence: medium
  context: or example, created the software that powered the American Idol SMS voting.
    Also here in Austria, we powered a couple
  name: American Idol SMS
  position: 5042
- category: unknown
  confidence: medium
  context: like it's so embarrassing for so many people from North America. So many
    of us are in this model culture. Then I
  name: North America
  position: 8431
- category: unknown
  confidence: medium
  context: America. So many of us are in this model culture. Then I even studied German
    for 12 years on Saturdays, an
  name: Then I
  position: 8487
- category: unknown
  confidence: medium
  context: ', if you will. Like, there''s like this concept of High German, if you
    will, or like proper German, *Hochdeutsch'
  name: High German
  position: 9486
- category: unknown
  confidence: medium
  context: sch*. Exactly. Yeah. So, I don't tend to do that. And I don't tend to do
    that with our kids as well, so w
  name: And I
  position: 9594
- category: unknown
  confidence: medium
  context: the type of German spoken in Austria and Germany. Habsburg Empire, Ottoman
    Empire. I don't know if I have a big stu
  name: Habsburg Empire
  position: 9979
- category: unknown
  confidence: medium
  context: n spoken in Austria and Germany. Habsburg Empire, Ottoman Empire. I don't
    know if I have a big stuff off. I have n
  name: Ottoman Empire
  position: 9996
- category: unknown
  confidence: medium
  context: ly to adopt the solution as well. This episode of Super Data Science is
    brought to you by AWS Trainium2, the latest ge
  name: Super Data Science
  position: 13890
- category: tech
  confidence: high
  context: y companies across the spectrum, from giants like Anthropic and Databricks
    to cutting-edge startups like Pool
  name: Anthropic
  position: 14337
- category: tech
  confidence: high
  context: ross the spectrum, from giants like Anthropic and Databricks to cutting-edge
    startups like Poolside, are choos
  name: Databricks
  position: 14351
- category: unknown
  confidence: medium
  context: Varity's. So, AdVarity is currently launching its Data Conversations product,
    which lets users query data in natural l
  name: Data Conversations
  position: 14851
- category: unknown
  confidence: medium
  context: nboard a generic source from a database or from a REST API, you want all
    the data types to be aligned, you k
  name: REST API
  position: 19199
- category: unknown
  confidence: medium
  context: r combining various sources and all those things. But I think it's very
    critical to get the quality right
  name: But I
  position: 19527
- category: tech
  confidence: high
  context: ed within two weeks and put onto, I don't know, a Snowflake table or whatever.
    Today it's a Snowflake table,
  name: Snowflake
  position: 24538
- category: tech
  confidence: high
  context: ample, you want to run marketing reporting across Google, Facebook, you
    name it. So, basically, you extrac
  name: Google
  position: 25843
- category: tech
  confidence: high
  context: ou want to run marketing reporting across Google, Facebook, you name it.
    So, basically, you extract data fro
  name: Facebook
  position: 25851
- category: unknown
  confidence: medium
  context: big table scheme. So, you end up with a database, Google BigQuery, Snowflake,
    you name it. So, we support quite a w
  name: Google BigQuery
  position: 26189
- category: unknown
  confidence: medium
  context: w, the things that the industry standard would be Power BI for many organizations,
    this still looks, or look
  name: Power BI
  position: 26692
- category: unknown
  confidence: medium
  context: tcomes faster. Extend your enterprise with AI and Gen AI at scale, powered
    by the broad Dell portfolio of
  name: Gen AI
  position: 31051
- category: unknown
  confidence: medium
  context: ack that includes GPUs and networking, as well as Nvidia AI Enterprise
    software, Nvidia inference microservices, models,
  name: Nvidia AI Enterprise
  position: 31254
- category: unknown
  confidence: medium
  context: either continuing to use it, say, for example, in Google Sheets, or materializing
    this in a Snowflake table, or q
  name: Google Sheets
  position: 35140
- category: tech
  confidence: high
  context: ol of choice, which, you know, could be Gemini or OpenAI or whatever agent
    that the company will go with,
  name: Openai
  position: 42701
- category: unknown
  confidence: medium
  context: ple want kind of about seven minutes of detail on Model Context Protocol,
    MCP. But this is an open-source framework from A
  name: Model Context Protocol
  position: 43127
- category: unknown
  confidence: medium
  context: to intuitively know exactly what I'm looking for. When I'm doing research
    for a podcast episode, for examp
  name: When I
  position: 44758
- category: unknown
  confidence: medium
  context: roblems? Sign up for Claude today and get 50% off Claude Pro when you use
    my link, Claude.ai/superdata. That's
  name: Claude Pro
  position: 45277
- category: ai_infrastructure
  confidence: high
  context: Sponsor of the podcast, mentioned for its Trainium II AI chip and infrastructure.
  name: AWS
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: Mentioned in the context of the 'Dell AI Factory with Nvidia,' indicating
    their role in AI hardware/infrastructure.
  name: Nvidia
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: The guest's company, an Austrian data analytics platform that is integrating
    conversational and agentic AI into its offering.
  name: AdVarity
  source: llm_enhanced
- category: ai_infrastructure
  confidence: medium
  context: Mentioned in the context of the 'Dell AI Factory with Nvidia,' implying
    involvement in AI hardware solutions.
  name: Dell
  source: llm_enhanced
- category: ai_company
  confidence: high
  context: Mentioned as a company choosing AWS Trainium2 to power its next generation
    of AI workloads.
  name: Anthropic
  source: llm_enhanced
- category: ai_company
  confidence: high
  context: Mentioned as a company choosing AWS Trainium2 to power its next generation
    of AI workloads.
  name: Databricks
  source: llm_enhanced
- category: ai_startup
  confidence: high
  context: Mentioned as a cutting-edge startup choosing AWS Trainium2 to power its
    next generation of AI workloads.
  name: Poolside
  source: llm_enhanced
- category: ai_technology
  confidence: high
  context: Referenced as the underlying technology powering the expected natural language
    query experience (generative algorithms like GPT-powered).
  name: GPT
  source: llm_enhanced
- category: data_source/infrastructure
  confidence: medium
  context: Mentioned as a source system for marketing data (Google Ads/Analytics)
    and as a potential destination database (Google BigQuery).
  name: Google
  source: llm_enhanced
- category: data_source
  confidence: medium
  context: Mentioned as a source system for marketing data.
  name: Facebook
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: Mentioned as a common cloud data warehouse platform used by clients, which
    AdVarity can integrate with or output data to.
  name: Snowflake
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: Mentioned as a common tool in the modern data stack for data transformations,
    which AdVarity can execute on behalf of the customer.
  name: dbt (Data Build Tool)
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as a standard Business Intelligence (BI) tool used by end consumers
    to visualize data.
  name: Power BI
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as a standard Business Intelligence (BI) tool used by end consumers.
  name: Looker
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as a standard Business Intelligence (BI) tool used by end consumers.
  name: Tableau
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Used as a general reference point for generative AI technology, particularly
    when defining agentic AI.
  name: ChatGPT
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Anthropic's flagship LLM, described as the speaker's go-to AI for research
    and reasoning.
  name: Claude
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: Mentioned as a potential LLM provider whose agent could be hooked into
    an environment using MCP capabilities.
  name: OpenAI
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Mentioned as a potential LLM provider whose agent could be hooked into
    an environment using MCP capabilities.
  name: Gemini
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: The premium subscription service for the Claude AI model.
  name: Claude Pro
  source: llm_enhanced
- category: ai_technology_general
  confidence: high
  context: General reference to Large Language Models, implying the major developers
    (like OpenAI, Google, Anthropic) are at the frontier.
  name: LLMs
  source: llm_enhanced
date: 2025-05-27 11:00:00 +0000
duration: 62
has_transcript: false
layout: episode
llm_enhanced: true
original_url: https://www.podtrac.com/pts/redirect.mp3/chrt.fm/track/E581B9/arttrk.com/p/VI4CS/pscrb.fm/rss/p/traffic.megaphone.fm/SUPERDATASCIENCEPTYLTD7262546662.mp3?updated=1748345059
processing_date: 2025-10-05 14:40:44 +0000
quotes:
- length: 155
  relevance_score: 5
  text: It's a full stack that includes GPUs and networking, as well as Nvidia AI
    Enterprise software, Nvidia inference microservices, models, and agent blueprints
  topics: []
- length: 90
  relevance_score: 4
  text: Say, for example, you want to run marketing reporting across Google, Facebook,
    you name it
  topics:
  - market
- length: 83
  relevance_score: 3
  text: You have to obviously go with the trend in a way, but that has always been
    the case
  topics: []
- length: 300
  relevance_score: 3
  text: So, having a capability like MCP in place and having a lot of SaaS products,
    and we certainly are going to do this as well, offer MCP capabilities to hook
    their company's tool of choice, which, you know, could be Gemini or OpenAI or
    whatever agent that the company will go with, into your environment
  topics:
  - saas
- impact_reason: 'A crucial observation: the traditional dashboard paradigm is becoming
    obsolete, paving the way for newer interaction models like conversational AI.'
  relevance_score: 10
  source: llm_enhanced
  text: And like I said, I think over the course of the last 10 years, I think reporting
    changed also how it's done within many of our customers, or many for many of our
    customers. And dashboards are not that relevant anymore than they used to be when
    we started.
  topic: AI Technology Trends/Predictions
- impact_reason: 'Crucial technical insight: grounding LLMs for data querying requires
    robust metadata management, lineage tracking, and semantic understanding (data
    dictionary) to ensure accuracy.'
  relevance_score: 10
  source: llm_enhanced
  text: one of the strengths that we have is a deep understanding of the lineage source
    of data, meaning of data. So, we manage the data catalog. We call that a data
    dictionary that has a clear connection to the source and also a deep description
    of what's going on, like what kind of meaning is behind the given attribute. That
    helps us ground the power system quite a bit to give proper answers.
  topic: technical
- impact_reason: Emphasizes that advanced AI features like conversational querying
    are entirely dependent on foundational data quality, completeness, and harmonization—a
    key lesson for building reliable AI products.
  relevance_score: 10
  source: llm_enhanced
  text: one really critical piece is the quality of the data underneath. So, each
    source... you need a complete data set that is also very well aligned with all
    the various sources that you have. So, harmonization plays a role in this as well.
  topic: practical lessons
- impact_reason: 'Advanced architectural insight: advocating for a multi-model approach
    (Mixture of Experts or specialized LLMs) rather than relying on a single monolithic
    model for all tasks within a complex application.'
  relevance_score: 10
  source: llm_enhanced
  text: the plan is also, at the moment we committed to one model, but there is also
    the plan to use different models for different aspects of our capability. So,
    for example, we could use a different model to compile our SQL query, a different
    model to do the pre-flight qualification of a question, a different model to do
    the actual conversation.
  topic: technical
- impact_reason: Provides a clear, high-level technical workflow for building a data
    querying LLM application (Input Classification -> Model Selection -> Prompt Engineering
    -> SQL Generation -> Validation -> Execution -> Synthesis).
  relevance_score: 10
  source: llm_enhanced
  text: it's pretty straightforward. You can qualify a user input into a type of question,
    select the model that you want to run with, basically feed it with a system prompt
    and additional information about the model, which is very critical to get down
    right. You use this to create a SQL query, verify it's actually a valid query
    that can be executed, fire the query, use the data to run some, you know, basic
    analysis, and create a decent, nice answer for the user.
  topic: technical
- impact_reason: 'This is the core strategic takeaway: AI/Data platforms should enable
    focus on business strategy rather than infrastructure plumbing (the ''amazing
    machinery'').'
  relevance_score: 10
  source: llm_enhanced
  text: So, we also going back into the overall topic of AI, I think people need to
    start concentrating on the business value and strategy on top of all this kind
    of, if you will, not saying magic, but you know, like this amazing machinery that
    you don't actually want to build a modern data stack with a lot of components
    and orchestrating a huge number of SaaS tools.
  topic: strategy
- impact_reason: 'Defines the primary benefit of the generative interface: replacing
    manual navigation/requesting with direct natural language querying to access data.'
  relevance_score: 10
  source: llm_enhanced
  text: Yeah, I think so. The most clear or the most standout difference is that rather
    than, you know, looking for the correct dashboard or correct set of data that
    you want to look at, you can formulate a natural query, and we're going to figure
    this out for you, rather than you looking for a specific data set on your own
    or asking a different team to get you to the data that you need to answer your
    business-type question.
  topic: AI/ML
- impact_reason: Contrasts the AI conversation capability with traditional BI drill-down,
    claiming the AI allows for cross-dataset exploration to answer 'why' questions,
    which is a significant leap in analytical depth.
  relevance_score: 10
  source: llm_enhanced
  text: And I think the second huge benefit is you get a system that you can actually
    explore deeper. I mean, that's been basic features for that, and or basically
    are in many BI tools, you can drill down into the data set and get more detailed
    data, but if you want to branch out into other data sets and understand, for example,
    why a trend is happening this way, you can do this with the conversation. You
    cannot do this with an explore function in, say, Looker or AdVarity for the matter.
  topic: AI/ML
- impact_reason: 'Poses the central question regarding AI''s impact on skilled data
    roles: displacement vs. augmentation.'
  relevance_score: 10
  source: llm_enhanced
  text: Nice. All right, so for people who are our core audience, people out there
    who are data analysts, data scientists, do you think that they should be worried
    about tools like this encroaching on their roles, or does it actually... Do automated
    conversations like this around data actually free up data analyst, data scientist,
    machine learning engineers to be tackling more interesting problems?
  topic: predictions
- impact_reason: Provides a strong, positive prediction about AI augmenting technical
    roles by eliminating 'busy work' and shifting focus to strategic value delivery.
  relevance_score: 10
  source: llm_enhanced
  text: this is going to allow a lot of analysts, also data engineers, to focus on
    more strategic stuff, the topics that, you know, are important for the business,
    and focus on what kind of value you can deliver for your company, rather than,
    you know, playing or having to... Not playing, but the technology allows you to
    do less busy work, if you will.
  topic: predictions/business
- impact_reason: Offers a clear, functional definition of Agentic AI centered on granting
    LLMs access to external functions to perform actions.
  relevance_score: 10
  source: llm_enhanced
  text: My understanding of this really is to give a ChatGPT or a generative AI type
    capability access to functions in a way that they can take action on behalf of
    the user sometime in the future.
  topic: technical
- impact_reason: 'A concise five-year prediction: the shift in focus for data professionals
    will move from the mechanics (''how'') to the strategic purpose (''why'') of data.'
  relevance_score: 10
  source: llm_enhanced
  text: we are talking maybe half a year, a year time here. But, yeah, I think mostly
    strategy and focus on the why rather than the how is probably something that will
    change quite a bit in the next five years.
  topic: predictions
- impact_reason: Sets the core theme of the discussion, focusing on the cutting edge
    application of Generative AI and Agentic AI in a specific business domain (data
    analytics).
  relevance_score: 9
  source: llm_enhanced
  text: Today, we've got an interesting one for you on how generative and agentic
    AI are transforming data analytics.
  topic: AI Technology Trends
- impact_reason: 'This clearly articulates the core pain point AdVarity was founded
    to solve: the extreme latency and manual effort in traditional data reporting
    (CSV to PowerPoint).'
  relevance_score: 9
  source: llm_enhanced
  text: We figured there must be something better than taking a CSV file and, you
    know, creating an ad hoc report and putting it into a PowerPoint presentation,
    we received like six weeks after the commercials aired.
  topic: Business Problem/Strategy
- impact_reason: Directly describes the implementation of generative AI (natural language
    querying) and agentic systems (proactive recommendations) in an enterprise analytics
    context.
  relevance_score: 9
  source: llm_enhanced
  text: AdVarity is currently launching its Data Conversations product, which lets
    users query data in natural language and even get proactive recommendations.
  topic: AI technology trends
- impact_reason: Provides a sharp critique of legacy data democratization methods,
    setting the stage for why GenAI/conversational interfaces are necessary evolutionary
    steps.
  relevance_score: 9
  source: llm_enhanced
  text: data catalogs and BI tools and dashboards were considered to democratize data
    access somehow. It turns out that those dashboards mostly are created once, not
    reviewed, and not updated, and always are getting challenged by the user...
  topic: strategy
- impact_reason: 'Defines the core value proposition of GenAI in data interaction:
    moving from fixed interfaces to fluid, human-language querying.'
  relevance_score: 9
  source: llm_enhanced
  text: there's an evolutionary step happening here with technology like generative
    AI that allows you to actually use human language to ask questions about the data.
  topic: AI technology trends
- impact_reason: 'Describes a robust MLOps/LLMOps strategy: continuous testing against
    expected outputs to maintain quality during rapid iteration.'
  relevance_score: 9
  source: llm_enhanced
  text: we'll be using frameworks to monitor that. The data science team is having
    a continuous test on, you know, we have a kind of a predefined set of responses
    that we expect from our questions, and we can monitor on those and improve in
    test models as we go.
  topic: practical lessons
- impact_reason: 'A pragmatic view on the current state of foundation models: commoditization
    of core LLM capabilities means competitive advantage lies in integration and application
    layer, not the base model itself.'
  relevance_score: 9
  source: llm_enhanced
  text: there's no trade secret in building. If you will, a lot of LLMs and the type
    of APIs they offer are similar in regards to their capabilities. And you see like
    all models kind of reaching the same capability.
  topic: business
- impact_reason: 'Reinforces the previous point: differentiation in the AI era comes
    from system design, integration, and unique use cases, not just access to the
    latest model.'
  relevance_score: 9
  source: llm_enhanced
  text: everyone's catching up to the same state of quality, if you will. I think
    where it then boils down to is how you put the components together to create a
    compelling and exciting use case on top of that.
  topic: strategy
- impact_reason: Highlights the paramount importance of prompt engineering and context
    injection (RAG/grounding data) for reliable LLM outputs.
  relevance_score: 9
  source: llm_enhanced
  text: system prompt and additional information about the model, which is very critical
    to get down right.
  topic: technical
- impact_reason: Illustrates the massive efficiency gain (reducing a two-week process
    to near real-time) achieved by modernizing data access workflows, likely through
    AI/automation.
  relevance_score: 9
  source: llm_enhanced
  text: So, rather than going through a full chain of various teams, you know, so
    it used to be that you had to create a ticket to get access to a data set, that
    data set would then be prepared within two weeks and put onto, I don't know, a
    Snowflake table or whatever. Today it's a Snowflake table, it used to be something
    completely different. So, with this, you can actually run the query, create a
    table in near real-time, available for your analysis, and that's kind of exciting
    for us.
  topic: business
- impact_reason: 'Clarifies the value proposition: AdVarity replaces the need to manage
    and integrate multiple best-of-breed tools (BigQuery, dbt, BI tools) into a single
    platform.'
  relevance_score: 9
  source: llm_enhanced
  text: I think what you get with our solution, you don't have to use those tools.
    So, basically, I see. So, you're giving the kind of that... So, that's what was
    confusing to me because I was like, this is all these different technologies are
    supported within AdVarity. So, you're saying that basically that is a kind of
    a common workflow, you know, Google BigQuery, Snowflake, dbt into Power BI, Looker,
    Tableau—that's a common kind of thing that a client of yours would typically be
    doing before they start working with AdVarity?
  topic: business
- impact_reason: 'Directly states the primary business benefit of consolidation: eliminating
    operational headaches caused by managing inter-platform dependencies.'
  relevance_score: 9
  source: llm_enhanced
  text: But then with AdVarity, you get one platform where you run all those things
    together, and then you don't have to worry about dependencies changing between
    platforms. It relieves a huge number of operational headaches downstream for your
    clients.
  topic: business
- impact_reason: Emphasizes the value of 'pre-harmonized' data, reducing the need
    for end-user data cleaning and modeling, which is often the biggest time sink.
  relevance_score: 9
  source: llm_enhanced
  text: But I think one key point is we already provide a harmonized, aligned, and
    properly structured data set for any purpose in marketing. So, if you go with
    the default and create a database that receives data from us, it's ready for analysis
    in your BI tool. So, you don't have to do all the in-between work.
  topic: business
- impact_reason: 'A critical warning: building and maintaining a modular data stack
    requires significant hidden engineering effort that platforms like AdVarity absorb.'
  relevance_score: 9
  source: llm_enhanced
  text: So, a lot of what we do really is we have baked-in governance and enterprise
    capabilities that make it very powerful to use as compared to something that you
    have to build on your own, because what many people don't see is that there is
    actually a lot of work in creating and maintaining a full modular modern data
    stack.
  topic: strategy
- impact_reason: 'Frames the decision to use a managed platform as a strategic investment
    choice: stop reinventing the wheel and focus engineering effort where it generates
    direct ROI.'
  relevance_score: 9
  source: llm_enhanced
  text: Right, exactly. So, what you're saying is that instead of having, instead
    of investing your engineering time and money in your organization on rebuilding
    and maintaining these same kinds of complex data stack interactions that all of
    your other competitors are doing, that it would make a lot of sense to focus on
    finding a solution like... and get an ROI, getting a return on our investment
    in our engineering team.
  topic: business
- impact_reason: Indicates that the AI goes beyond simple retrieval to perform complex,
    subject-matter-expert-level analysis (e.g., identifying best-performing campaigns).
  relevance_score: 9
  source: llm_enhanced
  text: But on top of that, there is also business analytics questions that you can
    ask about the data set, and we try to do the best in order to get to a solid response.
    So, you can ask for the best-performing campaigns, and the system will figure
    out how to connect the dots and create a useful response for that matter.
  topic: AI/ML
- impact_reason: Suggests that the LLM/generative layer is augmented with domain-specific
    knowledge graphs or rulesets to ensure accurate, expert-level answers.
  relevance_score: 9
  source: llm_enhanced
  text: So, all of the marketing-type specialized or subject matter expertise that
    we have built is also built into the system, so that's helping you to get to the
    response a lot faster.
  topic: AI/ML
- impact_reason: 'Addresses a major enterprise concern: generative AI tools must integrate
    governance and auditability, unlike a ''wild mix'' of unmanaged SaaS tools.'
  relevance_score: 9
  source: llm_enhanced
  text: And rather, and again, going back to the enterprise capabilities, I think
    what was very critical as well is to give it a tool that they can still manage
    on an audit, rather than having, you know, a wild mix of SaaS tools connected
    together that don't necessarily give you the level of governance you need in order
    to comply with a lot of regulations that we face today.
  topic: safety/governance
- impact_reason: Highlights a key advantage of conversational AI interfaces over traditional
    BI tools (like Looker) for deep, interconnected data exploration and root cause
    analysis.
  relevance_score: 9
  source: llm_enhanced
  text: You can drill down into the data set and get more detailed data, but if you
    want to branch out into other data sets and understand, for example, why a trend
    is happening this way, you can do this with the conversation. You cannot do this
    with an explore function in, say, Looker or AdVarity for the matter.
  topic: technical/business
- impact_reason: Poses the central question regarding AI's impact on highly skilled
    technical roles, setting up the subsequent discussion on job evolution.
  relevance_score: 9
  source: llm_enhanced
  text: Do automated conversations like this around data actually free up data analyst,
    data scientist, machine learning engineers to be tackling more interesting problems?
  topic: predictions/strategy
- impact_reason: Emphasizes the necessity of governance, monitoring, and supervision
    tools as AI adoption increases, linking directly to data quality and trust.
  relevance_score: 9
  source: llm_enhanced
  text: I think something that will certainly matter in this role moving forward is
    there's a lot about how you govern those tools and make sure that the responses
    are correct and right. So, having tools to monitor and supervise what's going
    on in your business, and that's critical.
  topic: safety/strategy
- impact_reason: Highlights the current trust barrier for fully autonomous AI agents,
    stressing the need for human oversight and control mechanisms.
  relevance_score: 9
  source: llm_enhanced
  text: I think we are not there where people would trust any solution to make decisions
    on their behalf fully. So, that needs to have some level of control and monitoring
    picked in.
  topic: safety
- impact_reason: Predicts the necessity of interoperability standards (like MCP) allowing
    enterprises to connect their preferred LLM/Agent framework to existing business
    tools.
  relevance_score: 9
  source: llm_enhanced
  text: offer MCP capabilities to hook their company's tool of choice, which, you
    know, could be Gemini or OpenAI or whatever agent that the company will go with,
    into your environment. I think that's very valuable and will probably truly help
    to get some of the solutions out there.
  topic: technical/business
- impact_reason: Points to Apache Iceberg as the emerging standard for open, accessible
    data lakes, enabling flexible connection to future AI/query tools.
  relevance_score: 9
  source: llm_enhanced
  text: the industry kind of settled on Iceberg as a format for that, and being able
    to connect this with various query engines depending on purpose, and likely in
    the future also with, you know, a generic generative AI capability.
  topic: technical
- impact_reason: Confirms active integration of the MCP standard, signaling its importance,
    while acknowledging current deployment hurdles (early stage, cloud desktop dependency).
  relevance_score: 9
  source: llm_enhanced
  text: we will offer the capability to connect this [MCP]. You know, it's in an early
    stage at the moment. You need, you know, cloud desktop in order to connect this
    in a proper fashion, but this will surely develop into a very good solution where
    you connect your chat agent with services and let them take action.
  topic: technical/business
- impact_reason: 'A significant strategic prediction: as technology (the ''how'')
    becomes more commoditized or abstracted, the fundamental business purpose (the
    ''why'') will become the primary differentiator and focus area.'
  relevance_score: 9
  source: llm_enhanced
  text: But, yeah, I think mostly strategy and focus on the why rather than the how
    is probably something that will change quite a bit in the next five years.
  topic: predictions/strategy
- impact_reason: This summary encapsulates the key discussion points, highlighting
    the problems (failing dashboards, busy work) and the proposed solutions (conversational
    AI, startup tips).
  relevance_score: 8
  source: llm_enhanced
  text: Martin details how a childhood fascination with computer programming evolved
    into founding a globally leading platform for marketing data analytics, what data
    democratization really means and how the traditional dashboard-based approach
    to data reporting is failing businesses, why data analysts are spending too much
    time on busy work instead of delivering business value, how conversational AI
    is overhauling how data insights are gleaned for hands-on data practitioners and
    business users alike, and finally, he provides his no-nonsense tips for tech startup
    success.
  topic: Strategy/Predictions/Business
- impact_reason: Detailed description of the inefficient, manual data workflow that
    modern AI/BI tools aim to replace.
  relevance_score: 8
  source: llm_enhanced
  text: The way we started was really about the workflow and reviewing how agencies
    initially, you know, at that point, created reports for their customers. And a
    lot of the work behind that used to be going into all the ad systems that they
    took care of, copying the data into a spreadsheet, using this to create a visualization
    and embedding this in a PowerPoint and creating a PDF to send around to clients.
  topic: Business Problem/Strategy
- impact_reason: Directly signals the transition to discussing the impact of conversational
    AI on data interaction.
  relevance_score: 8
  source: llm_enhanced
  text: So, yeah, it probably could bring us to data conversations as well, or how
    this might be changing.
  topic: AI Technology Trends
- impact_reason: Highlights a significant shift in data consumption, moving away from
    static dashboards towards more dynamic, interactive methods, which conversational
    AI directly addresses.
  relevance_score: 8
  source: llm_enhanced
  text: dashboards are not that relevant anymore than they used to be when we started.
  topic: strategy
- impact_reason: 'Crucial business advice: technology adoption requires parallel investment
    in human capital and domain expertise, not just technical integration.'
  relevance_score: 8
  source: llm_enhanced
  text: you need to do more than just extending your connectivity portfolio; you need
    to, you know, train people and staff accordingly to be able to work in other fields.
  topic: business
- impact_reason: 'Frames the purpose of their new GenAI product around a core, high-level
    business goal: making data accessible to everyone.'
  relevance_score: 8
  source: llm_enhanced
  text: there is one overarching theme, which is data democratization.
  topic: strategy
- impact_reason: Highlights the necessity of building dedicated data quality monitoring
    tools specifically to support downstream AI applications.
  relevance_score: 8
  source: llm_enhanced
  text: We built up actually a data quality component in our platform that helps you
    monitor all those issues that you can have in your data.
  topic: practical lessons
- impact_reason: 'A best practice for data engineering pipelines supporting AI: maintaining
    immutable raw data for rollback and iterative improvement of transformation logic.'
  relevance_score: 8
  source: llm_enhanced
  text: we keep always a raw data set that can then be used as a starting point to
    iterate on transformations, for example. So, you can always go back to the previous
    state and improve your transformations.
  topic: technical
- impact_reason: Illustrates the speed advantage of LLM-driven data access over traditional
    ticketing/provisioning systems, emphasizing near real-time data availability.
  relevance_score: 8
  source: llm_enhanced
  text: So with this, you can actually run the query, create a table in near real-time,
    available for your analysis, and that's kind of exciting for us.
  topic: predictions
- impact_reason: Highlights the dual focus on democratizing data access for both technical
    (IT) and non-technical (business) users, a key trend in modern data platforms.
  relevance_score: 8
  source: llm_enhanced
  text: 'Because what our approach to this is, first of all, in terms of democratization,
    we are targeting two sides of the business: one of which is IT and the other one
    is the business user. And both have a requirement to access data.'
  topic: strategy
- impact_reason: Maps out the standard 'Modern Data Stack' workflow (Ingestion ->
    Warehouse -> Transformation/Modeling -> BI Visualization), setting the baseline
    for comparison.
  relevance_score: 8
  source: llm_enhanced
  text: And I think most will then connect this with a BI model to do some further
    transformation, probably create subsets of data for different kinds of reporting.
    I can speak of the models itself, so that's up to the customer. And then in turn,
    this is usually connected with a BI system. So, mostly, you know, the things that
    the industry standard would be Power BI for many organizations, this still looks,
    or look at Studio, Tableau, to name a few.
  topic: strategy
- impact_reason: Shows how AI/platform abstraction handles complex orchestration tasks
    (like running dbt jobs) without requiring the customer to manage the underlying
    infrastructure.
  relevance_score: 8
  source: llm_enhanced
  text: And so, there is, you don't have to use dbt with us. We can execute dbt on
    your, on the customer's behalf as well. So, you don't have to manage an orchestrator,
    you know, or run another complex machinery to, you know, run dbt.
  topic: technical
- impact_reason: 'Highlights the specific pain point in marketing data: the constant,
    tedious maintenance required to keep up with source system API/schema changes
    (a task ideally suited for specialized AI/automation).'
  relevance_score: 8
  source: llm_enhanced
  text: Yeah, exactly. And maybe also what is very interesting about the marketing
    ecosystem is very dynamic. There's lots of changes happening on the source as
    well, so you don't want to keep up with that. If you go with a typically horizontal
    ETL solution, keeping up with the changes on the source, that might be, you know,
    like a very tedious and problematic.
  topic: business
- impact_reason: 'Shows the practical output of the generative query: a tangible,
    actionable data artifact (table) that can be instantly integrated into existing
    workflows.'
  relevance_score: 8
  source: llm_enhanced
  text: Because, like I said, the tabular response can be immediately acted upon by
    either continuing to use it, say, for example, in Google Sheets, or materializing
    this in a Snowflake table, or querying the table for the matter. So, you can immediately
    work with the data set once you're satisfied with the result.
  topic: AI/ML
- impact_reason: 'Reiterates the core democratization benefit: lowering the barrier
    to complex data interaction from SQL proficiency to natural language.'
  relevance_score: 8
  source: llm_enhanced
  text: it's easier for anyone to be composing their questions in natural language
    relative to, you know, a SQL query or something like that.
  topic: AI/ML
- impact_reason: 'Addresses a critical enterprise concern: governance and compliance
    when adopting new, potentially disparate AI/data tools.'
  relevance_score: 8
  source: llm_enhanced
  text: give it a tool that they can still manage on an audit, rather than having,
    you know, a wild mix of SaaS tools connected together that don't necessarily give
    you the level of governance you need in order to comply with a lot of regulations
    that we face today.
  topic: business/safety
- impact_reason: A cautionary note on buzzword inflation, specifically regarding 'Agentic
    AI,' highlighting the need for precise definitions.
  relevance_score: 8
  source: llm_enhanced
  text: I have a very hard time with the term today because it's been used across
    the board. Like, when AI entered the scene, basically meant like technology like
    ChatGPT, but very quickly many companies adopted the term for non-AI type problems,
    basically.
  topic: strategy
- impact_reason: Reinforces the importance of setting realistic expectations for AI
    capabilities by maintaining a strict definition of agentic behavior (LLM that
    can take actions).
  relevance_score: 8
  source: llm_enhanced
  text: I think that's a much more realistic definition of this because on the other
    hand, if you define it too broadly, people have expectations for a system that
    is not able to behave in a way that they would expect as well.
  topic: strategy
- impact_reason: Identifies the current industry phase as one of standardization (citing
    MCP) following initial hype cycles for new capabilities.
  relevance_score: 8
  source: llm_enhanced
  text: I think it's mostly also now in a phase where we establish standards. So,
    like a couple of weeks ago, you had all this hype going on about MCP, slightly
    another hype going on about agentic AI, the near future.
  topic: technical/strategy
- impact_reason: 'Identifies a major underlying infrastructure trend in data management:
    decoupling compute from storage, which impacts future data mobility and processing.'
  relevance_score: 8
  source: llm_enhanced
  text: there's also an interesting move in our industry as a, as a storage and disconnecting
    compute from storage, which is a shift that is happening underneath what we do
    today.
  topic: technical/strategy
- impact_reason: Provides a concrete, personal example of massive productivity gains
    (days to minutes) in research/content creation enabled by advanced AI.
  relevance_score: 8
  source: llm_enhanced
  text: What would take me days is now done in minutes. It's changed how I prep for
    every single episode, enabling me to get more high-quality content to you in each
    one, ever more relevant facts and better, richer questions for guests.
  topic: business
- impact_reason: 'A core strategic principle: emphasizing solution-fit over a one-size-fits-all
    approach, which is crucial when deploying various AI/data tools.'
  relevance_score: 8
  source: llm_enhanced
  text: I think that's very valuable to businesses to pick the right solution for
    the right case.
  topic: business/strategy
- impact_reason: 'Illustrates a key business benefit of modern tooling (like AdVarity):
    shifting engineering focus from maintenance/integration overhead to higher-value
    activities.'
  relevance_score: 8
  source: llm_enhanced
  text: Right, right, right. So, that's tying back to your point earlier in the conversation
    about tools like AdVarity allowing you to have your engineering team, your IT
    team focused less on integrating systems and keeping everything up to date, and
    more on
  topic: business/strategy
- impact_reason: Highlights key industry players and current infrastructure trends
    (AWS AI chips, Dell/Nvidia AI Factories) relevant to the ML/AI community.
  relevance_score: 7
  source: llm_enhanced
  text: Today's episode is brought to you by Traenium II, the latest AI chip from
    AWS, and by the Dell AI Factory with Nvidia.
  topic: Strategy/Technology Trends
- impact_reason: Defines their initial product as a 'verticalized BI solution,' a
    key strategic positioning in the analytics market.
  relevance_score: 7
  source: llm_enhanced
  text: So, we created a solution where it became very simple from our perspective,
    basically a verticalized BI solution to deal with the automated reporting.
  topic: Strategy/Product
- impact_reason: Provides insight into the strategic tension between platform generality
    (technical capability) and go-to-market specialization (business focus).
  relevance_score: 7
  source: llm_enhanced
  text: The platform itself could absolutely be used for other verticals as well.
    I think from a, for us as a company, from a go-to-market perspective, and also
    like when you look at the connectivity portfolio, there's obviously a bias towards
    marketing.
  topic: Business/Strategy
- impact_reason: Indicates the use of AI/ML (likely LLMs) to assist in the data wrangling/transformation
    process itself, showing AI being used to build the data foundation for other AI
    features.
  relevance_score: 7
  source: llm_enhanced
  text: there's also obviously today, and the AI system helping you to compose those
    transformations.
  topic: AI technology trends
- impact_reason: Defines a dual-user strategy for enterprise AI adoption, recognizing
    that technical and non-technical users require tailored data access solutions.
  relevance_score: 7
  source: llm_enhanced
  text: 'we are targeting two sides of the business: one of which is IT and the other
    one is the business user. And both have a requirement to access data.'
  topic: business
- impact_reason: 'Defines the core ETL/ELT challenge in marketing analytics: integrating
    disparate, high-volume sources into a usable structure.'
  relevance_score: 7
  source: llm_enhanced
  text: The predominant use case is to extract data from sources. Say, for example,
    you want to run marketing reporting across Google, Facebook, you name it. So,
    basically, you extract data from those source systems, prepare it in a way that
    is useful for reporting, and put it into a table.
  topic: technical
- impact_reason: Details a specific architectural decision (one big table scheme)
    for data consolidation and highlights platform interoperability with major cloud
    data warehouses.
  relevance_score: 7
  source: llm_enhanced
  text: And AdVarity adopted one big table scheme. So, you end up with a database,
    Google BigQuery, Snowflake, you name it. So, we support quite a wide range of
    data bases and have a full snapshot of the source data in your database.
  topic: technical
- impact_reason: Explicitly frames the traditional data solution as a 'highly composable
    or like a very modular stack of components,' which is the problem AdVarity aims
    to simplify.
  relevance_score: 7
  source: llm_enhanced
  text: So, yes, it's like, so confirm that that's the case. Yeah. No, I'm just mentioning
    one of the cases. So, and it becomes interesting because you would look at this
    from a modern data stack perspective, obviously, and like a highly composable
    or like a very modular stack of components that kind of create a data solution
    for you.
  topic: strategy
- impact_reason: Sets up the core discussion about the impact of the new generative
    AI feature (Data Conversations).
  relevance_score: 7
  source: llm_enhanced
  text: With the Data Conversations product that AdVarity has now released with this
    generative experience, how does that change everything for a user? ... What is
    the added value? What is the changing experience like with Data Conversations?
  topic: AI/ML
- impact_reason: 'A strong endorsement highlighting the desired characteristic of
    advanced LLMs: deep workflow understanding and collaborative reasoning, not just
    task execution.'
  relevance_score: 7
  source: llm_enhanced
  text: Claude is the AI for minds that don't stop at "good enough." It's the collaborator
    that actually understands your entire workflow and thinks with you, not for you.
  topic: business/strategy
- impact_reason: Highlights the importance of standardized data formats (like 'eberg')
    for interoperability, especially when integrating with diverse query engines and
    future generative AI systems.
  relevance_score: 7
  source: llm_enhanced
  text: eberg as a format for that, and being able to connect this with various query
    engines depending on purpose, and likely in the future also with, you know, a
    generic generative AI capability.
  topic: technical/strategy
- impact_reason: Provides context on the success and scale of a tech company built
    around data analytics, offering a benchmark for the industry.
  relevance_score: 6
  source: llm_enhanced
  text: AdVarity, an Austrian data analytics platform he co-founded a decade ago,
    and that has since raised over $160 million in venture capital.
  topic: Business/Strategy
- impact_reason: A concrete, high-profile example of scaling messaging and data systems
    for mass consumer interaction.
  relevance_score: 6
  source: llm_enhanced
  text: So, we, for example, created the software that powered the American Idol SMS
    voting.
  topic: Business/Scale
- impact_reason: Describes the evolution from simple automation to building connectivity
    layers for near real-time dashboarding.
  relevance_score: 6
  source: llm_enhanced
  text: Now, the vision was agencies would then use this to build dashboards that
    they can share with their clients and get near real-time reporting. And that's
    also how we expanded very quickly in terms of connectivity.
  topic: Strategy/Product Evolution
- impact_reason: Provides insight into the speaker's perception of the rapid pace
    of change in their industry (likely AI/Tech), suggesting short-term focus (6-12
    months) is more relevant than long-term (5 years).
  relevance_score: 6
  source: llm_enhanced
  text: But, you know, five years is a long time for me, because we are talking maybe
    half a year, a year time here.
  topic: strategy
- impact_reason: A relatable anecdote about the origins of a CTO's technical journey,
    often resonating with the early experiences of many in the tech field.
  relevance_score: 5
  source: llm_enhanced
  text: I got into computing at a, I'd say, fairly young age, I think eight or nine
    years old. I got an Amiga computer.
  topic: Strategy/Personal Journey
- impact_reason: Historical context on early mobile tech evolution (WAP), showing
    a long track record of adapting to emerging communication platforms.
  relevance_score: 5
  source: llm_enhanced
  text: We basically created apps for mobile network operators, this technology called
    WAP, which were kind of microsites that could be delivered through SMS.
  topic: Technical/History
- impact_reason: Explains the etymology of the company name, linking 'Ad' (advertising)
    with 'Varity' (truth), emphasizing the mission to find 'the truth behind advertising
    data.'
  relevance_score: 5
  source: llm_enhanced
  text: And so, that's kind of like it's got advertising in it, I guess, reflecting
    your advertising roots. And then the "variety," it's interesting. I don't know
    if that's just something that you chose because it sounds nice, but it's also
    that's kind of the Latin root that's related to the Latin root for truth, right?
    Yeah, exactly. So, that's kind of connected to that.
  topic: Business/Branding
- impact_reason: Pinpoints the founding moment and the initial focus on automating
    reporting.
  relevance_score: 5
  source: llm_enhanced
  text: So, this is really how we got started with something automating reporting,
    and in 2015, we decided to actually incorporate this as a standalone company,
    that's AdVarity today.
  topic: Business/History
source: Unknown Source
summary: '## Podcast Episode Summary: 891: Conversational AI is Overhauling Data Analytics,
  with Martin Brunthaler


  This episode of the Super Data Science Podcast features Martin Brunthaler, co-founder
  and CTO of AdVarity, discussing the transformative impact of Generative and Agentic
  AI on the field of data analytics, particularly moving beyond traditional dashboard-based
  reporting.


  **1. Focus Area:**

  The discussion centers on the evolution of data analytics platforms, specifically
  how **Conversational AI** is enabling true **data democratization** by replacing
  static dashboards with natural language querying. Key themes include the necessity
  of high-quality, harmonized underlying data, the challenges of traditional reporting
  workflows, and the technical implementation of grounding LLMs for reliable data
  insights.


  **2. Key Technical Insights:**

  *   **Grounding LLMs via Data Dictionary and Lineage:** Effective conversational
  analytics requires a robust data foundation, specifically a well-managed data catalog/dictionary
  that clearly links attributes to their source and meaning. This grounding is critical
  for the LLM to generate accurate, trustworthy answers.

  *   **Multi-Model Architecture Potential:** While currently committed to one model,
  AdVarity plans to leverage different LLMs for specialized tasks within the conversational
  pipeline (e.g., one model for SQL query generation, another for final conversational
  response).

  *   **Data Quality as a Prerequisite:** Successful implementation hinges on rigorous
  data quality monitoring, harmonization (e.g., aligning date formats to UTC), and
  anomaly detection built into the platform to prevent problematic data from reaching
  the conversational layer.


  **3. Business/Investment Angle:**

  *   **Failure of Static Dashboards:** Traditional BI dashboards are often static,
  quickly outdated, and fail to allow users to drill down or challenge assumptions,
  leading analysts to waste time on busywork rather than delivering value.

  *   **Accelerated Data Access:** Conversational AI drastically shortens the time-to-insight
  by allowing both technical (IT) and business users to generate ad-hoc reports or
  data tables in near real-time, bypassing lengthy ticketing processes.

  *   **AdVarity’s Market Position:** AdVarity, which has raised over $160 million,
  evolved from specialized TV ad reporting to a broader platform with a strong DNA
  in marketing data integration, though the core technology is applicable elsewhere.


  **4. Notable Companies/People:**

  *   **Martin Brunthaler:** Co-founder and CTO of AdVarity, bringing over 20 years
  of experience in scaling tech startups, including previous work in messaging systems
  (e.g., American Idol SMS voting).

  *   **AdVarity:** The company discussed, focused on marketing data analytics, now
  integrating conversational AI via its "Data Conversations" product.

  *   **Sponsors:** AWS (promoting Trainium2 AI chips) and Dell (promoting the Dell
  AI Factory with Nvidia).


  **5. Future Implications:**

  The industry is moving decisively away from fixed visualization tools toward dynamic,
  human-language interfaces for data interaction. The focus will shift from simply
  connecting data sources to ensuring the **quality, context, and lineage** of that
  data are perfectly integrated with LLMs to enable reliable, agentic data exploration.


  **6. Target Audience:**

  This episode is highly valuable for **Data Science Leaders, Product Managers building
  data tools, AI/ML Engineers** involved in implementing LLM applications, and **CTOs/Executives**
  interested in strategic shifts in enterprise analytics and data democratization.'
tags:
- artificial-intelligence
- generative-ai
- startup
- ai-infrastructure
- investment
- nvidia
- anthropic
- google
title: '891: Conversational AI is Overhauling Data Analytics, with Martin Brunthaler'
topics:
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 106
  prominence: 1.0
  topic: artificial intelligence
- keywords:
  - generative ai
  - genai
  - chatgpt
  - gpt
  - claude
  - text generation
  - image generation
  mentions: 22
  prominence: 1.0
  topic: generative ai
- keywords:
  - startup
  - entrepreneur
  - founder
  - venture
  mentions: 7
  prominence: 0.7
  topic: startup
- keywords:
  - gpu
  - tensor
  - training
  - inference
  - model deployment
  - vector database
  mentions: 4
  prominence: 0.4
  topic: ai infrastructure
- keywords:
  - investment
  - funding
  - valuation
  - ipo
  - acquisition
  mentions: 1
  prominence: 0.1
  topic: investment
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-10-05 14:40:44 UTC -->
