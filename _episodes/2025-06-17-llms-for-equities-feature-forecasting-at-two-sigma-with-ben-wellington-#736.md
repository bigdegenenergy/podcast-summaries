---
companies:
- category: unknown
  confidence: medium
  context: ompany over the next week, month, year, whatever. Maybe I'm going to end
    up using that as a trading signal
  name: Maybe I
  position: 355
- category: unknown
  confidence: medium
  context: ight, everyone. Welcome to another episode of the Twomo AI podcast. I am
    your host, Sam Charrington. Today,
  name: Twomo AI
  position: 622
- category: unknown
  confidence: medium
  context: episode of the Twomo AI podcast. I am your host, Sam Charrington. Today,
    I'm joined by Ben Wellington. Ben is depu
  name: Sam Charrington
  position: 656
- category: unknown
  confidence: medium
  context: your host, Sam Charrington. Today, I'm joined by Ben Wellington. Ben is
    deputy head of feature forecasting at 2 S
  name: Ben Wellington
  position: 694
- category: unknown
  confidence: medium
  context: with computers interacting with human languages. And I like to say I got
    onto it before it was cool, bef
  name: And I
  position: 1381
- category: unknown
  confidence: medium
  context: udents to draw sentence tree diagrams to make the Penn Treebank, which
    was like the pretty eminent data set. I me
  name: Penn Treebank
  position: 2199
- category: unknown
  confidence: medium
  context: t know, you're walking by a Target and you see a "Help Wanted" sign in
    the window, and then you say, "Oh, I did
  name: Help Wanted
  position: 6371
- category: unknown
  confidence: medium
  context: g the Target sign—that's a very organic scenario. But I've got to imagine
    at the scale you're operating a
  name: But I
  position: 10998
- category: unknown
  confidence: medium
  context: not helpful. Now, let's get to the nose touching. Could I have done that
    10 years ago? I think I could have
  name: Could I
  position: 17700
- category: unknown
  confidence: medium
  context: p, and all this stuff is suddenly in front of me. And LLMs have profoundly
    created this world where you don'
  name: And LLMs
  position: 19371
- category: unknown
  confidence: medium
  context: nothing is changing. And what do I mean by that? As I pointed out earlier,
    we might have had earlier pa
  name: As I
  position: 21016
- category: unknown
  confidence: medium
  context: swer usually. "Hey, what should I do in this car? Should I try to slow
    down or speed up?" There's usually a
  name: Should I
  position: 26821
- category: unknown
  confidence: medium
  context: that particular thing is to get now versus later. When I think about this
    again, this kind of hierarchical
  name: When I
  position: 40063
- category: tech
  confidence: high
  context: ', quote-unquote old ideas, around auto-ML, like a DataRobot thing, like,
    "I''m going to just take all these fe'
  name: Datarobot
  position: 40285
- category: tech
  confidence: high
  context: d there were all these fancy algorithms. One day, Google entered, and they
    had the five-year-old algorithm
  name: Google
  position: 42202
- category: unknown
  confidence: medium
  context: e time, I'm thinking of a conversation I had with Scott Stevenson, who
    founded a company called DeepGram, in the sp
  name: Scott Stevenson
  position: 44033
- category: ai_application
  confidence: high
  context: The investment manager where the guest, Ben Wellington, works. They use
    features and models (implying heavy ML/AI use) to predict asset prices.
  name: 2 Sigma
  source: llm_enhanced
- category: ai_research
  confidence: medium
  context: Mentioned as the place where the guest studied Natural Language Processing
    during his PhD, indicating a historical connection to AI/NLP research.
  name: NYU
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as an example of an older auto-ML concept where statistical programs
    run across features to combine them in different ways.
  name: DataRobot
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Mentioned in the context of machine translation, where they used a massive
    model with a lot of data to beat competitors using fancier algorithms, changing
    the world.
  name: Google
  source: llm_enhanced
- category: ai_startup
  confidence: high
  context: A company founded by Scott Stevenson in the speech-to-text, text-to-speech
    space, discussed in relation to domain jumping (audio vs. text).
  name: DeepGram
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as a specific open-source model family that the speaker is evaluating
    or using for controlled experiments.
  name: Llama 3
  source: llm_enhanced
date: 2025-06-17 19:33:00 +0000
duration: 60
has_transcript: false
insights:
- actionable: true
  confidence: medium
  extracted: be so naive that we can turn away anything that we don't understand
  text: we should be so naive that we can turn away anything that we don't understand.
  type: recommendation
- actionable: false
  confidence: medium
  extracted: an equity price based on features—it sounds like there's a line somewhere
    between one of those things and predicting the value of the portfolio given a
    decision to buy or not. So, we're predicting the future price of—if we're doing
    it. So, the key thing
  text: the future of an equity price based on features—it sounds like there's a line
    somewhere between one of those things and predicting the value of the portfolio
    given a decision to buy or not. So, we're predicting the future price of—if we're
    doing it. So, the key thing is that is where I tend to focus, where I focus somewhere
    where I work.
  type: prediction
- actionable: false
  confidence: medium
  extracted: nose touching
  text: The problem with nose touching is that it's a cool idea, but is it worth six
    months of the person's time? Maybe, maybe not, right? And what's so cool about
    this new era of LLMs is that that six months might become six minutes, right?
    "Hey, you know, did they touch their nose how many times?" The profound shift
    in the ability to study the ideas in your head and the trade-off, the return on
    your investment, the ROI of these ideas—that investment has been cut by 99% for
    some tasks.
  type: problem_identification
layout: episode
llm_enhanced: true
original_url: https://pscrb.fm/rss/p/traffic.megaphone.fm/MLN1374470913.mp3?updated=1750189327
processing_date: 2025-10-05 09:11:33 +0000
quotes:
- length: 245
  relevance_score: 5
  text: '" But how do you turn that into a portfolio that doesn''t have certain risks,
    that you''re not exposed to a particular industry, or you''re not—so, you have
    to keep everything neutral so that if something happens in the market, we can
    stay balanced'
  topics:
  - market
- length: 218
  relevance_score: 5
  text: So, you have to design your inputs and outputs so that you can wrap your new
    model around something such that it's easily ingestible into your system, as opposed
    to picking something and then customizing on top of that
  topics: []
- length: 198
  relevance_score: 5
  text: So, there is a time component, and you have to—it becomes back to that return
    on investment question and your priors as a researcher of how important that particular
    thing is to get now versus later
  topics:
  - investment
- length: 120
  relevance_score: 4
  text: We're going to be chatting a little bit about how LLMs and GenAI are changing
    the way you approach problem-solving there
  topics: []
- length: 81
  relevance_score: 4
  text: Today's LLMs are multimodal, so you can give them videos and ask questions,
    right
  topics: []
- length: 197
  relevance_score: 4
  text: I remember for a while, clearly, it's still—it's increasingly popular for
    organizations to build their own embeddings and to create embedding spaces for
    RAG-type of applications, that kind of thing
  topics: []
- length: 50
  relevance_score: 4
  text: And the LLM, under the hood, it's embedding things
  topics: []
- length: 189
  relevance_score: 4
  text: And so, if you have access to the internal workings, you can also pull the
    embedding right out of the process, depending on what the software is, or you
    could take the output and embed that
  topics: []
- length: 265
  relevance_score: 4
  text: 'And I made a concrete example: now that there are a lot of interesting things
    you can do with fine-tuning an LLM or something like that, you want to be in a
    position so that you can swap in the next model, whatever it comes from, however
    it comes from, very quickly'
  topics: []
- length: 265
  relevance_score: 4
  text: One thing I'm hearing is kind of like the minimum to build is owning the abstraction,
    right, so that you can swap things out, and then maybe you're selectively—I've
    got to imagine you're well down the road to fine-tuning your own LLMs for areas
    where it makes sense
  topics: []
- length: 202
  relevance_score: 3
  text: We typically, in order to get 20 years of data, a lot of the time you have
    to say, "Okay, let me start recording this, and I'll come back to it 20 years
    later," which is a very forward-looking statement
  topics: []
- length: 83
  relevance_score: 3
  text: So, you have to have—people used to ask me, "Hey, what data should you be
    recording
  topics: []
- length: 136
  relevance_score: 3
  text: '" I think today it is there is what shouldn''t we record, and obviously there
    are legal issues that you have to clear to record something'
  topics: []
- length: 108
  relevance_score: 3
  text: I mean, some of it is going to be valuable and innovative, and you have to
    use your priors—what's novel here
  topics: []
- length: 53
  relevance_score: 3
  text: Is that the tension that you have to—Yeah, absolutely
  topics: []
- impact_reason: This perfectly summarizes the historical debate in NLP between data-driven
    (empirical/statistical) and rule-based (syntactic) approaches, which modern deep
    learning has largely settled in favor of the empirical route.
  relevance_score: 10
  source: llm_enhanced
  text: 'There was this tension between empirical natural language processing, which
    is like, if we have enough data, we can solve over problems, and then sort of
    the more syntactic approach: no, no, no, we need to understand noun phrases and
    verb phrases.'
  topic: technical
- impact_reason: 'Highlights the critical challenge in time-series ML/quant finance:
    the necessity of deep, consistent historical data capture, not just current snapshots.'
  relevance_score: 10
  source: llm_enhanced
  text: I don't only need a job—this is the hard part—not only do I need the job postings
    there today, but in theory, I need historical views of those job postings.
  topic: technical/strategy
- impact_reason: Emphasizes the extreme difficulty and value of long-term, persistent
    data archiving, a major bottleneck for historical modeling.
  relevance_score: 10
  source: llm_enhanced
  text: And that 20 years—I can't stress enough here—where do you find 20 years of
    history on a company's website? That is the interesting, challenging part about
    this work.
  topic: strategy/technical
- impact_reason: 'This is a powerful strategic directive for data collection: prioritize
    recording everything now, as future analytical needs are unpredictable. It speaks
    directly to data hoarding as a competitive advantage.'
  relevance_score: 10
  source: llm_enhanced
  text: The answer was always, 'Anything that might be interesting in the future.'
    I'm okay. It's interesting now. It's like this is a time capsule, if you hit record
    today, this is a gift to either you in the future or another researcher at the
    firm who is going to suddenly have this rich history of data to then go and study
    because if you don't have that historical data, a lot of data just disappears
    like forever.
  topic: strategy
- impact_reason: 'Crucial advice for data science teams: preserve raw data fidelity
    to allow for future re-interpretation or application of new modeling techniques
    (like LLMs) that might leverage aspects of the data previously discarded.'
  relevance_score: 10
  source: llm_enhanced
  text: Don't worry, just make sure you have access to the rawest data possible. The
    more you analyze it and throw out the raw data, the less useful it will be in
    the future if someone wants to do something different.
  topic: technical/strategy
- impact_reason: 'A fundamental principle in data science: raw data offers maximum
    flexibility for future feature engineering, contrasting with derived features
    which lock you into past assumptions.'
  relevance_score: 10
  source: llm_enhanced
  text: You referenced earlier the idea that the closer you get to the raw data, the
    raw capture, the more valuable that data is.
  topic: technical
- impact_reason: This clearly articulates the strategic value of retaining raw data—it
    future-proofs analysis against new modeling techniques or novel hypotheses that
    haven't been conceived yet.
  relevance_score: 10
  source: llm_enhanced
  text: if you have raw data, you can create any of those derived features in the
    future, whereas if you deleted your raw data and you made derived features and
    then you had a new idea... it's waiting for you as a future creation and avenue.
  topic: strategy
- impact_reason: This is a massive claim about the impact of modern AI (specifically
    LLMs) on R&D velocity, suggesting a near-elimination of the technical barrier
    for testing hypotheses.
  relevance_score: 10
  source: llm_enhanced
  text: The profound shift in the ability to study the ideas in your head and the
    trade-off, the return on your investment, the ROI of these ideas—that investment
    has been cut by 99% for some tasks.
  topic: predictions
- impact_reason: Directly addresses the impact of LLMs on reducing the overhead (time,
    team size) required for feature engineering and initial analysis.
  relevance_score: 10
  source: llm_enhanced
  text: LLMs have profoundly created this world where you don't need a team anymore
    to—you don't need a giant project to answer basic questions like that, which makes
    the ability to create these features from either your head, for the moment you
    think of them, to the time you can analyze them—it's just a different world.
  topic: AI technology trends
- impact_reason: A profound statement on the inherent limits of prediction in complex,
    chaotic systems like financial markets, contrasting it with well-defined ML tasks
    (like cat vs. dog).
  relevance_score: 10
  source: llm_enhanced
  text: In finance, you actually—it's not clear that no matter how much information
    you have that there is enough information to predict with any real certainty what's
    going to happen tomorrow, right?
  topic: limitations
- impact_reason: Provides a concrete, industry-specific benchmark (R-squared of 0.05
    being 'too high') that illustrates the minute signal strength in financial prediction,
    highly valuable for ML practitioners in this domain.
  relevance_score: 10
  source: llm_enhanced
  text: The signal-to-noise ratio—the noise is just so much bigger, right? And so,
    if we can predict an R-squared, and if you see an R-squared of like 0.05, you
    know something's broken because that's way too high.
  topic: technical/limitations
- impact_reason: Captures the dual sentiment (fear and excitement) surrounding the
    potential for agentic AI systems, especially in high-stakes environments.
  relevance_score: 10
  source: llm_enhanced
  text: We have all these different models with all these different approaches and
    techniques. And yes, do I think a lot about what an agentic approach looks like?
    Absolutely, I do. I'm—it's terrifying and exciting all at once.
  topic: predictions/safety
- impact_reason: 'A crucial strategic takeaway for any tech company: the pace of innovation
    demands platform agility over deep, slow customization.'
  relevance_score: 10
  source: llm_enhanced
  text: Innovations seem to be happening pretty quickly at an increased pace... you
    need to be ready with a platform that can adapt nimbly to the latest technology,
    right?
  topic: strategy
- impact_reason: A strong warning against long, proprietary development cycles in
    fast-moving fields like NLP, favoring integration over building from scratch.
  relevance_score: 10
  source: llm_enhanced
  text: So, if you're going to go spend a year training up your own thing, and then
    you come up for air and the technology you used that you started a year ago is
    now obsolete, that's not going to work.
  topic: business/strategy
- impact_reason: 'Defines the core intellectual property/build decision: focus internal
    resources on owning the interfaces and abstractions, not the interchangeable components.'
  relevance_score: 10
  source: llm_enhanced
  text: One thing I'm hearing is kind of like the minimum to build is owning the abstraction,
    right? so that you can swap things out...
  topic: strategy
- impact_reason: 'A core strategic principle for building AI infrastructure: prioritize
    modularity and interchangeability to adapt to new models and tools.'
  relevance_score: 10
  source: llm_enhanced
  text: The things that you build need to be plug-and-playable with the changing world.
  topic: strategy
- impact_reason: Specific example (audio-to-audio translation bypassing text) demonstrating
    the power of removing human-imposed abstractions in favor of end-to-end data-driven
    learning.
  relevance_score: 10
  source: llm_enhanced
  text: That's an exact example where somebody had forced that hop [intermediate text
    step], you would actually have a less good system than we have today when they
    said, 'Oh, look, let me remove these abstractions that humans have added and just
    let the system go with enough data.'
  topic: AI technology trends
- impact_reason: 'Identifies a critical risk in using proprietary, black-box LLMs
    for time-sensitive tasks: temporal leakage and unintended historical bias influencing
    current analysis.'
  relevance_score: 10
  source: llm_enhanced
  text: So, it is kind of scary for us to use an off-the-shelf model that's been trained
    on data in 2020 to ask questions from a document of 2019, right? So, if I could
    say, 'Hey, here's this Enron conference call. Do you think it's good or bad?'
    Is the word 'Enron' going to trigger a negative reaction because somewhere deep
    in the psyche of the LLM, there was a big bankruptcy?
  topic: safety/ethics
- impact_reason: 'Strategic advice for AI adoption: diversification across models
    (Llama, GPT, etc.) is necessary because the market leader will constantly shift.'
  relevance_score: 10
  source: llm_enhanced
  text: there's not going to be a horse to bet on. You're going to be well-suited
    to have a diversified set of inputs to build interesting things, and you need
    to be comfortable using a wide array of technologies, not just betting on a single
    one.
  topic: strategy
- impact_reason: 'This is the philosophical justification for ensembling: prioritizing
    robustness and collective wisdom over singular peak performance.'
  relevance_score: 10
  source: llm_enhanced
  text: I'm not always looking at the best at things; I'm looking for a group of things
    that each have their own take that when I average out among them, I'm better off
    and more robust in the future than had I just picked one.
  topic: strategy/technical
- impact_reason: 'A fundamental principle of signal processing and ensemble methods
    applied to LLMs: orthogonality leads to reduced variance and smoother outcomes.'
  relevance_score: 10
  source: llm_enhanced
  text: '...which when you combine orthogonal signals, you get a much smoother response
    than when they''re correlated signals.'
  topic: technical
- impact_reason: 'This encapsulates the core philosophy of feature engineering and
    data acquisition in quantitative finance/ML: maximizing data breadth to improve
    predictive power.'
  relevance_score: 9
  source: llm_enhanced
  text: Ultimately, our goal is to find data and features and predictions in as many
    places as we can, right?
  topic: strategy
- impact_reason: A strong retrospective statement confirming the dominance of data-driven
    methods (which underpins modern deep learning and LLMs) over purely symbolic/syntactic
    methods.
  relevance_score: 9
  source: llm_enhanced
  text: I think looking back, the data route clearly won out, and we can talk about
    that journey today...
  topic: technical/strategy
- impact_reason: A fundamental, accessible definition of a 'feature' in the context
    of quantitative analysis, bridging the gap between general observation and ML
    input.
  relevance_score: 9
  source: llm_enhanced
  text: We think of breaking down the world into features, where a feature is just
    sort of an interesting observable fact of interest about something.
  topic: technical
- impact_reason: A concrete example of how proprietary, immutable historical data
    (the raw feed) can become more valuable than the publicly updated version, especially
    when dealing with evolving narratives.
  relevance_score: 9
  source: llm_enhanced
  text: The news company, they don't mind rewriting their headlines. They don't mind
    changing, adding little topics, editing. And so, they don't actually know at noon
    on this day what they actually had sent. They only knew the edited version. So,
    we kind of have this beautiful, real-time history of the world that many people
    didn't start recording.
  topic: business/strategy
- impact_reason: This speaks directly to the challenge of information overload in
    emerging tech fields (like AI) and emphasizes the critical role of researcher
    intuition ('priors') and identifying novelty ('the edge') for effective resource
    allocation.
  relevance_score: 9
  source: llm_enhanced
  text: I think 'needle in the haystack' is a good way to think of it. I mean, some
    of it is going to be valuable and innovative, and you have to use your priors—what's
    novel here? How is this different? What's the edge?—to try to decide what you
    want to spend your research time studying, right?
  topic: strategy
- impact_reason: Captures the excitement and democratization of ideation enabled by
    lowered technical barriers due to LLMs.
  relevance_score: 9
  source: llm_enhanced
  text: And because it's no longer a big decision, it's awesome because it's like
    a kid in the candy shop, and all this stuff is suddenly in front of me.
  topic: business
- impact_reason: A powerful summary statement describing the current era as a 'renaissance'
    driven by LLM capabilities in feature generation.
  relevance_score: 9
  source: llm_enhanced
  text: in some ways it's kind of like a renaissance of feature creation in right
    out of the back of these LLMs.
  topic: AI technology trends
- impact_reason: Illustrates the practical, accessible power of modern multimodal
    LLMs, where complex vision tasks are reduced to simple programmatic queries, bypassing
    traditional complex pipelines.
  relevance_score: 9
  source: llm_enhanced
  text: Today's LLMs are multimodal, so you can give them videos and ask questions,
    right? So, it's almost unexcitingly untechnical, right? What can you do? I can
    do a for loop across a thousand videos and ask, 'How many times did the person
    touch their nose?' and I could add—put it to a CSV file.
  topic: technical
- impact_reason: A crucial insight into the limitations of early LLMs (parroting/imitation
    vs. true knowledge/reasoning), important for setting realistic expectations for
    AI capabilities.
  relevance_score: 9
  source: llm_enhanced
  text: I think what people don't realize is that going back to my syntax versus empirical
    stuff is that LLMs actually—they're starting to add reasoning to them, but certainly
    as of a year ago, the chatty part we were all introduced to was just trying to
    imitate humans, right? It wasn't knowledge. It didn't say, 'Cats, the dog barks,'
    because it knows dogs bark. It said, 'The dog barks,' because, you know, a logical
    thing after the word 'dog' is the word 'barks,' and it was wild to feel like these
    things know about the world when, in fact, they're just kind of parroting humans
    in this really interesting way.
  topic: AI limitations
- impact_reason: Defines the vector space as the essential bridge between unstructured
    data (text/media) and quantitative machine learning models.
  relevance_score: 9
  source: llm_enhanced
  text: Once you're in this vector space, it becomes a much more natural connection
    into the machine learning world, right? If you've got everything as a 300-dimensional
    vector instead of a blob of words, you know what comes downstream is various sophisticated
    learning algorithms that can try to tie the thing that you're embedding... into
    a prediction about the world.
  topic: technical
- impact_reason: Highlights the fundamental advantage of modern NLP (embeddings) over
    older methods (like one-hot encoding or word counts) for capturing semantic meaning
    in unstructured data like news stories.
  relevance_score: 9
  source: llm_enhanced
  text: It is a much richer world to be able to convert that story into an embedding
    or multiple embeddings, or there are different ways you can approach that.
  topic: technical
- impact_reason: Directly links the output of embedding models (vectors) to the concept
    of engineered features in traditional ML pipelines, emphasizing semantic richness
    over simple counts.
  relevance_score: 9
  source: llm_enhanced
  text: It's more semantically rich, and so those vectors themselves could be features,
    right? You can make features about a company, you can make features about a story.
  topic: technical
- impact_reason: A critical cautionary note about applying ML to finance, emphasizing
    the extreme difficulty due to data noise.
  relevance_score: 9
  source: llm_enhanced
  text: 'But that''s a thing about financial modeling: it is so incredibly noisy.'
  topic: safety/limitations
- impact_reason: 'Clearly delineates the specialized roles within a large-scale ML
    operation: feature engineering, prediction modeling, and portfolio optimization.'
  relevance_score: 9
  source: llm_enhanced
  text: My team's responsibility is turning raw data to features, then features to
    just predictions. And after the predictions, another team is thinking about how
    to combine all those predictions and build a portfolio for a company that's going
    to maximize the returns for investors.
  topic: strategy
- impact_reason: 'Illustrates the reality of modern quantitative modeling: relying
    on an ensemble of thousands of specialized, interacting models rather than a single
    monolithic system.'
  relevance_score: 9
  source: llm_enhanced
  text: Our role is to build a bunch of different models. One model might look at
    CEO interviews, one might look at fundamental prices, one might look at what an
    analyst is doing... You end up with literally thousands of these models all interacting...
  topic: technical
- impact_reason: 'Presents a concrete vision for agentic systems: specialized agents
    communicating based on their domain expertise, rather than a single generalist
    agent.'
  relevance_score: 9
  source: llm_enhanced
  text: My best guess is that you have different agents that have done this—this is
    sort of the point of these agents, right? They have different understanding; they're
    experts on different things, right?
  topic: predictions
- impact_reason: A stark prediction about the automation of high-level research and
    analytical roles due to advanced reasoning LMs.
  relevance_score: 9
  source: llm_enhanced
  text: Any of our roles feel like they're heading towards automation, right? Many,
    many, many. And I don't think just because it's research or innovative, it doesn't
    mean that a good reasoning LM can't start to fill in some of those gaps.
  topic: predictions
- impact_reason: Quantifies the potential productivity gain from advanced AI tools,
    suggesting a rapid acceleration in research capability.
  relevance_score: 9
  source: llm_enhanced
  text: Can I have 10,000 researchers at my fingertips? That would be pretty powerful.
    And in some ways, it feels like that's the way we're going, and faster than I
    would have guessed.
  topic: predictions
- impact_reason: Actionable advice emphasizing the necessity of leveraging external,
    rapidly evolving tools (open source/vendors) rather than attempting to maintain
    parity internally.
  relevance_score: 9
  source: llm_enhanced
  text: You really need to be front-footed and look at what's happening in the world
    and build on top of the ability to take in modern open-source approaches or work
    with vendors and tools that are adapting very quickly...
  topic: business/strategy
- impact_reason: A concise summary of the required architectural philosophy for surviving
    rapid technological shifts.
  relevance_score: 9
  source: llm_enhanced
  text: I think the things that you build need to be plug-and-playable with the changing
    world.
  topic: strategy
- impact_reason: Details the technical requirement for model interchangeability—decoupling
    the core stack from the specific model implementation.
  relevance_score: 9
  source: llm_enhanced
  text: You want to be in a position so that you can swap in the next model, whatever
    it comes from, however it comes from, very quickly. The rest of your stack is
    not like, 'Oh, wait, it's a new model, it's from a new company, everything now
    has to be redone,' right?
  topic: technical/strategy
- impact_reason: Highlights the extreme pace of AI innovation, mandating platform
    agility over deep, proprietary, slow-to-develop solutions in rapidly changing
    areas.
  relevance_score: 9
  source: llm_enhanced
  text: your platform needs to jump on and off different things in different places
    to stay up with these new innovations because there's no time to stop and build
    something in the space that's going to be able to keep up with what's happening.
  topic: strategy
- impact_reason: Illustrates the rapid obsolescence of specialized fine-tuning efforts
    due to the continuous improvement of base models.
  relevance_score: 9
  source: llm_enhanced
  text: even with fine-tuning, the things that you had to fine-tune six months ago—the
    next model somehow is already risking being better at the thing you fine-tuned
    in your six-month model, right? I mean, it's moving that quickly.
  topic: AI technology trends
- impact_reason: 'Crucial insight for quantitative finance/AI applications: speed
    is paramount because competitive advantages (alpha) decay rapidly due to market
    efficiency.'
  relevance_score: 9
  source: llm_enhanced
  text: If you're six months out of the gate before the other group, that can make
    a big difference because what you find, by the way, is when you trace signals
    over time, they get weaker and weaker and weaker as your competition starts to
    come in. And so, it's called alpha decay, efficient market.
  topic: business
- impact_reason: A powerful historical anecdote reinforcing the 'data trumps fancy
    algorithms' lesson that drove the deep learning revolution.
  relevance_score: 9
  source: llm_enhanced
  text: Google entered, and they had the five-year-old algorithm, but they had this
    massive model, like ten times bigger, a hundred times bigger than anyone ever
    had, and they beat everybody. And everyone was like, 'Wait, we have all these
    fancy ideas.' And they were like, 'Yeah, but we have a lot of data.' And it kind
    of changed—it changed the world.
  topic: technical
- impact_reason: Argues against overly modular, human-defined pipelines (like old
    MT systems) when end-to-end learning with sufficient data can discover superior,
    non-intuitive connections.
  relevance_score: 9
  source: llm_enhanced
  text: If you force yourself into a set of chained events, you might lose a lot of
    the power of machine learning because at each handoff point, you strip things
    down into your assumption of what matters, and that algorithm might disagree.
  topic: technical
- impact_reason: 'Strong argument for using open-source models in high-stakes research:
    control over the training data allows for greater confidence in the results and
    avoids hidden biases.'
  relevance_score: 9
  source: llm_enhanced
  text: there are risks to using these off-the-shelf things because you can't control
    the data that's going in, and you might fool yourself. And so, that's one reason
    why we do prefer open source for more controlled experiments because we know what
    went in, and we know that what we're seeing we can actually believe in.
  topic: technical
- impact_reason: Advocates for LLM ensembling as a robustness strategy, prioritizing
    diversity of perspective over selecting the single best-performing model.
  relevance_score: 9
  source: llm_enhanced
  text: Is there value in having an ensemble of LLMs that each have their own strengths
    and weaknesses? And I'm not always looking at the best at things; I'm looking
    for a group of things that each have their own take that when I average out among
    them, I'm better off and more robust in the future than had I just [picked one].
  topic: technical
- impact_reason: This is crucial strategic advice for navigating the rapidly evolving
    AI landscape, advocating for technological flexibility over single-vendor lock-in.
  relevance_score: 9
  source: llm_enhanced
  text: you need to be comfortable using a wide array of technologies, not just betting
    on a single one.
  topic: strategy
- impact_reason: Highlights the growing viability and strategic advantage (transparency/control)
    of shifting workloads to open-source LLMs.
  relevance_score: 9
  source: llm_enhanced
  text: given your preference towards open source and understanding the training environment,
    data recipe, whatever, of a model, you've been able to shift a significant percentage
    of your workloads to open-source models...
  topic: business/technical
- impact_reason: Explains *why* diversity in models is beneficial—it creates orthogonal
    (uncorrelated) signals.
  relevance_score: 9
  source: llm_enhanced
  text: I really am of the belief that there are pros and cons, and that in itself
    is a strength because it builds orthogonality...
  topic: technical
- impact_reason: A clear, concise definition of an ML model's purpose in a high-stakes
    financial context (prediction of asset prices).
  relevance_score: 8
  source: llm_enhanced
  text: Maybe I'm going to end up using that as a trading signal eventually and build
    what we call a model, which is basically something that takes data in and makes
    predictions about future prices of the assets we trade.
  topic: technical/business
- impact_reason: Illustrates the creative, cross-domain application of feature engineering—using
    unstructured visual data for financial prediction.
  relevance_score: 8
  source: llm_enhanced
  text: That's a very interesting feature you could get from a satellite image, just
    a great example [counting cars in a parking lot to predict share price].
  topic: technical/business
- impact_reason: Describes the market shift from siloed data products to holistic,
    comprehensive data platforms, driven by the realization that interconnectedness
    yields predictive power.
  relevance_score: 8
  source: llm_enhanced
  text: As people started to realize, 'Oh, wait, there's value in a holistic world
    view of all the companies that we're looking at at once,' products started to
    emerge...
  topic: business
- impact_reason: 'Highlights the necessary skill of research prioritization in a data-saturated
    environment: using domain knowledge (''priors'') to filter noise and identify
    genuine potential competitive advantages (''the edge'').'
  relevance_score: 8
  source: llm_enhanced
  text: I mean, some of it is going to be valuable and innovative, and you have to
    use your priors—what's novel here? How is this different? What's the edge?—to
    try to decide what you want to spend your research time studying, right?
  topic: strategy
- impact_reason: Highlights the shift from simple data collection to using data to
    test specific, often creative, hypotheses (like non-verbal cues), which is central
    to advanced analytics.
  relevance_score: 8
  source: llm_enhanced
  text: The most exciting thing is it converts that data into hypothesis-driven ideas.
    Examples might be the number of times they touch their noses, exactly, right?
  topic: strategy
- impact_reason: Provides an excellent, intuitive explanation of word embeddings and
    semantic space, which is the foundation of modern NLP power.
  relevance_score: 8
  source: llm_enhanced
  text: And what we've seen is this move to embeddings, which is really neat, where
    instead of words just kind of existing in isolation of each other, they exist
    kind of floating in space like near words that are like them. So, 'cat' and 'dog'
    are kind of similar, and 'creativity' and 'innovation' are kind of similar.
  topic: technical
- impact_reason: 'Explains the core benefit of embeddings: enabling generalization
    and transfer learning across semantically related concepts.'
  relevance_score: 8
  source: llm_enhanced
  text: And what that lets you do is really generalize your model because now what
    I learned about creativity, I learn a little bit about innovation, right?
  topic: technical
- impact_reason: Clearly states the core business objective in a quantitative finance
    context, setting the stage for how AI/ML is applied.
  relevance_score: 8
  source: llm_enhanced
  text: Ultimately, our goal is to make predictions about where stocks are going.
  topic: business
- impact_reason: Provides insight into leveraging LLMs not just for final output,
    but as powerful embedding generators, a key technique in modern applied ML.
  relevance_score: 8
  source: llm_enhanced
  text: The LLM, under the hood, it's embedding things. And so, if you have access
    to the internal workings, you can also pull the embedding right out of the process...
  topic: technical
- impact_reason: 'Describes a successful organizational strategy for scaling complex
    quantitative research: centralization around a shared, robust technology platform.'
  relevance_score: 8
  source: llm_enhanced
  text: We are what we call a platform company because ultimately it's a very tech-heavy
    investment company, and we have a lot of different teams looking at a lot of different
    types of data, but they are doing that together into sort of a centralized set
    of portfolios.
  topic: strategy
- impact_reason: Applies core software engineering principles (abstraction, APIs)
    to the ML/data science workflow, essential for scalability and modularity.
  relevance_score: 8
  source: llm_enhanced
  text: We try to break up the investment process into abstractions that have good
    APIs, right?
  topic: strategy
- impact_reason: Emphasizes the strategic importance of model orthogonality (uncorrelated
    performance) to ensure robustness and diversification of predictive signals.
  relevance_score: 8
  source: llm_enhanced
  text: The idea is to keep your signal working there, hopefully orthogonal enough
    to one another that when one's not working, you know—and so that's how the company
    works overall.
  topic: strategy
- impact_reason: A direct warning against over-attributing agency or consciousness
    to complex models, grounding the discussion back in engineering reality.
  relevance_score: 8
  source: llm_enhanced
  text: 'I''m chasing down this signal that I''m latching on to and chasing down here:
    you can''t anthropomorphize the idea or these models having their own point of
    view or something along those lines.'
  topic: safety/limitations
- impact_reason: A compelling analogy used to justify comfort with complex, non-interpretable
    AI systems (black boxes) based on rigorous empirical validation of inputs and
    outputs, similar to established medical practices.
  relevance_score: 8
  source: llm_enhanced
  text: I get asked a lot about how comfortable we are with black boxes in investing,
    right? When I got my wisdom teeth out, okay. Did you know that modern science
    doesn't actually know how that works? We just tested the inputs, we tested the
    outputs, and we've grown comfortable with enough data that that general anesthetic
    has particular properties...
  topic: safety/ethics
- impact_reason: Balances the desire for interpretability (Occam's razor) with the
    pragmatic necessity of adopting powerful, opaque technologies if performance is
    equal or superior.
  relevance_score: 8
  source: llm_enhanced
  text: 'I tend to prefer interpretability. I have higher priors when I understand
    what''s happening, and it''s all about being equal—like outcomes—Occam''s razor:
    simple is better. But that doesn''t mean that we should be so naive that we can
    turn away anything that we don''t understand.'
  topic: safety/ethics
- impact_reason: Frames LLMs not as monolithic solutions, but as components (features)
    within a larger, higher-level system designed for sense-making.
  relevance_score: 8
  source: llm_enhanced
  text: the model is yet another feature in this basket of features, and you train
    all of your data on all of the models, and it's just one level higher that you
    go to make sense of things.
  topic: strategy
- impact_reason: A foundational definition of NLP, relevant as the field is now dominated
    by LLMs.
  relevance_score: 7
  source: llm_enhanced
  text: My background is in natural language processing. So, that's anything happening
    to do with computers interacting with human languages.
  topic: technical
- impact_reason: A concise definition of research effectiveness, emphasizing intuition
    and strategic focus over brute-force data processing.
  relevance_score: 7
  source: llm_enhanced
  text: 'And that''s what makes a good researcher: somebody who knows where to look
    for the next great idea.'
  topic: strategy
- impact_reason: A humorous but sharp illustration of the pitfalls of traditional
    NLP (like one-hot encoding) where context and polysemy are completely lost.
  relevance_score: 7
  source: llm_enhanced
  text: I remember looking at a plot where uncertainty spiked in the month of May
    off the—I was like, 'Oh, the word 'may'.' Oh, 'may.' Yeah. So, you know, that's
    how you have the one-hot encoding world can end up in a funny place.
  topic: technical
- impact_reason: Clearly contrasts simple, rule-based feature engineering (pre-embedding
    era) with modern methods.
  relevance_score: 7
  source: llm_enhanced
  text: Historically, I might make a dictionary of forward-looking words. I can find
    past-tense words. I could count. I can make a ratio. You don't need machine learning
    to count previous words versus forward-looking words, right? You make a ratio,
    kind of simple, right? And that's sort of the one-hot encoding NLP world of a
    decade ago.
  topic: technical
- impact_reason: Highlights the massive technological overhead required for robust
    backtesting in quantitative finance, emphasizing the need for sophisticated simulation
    infrastructure.
  relevance_score: 7
  source: llm_enhanced
  text: There's a lot of technology that goes into replaying the set of stocks and
    what would have—creating a virtual world where you're backtesting this new idea
    and see how it would have done.
  topic: technical
- impact_reason: Defines the specific prediction target in their modeling efforts,
    distinguishing it from portfolio allocation decisions.
  relevance_score: 7
  source: llm_enhanced
  text: We're predicting the future price of equities that we trade based on a feature,
    based on the model, based on everything you have, right?
  topic: technical
- impact_reason: Identifies portfolio optimization as a distinct, critical research
    area separate from raw signal prediction.
  relevance_score: 7
  source: llm_enhanced
  text: That's called optimization, basically converting the predictions into a portfolio
    that's been optimized to be kind of balanced.
  topic: strategy
- impact_reason: Introduces the concept of 'combinatorial research'—testing many models/features
    simultaneously—and acknowledges the risk of overwhelming complexity.
  relevance_score: 7
  source: llm_enhanced
  text: I love that concept [combinatorial research], and I think actually a colleague
    of mine last week was framing basically as combinatorial research, right? Exactly,
    the ultimate scary place to go and not get buried.
  topic: technical
- impact_reason: Introduces the term 'combinatorial research' in the context of AI/ML
    experimentation, suggesting a systematic approach to combining models or data
    paths.
  relevance_score: 7
  source: llm_enhanced
  text: I love that concept, and I think actually a colleague of mine last week was
    framing basically as combinatorial research, right?
  topic: technical
source: Unknown Source
summary: '## Podcast Summary: LLMs for Equities Feature Forecasting at Two Sigma with
  Ben Wellington - #736


  This episode of the Twomo AI podcast features an in-depth discussion with **Ben
  Wellington, Deputy Head of Feature Forecasting at Two Sigma**, focusing on how Large
  Language Models (LLMs) and Generative AI are revolutionizing the creation and utilization
  of predictive features for quantitative equity trading.


  ### 1. Focus Area

  The primary focus is the **application of advanced NLP/GenAI techniques (specifically
  LLMs) to financial data analysis for the purpose of generating novel, high-signal
  features** used in quantitative investment models. The discussion bridges Ben Wellington''s
  background in traditional NLP with the current paradigm shift driven by data-centric
  AI in finance.


  ### 2. Key Technical Insights

  *   **The ROI Revolution in Feature Engineering:** LLMs have drastically reduced
  the cost (from potentially months of specialized engineering to minutes) required
  to test complex hypotheses derived from unstructured data (e.g., analyzing video
  content for non-verbal cues like "nose touching" during CEO interviews). This lowers
  the barrier to entry for exploring previously intractable features.

  *   **Shift from Syntactic/One-Hot Encoding to Embeddings:** The evolution from
  older NLP methods (like counting specific words or using one-hot encoding) to using
  dense vector **embeddings** allows models to capture semantic relationships between
  concepts (e.g., understanding that "innovate" and "creative" are related), leading
  to better generalization in prediction models.

  *   **The Importance of Raw, Historical Data Capture:** A core philosophy at Two
  Sigma is the imperative to record the *rawest* form of data possible (e.g., raw
  video feeds, unedited news wires). This "time capsule" approach ensures that future,
  yet-to-be-invented analytical techniques (like advanced vision models) can be applied
  retrospectively to historical data, a capability that is impossible if only derived
  features are saved.


  ### 3. Business/Investment Angle

  *   **Feature Forecasting as the Core Business:** Two Sigma’s objective is to predict
  future asset prices by quantifying the world into millions of observable "features."
  Feature forecasting is the dedicated process of discovering, quantifying, and validating
  these signals.

  *   **The Value of Holistic Data Capture:** The firm prioritizes capturing data
  across *all* traded entities simultaneously (e.g., tracking job postings for every
  company), recognizing that a holistic, cross-sectional view often yields more predictive
  power than siloed data sets.

  *   **Competitive Edge in Data Provenance:** Having proprietary, time-stamped historical
  records (like unedited news feeds) that competitors lack provides a significant
  edge, as this data allows for testing hypotheses that others cannot validate historically.


  ### 4. Notable Companies/People

  *   **Ben Wellington (Two Sigma):** Deputy Head of Feature Forecasting, expert in
  NLP, driving the integration of GenAI into feature discovery.

  *   **Two Sigma:** The quantitative investment manager where this work is applied,
  focused on using data science to predict asset prices.

  *   **NYU:** Mentioned as the location where Ben Wellington pursued his PhD in machine
  translation, highlighting the historical context of NLP research.


  ### 5. Future Implications

  The conversation suggests a **renaissance in feature creation**. As the technical
  overhead for extracting complex signals from unstructured data plummets due to LLMs,
  researchers will shift from prioritizing technically feasible ideas to pursuing
  any hypothesis that seems potentially valuable, regardless of initial complexity.
  This democratization of feature engineering will likely lead to a rapid expansion
  of the feature space used in quantitative finance.


  ### 6. Target Audience

  This episode is highly valuable for **AI/ML Engineers, Quantitative Researchers
  (Quants), Data Scientists working in finance, and technology leaders** interested
  in the practical, high-stakes application of Generative AI beyond consumer-facing
  products.'
tags:
- artificial-intelligence
- investment
- generative-ai
- ai-infrastructure
- google
title: 'LLMs for Equities Feature Forecasting at Two Sigma with Ben Wellington - #736'
topics:
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 80
  prominence: 1.0
  topic: artificial intelligence
- keywords:
  - investment
  - funding
  - valuation
  - ipo
  - acquisition
  mentions: 8
  prominence: 0.8
  topic: investment
- keywords:
  - generative ai
  - genai
  - chatgpt
  - gpt
  - claude
  - text generation
  - image generation
  mentions: 2
  prominence: 0.2
  topic: generative ai
- keywords:
  - gpu
  - tensor
  - training
  - inference
  - model deployment
  - vector database
  mentions: 2
  prominence: 0.2
  topic: ai infrastructure
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-10-05 09:11:33 UTC -->
