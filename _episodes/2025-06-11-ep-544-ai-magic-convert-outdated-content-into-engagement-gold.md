---
companies:
- category: unknown
  confidence: medium
  context: This is the Everyday AI Show, the everyday podcast where we simplify AI
    and br
  name: Everyday AI Show
  position: 12
- category: unknown
  confidence: medium
  context: e of months, that process has completely changed. And I think it's something
    that all of us, if we're a k
  name: And I
  position: 530
- category: unknown
  confidence: medium
  context: o that's what we're going to be tackling today on Everyday AI. Little would
    I call a little AI magic and how yo
  name: Everyday AI
  position: 1020
- category: unknown
  confidence: medium
  context: be doing it live today for our new weekly series, Put AI to Work Wednesdays.
    All right, I'm excited for th
  name: Put AI
  position: 1201
- category: unknown
  confidence: medium
  context: t live today for our new weekly series, Put AI to Work Wednesdays. All
    right, I'm excited for this one. I hope you
  name: Work Wednesdays
  position: 1211
- category: unknown
  confidence: medium
  context: oing on, y'all? Welcome to Everyday AI. My name's Jordan Moulson and I'm
    the host. And if you're trying to grow yo
  name: Jordan Moulson
  position: 1343
- category: tech
  confidence: high
  context: the right place. We do this every single weekday, Monday through Friday,
    with our unscripted, unedited dai
  name: Monday
  position: 1510
- category: unknown
  confidence: medium
  context: example that we're going to be going over today. But I want you to think
    about your work. How much time
  name: But I
  position: 3320
- category: unknown
  confidence: medium
  context: where we're going to go over. We're going to use AI Studio to transcribe
    a visual PDF presentation. I'm goin
  name: AI Studio
  position: 4605
- category: tech
  confidence: high
  context: targeted deep research based on that content with Google Gemini. We're
    going to use AI Studio, Google's AI
  name: Google
  position: 4775
- category: unknown
  confidence: medium
  context: targeted deep research based on that content with Google Gemini. We're
    going to use AI Studio, Google's AI Studio
  name: Google Gemini
  position: 4775
- category: tech
  confidence: high
  context: you expand one. And then you're, you know, using Perplexity to help you
    research. And yes, you can do that. B
  name: Perplexity
  position: 6229
- category: unknown
  confidence: medium
  context: count, right? But even if you just have the basic Google Gemini Pro plan,
    you know, $20 a month or if you're a studen
  name: Google Gemini Pro
  position: 6798
- category: unknown
  confidence: medium
  context: vestream, go ahead, do this live with me. Pull up Google AI Studio on your
    computer, if you want. So that's this AI
  name: Google AI Studio
  position: 7286
- category: unknown
  confidence: medium
  context: 'e this on my screen here. I did an episode called Small Language Models:
    What They Are and Do We Need Them? I believe thi'
  name: Small Language Models
  position: 8879
- category: unknown
  confidence: medium
  context: 'e. I did an episode called Small Language Models: What They Are and Do
    We Need Them? I believe this was I should'
  name: What They Are
  position: 8902
- category: unknown
  confidence: medium
  context: 'e called Small Language Models: What They Are and Do We Need Them? I believe
    this was I should have looked this up,'
  name: Do We Need Them
  position: 8920
- category: unknown
  confidence: medium
  context: language model? 14 facts you need to know, right? So I go through here,
    and although the definitions nec
  name: So I
  position: 9639
- category: unknown
  confidence: medium
  context: something like that in this new document, right? When I'm doing a new episode
    on Everyday AI, I do like t
  name: When I
  position: 10738
- category: unknown
  confidence: medium
  context: I should know that. When was I in? When was I in Las Vegas for Google I/O?
    When was that? I can't even see i
  name: Las Vegas
  position: 11576
- category: unknown
  confidence: medium
  context: that. When was I in? When was I in Las Vegas for Google I/O? When was that?
    I can't even see it now. May? N
  name: Google I
  position: 11590
- category: unknown
  confidence: medium
  context: eed to sleep more. I wasn't at that one. I was at Cloud Next. All right.
    That was in April. All right. There w
  name: Cloud Next
  position: 11739
- category: unknown
  confidence: medium
  context: right. That was in April. All right. There we go. So Google updated their
    deep research in April with Google
  name: So Google
  position: 11805
- category: unknown
  confidence: medium
  context: uding blind, the kind of blind taste test that is LM Arena. So one thing
    when they updated their deep resear
  name: LM Arena
  position: 12160
- category: unknown
  confidence: medium
  context: the difference is this is using a thinking model. So Google Gemini 2.5
    is obviously a hybrid model. So when it needs
  name: So Google Gemini
  position: 12476
- category: tech
  confidence: high
  context: out of the first 10 websites, it went to a lot of Microsoft websites, which
    I find interesting. Right. So, yo
  name: Microsoft
  position: 13199
- category: unknown
  confidence: medium
  context: ideos with native audio generation. Try it with a Google AI Pro plan or
    get the highest access with the Ultra pla
  name: Google AI Pro
  position: 14976
- category: unknown
  confidence: medium
  context: e is we're going to toggle on this grounding with Google Search. So all
    that means is, yes, we're telling Google
  name: Google Search
  position: 18524
- category: unknown
  confidence: medium
  context: then the presentation PDF is this older version. Like I said, this is the
    old Small Language Model presen
  name: Like I
  position: 19232
- category: unknown
  confidence: medium
  context: this older version. Like I said, this is the old Small Language Model presentation.
    So a lot of times when I do these l
  name: Small Language Model
  position: 19261
- category: unknown
  confidence: medium
  context: e PDF, like, who has this doc, right? Who has the Google Slides and no
    one knows, right? And you're like, oh, gre
  name: Google Slides
  position: 20578
- category: unknown
  confidence: medium
  context: this is actually important and pretty impressive. This PDF is a bunch of
    images, right? So it's literally go
  name: This PDF
  position: 20984
- category: unknown
  confidence: medium
  context: is a bunch of JPEGs. It's, it's not like a proper PDF I created in Canva.
    It's a bunch of like images, sc
  name: PDF I
  position: 21296
- category: unknown
  confidence: medium
  context: t there to be able to transcribe that entire PDF. Then I'm telling it,
    I need the transcription verbatim.
  name: Then I
  position: 21687
- category: unknown
  confidence: medium
  context: and export it. All right. So it's opening now in Google Docs. That's a
    feature. I'm going to go ahead and rena
  name: Google Docs
  position: 22097
- category: unknown
  confidence: medium
  context: e 2025. So if you remember originally, I told the Google Google Gemini
    deep research to focus on 2025. Okay. But now I'm
  name: Google Google Gemini
  position: 23140
- category: unknown
  confidence: medium
  context: going to go through and read all this right now. Maybe I'll go through
    and, you know, put the human in the
  name: Maybe I
  position: 27111
- category: unknown
  confidence: medium
  context: filled the gaps because that's important. Right? Because I almost like
    it was like handing it off to another
  name: Because I
  position: 28803
- category: unknown
  confidence: medium
  context: at at prompt engineering or know anything tricky. All I'm saying is turn
    this content into a more interac
  name: All I
  position: 30072
- category: unknown
  confidence: medium
  context: language model players have something like this. So OpenAI also their mode
    is called Canvas. I think Grok ha
  name: So OpenAI
  position: 30617
- category: tech
  confidence: high
  context: nguage model players have something like this. So OpenAI also their mode
    is called Canvas. I think Grok ha
  name: Openai
  position: 30620
- category: tech
  confidence: high
  context: '? It can go do research and build apps. You know, Anthropic has a very
    popular version of this called Artifac'
  name: Anthropic
  position: 30828
- category: unknown
  confidence: medium
  context: 'tation. So it says Small Language Models in 2025: The Year of On-Device,
    Agentic, and Specialized AI. And th'
  name: The Year
  position: 31285
- category: unknown
  confidence: medium
  context: 'dels in 2025: The Year of On-Device, Agentic, and Specialized AI. And
    then the subhead is How Efficient, Powerful'
  name: Specialized AI
  position: 31321
- category: unknown
  confidence: medium
  context: ntic, and Specialized AI. And then the subhead is How Efficient, Powerful
    Models Are Moving From the Cloud to You
  name: How Efficient
  position: 31361
- category: unknown
  confidence: medium
  context: alized AI. And then the subhead is How Efficient, Powerful Models Are Moving
    From the Cloud to Your Pocket. That says Jordan Wilson
  name: Powerful Models Are Moving From
  position: 31376
- category: unknown
  confidence: medium
  context: ent, Powerful Models Are Moving From the Cloud to Your Pocket. That says
    Jordan Wilson, founder and host, Every
  name: Your Pocket
  position: 31421
- category: unknown
  confidence: medium
  context: e Moving From the Cloud to Your Pocket. That says Jordan Wilson, founder
    and host, Everyday AI, even put the webs
  name: Jordan Wilson
  position: 31444
- category: tech
  confidence: high
  context: these pops of colors. The main page had this like gradient, like it looks
    really, really good. Like this, es
  name: Gradient
  position: 32219
- category: unknown
  confidence: medium
  context: re is something. And this is one of those things. Remember I said this
    little thing got swept under the rug? A
  name: Remember I
  position: 32798
- category: big_tech
  confidence: high
  context: The primary AI model used by the host for deep research and general interaction.
  name: Google Gemini
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: The platform used to build and prototype AI applications, currently free
    to use.
  name: Google AI Studio
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: The developer of Gemini and AI Studio, and the sponsor of the podcast segment.
  name: Google
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as a platform the host previously used to pull information from
    documents.
  name: ChatGPT
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as a research tool the host uses, noting its significant improvement
    over time.
  name: Perplexity
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: The specific, powerful model version referenced that powers the deep research
    feature.
  name: Google Gemini 2.5 Pro
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Google's small language model, mentioned as potentially the best in its
    class.
  name: Gemma 3n
  source: llm_enhanced
- category: ai_research
  confidence: medium
  context: A platform used for blind taste tests/benchmarking models.
  name: LM Arena
  source: llm_enhanced
- category: big_tech
  confidence: medium
  context: A Google event mentioned in passing regarding the timing of a model update.
  name: Google I/O
  source: llm_enhanced
- category: big_tech
  confidence: medium
  context: A Google event where the deep research feature was updated in April.
  name: Cloud Next
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: The URL/platform where users can access Gemini features.
  name: Gemini.google
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: The application where the V.O.3 video generation model is accessible.
  name: Gemini app
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Google's AI model, mentioned in relation to deep research and used within
    Google AI Studio.
  name: Gemini
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: The specific, new version of the Gemini model being used in AI Studio.
  name: Gemini 2.5 Pro preview 605
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Used as a grounding source within Google AI Studio to provide up-to-date
    information.
  name: Google Search
  source: llm_enhanced
- category: big_tech
  confidence: medium
  context: The application used to export the research PDF generated by Gemini.
  name: Google Docs
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: A website cited by the AI model as a source during its research/grounding
    process.
  name: customgpt.ai
  source: llm_enhanced
- category: ai_company
  confidence: high
  context: Mentioned as a major player in the LLM space, specifically noting their
    Canvas mode.
  name: OpenAI
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: Mentioned as having its own version of a canvas/app-building mode.
  name: Grok
  source: llm_enhanced
- category: ai_company
  confidence: high
  context: Mentioned for having a popular version of the canvas/app-building feature
    called Artifacts.
  name: Anthropic
  source: llm_enhanced
- category: big_tech
  confidence: medium
  context: Mentioned indirectly through their 'Microsoft 5 models' (likely referring
    to Phi or similar small models) that were updated.
  name: Microsoft
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: Mentioned as the tool the speaker usually uses to create slides, contrasting
    with the AI-generated presentation.
  name: Canva
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: Referenced in the context of embedding AI capabilities (like 'Deeper Dive')
    into the generated presentation.
  name: Gemini API
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: The name of the podcast/host's brand, mentioned in the generated presentation
    output.
  name: Everyday AI
  source: llm_enhanced
date: 2025-06-11 14:00:00 +0000
duration: 44
has_transcript: false
layout: episode
llm_enhanced: true
original_url: https://pscrb.fm/rss/p/www.buzzsprout.com/2175779/episodes/17319084-ep-544-ai-magic-convert-outdated-content-into-engagement-gold.mp3
processing_date: 2025-10-05 10:36:07 +0000
quotes:
- length: 70
  relevance_score: 5
  text: So here on the outputs or the deliverables, here's what it's giving me
  topics: []
- length: 93
  relevance_score: 4
  text: Myself and my team, we've been using generative AI, large language models
    to create documents
  topics: []
- length: 38
  relevance_score: 3
  text: So here's what I'm trying to do, right
  topics: []
- length: 213
  relevance_score: 3
  text: And there are some other toggles here such as structured outputs, you know,
    if you want always Google Gemini or sorry, Google AI Studio to, you know, output
    something in a structured way, you can go and build that
  topics: []
- length: 70
  relevance_score: 3
  text: Google AI Studio is actually going to go through using computer vision
  topics: []
- length: 133
  relevance_score: 3
  text: You need to do a separate thing here because the deep research, I didn't say
    here's my old presentation, here's what I'm trying to do
  topics: []
- length: 184
  relevance_score: 3
  text: So if you've ever done anything in, you know, analytics and marketing content
    creation, business, you know, business intelligence, you probably do a lot of,
    you know, document juggling
  topics:
  - market
- impact_reason: 'Highlights a significant, cutting-edge application of AI: turning
    static content into interactive, functional software components, which is a major
    trend in content repurposing.'
  relevance_score: 10
  source: llm_enhanced
  text: We're literally going to embed live AI capabilities into this presentation.
    Yeah, we're essentially going to build a piece of AI software from an old document.
  topic: technical
- impact_reason: Provides a clear, actionable, multi-step workflow demonstrating advanced
    content modernization using specific Google tools.
  relevance_score: 10
  source: llm_enhanced
  text: I'm going to try to make this one a tight one. Here's exactly what we're going
    to learn. We're going to use AI Studio to transcribe a visual PDF presentation.
    We're going to perform a targeted deep research based on that content with Google
    Gemini. We're going to use AI Studio, Google's AI Studio to bring factual keyword,
    factual new life to an older presentation. And we're going to embed. Get this.
    We are literally going to embed live AI capabilities into this presentation.
  topic: technical
- impact_reason: Provides a strong, specific endorsement of Gemini 2.5 Pro's current
    state-of-the-art performance, referencing key industry benchmarks (LM Arena).
  relevance_score: 10
  source: llm_enhanced
  text: Google updated their deep research in April with Google Gemini 2.5 Pro. This
    is by all really measurements, the most powerful model in the world. Google even
    updated it last week, even though it was the most already the most powerful model
    in the world by almost every single benchmark imaginable, including blind, the
    kind of blind taste test that is LM Arena.
  topic: breakthroughs
- impact_reason: Excellent explanation of the hybrid nature of advanced models like
    Gemini 2.5 Pro—balancing speed with deliberate, strategic 'thinking' capabilities.
  relevance_score: 10
  source: llm_enhanced
  text: Think of that times a thousand, but the difference is this is using a thinking
    model. So Google Gemini 2.5 is obviously a hybrid model. So when it needs to think
    and go very slowly and plan like a smart researcher would, it will do that. When
    it needs to just be fast, it'll do that as well.
  topic: technical
- impact_reason: This describes a key architectural feature—hybridity—allowing the
    model to dynamically switch between slow, deliberate planning (reasoning) and
    fast execution, a significant advancement in efficiency and capability.
  relevance_score: 10
  source: llm_enhanced
  text: So Google Gemini 2.5 is obviously a hybrid model. So when it needs to think
    and go very slowly and plan like a smart researcher would, it will do that. When
    it needs to just be fast, it'll do that as well.
  topic: Technical insights
- impact_reason: 'This demonstrates sophisticated agentic behavior: research, followed
    by internal reflection/synthesis before proceeding, mimicking a human researcher''s
    workflow.'
  relevance_score: 10
  source: llm_enhanced
  text: it is actually first thinking about my very simple research prompt I gave
    it. And then it started to do a round of research. So it looks like it went to
    about 10 websites. And then after going to those 10 websites, it actually started
    to first reflect and think of the information that it found on those 10 websites
    first.
  topic: AI technology trends/Agentic AI
- impact_reason: Highlights the integration of Computer Vision (CV) and Optical Character
    Recognition (OCR) capabilities directly into the LLM workflow, moving beyond simple
    text processing.
  relevance_score: 10
  source: llm_enhanced
  text: This PDF is a bunch of images, right? So it's literally going to use computer
    vision, go through and grab all of this text. A lot of this information... it's
    going to use computer vision to grab all this as well.
  topic: Technical breakthroughs (Multimodality)
- impact_reason: This underscores the extreme volatility and rapid iteration cycle
    in state-of-the-art LLMs. It serves as a warning that established prompt engineering
    techniques can break quickly as models are updated, necessitating continuous testing.
  relevance_score: 10
  source: llm_enhanced
  text: even this version of Gemini 2.5 Pro preview, the 605 version, it behaves much
    differently than the version that was released a month ago, the 506, and it's
    different. You're difficult, right? May 6th versus June 5th, it behaves differently.
  topic: technical
- impact_reason: 'This prediction, derived from the AI''s generated title, highlights
    key anticipated vectors for future SLM development: moving to the edge (On-Device),
    increased autonomy (Agentic), and domain specificity (Specialized AI).'
  relevance_score: 10
  source: llm_enhanced
  text: 'It essentially created an interactive presentation so it says Small Language
    Models in 2025: The Year of On-Device, Agentic, and Specialized AI.'
  topic: predictions
- impact_reason: 'This details a specific, powerful implementation of embedded AI
    agents within documents: context-aware summarization and on-demand deep-dive research
    linked directly to slide content.'
  relevance_score: 10
  source: llm_enhanced
  text: Summarize Slide. Click this to get a concise AI-generated summary of the key
    points on the current slide. And then it says Deeper Dive. This button uses the
    slide's headline to ask the Gemini API for more detailed information.
  topic: technical
- impact_reason: A provocative statement challenging the common assumption that merely
    using AI equals optimal efficiency, setting up the core theme of the episode.
  relevance_score: 9
  source: llm_enhanced
  text: if I'm using AI to do this, I'm doing it probably the correct way. And I'd
    argue you're probably not.
  topic: business
- impact_reason: Signals the introduction of a potentially overlooked but powerful
    new feature or technology (likely related to Google AI Studio/Gemini) that the
    audience needs to know about.
  relevance_score: 9
  source: llm_enhanced
  text: I think this new announcement from Google literally got swept under the rug,
    like no one's talking about this, and it's actually pretty amazing.
  topic: breakthroughs
- impact_reason: Directly addresses a massive pain point for knowledge workers and
    critiques the superficial adoption of AI tools without optimizing the underlying
    workflow.
  relevance_score: 9
  source: llm_enhanced
  text: How much time do you spend updating old documents or repurposing old content
    and you're using AI? And I think sometimes we fall into this false sense of security,
    like, oh, well, as long as I'm using AI at some part of the process, I'm probably
    being efficient.
  topic: business
- impact_reason: A strategic insight on the future of knowledge presentation, moving
    from static documents to interactive, AI-enhanced experiences.
  relevance_score: 9
  source: llm_enhanced
  text: Do you want to make it interactive, right? That's another thing with generative
    AI. I think we have to relook at how we present information, whether that's internally
    or externally. Right. I think so many things that even used to be boring PowerPoints,
    right, they can be interactive websites.
  topic: predictions
- impact_reason: Illustrates the crucial step of synthesis and reflection in advanced
    AI research, moving beyond simple data aggregation.
  relevance_score: 9
  source: llm_enhanced
  text: And then after going to those 10 websites, it actually started to first reflect
    and think of the information that it found on those 10 websites first.
  topic: technical
- impact_reason: This sets a high bar for the current state-of-the-art model being
    discussed (implied to be Gemini 2.5), highlighting its superior performance validated
    by community benchmarks like LM Arena.
  relevance_score: 9
  source: llm_enhanced
  text: it was the most already the most powerful model in the world by almost every
    single benchmark imaginable, including blind, the kind of blind taste test that
    is LM Arena.
  topic: technical/benchmarking
- impact_reason: Highlights that advanced agentic behavior is becoming accessible
    with simpler prompting, lowering the barrier to entry for complex, multi-step
    tasks.
  relevance_score: 9
  source: llm_enhanced
  text: it is agentic in its nature, right? So I didn't have to do a lot of tricky
    prompting in order for it to accomplish this level of research.
  topic: AI technology trends
- impact_reason: Explains the practical function of Retrieval-Augmented Generation
    (RAG) within the Google ecosystem, emphasizing the combination of internal model
    knowledge and external web data.
  relevance_score: 9
  source: llm_enhanced
  text: We're going to toggle on this grounding with Google Search. So all that means
    is, yes, we're telling Google AI Studio, hey, you can go use the web as well as
    the model that you're using in any information that you're going to be inputting.
  topic: Technical insights/RAG
- impact_reason: Articulates a universal pain point for knowledge workers—dealing
    with outdated, un-sourced legacy documents—which AI is now positioned to solve.
  relevance_score: 9
  source: llm_enhanced
  text: how many times have you been handed a presentation, a document, right, and
    it's your job to update this now? And you're like, who put this together two years
    ago? ... no one knows, right? And you're like, oh, great, what am I supposed to
    do?
  topic: Predictions/Impact on industries
- impact_reason: 'Defines the core value proposition of advanced agentic AI: identifying
    knowledge gaps and performing targeted, time-sensitive research to update stale
    information.'
  relevance_score: 9
  source: llm_enhanced
  text: This is something that so many knowledge workers spend so much time. But I'm
    telling you, you need to go find the gaps. And then you need to go addition, go
    do additional research that's just information from May 2025 to June 2025 to understand
    the current state...
  topic: Business advice/Productivity
- impact_reason: 'Crucial advice for effective LLM interaction: monitor the Chain
    of Thought (CoT) to catch deviations early, even if the model attempts to self-correct
    later.'
  relevance_score: 9
  source: llm_enhanced
  text: You should be reading the chain of thought or the summary chain of thought
    here, right? So you can understand what the model is doing. And a lot of times
    what you'll see is it's going to start to do something. You're going to be like,
    wait, that's not exactly what I wanted it to do, right? And it's still going to
    kind of finish the task and adjust on the fly.
  topic: Practical lessons/Prompt Engineering
- impact_reason: 'This highlights a critical workflow for leveraging LLMs: using them
    not just for generation, but for identifying knowledge gaps and proactively seeking
    external, up-to-date information to fill those gaps, emphasizing the need for
    grounding in current data.'
  relevance_score: 9
  source: llm_enhanced
  text: you need to go find the gaps. And then you need to go addition, go do additional
    research that's just information from May 2025 to June 2025 to understand the
    current state and clarify any questions you have.
  topic: strategy
- impact_reason: This describes the power of Retrieval-Augmented Generation (RAG)
    integrated with agentic workflows—the model acts as an autonomous researcher tasked
    with verification and gap-filling, moving beyond simple summarization.
  relevance_score: 9
  source: llm_enhanced
  text: I see it also by grounding Google AI Studio in Google Search and went out
    and filled the gaps because that's important. Right? Because I almost like it
    was like handing it off to another assistant. It was handing it off to another
    person, be like, yo, here's a bunch of work. You need to double-check everything.
    You need to find the gaps and then you need to go out there and explore and find
    the gaps.
  topic: strategy
- impact_reason: 'This identifies a major emerging trend: ''Canvas'' or ''Labs'' modes
    across major LLM platforms, signifying a move from text-in/text-out to visual,
    code-generating, and application-building interfaces.'
  relevance_score: 9
  source: llm_enhanced
  text: So this is now we have canvas mode inside Google Gemini. So if you don't know
    canvas mode, you know, a lot of the big large language model players have something
    like this. So OpenAI also their mode is called Canvas. I think Grok has their
    version. Perplexity has Labs, which is kind of different, kind of the same in
    some ways, right? It can go do research and build apps.
  topic: AI technology trends
- impact_reason: Highlights the potential impact of seamlessly embedding AI capabilities
    (like Q&A agents) directly into productivity outputs (presentations), suggesting
    this feature is vastly underestimated by the broader tech community.
  relevance_score: 9
  source: llm_enhanced
  text: And guess what? With Google Gemini, one click. So it's very small. This is
    one of those features. I wish that Google literally just did a full like keynote
    presentation about this at I/O. It was part of their presentation, but it should
    have been like a main feature. This is wild.
  topic: AI technology trends
- impact_reason: Points to the semantic shift in the definition of 'Small Language
    Models' (SLMs) as models become more capable, suggesting that size metrics are
    becoming less relevant than efficiency and specialization.
  relevance_score: 9
  source: llm_enhanced
  text: redefining the small in small language models. This is good. Right? Because
    it's saying, you know, how the definition has evolved of what a small language
    model even is, which is, you know, super interesting with some of the more recent
    small language models.
  topic: AI technology trends
- impact_reason: Emphasizes the extreme velocity of AI development, suggesting that
    even expert users must constantly adapt their workflows.
  relevance_score: 8
  source: llm_enhanced
  text: I feel that there are so many new features that the big AI companies have
    rolled out in the last just like last two months alone that have honestly kind
    of even challenged me for someone that's, like I said, I've used generative AI
    since 2020.
  topic: technology trends
- impact_reason: 'Crucial business insight: the advanced techniques discussed are
    accessible with free or low-cost tools, lowering the barrier to entry for adoption.'
  relevance_score: 8
  source: llm_enhanced
  text: And the crazy thing is most of this can be done even if you don't even have
    a paid account, right? But even if you just have the basic Google Gemini Pro plan,
    you know, $20 a month or if you're a student, it's literally free for the next
    year.
  topic: business
- impact_reason: Describes the 'planning' or 'thinking' phase of advanced LLM research
    tools, highlighting a key difference from older, purely reactive search tools.
  relevance_score: 8
  source: llm_enhanced
  text: Google Gemini is creating a plan on how it's going to do deep research. I'm
    going to have to approve the plan and then we'll I'll be able to talk through
    that once we get actually just let me tell you the prompt right now.
  topic: technical
- impact_reason: Offers a nuanced opinion on the best SLM (Gemma 3) while praising
    Gemini's strength in comprehensive, multi-source web research, showing an understanding
    of the model ecosystem.
  relevance_score: 8
  source: llm_enhanced
  text: Even though I think Google's Gemma 3, Gemma's Gemma 3n is the best small language
    model, it's actually looking at information from all across the web.
  topic: technical
- impact_reason: A crucial business/strategy warning for developers relying on Google
    AI Studio, suggesting the current free access model is temporary.
  relevance_score: 8
  source: llm_enhanced
  text: I say right now because there are rumblings on the internet that, you know,
    Google is eventually just going to move away from this kind of free model and
    you're going to have to use your own API key.
  topic: Business advice/Strategy
- impact_reason: 'Indicates a positive trend in developer tooling: platforms designed
    for experts are rapidly improving UX to accommodate beginners.'
  relevance_score: 8
  source: llm_enhanced
  text: over the last six months, a lot of the features, the user interface, the user
    experience, it's actually made it a lot more beginner friendly.
  topic: Business/Strategy (Product UX)
- impact_reason: A clear, concise explanation of the 'temperature' parameter, essential
    knowledge for anyone using LLM APIs or studios.
  relevance_score: 8
  source: llm_enhanced
  text: There's something temperature, that's essentially the creativity. So you can
    turn that down, and it, you know, it's going to kind of take away the creativity,
    or you can turn it up, it's going to be more creative.
  topic: Technical insights
- impact_reason: Quantifies the manual labor (thousands of hours) that complex knowledge
    synthesis tasks require, setting up the contrast for how much time AI can save.
  relevance_score: 8
  source: llm_enhanced
  text: This is someone again, this I've spent thousands of hours in my life doing
    this, essentially combining, you know, two to three documents and then doing additional
    research to fill on those gaps.
  topic: Business impact/Productivity
- impact_reason: A direct observation on the current capabilities of multimodal LLMs
    (like Gemini 2.5 Pro) regarding document understanding, specifically transcription
    and analysis of long, complex inputs.
  relevance_score: 8
  source: llm_enhanced
  text: Today's large language models are extremely impressive at their ability to
    accurately be able to see and analyze and create transcripts from very long PDFs.
  topic: technical
- impact_reason: This outlines a future workflow where content creation is immediately
    followed by transformation into interactive, AI-enhanced formats, suggesting a
    shift away from static presentation decks.
  relevance_score: 8
  source: llm_enhanced
  text: The last step that we're going to do, two steps. We're going to turn this
    into an interactive presentation and then we're going to add AI.
  topic: predictions
- impact_reason: A direct observation of how modern LLM interfaces are leveraging
    underlying code generation capabilities to create functional, complex outputs
    (like an interactive website/presentation) from natural language input.
  relevance_score: 8
  source: llm_enhanced
  text: But essentially what's happening on my screen right now is I pasted in all
    this information and it's building something with code.
  topic: technical
- impact_reason: Emphasizes the importance of verifiable AI outputs through citation
    and click-through capability, which is crucial for trust and adoption in professional
    settings.
  relevance_score: 8
  source: llm_enhanced
  text: I can see according to the citations in here by looking at the kind of the
    outputs is I can always click on this information.
  topic: safety/strategy
- impact_reason: Establishes the host's deep, long-term experience with generative
    AI, lending credibility to the subsequent advice.
  relevance_score: 7
  source: llm_enhanced
  text: I've spent thousands of hours of my life using AI to create documents, which
    is kind of wild when you think about it, but yeah, I actually did the math since
    2020.
  topic: strategy
- impact_reason: Manages expectations by focusing on accessible, practical steps rather
    than complex, enterprise-level automation, making the advice widely applicable.
  relevance_score: 7
  source: llm_enhanced
  text: I want you to look at the process we're going to go over today. You know,
    it's not fully automated, right? I'm not going to sit here and build an automated
    workflow and, you know, with, you know, a genetic AI sprinklings. I want to do
    something very simple, very basic. You don't need to even have any experience.
  topic: strategy
- impact_reason: Provides a concrete example of content obsolescence in a fast-moving
    field (SLMs), illustrating the necessity of the modernization process being taught.
  relevance_score: 7
  source: llm_enhanced
  text: 'I did an episode called Small Language Models: What They Are and Do We Need
    Them? I believe this was I should have looked this up, probably about two years
    ago, maybe a year and a half ago. So what I''m trying to say is I want to do a
    new presentation, I want to do a new episode on small language models. And this
    is, you know, the outline is pretty good, but I know a lot of it''s going to be
    old.'
  topic: technology trends
- impact_reason: A practical tip for users dealing with long-running AI processes,
    acknowledging a common UI/UX issue across major platforms and offering a troubleshooting
    solution (refreshing).
  relevance_score: 7
  source: llm_enhanced
  text: I do find and this is not just with Google Gemini, same thing with ChatGPT,
    other platforms, sometimes the deep research looks like they stall out, but it
    actually doesn't.
  topic: Practical lessons
- impact_reason: A final, strong piece of advice emphasizing that iterative testing
    and monitoring (reading the CoT) is the only path to mastery in using LLMs.
  relevance_score: 7
  source: llm_enhanced
  text: This is the only way that you're going to get better working at large language
    models.
  topic: Practical lessons
- impact_reason: A fundamental caution about the non-deterministic nature of generative
    AI, reminding users that consistency requires careful prompting and validation,
    even with advanced models.
  relevance_score: 7
  source: llm_enhanced
  text: The thing with generative AI all is it's generative. It's a role of the dice.
    It's going to be a little bit different each and every time.
  topic: safety/strategy
- impact_reason: Demonstrates the rapid advancement in AI's ability to handle complex
    visual design and aesthetics, moving beyond basic layouts to professional-grade
    presentation quality.
  relevance_score: 7
  source: llm_enhanced
  text: This looks like a designer, like an actual designer made it. There's literally
    a gradient layer across the text. It looks really, really good.
  topic: AI technology trends
- impact_reason: An anecdotal expression emphasizing the immense, perhaps unsustainable,
    value provided by the free tier of the platform.
  relevance_score: 6
  source: llm_enhanced
  text: I feel criminal how much I've been using Google AI Studio.
  topic: Business advice
- impact_reason: This sets up a comparison, implying that the integrated, context-aware
    AI features demonstrated are superior to previous, siloed AI tools.
  relevance_score: 6
  source: llm_enhanced
  text: think of all the different AI tools that you've used before, right? A lot
    of them, you...
  topic: strategy
source: Unknown Source
summary: "## Podcast Summary: EP 544: AI Magic - Convert Outdated Content into Engagement\
  \ Gold\n\nThis episode of The Everyday AI Show, hosted by Jordan Moulson, focuses\
  \ on a powerful, yet under-discussed, application of generative AI: **transforming\
  \ and modernizing outdated internal or external content (like presentations and\
  \ documents) into highly engaging, interactive assets.** The host argues that many\
  \ knowledge workers are using AI inefficiently, often performing manual steps even\
  \ when using AI tools. This episode introduces a \"live demo\" workflow, part of\
  \ a new weekly segment called \"Put AI to Work Wednesdays,\" showcasing how to leverage\
  \ recent advancements, particularly within the Google ecosystem, to automate this\
  \ repurposing process.\n\nThe core narrative arc follows the host as he attempts\
  \ to update a nearly two-year-old presentation on \"Small Language Models\" into\
  \ a modern, factually current, and interactive asset. The process involves chaining\
  \ together several powerful AI capabilities to achieve what used to require significant\
  \ manual document juggling and research.\n\n### Key Discussion Points & Workflow:\n\
  \n1.  **Identifying the Problem:** Knowledge workers waste hundreds of hours annually\
  \ updating old documents. Simply using AI somewhere in the process doesn't guarantee\
  \ efficiency; many manual steps remain.\n2.  **The Goal:** Convert an old, static\
  \ PDF presentation into a new, interactive piece of content that is factually current,\
  \ using AI to fill knowledge gaps.\n3.  **Step 1: Deep Research (Google Gemini):**\
  \ The host initiates a **Deep Research** task using Google Gemini (powered by Gemini\
  \ 2.5 Pro). He highlights that this feature is significantly improved (post-April\
  \ updates) and acts agentically, planning research, executing searches across multiple\
  \ sources, reflecting on findings, and iteratively deepening the research until\
  \ satisfied. The goal here is to generate a comprehensive, up-to-date research document\
  \ (PDF) on the topic.\n4.  **Step 2: Content Transformation (Google AI Studio):**\
  \ The host moves to **Google AI Studio**, noting that while technically for developers,\
  \ its UX is becoming increasingly beginner-friendly and it remains free (though\
  \ API key usage might be the future).\n5.  **Chaining Inputs:** Within AI Studio,\
  \ the host uploads two key documents: the **outdated presentation PDF** and the\
  \ **new research PDF** generated by Gemini Deep Research.\n6.  **AI Magic - Multi-Step\
  \ Prompting:** The core instruction set given to Gemini 2.5 Pro in AI Studio involves\
  \ four critical actions:\n    *   **Transcription:** Use computer vision (OCR) to\
  \ verbatim transcribe the old presentation PDF, even if it's composed of image screenshots.\n\
  \    *   **Gap Analysis:** Analyze the old transcription against the new research\
  \ document to identify missing or outdated information.\n    *   **Targeted Extension:**\
  \ Conduct *additional* targeted web research (grounded via Google Search toggle)\
  \ specifically focusing on the most recent data (e.g., May/June 2025) to fill the\
  \ identified gaps.\n    *   **Final Output:** Update the presentation outline *in\
  \ its entirety* based on the transcription, the initial research, and the new, targeted\
  \ web findings, effectively creating a brand-new, current presentation outline.\n\
  7.  **The Implication:** This process turns static documents into dynamic software-like\
  \ outputs, embedding live AI capabilities into the resulting content structure,\
  \ making the final product interactive and far more engaging than a traditional\
  \ slide deck.\n\n---\n\n### Summary Analysis:\n\n| Category | Insight |\n| :---\
  \ | :--- |\n| **1. Focus Area** | Practical application of advanced LLMs (specifically\
  \ Google Gemini 2.5 Pro) for **content lifecycle management, document modernization,\
  \ and interactive asset creation** using Google AI Studio. |\n| **2. Key Technical\
  \ Insights** | 1. **Agentic Deep Research:** Gemini's research capability iteratively\
  \ plans, executes, reflects, and deepens searches without extensive manual prompting.\
  \ 2. **Multimodal Input Processing:** The ability of the model within AI Studio\
  \ to accurately transcribe text from image-heavy PDFs using computer vision/OCR.\
  \ 3. **Chained Task Execution:** Successfully instructing a single model instance\
  \ to perform sequential, complex tasks: transcribe, analyze gaps, research externally,\
  \ and synthesize a final updated document. |\n| **3. Business/Investment Angle**\
  \ | 1. **Productivity Leap:** Significant time savings for knowledge workers involved\
  \ in compliance updates, handbook revisions, or content refreshes. 2. **Content\
  \ Value Maximization:** Outdated content is not discarded but resurrected and enhanced,\
  \ maximizing ROI on past creation efforts. 3. **Ecosystem Lock-in:** The demonstration\
  \ heavily favors the Google stack (Gemini, AI Studio), suggesting strong momentum\
  \ for their developer and enterprise tools. |\n| **4. Notable Companies/People**\
  \ | **Jordan Moulson** (Host, Everyday AI); **Google Gemini** (specifically 2.5\
  \ Pro and its Deep Research feature); **Google AI Studio** (the platform used for\
  \ chaining inputs and outputs). |\n| **5. Future Implications** | The industry is\
  \ moving toward **AI-native content creation**, where documents are not static files\
  \ but dynamic interfaces capable of self-updating and interacting with the user\
  \ or external data sources. The barrier to creating sophisticated, AI-enhanced applications\
  \ from simple documents is rapidly dropping. |\n| **6. Target Audience** | **Knowledge\
  \ Workers, Content Strategists, Marketing Professionals, and AI Practitioners**\
  \ who need actionable, real-world workflows to improve efficiency and modernize\
  \ existing corporate assets. |"
tags:
- artificial-intelligence
- generative-ai
- startup
- google
- microsoft
- openai
- anthropic
title: 'EP 544: AI Magic - Convert Outdated Content into Engagement Gold'
topics:
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 126
  prominence: 1.0
  topic: artificial intelligence
- keywords:
  - generative ai
  - genai
  - chatgpt
  - gpt
  - claude
  - text generation
  - image generation
  mentions: 11
  prominence: 1.0
  topic: generative ai
- keywords:
  - startup
  - entrepreneur
  - founder
  - venture
  mentions: 1
  prominence: 0.1
  topic: startup
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-10-05 10:36:07 UTC -->
