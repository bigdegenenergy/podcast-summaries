---
companies:
- category: unknown
  confidence: medium
  context: o it as well, which is quite surprising. Today on Training Data, we're
    joined by Block CTO, Donji Prasana. Earlie
  name: Training Data
  position: 574
- category: unknown
  confidence: medium
  context: rprising. Today on Training Data, we're joined by Block CTO, Donji Prasana.
    Earlier this year, Block released
  name: Block CTO
  position: 605
- category: unknown
  confidence: medium
  context: oday on Training Data, we're joined by Block CTO, Donji Prasana. Earlier
    this year, Block released Goose, which i
  name: Donji Prasana
  position: 616
- category: unknown
  confidence: medium
  context: for you. Goose is used widely for everything from Jack Dorsey's first web
    of BitChat to non-engineers vibe codi
  name: Jack Dorsey
  position: 798
- category: unknown
  confidence: medium
  context: s, but if you build bombs with it, it's terrible. So I think AI is very
    similar in that regard. It has a
  name: So I
  position: 2128
- category: unknown
  confidence: medium
  context: to do a lot of good. We've already seen that with Alpha Fold and all of
    the great things similar to that, but
  name: Alpha Fold
  position: 2250
- category: unknown
  confidence: medium
  context: ds on who's holding it and what their purpose is. But I was thinking about
    it specifically for us at Bloc
  name: But I
  position: 2468
- category: unknown
  confidence: medium
  context: . Absolutely. Our two main pillars are Square and Cash App. So Square serves
    merchants and sellers. And Cash
  name: Cash App
  position: 4463
- category: unknown
  confidence: medium
  context: ly. Our two main pillars are Square and Cash App. So Square serves merchants
    and sellers. And Cash App serves
  name: So Square
  position: 4473
- category: unknown
  confidence: medium
  context: Cash App. So Square serves merchants and sellers. And Cash App serves consumers
    as a financial services app. And
  name: And Cash App
  position: 4513
- category: unknown
  confidence: medium
  context: e industry and is also energy and cost efficient. And I believe we've done
    that with RIG. So it's an impr
  name: And I
  position: 5190
- category: unknown
  confidence: medium
  context: the other half he did end up hiring me. No good. Did Goose and punish?
    Well, with the other components of th
  name: Did Goose
  position: 8167
- category: unknown
  confidence: medium
  context: And I worked very closely with Brian, who was our Cash App CEO and Jack
    to help create this separation. And a lo
  name: Cash App CEO
  position: 10092
- category: unknown
  confidence: medium
  context: ingular organizational focus is really important. And Jack was a huge proponent
    of that view as well. Have y
  name: And Jack
  position: 10605
- category: unknown
  confidence: medium
  context: the UI. And it is built using what's known as the Model Context Protocol
    or the MCP, which you might have heard of. And Go
  name: Model Context Protocol
  position: 12971
- category: unknown
  confidence: medium
  context: otocol or the MCP, which you might have heard of. And Goose was one of
    the earliest adopters of the MCP. And
  name: And Goose
  position: 13037
- category: tech
  confidence: high
  context: s. So all of our existing systems, be it Gmail or Google Docs, be it Square
    Payments, any of these things,
  name: Google
  position: 13360
- category: unknown
  confidence: medium
  context: s. So all of our existing systems, be it Gmail or Google Docs, be it Square
    Payments, any of these things, and
  name: Google Docs
  position: 13360
- category: unknown
  confidence: medium
  context: isting systems, be it Gmail or Google Docs, be it Square Payments, any
    of these things, and orchestrate workflows b
  name: Square Payments
  position: 13379
- category: tech
  confidence: high
  context: we did in Q3. And then it goes away. It looks in Snowflake, pulls out the
    data. It might look in Looker, Tab
  name: Snowflake
  position: 13601
- category: unknown
  confidence: medium
  context: . And then it can deliver all of that as a PDF or Google Doc and even email
    it for you. So this is kind of giv
  name: Google Doc
  position: 13812
- category: unknown
  confidence: medium
  context: s developed by one of our engineers whose name is Brad Axen. And he had
    been developing this thesis that agen
  name: Brad Axen
  position: 14677
- category: unknown
  confidence: medium
  context: ve their weight. Why is it called Goose? That's a Top Gun reference. So
    it is. I wasn't sure. Brad looks, h
  name: Top Gun
  position: 14971
- category: unknown
  confidence: medium
  context: s laptop. So we have this really cool tool called Headless Goose. And it
    runs, for example, in our CI pipeline. An
  name: Headless Goose
  position: 20148
- category: unknown
  confidence: medium
  context: e. We were using BitChat yesterday. It's amazing. Was Goose built on Goose?
    Yeah, it was the initial version
  name: Was Goose
  position: 21681
- category: unknown
  confidence: medium
  context: literally everything he does, including Slack or Google Meet calls, everything
    in between. And it intervenes f
  name: Google Meet
  position: 22587
- category: unknown
  confidence: medium
  context: use cases, they like the Cloud family of models. And GPT-4 is now getting
    pretty close in capability as we
  name: And GPT
  position: 27142
- category: unknown
  confidence: medium
  context: if I want to know some historical fact about the Soviet Union, it's going
    to tell me that instantly. But if I a
  name: Soviet Union
  position: 28312
- category: unknown
  confidence: medium
  context: g, I fully expect that number to keep ticking up. So Block has a long history
    of participating in the open s
  name: So Block
  position: 29676
- category: unknown
  confidence: medium
  context: open source contribution. So I used to work with Bob Lee, who was our CTO
    before me, our first CTO. And it
  name: Bob Lee
  position: 30587
- category: unknown
  confidence: medium
  context: that don't have the same level of competition as Silicon Valley, for example.
    And we were very early to tap into
  name: Silicon Valley
  position: 38320
- category: unknown
  confidence: medium
  context: sit there and come up with something on your own. The LLMs are surprisingly
    good at writing performance code
  name: The LLMs
  position: 41222
- category: unknown
  confidence: medium
  context: or that, you definitely need manual intervention. Where I think humans
    are called for is in the higher-leve
  name: Where I
  position: 41626
- category: unknown
  confidence: medium
  context: nd there's different numbers for different teams. Like I said, engineers
    in the most engaged engineers wit
  name: Like I
  position: 43665
- category: unknown
  confidence: medium
  context: plex and difficult for agents to work with. Yeah. As I told you before,
    in AI-first teams, it's pretty m
  name: As I
  position: 43891
- category: unknown
  confidence: medium
  context: teams, it's pretty much all entirely vibe coded. So Goose itself, every
    PR that is open is written by Goose
  name: So Goose
  position: 43974
- category: ai_application
  confidence: high
  context: The company whose CTO is being interviewed; they are developing the AI
    agent Goose and transforming their organization to be AI-first.
  name: Block
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Block's open-source, extensible general-purpose AI agent built using the
    Model Context Protocol (MCP).
  name: Goose
  source: llm_enhanced
- category: ai_research
  confidence: medium
  context: Mentioned as an example of AI doing great things, likely referencing the
    DeepMind project.
  name: Alpha Fold
  source: llm_enhanced
- category: ai_infrastructure
  confidence: medium
  context: A data system mentioned as a source Goose pulls data from for reporting.
  name: Snowflake
  source: llm_enhanced
- category: ai_infrastructure
  confidence: medium
  context: A system mentioned that Goose might query for data visualization/reporting.
  name: Looker
  source: llm_enhanced
- category: ai_infrastructure
  confidence: medium
  context: A system mentioned that Goose might query for data visualization/reporting.
  name: Tableau
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: An existing tool Goose can connect to via formalized wrappers (MCP).
  name: Gmail
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: An existing tool Goose can connect to via formalized wrappers (MCP).
  name: Google Docs
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: Mentioned as an enterprise system (for customer management) that Block
    is integrating AI capabilities with.
  name: Salesforce
  source: llm_enhanced
- category: ai_infrastructure
  confidence: low
  context: The platform where the CTO made an early commit to Block's code.
  name: GitHub
  source: llm_enhanced
- category: ai_application
  confidence: low
  context: An open-source initiative by Block to help users securely hold Bitcoin.
  name: Bitkey
  source: llm_enhanced
- category: ai_application
  confidence: low
  context: Block's initiative to build energy-efficient Bitcoin mining hardware.
  name: RIG
  source: llm_enhanced
- category: ai_application
  confidence: low
  context: Block's music streaming service.
  name: Tidal
  source: llm_enhanced
- category: ai_application
  confidence: low
  context: One of Block's main business pillars, serving merchants.
  name: Square
  source: llm_enhanced
- category: ai_application
  confidence: low
  context: One of Block's main business pillars, serving consumers.
  name: Cash App
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Used as an analogy for the application interface of Goose.
  name: ChatGPT
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: A Goose-inspired tool running in CI pipelines to automatically fix vulnerability
    tickets.
  name: Headless Goose
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: A decentralized chat application built initially using Goose.
  name: BitChat
  source: llm_enhanced
- category: ai_technology
  confidence: high
  context: General term for Large Language Models, used frequently as the underlying
    'brain' for Goose.
  name: LLM
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: Mentioned as an open source provider that Goose has plugins to support.
  name: Ollama
  source: llm_enhanced
- category: ai_model
  confidence: high
  context: Mentioned as an open source LLM model used by privacy-conscious users.
  name: Qwen
  source: llm_enhanced
- category: ai_model
  confidence: high
  context: Mentioned as an open source LLM model used by privacy-conscious users.
  name: DeepSeek
  source: llm_enhanced
- category: ai_model
  confidence: medium
  context: Mentioned as models preferred by users for coding use cases.
  name: Cloud family of models
  source: llm_enhanced
- category: ai_model
  confidence: high
  context: Mentioned as a proprietary model whose capability is getting close to others
    in certain areas.
  name: GPT-4
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: Mentioned as the source of a reporter/study suggesting big companies aren't
    benefiting much from AI.
  name: MIT
  source: llm_enhanced
- category: investment_firm
  confidence: high
  context: Venture capital firm mentioned as being inspired by a conversation to start
    an open source fellowship.
  name: Sequoia
  source: llm_enhanced
- category: software_foundation
  confidence: medium
  context: Referenced in the lineage of open source commitment.
  name: GNU
  source: llm_enhanced
- category: ai_developer_company
  confidence: high
  context: A product/experiment from Block, mentioned alongside Goose.
  name: Proto
  source: llm_enhanced
date: 2025-09-30 09:00:00 +0000
duration: 60
has_transcript: false
insights:
- actionable: false
  confidence: medium
  extracted: how we realize utility from AI. And it turned out to be right. And we
    ringfenced him and gave him a team of six or seven people. And they've really
    punched above their weight. Why
  text: the future of how we realize utility from AI. And it turned out to be right.
    And we ringfenced him and gave him a team of six or seven people. And they've
    really punched above their weight. Why is it called Goose? That's a Top Gun reference.
  type: prediction
- actionable: false
  confidence: medium
  extracted: unlocking coding capability from these models
  text: the future of unlocking coding capability from these models is swarm intelligence.
  type: prediction
layout: episode
llm_enhanced: true
original_url: https://audio.listennotes.com/e/p/ac7a1c92c8fd4cbb8bc9857f268f50a9/
processing_date: 2025-10-06 05:26:27 +0000
quotes:
- length: 166
  relevance_score: 4
  text: It's, it's deep learning and the ability to do more than just classification
    or clustering or those common machine learning use cases that traditional ML was
    aimed at
  topics: []
- length: 159
  relevance_score: 4
  text: Have you had to embrace a different, almost product building mindset to build
    around LLMs and generative AI compared to how your developers are used to working
  topics: []
- length: 209
  relevance_score: 4
  text: But can you leverage open source model X because it's small enough and it's
    cheap enough to run 50, 60, 500, a thousand copies of and that accumulated capability
    is greater than any single large language model
  topics: []
- length: 286
  relevance_score: 4
  text: It could be a hierarchical swarm where you leverage some large language models,
    like some very capable models to do the planning for you or to do the reintegration
    for you and you break things down into very small, almost nano services that these
    simpler models can bite off and consume
  topics: []
- length: 188
  relevance_score: 4
  text: You mentioned at the beginning of our conversation that generative AI is the
    big difference between what you were doing with machine learning before and how
    you're hoping to embrace AI now
  topics: []
- length: 77
  relevance_score: 3
  text: So there's a lot of wild things that are, you have to have the stomach for
    it
  topics: []
- length: 48
  relevance_score: 3
  text: Yeah, you have to stop thinking like an engineer
  topics: []
- length: 83
  relevance_score: 3
  text: And you have to start thinking more like a data scientist for lack of a better
    term
  topics: []
- impact_reason: A striking example of AI-assisted development where the product (Goose)
    is actively building itself, illustrating the potential for self-improvement loops.
  relevance_score: 10
  source: llm_enhanced
  text: So the Goose team actually writing the vast majority of net new code for the
    Goose codebase itself. Talk about recursion.
  topic: technical
- impact_reason: Provides a concrete example of organizational restructuring (moving
    from GM/siloed to functional/centralized) specifically to enable deep technological
    focus required by seismic industry shifts like AI.
  relevance_score: 10
  source: llm_enhanced
  text: Progressively, we started to unwind our GM structure... And we brought them
    all together and actually adding our platform teams to that... made it that much
    more powerful and gave us a really strong springboard. So as we sort of centralized
    each part of the company, into a functional org structure, we drove engineering
    excellence, technical excellence, and we could unify policies.
  topic: strategy
- impact_reason: 'This is the core architectural insight: abstracting all business
    functions (internal and external) as ''capabilities'' accessed via an agent middleware
    layer (Goose). This is a blueprint for building an AI-native enterprise.'
  relevance_score: 10
  source: llm_enhanced
  text: We looked at Block, not as here's an enterprise and here's some tools and
    here's our products and here's our business. But everything is a capability at
    Block... And we treated the corporate side like that too... And then we put an
    agent middleware layer on top, so effectively Goose. And all our UIs are now evolving
    to talk to our capabilities through this agent layer.
  topic: technical/strategy
- impact_reason: Provides a clear, accessible definition of the Model Context Protocol
    (MCP) as the necessary abstraction layer (tool wrappers) for enabling agents to
    interact with enterprise systems.
  relevance_score: 10
  source: llm_enhanced
  text: Goose is built using what's known as the Model Context Protocol or the MCP,
    which you might have heard of. And the MCP is just a fancy way of saying, we're
    going to create a set of formalized wrappers for existing tools or capabilities
    and expose them to your AI agent.
  topic: technical
- impact_reason: 'This outlines a core architectural shift: treating all enterprise
    functions (like creating issues/PRs) as modular ''capabilities'' orchestrated
    by an agent middleware layer (Goose). This is a key pattern for next-generation
    enterprise software integration.'
  relevance_score: 10
  source: llm_enhanced
  text: So creating an issue, opening a PR, all of these are just capabilities. And
    then we put an agent middleware layer on top, so effectively Goose. And all our
    UIs are now evolving to talk to our capabilities through this agent layer. And
    that's unlocked an enormous amount of value.
  topic: technical/strategy
- impact_reason: A powerful insight into the democratization of software creation.
    Non-technical users gaining the ability to build complex tools (like dashboards)
    autonomously via agents.
  relevance_score: 10
  source: llm_enhanced
  text: We never expected our sales guy or our financial person to be writing software
    dashboards for themselves. But it turns out it's possible and it doesn't take
    long, it doesn't take much work to do.
  topic: predictions/business
- impact_reason: 'Addresses a major security concern: AI agent safety and scope. The
    agent''s actions are strictly bound by the user''s existing permissions, limiting
    the ''blast radius.'''
  relevance_score: 10
  source: llm_enhanced
  text: Goose acts as you. So it's not like a wild robot going off, running into our
    data centers and doing its own thing. It follows the same access controls that
    each user has. And so its blast radius is highly limited to any actions humans
    take or to that individual's authorization level.
  topic: safety/security
- impact_reason: This is a profound statement on self-improvement and recursive development
    in AI. The goal of 100% self-rewriting code points toward AGI development milestones.
  relevance_score: 10
  source: llm_enhanced
  text: We also use Goose to build Goose. So the vast majority of Goose's code is
    written by Goose. And so we almost fully bootstrapped it. There's still some human-written
    code in there that's at a level of complexity that Goose hasn't reached yet, but
    our goal is for it to be completely autonomous and for each release for it to
    rewrite itself 100% from scratch.
  topic: predictions/technical
- impact_reason: A perfect analogy distinguishing the LLM (the reasoning engine/brain)
    from the Agent Framework (the execution layer/arms and legs) necessary for real-world
    utility.
  relevance_score: 10
  source: llm_enhanced
  text: I would look at Goose as the arms and legs. If you think of the LLM as a brain
    in a jar, that's not capable of anything except chatting with you. Goose gives
    it arms and legs to go out and act in the real world.
  topic: technical/architecture
- impact_reason: Provides a concrete, measurable KPI for AI value realization in a
    corporate setting (25% manual hours saved is significant).
  relevance_score: 10
  source: llm_enhanced
  text: We have a metric internally, which we track on a weekly basis. And that metric
    is very simply manual hours saved by Goose. And that metric started at 0% and
    now it's going to hit probably 25% of manual hours saved by the end of the year.
  topic: business
- impact_reason: 'This is the most significant technical prediction: the shift from
    single-agent interaction (Copilot) to multi-agent collaboration (swarm intelligence)
    for complex tasks.'
  relevance_score: 10
  source: llm_enhanced
  text: But I really think the future of unlocking coding capability from these models
    is swarm intelligence. So it's not just one agent doing work with you in a sort
    of Copilot-y style way. It's how do you unlock 50 instances of the agent or 100
    instances of Goose or Geese, if you will, to go off and work with each other to
    build fairly complex applications?
  topic: predictions
- impact_reason: 'Articulates the core hypothesis for the success of open-source AI:
    collective, distributed capability (swarm) can overcome the raw performance gap
    of proprietary, monolithic models.'
  relevance_score: 10
  source: llm_enhanced
  text: So the competition may not be as open source model X as good as closed model
    Y. But can you leverage open source model X because it's small enough and it's
    cheap enough to run 50, 60, 500, a thousand copies of and that accumulated capability
    is greater than any single large language model?
  topic: strategy
- impact_reason: A powerful personal endorsement from a CTO that the AI coding era
    is already here for daily tasks, even for leadership.
  relevance_score: 10
  source: llm_enhanced
  text: I write code every day, and it's all through Goose. It's all through vibe
    code or through some of the other AI agents when I'm evaluating how good they
    go. So I very rarely manually write code.
  topic: technical
- impact_reason: 'Identifies a current key limitation of LLMs in coding: context window
    constraints prevent effective large-scale refactoring or modification of massive
    legacy codebases.'
  relevance_score: 10
  source: llm_enhanced
  text: I think that it's a difficult proposition the more complex the code goes.
    And this is why I think it's more effective to vibe code these smaller tools like
    dashboards and reports and interactive kind of systems on a per individual basis
    rather than make massive changes to 10 million line code bases.
  topic: technical
- impact_reason: 'Pinpoints a critical, persistent weakness of general-purpose LLMs:
    lack of knowledge regarding private, proprietary APIs and internal frameworks.'
  relevance_score: 10
  source: llm_enhanced
  text: Where they do fail is understanding how to call proprietary APIs, because
    these are not in the training set often. And especially if you have very complex
    proprietary frameworks, then they can struggle to reason about them. And for that,
    you definitely need manual intervention.
  topic: technical
- impact_reason: 'Clearly defines the enduring value proposition of human engineers:
    complex system architecture, concurrency management (race conditions), and cross-system
    orchestration.'
  relevance_score: 10
  source: llm_enhanced
  text: Where I think humans are called for is in the higher-level architectural design,
    in understanding race conditions and coordinating, orchestrating across multiple
    systems in a topology. Those kinds of things we definitely need people in the
    LLM for.
  topic: predictions
- impact_reason: Provides a concrete metric (30-40% code generation via AI) for highly
    engaged engineers working on complex legacy systems, offering a benchmark for
    current AI coding productivity.
  relevance_score: 10
  source: llm_enhanced
  text: Do you have a, and if you can't share us, okay, but I'm curious if you even
    look at how much of the code base is being written by Goose or being written by
    AI today and do a guess for how that might evolve over time. Yeah, we are measuring
    it. And there's different numbers for different teams. Like I said, engineers
    in the most engaged engineers with Goose probably generate about 30 to 40% of
    the code they write in existing legacy code bases...
  topic: technical
- impact_reason: 'Presents an aspirational future state: ''AI-first teams'' where
    the AI agent generates 100% of the code for new Pull Requests, indicating near-total
    automation for greenfield/AI-native projects.'
  relevance_score: 10
  source: llm_enhanced
  text: As I told you before, in AI-first teams, it's pretty much all entirely vibe
    coded. So Goose itself, every PR that is open is written by Goose.
  topic: predictions
- impact_reason: A strong testament to the emergent capabilities of AI agents when
    given autonomy, suggesting that human pre-configuration might limit potential.
  relevance_score: 9
  source: llm_enhanced
  text: We find that Goose is more capable than if you tried to figure out how to
    make a tool Goose friendly. So it figures things out in surprising ways that you
    wouldn't think of as a human. And it does it quicker than you might do it as well,
    which is quite surprising.
  topic: predictions/technical
- impact_reason: Provides a balanced, philosophical framework for viewing disruptive
    technology like AI, emphasizing human intent and governance over the technology
    itself.
  relevance_score: 9
  source: llm_enhanced
  text: AI is friend or is AI foe? Well, I have two answers to that. First of all,
    I think any new technology, you can think of nuclear energy as an analog. It really
    depends on who is developing it and to what purpose they're putting it.
  topic: safety/strategy
- impact_reason: 'A key strategic mindset for established companies facing technological
    disruption: viewing the core identity through a technology lens rather than a
    static industry lens.'
  relevance_score: 9
  source: llm_enhanced
  text: I've always thought of Block not as a financial services company, but as a
    technology company. So we've always been early to embrace whatever new technology
    there is and then figure out how best to serve our customers with it.
  topic: strategy
- impact_reason: Clearly delineates the shift from traditional ML (classification/clustering)
    to modern AI (generative AI/deep learning) based on capability.
  relevance_score: 9
  source: llm_enhanced
  text: I think generative AI is the difference, right? It's, it's deep learning and
    the ability to do more than just classification or clustering or those common
    machine learning use cases that traditional ML was aimed at.
  topic: technical
- impact_reason: 'Demonstrates the practical power of the agent architecture: seamless
    orchestration across disparate, legacy, and modern enterprise tools.'
  relevance_score: 9
  source: llm_enhanced
  text: Goose has been able to connect to all of our systems. So all of our existing
    systems, be it Gmail or Google Docs, be it Square Payments, any of these things,
    and orchestrate workflows between them completely on its own.
  topic: technical
- impact_reason: Defines Goose as a leading example of a general-purpose, open-source
    AI agent, emphasizing its accessibility (laptop install) and its reliance on the
    emerging Model Context Protocol (MCP).
  relevance_score: 9
  source: llm_enhanced
  text: Goose is a general purpose AI agent. So it's a program that you can download
    and use on your laptop. And it's got a UI. So you can either use it on a command
    line or in the UI. And it is built using what's known as the Model Context Protocol
    or the MCP.
  topic: technical/architecture
- impact_reason: Provides a clear, concise definition of the Model Context Protocol
    (MCP) as the standardization layer for connecting LLMs to external tools/APIs.
  relevance_score: 9
  source: llm_enhanced
  text: The MCP is just a fancy way of saying, we're going to create a set of formalized
    wrappers for existing tools or capabilities and expose them to your AI agent.
  topic: technical/architecture
- impact_reason: Demonstrates the practical power of agent orchestration across disparate
    enterprise systems (email, documents, payments), showcasing true cross-application
    workflow automation.
  relevance_score: 9
  source: llm_enhanced
  text: And Goose has been able to connect to all of our systems. So all of our existing
    systems, be it Gmail or Google Docs, be it Square Payments, any of these things,
    and orchestrate workflows between them completely on its own.
  topic: predictions/business
- impact_reason: 'Highlights the critical design principle of robust AI agents: enabling
    deep, self-correcting autonomy loops rather than stopping at the first failure.'
  relevance_score: 9
  source: llm_enhanced
  text: But at its core, Goose is very much about pushing autonomy. So we let the
    agent loop run as far as it can. So if it stumbles, if it hits obstacles, it'll
    back up and it'll try another approach.
  topic: technical/architecture
- impact_reason: A concrete, high-value application of autonomous agents in DevOps/Security
    (DevSecOps). Headless Goose automates vulnerability remediation within the CI
    pipeline.
  relevance_score: 9
  source: llm_enhanced
  text: So we have this really cool tool called Headless Goose. And it runs, for example,
    in our CI pipeline. And every time there's a vulnerability ticket filed by InfraSec,
    Headless Goose will go and try to fix that vulnerability automatically.
  topic: business/technical
- impact_reason: Illustrates the extreme potential of hyper-personalized, context-aware
    agents that proactively act on inferred user intent derived from ambient communication.
  relevance_score: 9
  source: llm_enhanced
  text: He has Goose watching literally everything he does, including Slack or Google
    Meet calls, everything in between. And it intervenes for him in really surprising
    ways. So he'll be talking with one of his colleagues about a new feature idea.
    And then a few hours later, he'll see that Goose has already tried to develop
    this feature and open a PR for it. He's not asked it.
  topic: predictions/strategy
- impact_reason: Highlights the importance of model agnosticism in agent architecture.
    The agent framework (Goose/MCP) is decoupled from the specific LLM, allowing for
    rapid upgrades as new foundation models emerge.
  relevance_score: 9
  source: llm_enhanced
  text: Goose under the hood uses a variety of different underlying foundation models.
    We have a pluggable provider system so we can essentially use any LLM that's capable
    of tool calling.
  topic: technical/architecture
- impact_reason: 'Crucial advice for building agent systems: prioritize letting the
    agent discover optimal interaction patterns over manually engineering tool wrappers
    for specific agent behaviors.'
  relevance_score: 9
  source: llm_enhanced
  text: I would say that our approach has been to not overengineer it. So we like
    to let Goose learn from doing things. We find that Goose is more capable than
    if you tried to figure out how to make a tool Goose friendly.
  topic: business/strategy
- impact_reason: Provides a technical insight into the current gap between proprietary
    models (native tool calling) and open-source models, and a practical solution
    ('tool shim') to bridge that gap.
  relevance_score: 9
  source: llm_enhanced
  text: The open source providers have no tool calling support, so they just generate
    text. Although some of them are fine-tuned to be better at tool use. So we have
    this system called tool shim, which basically adapts those LLMs to be able to
    use the MCP.
  topic: technical
- impact_reason: 'Defines the current limitation of general-purpose LLMs (lack of
    deep, specialized expertise) and points toward the solution: combining LLMs with
    domain experts.'
  relevance_score: 9
  source: llm_enhanced
  text: But if I am a researcher in neuroscience and like my wife is, and she wants
    to know something very particular about a type of dementia that she's researching,
    then it starts to struggle there. And really, when you put people with a lot of
    depth in an organization together, they tend to outperform the basic LLM capability.
  topic: limitations
- impact_reason: A forward-looking statement suggesting that current LLM applications
    are just scratching the surface, and true utility will come from advanced agentic
    architectures.
  relevance_score: 9
  source: llm_enhanced
  text: And that's really where we've seen most of the progress. And then we have
    another layer of advancement where which we're trying that I described earlier
    with our agentic middleware layer. That's, I think, going to unlock a whole lot
    more utility for us. But it's early days. I would say the utility phase of LLMs
    and agents is still ahead of us.
  topic: predictions
- impact_reason: Quantifies the immediate productivity gain for engineers using their
    specific tool (8-10 hours/week is substantial time savings).
  relevance_score: 9
  source: llm_enhanced
  text: So engineers report eight to 10 hours per week right now with Goose in particular.
  topic: business
- impact_reason: A strong philosophical stance favoring open weights, crucial for
    the long-term direction of AI research and democratization.
  relevance_score: 9
  source: llm_enhanced
  text: My preference would be for all models to be open source and open weights.
  topic: safety/ethics
- impact_reason: A powerful analogy framing the desired future state for core AI technology—accessible,
    foundational, and universally available.
  relevance_score: 9
  source: llm_enhanced
  text: It should be like a utility the way the internet was imagined to be.
  topic: predictions
- impact_reason: 'Suggests a concrete architecture for swarm intelligence: a hierarchical
    structure using large models for high-level planning and small, specialized models
    for execution.'
  relevance_score: 9
  source: llm_enhanced
  text: So I think there is a question around that and like it's a worthwhile research
    direction. I'm not exactly sure how it would, how it's going to play out. It could
    be a hierarchical swarm where you leverage some large language models, like some
    very capable models to do the planning for you or to do the reintegration for
    you and you break things down into very small, almost nano services that these
    simpler models can bite off and consume.
  topic: technical
- impact_reason: 'Provides a strong business case for remote work: accessing elite,
    specialized talent pools unavailable in high-competition hubs like Silicon Valley.'
  relevance_score: 9
  source: llm_enhanced
  text: there are some employees that we can only have because we support remote work.
    So we have certain employees who, you know, they're the leading lights in their
    industries or in their fields. And they would just never work for us if we weren't
    able to employ them, say, in Sweden, or in Sydney as well.
  topic: strategy
- impact_reason: Offers a nuanced view on remote work trade-offs, concluding that
    superior talent acquisition and retention outweigh the loss of spontaneous in-person
    collaboration.
  relevance_score: 9
  source: llm_enhanced
  text: while you do trade off some amount of velocity and serendipity, like coming
    together with the water cooler conversations and those kinds of things really
    do accelerate work, I think the benefit clearly outweighs that cost because we're
    able to hire these incredible engineers and retain them for six, seven, eight
    years in markets that don't have the same level of competition as Silicon Valley,
    for example.
  topic: strategy
- impact_reason: Explicitly names the 'context window' as the primary technical bottleneck
    preventing AI from tackling massive, complex code changes.
  relevance_score: 9
  source: llm_enhanced
  text: And that's purely a limitation of the context window and the ability of the
    LLMs to scale to that size.
  topic: technical
- impact_reason: 'Offers a strategic workflow recommendation for leveraging AI: use
    it as a rapid prototyping/skeleton generator, shifting the developer role from
    creator to editor/sculptor.'
  relevance_score: 9
  source: llm_enhanced
  text: But I would argue that even there, the developer is better off starting with
    an LLM to code first and then seeing where they can make improvements. So it's
    a little bit like a sculpture or if you're writing a short story or something
    like that, just having a skeleton to work from is much more productive than trying
    to sit there and come up with something on your own.
  topic: strategy
- impact_reason: Highlights a philosophy of iterative learning and avoiding premature
    optimization in agent development, favoring emergent behavior.
  relevance_score: 8
  source: llm_enhanced
  text: Our approach has been to not overengineer it. So we like to let Goose learn
    from doing things.
  topic: strategy
- impact_reason: Defines the core utility and nature of Goose—an open-source, local,
    general-purpose AI agent.
  relevance_score: 8
  source: llm_enhanced
  text: Goose, which is an open source, extensible agent that can do work on your
    computer for you.
  topic: technical
- impact_reason: Reveals the urgency and proactive measures taken by leadership to
    address perceived lag in AI adoption, emphasizing the need for dedicated transformation
    leadership.
  relevance_score: 8
  source: llm_enhanced
  text: I said hire someone, not me, who can be CTO, and get our company transformed
    to using AI, because we're well behind the eight ball and we need to get ahead.
  topic: business/strategy
- impact_reason: Acknowledges the paradigm shift required in product development when
    integrating LLMs, emphasizing that no single approach works universally.
  relevance_score: 8
  source: llm_enhanced
  text: Have you had to embrace a different, almost product building mindset to build
    around LLMs and generative AI compared to how your developers are used to working?
    Well, I would say there are a couple of different approaches that we've tried.
    There's no panacea to this.
  topic: business/strategy
- impact_reason: A warning against premature optimization in agent tooling. The rapid
    pace of LLM improvement means custom scaffolding might quickly become obsolete.
  relevance_score: 8
  source: llm_enhanced
  text: And with the rate at which LLMs are evolving, that capability is improving
    rapidly as well. So even if we did find something that we could build some engineering
    scaffolding around to make Goose more effective on some particular tool, the next
    release of the LLM provider might just blow that capability out of the water.
  topic: strategy
- impact_reason: A highly relatable, non-enterprise example showing agents solving
    complex personal logistics problems (optimization/planning) instantly.
  relevance_score: 8
  source: llm_enhanced
  text: I saw someone who was taking a holiday in Paris, who had Goose build her a
    map of all of the interesting sites in Paris and do a little traveling salesman
    walk for her to get through all of those sites.
  topic: predictions/business
- impact_reason: 'Describes the adoption curve for autonomous agents: users start
    cautiously (''in the loop'') but realize the full power only when transitioning
    to full autonomy.'
  relevance_score: 8
  source: llm_enhanced
  text: Or once you get comfortable with it, you can push it to fully autonomous mode.
    And a lot of people start to see the value of how strong it is when they start
    to do that.
  topic: safety/adoption
- impact_reason: Highlights the growing viability and performance of running powerful
    models locally (on-device inference), which is critical for privacy-focused use
    cases.
  relevance_score: 8
  source: llm_enhanced
  text: I just built one on the plane on the way here, which was using an embedded
    model provider, which is blindingly fast on our latest MacBooks.
  topic: technical
- impact_reason: 'Directly links specific open-source models (Qwen, DeepSeek) to a
    key business/user requirement: maximum privacy via local execution.'
  relevance_score: 8
  source: llm_enhanced
  text: So some people are very privacy conscious. They don't want a single token
    to leave their laptop. So they'll use Qwen and models like that, DeepSeek.
  topic: business
- impact_reason: A major strategic decision by a large company (Block) to open-source
    a core AI product, signaling a commitment to the open ecosystem.
  relevance_score: 8
  source: llm_enhanced
  text: We made the decision to open source Goose. And I think the company does a
    lot in other aspects of open source.
  topic: strategy
- impact_reason: 'Details a nuanced approach to model development: focusing internal
    efforts on specialized SLMs and proprietary frontier research (like speech-to-speech)
    while advocating for open research findings.'
  relevance_score: 8
  source: llm_enhanced
  text: We don't develop LLMs ourselves, but we do develop SLMs, like smaller language
    models that are focused around customer service and risk. And we also develop
    other frontier models that we're doing purely for research. So we're working on
    a speech-to-speech model which we will open source and we'll publish all our findings.
  topic: technical
- impact_reason: Identifies speed and responsiveness as the primary bottleneck in
    large-scale corporate AI deployment, linking it to developer momentum and energy.
  relevance_score: 8
  source: llm_enhanced
  text: I always wish I could move faster. That's always been a bugbear for me. Like
    there's a certain responsiveness to tools that you use locally that are really
    energizing and that let you build momentum.
  topic: business
- impact_reason: Identifies a specific, emerging methodology ('vibe coding') and credits
    the speaker's internal tool (Goose) with pioneering its adoption.
  relevance_score: 8
  source: llm_enhanced
  text: Vibe coding, that's, I think, Goose basically pioneered vibe coding. I don't
    think it's too much of a statement to say that, or at least it was very early
    in the vibe coding world.
  topic: technical
- impact_reason: Distinguishes the current wave of Generative AI from previous ML
    efforts, suggesting a fundamental shift in application and capability.
  relevance_score: 8
  source: llm_enhanced
  text: generative AI is the big difference between what you were doing with machine
    learning before and how you're hoping to embrace AI now.
  topic: technical
- impact_reason: A concluding strategic thought suggesting that the paradigm shift
    brought by agents requires developers to adopt a less prescriptive, more outcome-oriented
    mindset.
  relevance_score: 7
  source: llm_enhanced
  text: You have to stop thinking like an engineer. This is one thing t
  topic: strategy
- impact_reason: A general business insight on corporate culture, highlighting the
    risk of 'infanticide' (killing promising internal projects) in large organizations,
    contrasting it with Block's success in fostering innovation like Goose.
  relevance_score: 7
  source: llm_enhanced
  text: It's a great story of how big companies can find talent and give them the
    space to flourish. I sometimes wonder that bigger companies are more at risk of
    infanticide than anything. They kill their own ideas.
  topic: business/strategy
- impact_reason: 'A realistic view on innovation: success requires a high volume of
    experimentation, acknowledging that most internal projects fail.'
  relevance_score: 7
  source: llm_enhanced
  text: Not a lot of these work out. So like we've tried many, many more things than
    we've actually had home runs with. But certainly Cash App and Goose are two big
    ones.
  topic: business/strategy
- impact_reason: Contextualizes the importance of open-sourcing Goose by linking it
    to Block's massive existing footprint in mobile technology and their philosophy
    of uplifting the community.
  relevance_score: 7
  source: llm_enhanced
  text: I would say our technologies run in close to 4 billion mobile devices all
    over the world. And yeah, we think Goose should follow in that tradition and try
    to uplift everyone and show the way for everyone like it did when we first released
    it.
  topic: strategy
- impact_reason: 'Reiterates the ultimate business goal: rapid iteration to deliver
    customer value, which AI tools are expected to unlock.'
  relevance_score: 7
  source: llm_enhanced
  text: And ultimately, all of this stuff is so we can build useful things for our
    customers and our community. So being able to do that rapidly and iterate would
    be the dream.
  topic: business
- impact_reason: Connects the pursuit of speed and iteration directly to customer
    value, framing rapid development as a core business objective enabled by new tools.
  relevance_score: 7
  source: llm_enhanced
  text: But that's definitely on my wish list. It's like, how do we move faster on
    all fronts? How do we get more feedback from the data that we do have? And ultimately,
    all of this stuff is so we can build useful things for our customers and our community.
  topic: business
- impact_reason: Demonstrates internal validation and adoption of the AI coding tool
    within the company's own engineering department, treating the internal team as
    a customer.
  relevance_score: 7
  source: llm_enhanced
  text: Our technology team, in particular, is actually a customer, by the way. They're
    using Goose internally to build some of our own applications.
  topic: business
- impact_reason: Provides insight into the motivation driving high-level engineering
    talent, emphasizing the pursuit of novel utility over incremental improvement.
  relevance_score: 6
  source: llm_enhanced
  text: The reason I get up to come into work is to build something cool, build something
    that no one else has ever built before, and realize some utility or some value
    from it that people have been struggling with for a long time.
  topic: strategy
source: Unknown Source
summary: '## Podcast Summary: Block CTO Dhanji Prasanna on Building the AI-First Enterprise
  with Goose


  This 59-minute episode of *Training Data* features Block CTO Dhanji Prasanna discussing
  Block’s aggressive pivot toward becoming an "AI-First" enterprise, centered around
  their open-source, extensible AI agent, **Goose**.


  ### 1. Focus Area

  The discussion centers on the practical application of **AI Agents** in a large
  enterprise setting, contrasting traditional Machine Learning (ML) with modern **Generative
  AI/Deep Learning**. Key themes include organizational transformation, the role of
  **tool use** and **agent middleware**, and the development and philosophy behind
  Goose. The conversation also touches upon Block’s broader activities, including
  Square, Cash App, and their Bitcoin initiatives (Bitkey, RIG mining).


  ### 2. Key Technical Insights

  *   **Goose as Agent Middleware:** Goose is positioned as the "arms and legs" for
  the LLM "brain in a jar," providing the orchestration layer necessary for AI to
  act in the real world by connecting to existing digital systems.

  *   **Model Context Protocol (MCP):** Goose is built using the MCP, a formalized
  standard for creating wrappers around existing tools/capabilities, allowing the
  agent to connect to and orchestrate diverse systems (e.g., Snowflake, Looker, Gmail).

  *   **Learning Through Doing & Recipes:** Block avoids over-engineering tool compatibility,
  preferring to let Goose learn workflows organically. Successful user workflows can
  be "baked" into shareable scripts called **recipes**.


  ### 3. Business/Investment Angle

  *   **AI as Strength, Not Threat:** Prasanna views AI not as a disruption that will
  usurp Block, but as a necessary technology to embrace, consistent with Block''s
  history of adopting innovations (like the original card reader or blockchain).

  *   **Organizational Centralization:** Block transitioned from a siloed General
  Manager (GM) structure to a centralized, functional organization to drive engineering
  excellence and unify AI policy across Square, Cash App, and Tidal.

  *   **Agent Utility for Non-Engineers:** A major unexpected business value is non-technical
  staff (sales, finance) using Goose to build their own software dashboards and reporting
  tools, unlocking significant productivity.


  ### 4. Notable Companies/People

  *   **Dhanji Prasanna (Block CTO):** Drove the central mandate for Block to become
  AI-first, advocating for centralized investment in AI transformation.

  *   **Jack Dorsey (Block Founder):** Fully aligned with Prasanna on the necessity
  of AI investment; credited with driving the company''s strong focus on Bitcoin.

  *   **Brad Axen (Goose Developer):** The engineer who developed the initial thesis
  and prototype for Goose, which was subsequently ringfenced and scaled.


  ### 5. Future Implications

  The conversation suggests a future where AI agents, leveraging protocols like MCP,
  become the primary interface for interacting with enterprise software, moving beyond
  simple chat interfaces. Block is aiming for **recursive self-improvement**, with
  the goal of Goose rewriting 100% of its own codebase in future releases. The most
  advanced use cases hint at agents operating with high autonomy, monitoring communications
  and proactively developing features or managing schedules.


  ### 6. Target Audience

  This episode is highly valuable for **AI/ML Engineers, CTOs, Enterprise Software
  Architects, and Technology Strategists** interested in the practical implementation,
  organizational structuring, and security considerations of deploying autonomous
  AI agents within a large, established technology company.'
tags:
- artificial-intelligence
- generative-ai
- ai-infrastructure
- investment
- startup
- google
title: 'Block CTO Dhanji Prasanna: Building the AI-First Enterprise with Goose, their
  Open Source Agent'
topics:
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 104
  prominence: 1.0
  topic: artificial intelligence
- keywords:
  - generative ai
  - genai
  - chatgpt
  - gpt
  - claude
  - text generation
  - image generation
  mentions: 6
  prominence: 0.6
  topic: generative ai
- keywords:
  - gpu
  - tensor
  - training
  - inference
  - model deployment
  - vector database
  mentions: 3
  prominence: 0.3
  topic: ai infrastructure
- keywords:
  - investment
  - funding
  - valuation
  - ipo
  - acquisition
  mentions: 2
  prominence: 0.2
  topic: investment
- keywords:
  - startup
  - entrepreneur
  - founder
  - venture
  mentions: 1
  prominence: 0.1
  topic: startup
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-10-06 05:26:27 UTC -->
