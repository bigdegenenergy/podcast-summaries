---
companies:
- category: unknown
  confidence: medium
  context: This is the Everyday AI Show, the everyday podcast where we simplify AI
    and br
  name: Everyday AI Show
  position: 12
- category: tech
  confidence: high
  context: ', and everyday life. This podcast is supported by Google.


    Hey folks, Stephen Johnson here, co-founder of'
  name: Google
  position: 226
- category: unknown
  confidence: medium
  context: 'This podcast is supported by Google.


    Hey folks, Stephen Johnson here, co-founder of NotebookLM. As an author, I''v'
  name: Stephen Johnson
  position: 246
- category: unknown
  confidence: medium
  context: d understand if you're actually getting an ROI on Gen AI? This is something
    I've literally talked to hundr
  name: Gen AI
  position: 856
- category: unknown
  confidence: medium
  context: 'e you are too.


    What''s going on, Neil? Welcome to Everyday AI. My name is Jordan Molson. We do
    this thing every'
  name: Everyday AI
  position: 1554
- category: unknown
  confidence: medium
  context: oing on, Neil? Welcome to Everyday AI. My name is Jordan Molson. We do
    this thing every single day. It's a live s
  name: Jordan Molson
  position: 1578
- category: unknown
  confidence: medium
  context: s. But that's not how companies are using AI now. Something I've been thinking
    about a lot over the last year o
  name: Something I
  position: 2600
- category: unknown
  confidence: medium
  context: chatbots as their AI operating system of choice. And I'm going to be talking
    a little bit more about thi
  name: And I
  position: 4262
- category: unknown
  confidence: medium
  context: ck-end API and front-end operating system, right? So I think in early,
    you know, in 2023 and the earlier
  name: So I
  position: 5385
- category: tech
  confidence: high
  context: s essentially fine-tune these models from Google, OpenAI, Anthropic, etc.,
    for their own use. They build R
  name: Openai
  position: 5532
- category: tech
  confidence: high
  context: ially fine-tune these models from Google, OpenAI, Anthropic, etc., for
    their own use. They build RAG pipeline
  name: Anthropic
  position: 5540
- category: unknown
  confidence: medium
  context: 'ier to evaluate these models and to measure ROI.


    But I don''t think that''s how most people should be usin'
  name: But I
  position: 6232
- category: tech
  confidence: high
  context: on their operating system. Are you going to be a Microsoft Windows organization?
    Are you going to be Mac OS?
  name: Microsoft
  position: 6476
- category: unknown
  confidence: medium
  context: on their operating system. Are you going to be a Microsoft Windows organization?
    Are you going to be Mac OS? Are you
  name: Microsoft Windows
  position: 6476
- category: unknown
  confidence: medium
  context: crosoft Windows organization? Are you going to be Mac OS? Are you going
    to be Linux, right? And then from
  name: Mac OS
  position: 6528
- category: unknown
  confidence: medium
  context: amic data, essentially creating a mini version of Retrieval Augmented Generation
    or RAG pipelines with your company's dynamic data
  name: Retrieval Augmented Generation
  position: 10395
- category: unknown
  confidence: medium
  context: ChatGPT business plan, a ChatGPT enterprise plan, Google Gemini team plan,
    Claude enterprise plan, because you ne
  name: Google Gemini
  position: 11112
- category: unknown
  confidence: medium
  context: but variants and reliability are never measured. Generative AI is generative,
    right? So a lot of times, companie
  name: Generative AI
  position: 12453
- category: unknown
  confidence: medium
  context: e seven steps to evaluate, what are Evals, right? So AI Evals are essentially
    structured quality checks for AI
  name: So AI Evals
  position: 13483
- category: unknown
  confidence: medium
  context: ly important. So using these ensures reliability. So Evals verify the AI
    performs its tasks consistently and
  name: So Evals
  position: 13789
- category: unknown
  confidence: medium
  context: r great resources to at least get started, right? Because I'm not saying
    that one model or one mode is going
  name: Because I
  position: 14782
- category: unknown
  confidence: medium
  context: 'started?


    Well, most of these publicly available AI Eval sites look at different scientific
    benchmarks as'
  name: AI Eval
  position: 15181
- category: unknown
  confidence: medium
  context: er benchmarks. And then depending, you know, like LM Arena is a good example.
    We talk about this a lot on th
  name: LM Arena
  position: 15298
- category: unknown
  confidence: medium
  context: tions of the models as well. Another great one is Epoch AI. They have their
    AI benchmarking across different
  name: Epoch AI
  position: 16518
- category: unknown
  confidence: medium
  context: 't, this is a newer one I like from Scale: their C-LLM Leader. So a lot
    of these look at different aspects, rig'
  name: LLM Leader
  position: 16673
- category: unknown
  confidence: medium
  context: even know how to select the right battle, right? CEO Sam Altman recently
    said around the GPT-5 launch that only,
  name: CEO Sam Altman
  position: 25680
- category: big_tech
  confidence: high
  context: Mentioned as a supporter of the podcast and the developer of Gemini and
    NotebookLM.
  name: Google
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: An AI-first tool built by Stephen Johnson to help organize ideas and make
    connections from uploaded documents.
  name: NotebookLM
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as a leading front-end AI model/operating system, with discussions
    around its various models (GPT-4o, GPT-3o, GPT-4 mini) and features (Apps, DevDay
    announcements).
  name: ChatGPT
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as a major large language model/front-end AI system alongside
    ChatGPT and Gemini.
  name: Claude
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as a major large language model/front-end AI system developed
    by Google.
  name: Gemini
  source: llm_enhanced
- category: media/organization
  confidence: high
  context: The name of the podcast/live stream/newsletter focused on simplifying and
    leveraging AI.
  name: Everyday AI Show
  source: llm_enhanced
- category: media/organization
  confidence: high
  context: The website associated with the Everyday AI Show.
  name: youreverydayai.com
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: Mentioned as a developer of large language models and for recent announcements
    at their DevDay regarding 'Apps' within ChatGPT.
  name: OpenAI
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: Mentioned as a developer of large language models (like Claude) that enterprises
    fine-tune or use via API.
  name: Anthropic
  source: llm_enhanced
- category: big_tech
  confidence: medium
  context: Implicitly referenced via 'Copilot', which is a Microsoft product often
    integrated with OpenAI models.
  name: Microsoft
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as a front-end AI tool that teams are adopting, often associated
    with Microsoft's ecosystem.
  name: Copilot
  source: llm_enhanced
- category: ai_evaluation
  confidence: high
  context: Cited as one of the best publicly available AI Eval sites, using blind
    LLM taste tests (battles) to generate Elo scores.
  name: LM Arena
  source: llm_enhanced
- category: ai_evaluation
  confidence: high
  context: Mentioned as an AI evaluation site looking at reasoning, coding, mathematics,
    and data analysis across different models.
  name: LiveBench
  source: llm_enhanced
- category: ai_evaluation
  confidence: high
  context: Mentioned as an organization providing AI benchmarking across different
    categories.
  name: Epoch AI
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: Mentioned as the source of a newer AI evaluation tool called 'C-LLM Leader'.
  name: Scale
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: A newer LLM evaluation tool provided by Scale.
  name: C-LLM Leader
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: Co-founder of NotebookLM, discussing the tool's purpose.
  name: Stephen Johnson
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: CEO mentioned regarding usage statistics for GPT-5's 'thinking models'.
  name: Sam Altman
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned in the context of its launch and low adoption rate of its 'thinking
    models'.
  name: GPT-5
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as a model that was recently updated, highlighting the need for
    continuous retesting.
  name: GPT-4o
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: Mentioned as a model of choice that receives frequent updates, implying
    a specific version of a large language model (likely OpenAI's).
  name: GPT-5 thinking
  source: llm_enhanced
date: 2025-10-09 13:00:00 +0000
duration: 40
has_transcript: false
insights:
- actionable: true
  confidence: medium
  extracted: be using them in their interface because they're so much more powerful
    when you have access to all of these different modes and features that aren't
    available when you're using an API
  text: we should be using them in their interface because they're so much more powerful
    when you have access to all of these different modes and features that aren't
    available when you're using an API.
  type: recommendation
- actionable: true
  confidence: medium
  extracted: be moving our processes inside of one of these team modes, right? So
    obviously, all the big AI models, you can have a team account, an enterprise account,
    bring thousands of users
  text: we should be moving our processes inside of one of these team modes, right?
    So obviously, all the big AI models, you can have a team account, an enterprise
    account, bring thousands of users.
  type: recommendation
layout: episode
llm_enhanced: true
original_url: https://pscrb.fm/rss/p/www.buzzsprout.com/2175779/episodes/17982897-ep-628-what-s-the-best-llm-for-your-team-7-steps-to-evaluate-and-create-roi-for-ai.mp3
processing_date: 2025-10-09 14:44:24 +0000
quotes:
- length: 95
  relevance_score: 5
  text: Generative AI can be kind of like a roll of the day sometimes, so you have
    to keep that in mind
  topics: []
- length: 56
  relevance_score: 5
  text: All right, you have to plan your evaluation sprint first
  topics:
  - valuation
- length: 127
  relevance_score: 4
  text: 'Don''t be wrong, there are great resources out there: scientific benchmarks,
    evaluation sites that look at large language models'
  topics:
  - valuation
- length: 137
  relevance_score: 4
  text: They build RAG pipelines and they essentially create versions of these large
    language models for their employees to use internally, right
  topics: []
- length: 218
  relevance_score: 4
  text: And now there's this whole concept, especially after OpenAI earlier this week
    announced a couple of things at their DevDay, but one of the biggest ones was
    "Apps," so bringing in entire apps into the ChatGPT experience
  topics: []
- length: 150
  relevance_score: 4
  text: This brings your dynamic data, essentially creating a mini version of Retrieval
    Augmented Generation or RAG pipelines with your company's dynamic data
  topics: []
- length: 116
  relevance_score: 4
  text: They're important, especially for generative AI, because you can run the same
    input and get wildly different outputs
  topics: []
- length: 80
  relevance_score: 4
  text: That's how generative AI works, which is why evaluations are extremely important
  topics:
  - valuation
- length: 169
  relevance_score: 3
  text: So I think in early, you know, in 2023 and the earlier days, 2024, larger
    enterprise organizations essentially fine-tune these models from Google, OpenAI,
    Anthropic, etc
  topics: []
- length: 45
  relevance_score: 3
  text: I think you have to make that same choice now
  topics: []
- length: 76
  relevance_score: 3
  text: You have to calculate the time that it takes for your people to do a project
  topics: []
- length: 69
  relevance_score: 3
  text: You have to calculate any hard costs, software expenditures, whatever
  topics: []
- length: 123
  relevance_score: 3
  text: To get the most out of Gen AI, you have to constantly be iterating and kind
    of going in a cycle of improvement and feedback
  topics: []
- length: 48
  relevance_score: 3
  text: If you have to go take this through legal, right
  topics: []
- length: 134
  relevance_score: 3
  text: You have to hope that if they encounter a problem, they will adapt, they will
    adapt and overcome it, just like hopefully a human would
  topics: []
- length: 60
  relevance_score: 3
  text: That's why you have to retest monthly to track changes, okay
  topics: []
- impact_reason: This is a core strategic thesis of the podcast, suggesting a fundamental
    shift in how LLMs will be used—moving from simple tools to comprehensive work
    environments.
  relevance_score: 10
  source: llm_enhanced
  text: large language models are slowly morphing under our eyes into AI operating
    systems.
  topic: predictions
- impact_reason: A strong argument for prioritizing front-end interaction over pure
    API integration to unlock multimodal capabilities and features (modes).
  relevance_score: 10
  source: llm_enhanced
  text: maybe we shouldn't just be using models on the back end via an API connection.
    And maybe we should be using them in their interface because they're so much more
    powerful when you have access to all of these different modes and features that
    aren't available when you're using an API.
  topic: technical/strategy
- impact_reason: Clearly distinguishes 'models' (the engine) from 'modes' (the features/tools)
    and asserts that modes are the source of front-end value.
  relevance_score: 10
  source: llm_enhanced
  text: But then you talk about modes. And this is where you don't get this if you're
    just working on the back end via an API. And these modes are where the magic happen.
  topic: technical
- impact_reason: 'Pinpoints the fundamental flaw in ROI calculation: the failure to
    establish pre-AI performance metrics (baselines).'
  relevance_score: 10
  source: llm_enhanced
  text: not properly measuring pre-Gen AI human input efforts. How long did these
    projects take before there was AI? We don't have baselines.
  topic: business
- impact_reason: A concise, memorable summary distinguishing the underlying engine
    (model) from the functional capabilities (modes) that drive productivity.
  relevance_score: 10
  source: llm_enhanced
  text: difference between models and modes are where work happens.
  topic: technical/strategy
- impact_reason: Provides a clear definition of AI Evals and explains their necessity
    specifically for generative models due to output variance.
  relevance_score: 10
  source: llm_enhanced
  text: AI Evals are essentially structured quality checks for AI systems. They're
    important, especially for generative AI, because you can run the same input and
    get wildly different outputs.
  topic: technical
- impact_reason: 'Provides concrete, actionable advice for starting an evaluation
    sprint: time-box it, focus on one workflow, and maintain model consistency.'
  relevance_score: 10
  source: llm_enhanced
  text: You need to plan a two to four-week sprint, testing just one workflow, freeze
    your model choice, and ignore all shiny new objects.
  topic: strategy
- impact_reason: Strongly criticizes the widespread failure to establish pre-AI human
    performance metrics, calling it essential for proving ROI.
  relevance_score: 10
  source: llm_enhanced
  text: 'Step two: Measure your human baseline first. I don''t understand why no one''s
    doing this. This is mind-boggling to me.'
  topic: business
- impact_reason: Directly links the need for a human benchmark to validating advertised
    LLM productivity gains (60-70% time savings), framing the alternative as mere
    guesswork.
  relevance_score: 10
  source: llm_enhanced
  text: Okay? Well, you see all these studies about 60 to 70% time savings when using
    large language models. Well, do you want that? Well, if so, you've got to get
    the pre-Gen AI human benchmark. You need to calculate the average time, error
    rate, rework minutes, cost per completed task. This is your baseline. And this
    will ultimately prove whether the AI actually saves time or not. Without it, you're
    just guessing. Stop guessing.
  topic: business
- impact_reason: A striking statistic revealing low adoption of advanced/more capable
    AI modes (like 'thinking' models), suggesting a massive gap between model capability
    and user proficiency.
  relevance_score: 10
  source: llm_enhanced
  text: CEO Sam Altman recently said around the GPT-5 launch that only, I think, 7%
    of paid users used thinking models, which is an absolutely asinine thing to think
    about.
  topic: technical/business
- impact_reason: A blunt assessment of the current state of LLM user literacy, emphasizing
    that effective AI utilization requires specific, learned skills (prompt engineering).
  relevance_score: 10
  source: llm_enhanced
  text: Most humans have no clue what they're doing when they're using large language
    models. You need to use the right model, the right mode, and the right prompting
    techniques. You got to know the basics.
  topic: technical/strategy
- impact_reason: 'A critical requirement for enterprise adoption: demanding verifiable
    outputs (grounding) to combat hallucination and ensure accountability.'
  relevance_score: 10
  source: llm_enhanced
  text: You also need to require working citations, file paths, or artifacts for every
    accepted answer. No exceptions.
  topic: safety/strategy
- impact_reason: Provides a concise, comprehensive framework (a 7-point checklist)
    for monitoring and reporting on the performance and risk profile of deployed AI
    systems.
  relevance_score: 10
  source: llm_enhanced
  text: I think these seven factors are pretty good to keep a look to keep a look
    at. So cost, latency, accuracy, stability, safety, integration, and compliance,
    right?
  topic: strategy/safety
- impact_reason: A direct mandate for continuous integration/continuous deployment
    (CI/CD) principles applied to AI models, acknowledging that underlying models
    are constantly updated by vendors.
  relevance_score: 10
  source: llm_enhanced
  text: You need to retest this monthly to track changes.
  topic: technical/strategy
- impact_reason: 'Reveals the hidden complexity of using proprietary AI services:
    features and underlying models (like Canvas mode) are frequently updated without
    user awareness, necessitating retesting.'
  relevance_score: 10
  source: llm_enhanced
  text: Let's say for whatever reason, you're using GPT-5 thinking as your model of
    choice, and then you're using Canvas mode, okay? Canvas mode gets updated often.
    Most people, unless you're a nerd like me, don't know this.
  topic: technical
- impact_reason: Identifies prompt engineering as the single greatest point of failure
    in AI adoption, even when infrastructure and process are sound.
  relevance_score: 10
  source: llm_enhanced
  text: This is probably where even if you follow these steps one through seven, this
    is probably where you're going to fail. Most people have no clue how to prompt
    an AI.
  topic: technical/strategy
- impact_reason: Reinforces the 'AI Operating System' concept, indicating that front-end
    interfaces (chatbots) are becoming the primary locus of knowledge work, necessitating
    new evaluation methods.
  relevance_score: 9
  source: llm_enhanced
  text: That's where work happens as your everyday ChatGPT, Claude, Gemini, etc.,
    are becoming places of work and where teams go to get work done.
  topic: strategy
- impact_reason: Highlights the critical gap between academic/API-centric benchmarks
    and real-world, front-end enterprise ROI measurement.
  relevance_score: 9
  source: llm_enhanced
  text: 'ROI is important, right? But how do you evaluate it? Don''t be wrong, there
    are great resources out there: scientific benchmarks, evaluation sites that look
    at the models themselves. But here''s the issue: they''re just looking at the
    models themselves. They''re looking mainly if you''re using one of these big APIs.'
  topic: business
- impact_reason: 'A crucial warning about the hidden cost of poor adoption: reduced
    productivity due to lack of training on complex, evolving front-end features.'
  relevance_score: 9
  source: llm_enhanced
  text: if your team is not properly trained and doesn't understand how large language
    models work, especially on the front end with all of these new modes that are
    being added all of the time, you might end up spending more time in AI than you
    would if you weren't doing it with AI.
  topic: safety/business
- impact_reason: Provides a powerful historical analogy (the OS wars) to frame the
    current strategic decision organizations face regarding which LLM interface to
    standardize on.
  relevance_score: 9
  source: llm_enhanced
  text: In the '90s, you know, most companies in the early 2000s had to make a choice
    on their operating system. Are you going to be a Microsoft Windows organization?
    Are you going to be Mac OS? Are you going to be Linux, right? And then from there,
    you essentially built your processes around those operating systems... I think
    that's the junction that we're at right now.
  topic: strategy
- impact_reason: Explains how front-end 'Connectors' function as accessible, built-in
    RAG mechanisms, democratizing data integration.
  relevance_score: 9
  source: llm_enhanced
  text: Using modes like Connectors, you know, and all the major players have their
    version of connectors. This brings your dynamic data, essentially creating a mini
    version of Retrieval Augmented Generation or RAG pipelines with your company's
    dynamic data.
  topic: technical
- impact_reason: A powerful analogy comparing API-only usage to a useless, bare-bones
    computer, emphasizing the necessity of utilizing front-end features/modes.
  relevance_score: 9
  source: llm_enhanced
  text: Imagine if you had a computer with no programs. Right? No, no office programs,
    no terminal, no nothing. That's kind of what I feel if your company is only using
    something via an API.
  topic: strategy
- impact_reason: 'Identifies the single biggest non-technical blocker to AI ROI: insufficient
    investment in human capital preparation.'
  relevance_score: 9
  source: llm_enhanced
  text: Change management and training are basically non-existent in most, even large
    organizations. I'm constantly shocked at the lack of change management that gets
    invested, as well as training.
  topic: business
- impact_reason: A critical warning about the unreliability/variability of generative
    outputs and the danger of premature, narrow scaling.
  relevance_score: 9
  source: llm_enhanced
  text: one lucky run is celebrated when it comes to AI, but variants and reliability
    are never measured. Generative AI is generative, right? So a lot of times, companies
    find one use case, and then they just roll that very small use case out to everyone
    without properly testing it.
  topic: safety/business
- impact_reason: Highlights the critical challenge of measuring AI ROI due to the
    lack of pre-AI performance baselines, a major hurdle for business adoption.
  relevance_score: 9
  source: llm_enhanced
  text: If you want to talk about ROI, what is it? You have to calculate the time
    that it takes for your people to do a project. You have to calculate any hard
    costs, software expenditures, whatever. But people didn't measure this before
    AI, so there's no baseline to compare it to.
  topic: business
- impact_reason: 'Points out a common pitfall in AI adoption: over-celebrating single
    successful outputs without assessing the model''s consistency and reliability
    across multiple runs.'
  relevance_score: 9
  source: llm_enhanced
  text: Also, I think sometimes one lucky run is celebrated when it comes to AI, but
    variants and reliability are never measured.
  topic: safety/strategy
- impact_reason: Identifies 'shiny object AI syndrome' as a primary barrier to achieving
    ROI, stressing the need for focus amidst rapid technological announcements.
  relevance_score: 9
  source: llm_enhanced
  text: And then last but definitely not least, one of the common, most common traps
    of companies not finding ROI on Gen AI is the shiny object AI syndrome, right?
    Every single week, in multiple times a week, there are shiny distractions, right?
  topic: strategy
- impact_reason: Describes the methodology of blind, comparative LLM evaluation (Elo
    scoring via LM Arena), which is a key technique for objective model comparison.
  relevance_score: 9
  source: llm_enhanced
  text: LM Arena is a good example. We talk about this a lot on the show, but with
    LM Arena, you can go on there. You essentially have a battle. Okay? You put in
    one prompt, you get two different responses from a large language model. You choose
    which one is better. You don't see which model it is. It's a blind LLM taste test.
  topic: technical
- impact_reason: Explains the value of categorized benchmarking (Elo scores across
    specific tasks), allowing users to select models based on specific domain performance
    rather than a single aggregate score.
  relevance_score: 9
  source: llm_enhanced
  text: And then after millions of votes, obviously, you start to see which models
    are best. And then also they classify what this was about. Was this a creative
    writing prompt? Was it a factual test? Was it a coding task, right? Was it math?
    Was it science? So not only do you get scores—these are called Elo scores—but
    you're also able to classify them across different arenas, right?
  topic: technical
- impact_reason: Emphasizes the necessity of formalizing success criteria upfront,
    treating the pilot like a defined project with clear deliverables.
  relevance_score: 9
  source: llm_enhanced
  text: 'Step one: Define your success criteria before you start testing. You need
    to literally like write a job description for this pilot, right? For this test.'
  topic: strategy
- impact_reason: Advocates for measurable, binary KPIs (black and white) over subjective
    metrics when evaluating AI performance.
  relevance_score: 9
  source: llm_enhanced
  text: You need to choose three to five simple KPIs that the workflow impacts. Number
    one, obviously, is human time spent, accuracy, revisions required, value created,
    et cetera, right? Because there are some things that might be great area. Try
    not to, with your success criteria and your KPIs, try not to choose anything that's
    too gray, right? Try to choose as many black and white things as you can, right?
  topic: business
- impact_reason: Stresses the importance of using realistic, messy data (20-40 examples)
    to test models, mirroring real-world operational conditions.
  relevance_score: 9
  source: llm_enhanced
  text: 'Step three: You need to build a realistic and controllable test data set.
    . . You need to gather 20 to 40, 20 to 40 actual work examples. You need to have
    messiness, right? Don''t start with something that''s too clean, too structured,
    too organized, right?'
  topic: technical/safety
- impact_reason: Mandates that testing environments must mirror production configurations,
    including access rights and tool availability, to ensure valid results.
  relevance_score: 9
  source: llm_enhanced
  text: 'Step four: You need to configure your workspace like production. Okay? So
    you need to set up properly. You need to set up the shared workspace matching
    real permissions for the right tools and the models that users will ultimately
    have.'
  topic: strategy
- impact_reason: Strongly advises against testing with free/consumer-grade models
    if the production environment requires paid, feature-rich versions (e.g., $200/month
    plans).
  relevance_score: 9
  source: llm_enhanced
  text: I don't know why some organizations, they're like, I'm not going to pay for
    AI. I'm going to use the free one. Stop, right? You need to be using the exact
    same mode or model that you want to be using on the front end or on like once
    this goes live with the rest of your team.
  topic: business
- impact_reason: 'Crucial advice for MLOps/DevOps in AI deployment: testing environments
    must mirror production to avoid deployment surprises.'
  relevance_score: 9
  source: llm_enhanced
  text: You need to configure your workspace like production.
  topic: business/strategy
- impact_reason: Strong business advice against using free/unrepresentative models
    for critical testing, highlighting the risk of feature disparity between test
    and production environments.
  relevance_score: 9
  source: llm_enhanced
  text: I'm not going to pay for AI. I'm going to use the free one. Stop, right? You
    need to be using the exact same mode or model that you want to be using on the
    front end or on like once this goes live with the rest of your team.
  topic: business
- impact_reason: Highlights the inherent stochastic nature of generative AI, necessitating
    rigorous, repeated testing to establish reliability, contrasting with deterministic
    software testing.
  relevance_score: 9
  source: llm_enhanced
  text: You don't do one-offs. You run this multiple times. I'd say you need to run
    at least this trial three times, both with your humans and on the AI side, and
    demand proof.
  topic: technical/strategy
- impact_reason: 'Specific, actionable technical advice for reproducible testing:
    disabling context memory to ensure each trial is independent.'
  relevance_score: 9
  source: llm_enhanced
  text: You're probably going to want to turn off memory. If you're using ChatGPT,
    as an example, or all the front-end AI large language models have something like
    this, you're going to want to turn off memory. You're going to want to turn off
    pass chat history, you know, to make sure that it's not pulling from other things.
  topic: technical
- impact_reason: Advocates for a 'blind taste test' methodology in evaluation to mitigate
    human bias (positive or negative) towards AI-generated content.
  relevance_score: 9
  source: llm_enhanced
  text: I would have the grading be from someone that doesn't know which ones are
    human and which ones are AI, right? So this might also require you having a certain
    output to where human graders wouldn't be able to tell which one came from a human
    and which one came from an AI.
  topic: strategy/safety
- impact_reason: Highlights the critical issue of AI model drift or inconsistency,
    emphasizing that stability (consistency over time) is as important as initial
    accuracy.
  relevance_score: 9
  source: llm_enhanced
  text: Stability. Well, when AI systems do great the first three runs and then go
    off the rails the next three, you need to be measuring these things and reporting
    on them as well.
  topic: technical/safety
- impact_reason: Reinforces the previous point with a current example (GPT-4o), underscoring
    that model versioning is dynamic and requires active monitoring by the consumer.
  relevance_score: 9
  source: llm_enhanced
  text: GPT-4o auto just got updated this week, and you probably didn't know it, right?
    That's why you have to retest monthly to track changes.
  topic: technical
- impact_reason: 'A concise summary of the three pillars of effective LLM interaction:
    model selection, configuration mode, and input technique.'
  relevance_score: 9
  source: llm_enhanced
  text: You need to use the right model, the right mode, and the right prompting techniques.
  topic: technical
- impact_reason: 'Suggests an optimal division of labor for evaluation: automation
    handles verifiable facts (citations, accuracy), while humans focus on subjective
    quality (tone).'
  relevance_score: 9
  source: llm_enhanced
  text: You need to use the automated checks for citations and accuracy, and the humans
    can grade for tone and quality.
  topic: strategy
- impact_reason: Clearly defines the target audience and the context (front-end OS
    adoption) for the evaluation framework being presented.
  relevance_score: 8
  source: llm_enhanced
  text: I think this is for teams and organizations that are evaluating using front-end
    AI chatbots as their AI operating system of choice.
  topic: strategy
- impact_reason: Confirms the current trend among leading organizations regarding
    AI adoption strategy.
  relevance_score: 8
  source: llm_enhanced
  text: Smart organizations are starting to move their day-to-day business processes
    inside the front end of a large language model.
  topic: strategy
- impact_reason: Emphasizes the necessity of choosing and committing to a front-end
    AI platform for success, rather than avoiding the decision.
  relevance_score: 8
  source: llm_enhanced
  text: The guaranteed way to not use one of those three big operating systems, but
    if you wanted to succeed, you had to. I think you have to make that same choice
    now.
  topic: strategy
- impact_reason: Illustrates the complexity and 'model sprawl' users face within a
    single platform (ChatGPT), directly undermining ease of use claims.
  relevance_score: 8
  source: llm_enhanced
  text: I have 10 different models that I can choose from. Okay, that's not easy,
    right? You have all the different variations of GPT-4o, auto, instant, thinking,
    mini, thinking in Pro, and then you have your legacy models...
  topic: technical
- impact_reason: 'Actionable advice on project management: AI pilots must be short
    and iterative to avoid organizational inertia.'
  relevance_score: 8
  source: llm_enhanced
  text: The pilots are always too long. You can do a year-long pilot in AI, that's,
    you know, you're failing before you start.
  topic: business
- impact_reason: Describes a pervasive organizational distraction endemic to the current
    AI landscape, hindering focused implementation.
  relevance_score: 8
  source: llm_enhanced
  text: one of the common, most common traps of companies not finding ROI on Gen AI
    is the shiny object AI syndrome, right? Every single week... there's a shiny object
    every single week, multiple times, and companies get too easily distracted by
    that.
  topic: strategy
- impact_reason: A concise warning about the inherent variability and potential inconsistency
    of generative AI outputs, emphasizing the need for robust testing.
  relevance_score: 8
  source: llm_enhanced
  text: Generative AI can be kind of like a roll of the day sometimes, so you have
    to keep that in mind.
  topic: technical/safety
- impact_reason: A crucial warning against scope creep during evaluation sprints due
    to continuous platform updates (like GPT Apps), stressing the need to freeze the
    scope.
  relevance_score: 8
  source: llm_enhanced
  text: You need to set clear ground rules because again, these models and modes are
    always changing. So, you know, if good example, all right, a good example, ChatGPT
    just launched their Apps. If you were midway through and you're like, oh yeah,
    we could use this app for that. No, you said, this is what we're doing. We're
    not doing anything else.
  topic: strategy
- impact_reason: Introduces the concept of 'drift cases' or intentional traps in test
    data to assess model robustness and adaptability, especially for agentic systems.
  relevance_score: 8
  source: llm_enhanced
  text: 'Also, I would add six drift cases: you know, rename files, dead links. You
    need to put actual traps in there, both for humans and for AI.'
  topic: technical/safety
- impact_reason: Highlights that configuration testing must include verifying tool
    usage and implicitly points to poor prompt engineering as a common failure point.
  relevance_score: 8
  source: llm_enhanced
  text: Then you need to verify during the test that the AI uses the expected tools,
    not workarounds or guessing. This is the other thing. So many people don't know
    prompt engineering basics.
  topic: technical/strategy
- impact_reason: Emphasizes the necessity of defining objective, quantifiable metrics
    (reliability score) *before* testing begins, linking testing design directly to
    evaluation.
  relevance_score: 8
  source: llm_enhanced
  text: You need to calculate the reliability score, right? So when you are creating
    this rubric on the front end, you need to know how it's going to be scored on
    the back end...
  topic: strategy
- impact_reason: A practical warning about 'AI fingerprinting' in outputs and the
    need to normalize formatting to ensure fair, objective grading.
  relevance_score: 8
  source: llm_enhanced
  text: A lot of times large language models will cite things in line, right? So you
    don't want to just copy and paste that over because someone's going to know, oh,
    this is from an LLM, and then they might, depending on their objective and their
    agenda, they might grade it accordingly, either better or worse.
  topic: technical/strategy
- impact_reason: 'Actionable financial advice for proving AI value: calculating true
    Net ROI by factoring in fully loaded human costs and subscription overhead.'
  relevance_score: 8
  source: llm_enhanced
  text: You need to convert time savings to dollars using a fully loaded rate and
    then subtract the subscription costs, right? Whatever you're paying for these
    AI systems for net ROI, right?
  topic: business
- impact_reason: 'A key testing requirement for agentic systems: ensuring the model
    follows the intended execution path (tool use) rather than finding unexpected,
    potentially fragile, shortcuts.'
  relevance_score: 8
  source: llm_enhanced
  text: You need to verify during the test that the AI uses the expected tools, not
    workarounds or guessing.
  topic: technical
- impact_reason: Provides a specific, repeatable methodology for testing generative
    systems to account for non-determinism.
  relevance_score: 8
  source: llm_enhanced
  text: You need to repeat each test case three times in separate chats, right? So
    turn off, depending on what you know front-end AI chatbot you're using, but you're
    probably going to want to turn off memory.
  topic: technical
- impact_reason: 'Reiterates the fundamental challenge of evaluating generative systems:
    the need for pre-defined, objective scoring mechanisms due to inherent variability.'
  relevance_score: 8
  source: llm_enhanced
  text: And then you need to calculate the reliability score, right? So when you are
    creating this rubric on the front end, you need to know how it's going to be scored
    on the back end because again, y'all, generative AI is generative.
  topic: strategy
- impact_reason: Frames AI safety and compliance not as a unique technical hurdle,
    but as an extension of existing corporate governance standards applied to human
    workers.
  relevance_score: 8
  source: llm_enhanced
  text: don't want an AI going off the rails and doing something against company policies
    in the same way you wouldn't want a human doing something, right? Safety, same
    thing, accuracy, same thing...
  topic: safety
- impact_reason: 'Identifies a major practical challenge for enterprise adoption:
    the rapid, unannounced evolution of front-end features and models.'
  relevance_score: 7
  source: llm_enhanced
  text: even front-end AI systems are complicated, confusing, and change too often
    without notice.
  topic: business
- impact_reason: A specific product endorsement illustrating an AI application focused
    on knowledge synthesis and personal expertise.
  relevance_score: 7
  source: llm_enhanced
  text: NotebookLM as an AI-first tool for anyone trying to make sense of complex
    information. Upload your documents, and NotebookLM instantly becomes your personal
    expert on covering insights and helping you brainstorm.
  topic: business
- impact_reason: Provides a quick comparative snapshot of model selection complexity
    across major LLM providers (GPT vs. Gemini vs. Claude).
  relevance_score: 7
  source: llm_enhanced
  text: It's not as bad in Gemini, right? There are essentially two. You know, Claude
    is a little, you know, in between, I think there are about six, six different
    models.
  topic: technical
- impact_reason: Illustrates the real-world complexity of multi-model enterprise adoption,
    suggesting that different models might be optimal for different organizational
    segments.
  relevance_score: 7
  source: llm_enhanced
  text: You might have some people, you know, you might have 100 employees on a ChatGPT
    team's plan, and you might have, you know, 200 on a Claude enterprise plan. So
    where do you get started?
  topic: business
- impact_reason: This sets a high bar for AI performance, suggesting that production-ready
    AI should exhibit human-like resilience and problem-solving capabilities during
    testing.
  relevance_score: 7
  source: llm_enhanced
  text: hat if they encounter a problem, they will adapt, they will adapt and overcome
    it, just like hopefully a human would.
  topic: strategy
- impact_reason: Focuses on access control and security configuration in the AI development/testing
    pipeline, ensuring users only interact with authorized resources.
  relevance_score: 7
  source: llm_enhanced
  text: You need to set up the shared workspace matching real permissions for the
    right tools and the models that users will ultimately have.
  topic: safety/business
- impact_reason: Stresses the importance of comprehensive documentation for reproducibility
    and auditing in AI workflows.
  relevance_score: 7
  source: llm_enhanced
  text: 'Also, you need to document the configuration: which model, which tools can
    be used, which connectors, you know, who has what access level?'
  topic: strategy
- impact_reason: Establishes the speaker's authority and long-term perspective on
    the AI OS paradigm shift.
  relevance_score: 6
  source: llm_enhanced
  text: I've been one of the first people, I think, shouting and screaming about this
    AI operating system thing.
  topic: strategy
- impact_reason: Practical call to action for accessing multimedia content.
  relevance_score: 3
  source: llm_enhanced
  text: If you ever want the video version, make sure to go to our website at youreverydayai.com.
    You can watch the video version there. Click on episodes.
  topic: general
source: Unknown Source
summary: '## Podcast Summary: EP 628: What’s the best LLM for your team? 7 Steps to
  evaluate and create ROI for AI


  This episode of the Everyday AI Show, hosted by Jordan Molson, focuses on providing
  a practical framework for organizations to select the right Large Language Model
  (LLM) for their needs and, crucially, how to measure the Return on Investment (ROI)
  when deploying these tools, particularly in their front-end, "AI Operating System"
  capacity.


  The central narrative argues that the industry is shifting from using LLMs primarily
  via backend APIs to integrating them as front-end **AI Operating Systems** (like
  enterprise versions of ChatGPT, Gemini, or Claude), where users interact directly
  with rich interfaces, modes, and external applications. This shift necessitates
  a new, rigorous evaluation process beyond standard scientific benchmarks.


  ### 1. Focus Area

  The primary focus is on **evaluating front-end LLM deployments** for knowledge workers,
  moving beyond simple API benchmarks to assess real-world utility, reliability, and
  ROI within enterprise workflows. Key themes include the concept of the LLM as an
  operating system, the complexity introduced by multiple models and "modes" (e.g.,
  web search, agent mode), and common pitfalls in achieving measurable AI ROI.


  ### 2. Key Technical Insights

  *   **Front-End vs. API Usage:** The most powerful use cases emerge when utilizing
  the **modes and features** available in the front-end interfaces (like ChatGPT''s
  Connectors, Canvas, or Agent mode), which are often unavailable or abstracted when
  using models purely via API connections.

  *   **Generative Reliability:** Because generative AI outputs vary significantly
  even with identical inputs, structured **AI Evals (Evaluations)** are essential
  for ensuring consistency, verifying performance, and catching bias before company-wide
  deployment.

  *   **Public Evals as Starting Points:** While custom testing is necessary, organizations
  can leverage public evaluation sites like **LM Arena** (which uses blind user voting
  to generate Elo scores across categories like coding, math, and creativity) and
  **LiveBench** to narrow down which models to test internally.


  ### 3. Business/Investment Angle

  *   **The AI Operating System Decision:** Companies must treat the choice of a primary
  front-end LLM (ChatGPT, Gemini, Claude) as a strategic decision akin to choosing
  a foundational operating system (like Windows or macOS) in the 90s, as business
  processes will reorganize around it.

  *   **ROI Traps:** Common reasons for failing to see ROI include overly long pilot
  phases, severe lack of **change management and training**, and, most critically,
  **failing to measure pre-Gen AI human baselines** for comparison.

  *   **Shiny Object Syndrome:** Businesses frequently get distracted by weekly AI
  advancements, preventing them from locking down a test workflow and seeing a pilot
  through to measurable completion.


  ### 4. Notable Companies/People

  *   **Stephen Johnson (Co-founder of NotebookLM):** Featured as a guest/expert,
  emphasizing the need for tools that help organize complex information and discussing
  the shift toward AI operating systems.

  *   **Jordan Molson (Host):** Driving the discussion, advocating for the AI Operating
  System concept and detailing the 7-step evaluation framework.

  *   **LLM Providers:** OpenAI (ChatGPT), Google (Gemini), and Anthropic (Claude)
  are the primary platforms whose enterprise/team plans are the focus of the evaluation.

  *   **Evaluation Platforms:** LM Arena, LiveBench, Epoch AI, and Scale’s C-LLM Leader
  were cited as valuable public resources for initial model assessment.


  ### 5. Future Implications

  The conversation strongly suggests that the future of knowledge work involves embedding
  business processes directly into the user interfaces of major LLM platforms, leveraging
  integrated apps and connectors. Success will depend not just on the model''s raw
  intelligence but on the organization''s ability to rigorously test, train staff,
  and establish clear, measurable baselines to prove efficiency gains.


  ### 6. Target Audience

  This episode is highly valuable for **Business Leaders, IT/Digital Transformation
  Managers, AI Strategy Teams, and Knowledge Workers** responsible for piloting, selecting,
  and scaling generative AI tools within their organizations.


  ---


  ### Comprehensive Summary of the 7-Step Evaluation Framework


  The core of the episode is the **7-Step Plan for Evaluating AI Models and Creating
  ROI**. The speaker stresses that before starting, organizations must secure executive
  buy-in, clear legal/security permissions, and commit to a short (2-4 week) evaluation
  sprint focused on **one specific workflow**, ignoring new advancements during that
  period.


  **The First Four Steps Detailed:**


  1.  **Define Success Criteria:** Write a "job description" for the pilot, explicitly
  identifying the required outcome, constraints, allowed tools, and "do not do" actions.
  Create a measurable grading rubric (1-10 scale) and define 3-5 black-and-white Key
  Performance Indicators (KPIs) for the workflow (e.g., human time spent, accuracy,
  revisions required).

  2.  **Measure Your Human Baseline First:** This is deemed critical but often skipped.
  Multiple employees must complete the exact same task *without* AI to establish average
  time, error rate, and cost per task. Without this baseline, ROI calculation is impossible
  guesswork.

  3.  **Build a Realistic and Controllable Test Data Set:** Gather 20-40 actual work
  examples that include "messiness" (e.g., renamed files, dead links) to test the
  model’s adaptability, especially for agentic workflows. Create a pass/fail checklist
  for each test case tied to the rubric.

  4.  **Configure Your Workspace Like Production:** Test using the exact subscription
  tier (e.g.,'
tags:
- artificial-intelligence
- generative-ai
- investment
- ai-infrastructure
- startup
- google
- openai
- anthropic
title: 'EP 628: What’s the best LLM for your team? 7 Steps to evaluate and create
  ROI for AI'
topics:
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 141
  prominence: 1.0
  topic: artificial intelligence
- keywords:
  - generative ai
  - genai
  - chatgpt
  - gpt
  - claude
  - text generation
  - image generation
  mentions: 61
  prominence: 1.0
  topic: generative ai
- keywords:
  - investment
  - funding
  - valuation
  - ipo
  - acquisition
  mentions: 5
  prominence: 0.5
  topic: investment
- keywords:
  - gpu
  - tensor
  - training
  - inference
  - model deployment
  - vector database
  mentions: 4
  prominence: 0.4
  topic: ai infrastructure
- keywords:
  - startup
  - entrepreneur
  - founder
  - venture
  mentions: 2
  prominence: 0.2
  topic: startup
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-10-09 14:44:24 UTC -->
