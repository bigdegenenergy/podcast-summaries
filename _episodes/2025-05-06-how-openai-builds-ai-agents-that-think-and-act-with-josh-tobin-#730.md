---
companies:
- category: unknown
  confidence: medium
  context: ight, everyone. Welcome to another episode of the Twomol AI podcast. I
    am your host, Sam Charington. Today, I
  name: Twomol AI
  position: 682
- category: unknown
  confidence: medium
  context: episode of the Twomol AI podcast. I am your host, Sam Charington. Today,
    I am joined by Josh Tobin. Josh is a Memb
  name: Sam Charington
  position: 717
- category: unknown
  confidence: medium
  context: your host, Sam Charington. Today, I am joined by Josh Tobin. Josh is a
    Member of Technical Staff at OpenAI. J
  name: Josh Tobin
  position: 755
- category: unknown
  confidence: medium
  context: y, I am joined by Josh Tobin. Josh is a Member of Technical Staff at OpenAI.
    Josh, it is great to have you on the s
  name: Technical Staff
  position: 787
- category: tech
  confidence: high
  context: osh Tobin. Josh is a Member of Technical Staff at OpenAI. Josh, it is great
    to have you on the show. We la
  name: Openai
  position: 806
- category: unknown
  confidence: medium
  context: l, you have done a few things since then. I think Full Stack Deep Learning
    was one of the things that folks may have heard y
  name: Full Stack Deep Learning
  position: 1371
- category: unknown
  confidence: medium
  context: that power our agentic products like Operator and Deep Research and the
    Codex CLI, which we launched a few weeks
  name: Deep Research
  position: 1989
- category: unknown
  confidence: medium
  context: 'products like Operator and Deep Research and the Codex CLI, which we launched
    a few weeks ago.


    And we are g'
  name: Codex CLI
  position: 2011
- category: unknown
  confidence: medium
  context: was a key element of what ML was offering folks. And I think business being
    model-driven is even more tr
  name: And I
  position: 4779
- category: unknown
  confidence: medium
  context: referring to a tweet or X that went viral by the Shopify CEO. I forget
    his name. And he talked about trying to
  name: Shopify CEO
  position: 5602
- category: unknown
  confidence: medium
  context: bit of time tinkering, building agents on top of LLM APIs. And the problem
    that we ran into, I think, is th
  name: LLM APIs
  position: 6581
- category: unknown
  confidence: medium
  context: build their own agents using workflows on top of LLM API calls—is that
    it is very tempting to think, "Oh,
  name: LLM API
  position: 6746
- category: unknown
  confidence: medium
  context: n it into something that just happens on its own. But I think what a lot
    of us found trying to do this is
  name: But I
  position: 7043
- category: unknown
  confidence: medium
  context: nk I am borrowing this idea from an old idea from Andrej Karpathy, but
    good models are just much better at this tha
  name: Andrej Karpathy
  position: 11472
- category: unknown
  confidence: medium
  context: can use real, working, actual useful agents now. And Deep Research, I think,
    has been incredibly useful for a lot of
  name: And Deep Research
  position: 12628
- category: unknown
  confidence: medium
  context: s that are smarter and knowing how much to think. So I cut you off when
    you were talking about Deep Rese
  name: So I
  position: 15773
- category: unknown
  confidence: medium
  context: 'coming up with a much more researched response.


    So Deep Research was the first agentic offering. We also have Oper'
  name: So Deep Research
  position: 22492
- category: unknown
  confidence: medium
  context: 's education and entertainment?


    Yeah, absolutely. So Operator, I would say, is like the technology to make Oper'
  name: So Operator
  position: 24079
- category: unknown
  confidence: medium
  context: mostly just helping to clarify the intent, like, "If I want to book a flight,
    here is how you do that,"
  name: If I
  position: 27290
- category: ai_developer
  confidence: high
  context: The employer of the guest (Josh Tobin) and the developer of the foundational
    models (GPT-3, GPT-4) and agentic products like Operator, Deep Research, and Codex
    CLI.
  name: OpenAI
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: A machine learning infrastructure startup co-founded by the guest, Josh
    Tobin, before he rejoined OpenAI.
  name: Gantry
  source: llm_enhanced
- category: ai_education/community
  confidence: medium
  context: An organization or program the guest was involved with between stints at
    OpenAI.
  name: Full Stack Deep Learning
  source: llm_enhanced
- category: ai_user/enterprise
  confidence: medium
  context: Mentioned as an example of a company whose CEO is urging internal AI adoption,
    though Shopify itself is an e-commerce platform, not primarily an AI developer.
  name: Shopify
  source: llm_enhanced
- category: ai_researcher/individual
  confidence: high
  context: Mentioned as the source of an old idea regarding system design vs. model
    capability.
  name: Andrej Karpathy
  source: llm_enhanced
- category: ai_tooling/platform
  confidence: high
  context: Mentioned as a source where the Deep Research agent finds and understands
    publicly available code.
  name: GitHub
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: An agentic offering/system discussed extensively for in-depth research,
    literature review, and coding tasks.
  name: Deep Research
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: The general conversational AI platform, often used as a baseline or comparison
    point for the more advanced offerings.
  name: ChatGPT
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as a strong reasoner, often compared against the capabilities
    of the newer models/offerings.
  name: GPT-4
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: An agentic system designed to interact with the real world (e.g., booking
    reservations) via a virtual browser.
  name: Operator
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned alongside Operator and Deep Research as an example of an agentic
    system.
  name: Codex CLI
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: Mentioned as a platform used by an Operator user for arbitrage (finding
    items to resell).
  name: eBay
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: Mentioned as a platform used by an Operator user for arbitrage (reselling
    items found elsewhere).
  name: Craigslist
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: Mentioned as a platform users try to interact with via Operator to get
    discounts.
  name: Airbnb
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: Referenced as an early technology preview, similar to the current stage
    of Operator.
  name: GPT-3 API
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: Mentioned as a service whose hosts the 'Operator' agent messages for discounts.
  name: Airbnbs
  source: llm_enhanced
- category: ai_model
  confidence: high
  context: A specific model developed by OpenAI, mentioned in comparison to the current
    state of the Operator technology.
  name: GPT-3
  source: llm_enhanced
date: 2025-05-06 22:50:00 +0000
duration: 67
has_transcript: false
layout: episode
llm_enhanced: true
original_url: https://pscrb.fm/rss/p/traffic.megaphone.fm/MLN6458824254.mp3?updated=1746809590
processing_date: 2025-10-05 19:43:42 +0000
quotes:
- length: 113
  relevance_score: 5
  text: And sort of the root cause of the problem is that most LLMs historically have
    not been trained to do agentic work
  topics: []
- length: 295
  relevance_score: 5
  text: '" And so the key is really raising models that are trained end-to-end to
    solve the kinds of tasks that users need them to solve using reinforcement learning
    so that they are able to see these multi-step processes, see the kinds of failures
    that happen in training, and learn to recover from them'
  topics: []
- length: 219
  relevance_score: 4
  text: I am curious, thinking about Gantry and what you were doing there, and I think
    Gantry was in a crop of ML infrastructure, MLOps companies that I think ran into
    this—all of the air getting sucked out of the room by GenAI
  topics: []
- length: 109
  relevance_score: 3
  text: I am curious if you have any takes on that space and how it relates to what
    OpenAI is trying to do with GenAI
  topics: []
- length: 175
  relevance_score: 3
  text: I think the misconception that a lot of folks have about agents is—before
    I came back to OpenAI, I had spent a little bit of time tinkering, building agents
    on top of LLM APIs
  topics: []
- length: 107
  relevance_score: 3
  text: So even if you are 90% accurate on one step, if you have to take 10 steps,
    then your accuracy will fall off
  topics: []
- length: 107
  relevance_score: 3
  text: I am trying to imagine how obscure you have to get in order to go to Deep
    Research for that kind of problem
  topics: []
- length: 273
  relevance_score: 3
  text: Yeah, what we found is that Deep Research is designed to go deep and collect
    a lot of information and come back to you with a very detailed report that is
    really excellent at covering all the finer points or the nuances of the initial
    framing of the question that you wrote
  topics: []
- impact_reason: 'This quote perfectly diagnoses the current, limited paradigm of
    agent building: manual, rule-based workflow design, which fails in messy, real-world
    scenarios.'
  relevance_score: 10
  source: llm_enhanced
  text: In 2023, 2024, the way most people are trying to build agents is a human designs
    a system, and that system kind of breaks the problem down into multiple steps.
    It assigns each of those steps to an LLM. Maybe there are some rules built in,
    but oftentimes the real world is messy, and that workflow that you built might
    be an oversimplification of the actual process a real expert at this task would
    follow.
  topic: technical/strategy
- impact_reason: 'This is the core thesis for the future of agentic AI: moving from
    human-designed workflows to end-to-end, reward-driven learning, leading to superior,
    emergent processes.'
  relevance_score: 10
  source: llm_enhanced
  text: When models are able to learn how to do the process by being rewarded for
    succeeding at the process, they are able to figure out in many cases something
    that is better than you could easily sit down and design yourself.
  topic: technical/predictions
- impact_reason: 'Details the practical failure point of early agent design: relying
    on sequential LLM calls leads to brittle systems due to compounding errors and
    lack of error recovery.'
  relevance_score: 10
  source: llm_enhanced
  text: The problem that we ran into, I think, is the problem pretty much everyone
    runs into when they try to build their own agents using workflows on top of LLM
    API calls—is that it is very tempting to think, 'Oh, LLMs are good at kind of
    making point predictions, making decisions,' and so we build a workflow around
    this LLM... But then when you try to actually deploy this... you start to run
    into all kinds of edge cases and failure modes, and getting the things to work
    reliably is really hard.
  topic: technical/limitations
- impact_reason: 'Explains the technical root cause of agent unreliability: standard
    LLMs are optimized for single-turn accuracy, not multi-step process reliability
    (compounding error).'
  relevance_score: 10
  source: llm_enhanced
  text: Most LLMs historically have not been trained to do agentic work. And what
    that means is that at any given step of the process, maybe they are relatively
    accurate because they are pretty smart general-purpose AI systems. But as you
    run a process that requires many steps, the small errors at one step compound
    as you take multiple steps.
  topic: technical/limitations
- impact_reason: 'Identifies the solution: end-to-end training, likely via Reinforcement
    Learning (RL), where the model learns error correction and rerouting strategies
    inherently.'
  relevance_score: 10
  source: llm_enhanced
  text: The missing ingredient has been that we need to directly train these agents
    end-to-end to do these workflow-like tasks. By doing that, you can train the agents
    in such a way that they see failures during their training and they learn to recover
    from those failures.
  topic: technical/breakthroughs
- impact_reason: 'Provides a compelling vision for the future of conversational AI:
    a unified, context-aware, multi-role assistant that dynamically chooses the appropriate
    level of effort.'
  relevance_score: 10
  source: llm_enhanced
  text: I think the thing that I would love ChatGPT to become is a place where you
    can just go, and it is like talking to your friend and your coworker and your
    personal assistant and your coach all in one, to where you can just ask a question
    like you would to a person, and just like a great coworker would, it knows when
    to come back to you with a really quick answer off the top of its head versus
    from the context and from knowing you, when it should actually go and do a bunch
    of research and come back to you with something more thorough...
  topic: predictions
- impact_reason: Provides a clear, actionable definition of an 'agentic system' based
    on duration and real-world interaction, useful for product categorization.
  relevance_score: 10
  source: llm_enhanced
  text: I think of an agentic system as any AI system that is able to go work on tasks
    for you that take longer than a few seconds and that has to interact with the
    real world in order to solve your problem.
  topic: technical
- impact_reason: Draws a powerful historical parallel to the early GPT-3 API, suggesting
    that complex, high-potential AI tools often start as previews for power users
    before mass adoption.
  relevance_score: 10
  source: llm_enhanced
  text: I think of it a lot like early GPT-3 API, right? Where it is like people used
    it, and it was—I do not think OpenAI would have framed it this way at the time,
    but in a lot of ways it is kind of a technology preview.
  topic: strategy
- impact_reason: Offers a concrete, actionable technique (site-specific instructions)
    for improving agent performance, addressing the context gap.
  relevance_score: 10
  source: llm_enhanced
  text: So one thing that I found to be really helpful for getting the most value
    from it is there is a way to add site-specific instructions, add or customize
    site-specific instructions.
  topic: technical
- impact_reason: Provides a concrete, actionable technique (site-specific instructions/context
    injection) for improving agent performance on specific websites.
  relevance_score: 10
  source: llm_enhanced
  text: One thing that I found to be really helpful for getting the most value from
    it is there is a way to add site-specific instructions, add or customize site-specific
    instructions.
  topic: technical
- impact_reason: Illustrates the required level of granularity for effective prompt
    engineering when dealing with visual/UI elements for agents, moving beyond simple
    command language.
  relevance_score: 10
  source: llm_enhanced
  text: Do not just say, 'Click upload in the menu.' Say, 'The menu is the hamburger
    thing on the right, and upload,' like how granular do you need to—
  topic: technical
- impact_reason: Offers a crucial historical analogy for understanding the current
    state of advanced agent technology, framing it as a 'technology preview' that
    requires user ingenuity to unlock value.
  relevance_score: 10
  source: llm_enhanced
  text: I think of it a lot like early GPT-3 API, if you remember that, right? Where
    it is like people used it, and it was—I do not think OpenAI would have framed
    it this way at the time, but in a lot of ways it is kind of a technology preview.
  topic: strategy/predictions
- impact_reason: Offers concrete advice on prompt engineering for agents, emphasizing
    the need for extreme granularity and visual/spatial context when instructing navigation
    tasks.
  relevance_score: 10
  source: llm_enhanced
  text: Do not just say, "Click upload in the menu." Say, "The menu is the hamburger
    thing on the right, and upload," like how granular do you need to—first of all,
    are we talking about localizing capabilities on the page, or are we talking about
    other types of context that is useful for the agent?
  topic: technical/prompt engineering
- impact_reason: Highlights the major shift in the MLOps/infrastructure space caused
    by foundation models—the assumption that every business needed custom training
    is now largely obsolete.
  relevance_score: 9
  source: llm_enhanced
  text: 'A lot of companies'' mental models were that every company is going to need
    to be training models. Before we had GPT-3 and later models that did this more
    effectively, the thinking was: the way to create actual value with AI is to train
    models that are fit for purpose for the thing that your business needs to do.'
  topic: business/strategy
- impact_reason: A concise summary of the value proposition of foundation models and
    the reason why many specialized ML infrastructure startups struggled post-ChatGPT.
  relevance_score: 9
  source: llm_enhanced
  text: What turned out to be true is that general-purpose models, GPT-3, GPT-4, other
    large language models, are pretty good at most tasks that you can specify.
  topic: business/strategy
- impact_reason: Direct, actionable business advice for companies adopting AI, prioritizing
    leverage of existing powerful APIs over expensive internal model development.
  relevance_score: 9
  source: llm_enhanced
  text: 'I generally tell them: don''t even think about training your own models until
    you have exhausted what you can do with the models that OpenAI or any other foundation
    model provider will sell you.'
  topic: business/strategy
- impact_reason: Provides a concrete example of how RL training enables self-correction
    in multi-step tasks, contrasting it with the failure mode of non-agent-trained
    LLMs.
  relevance_score: 9
  source: llm_enhanced
  text: Whereas an agent that is trained to do web research has been trained using
    reinforcement learning to sort of be good at this multi-step process. Well, in
    its training, it has seen many instances where it searched for the wrong term,
    and the training has incentivized it to learn to recover from those instances
    and instead go back and think, 'Oh, you know, I searched for this term, but I
    got results that were not relevant. Maybe that means that I had the wrong search
    term. So let me go try again and pick a different one.'
  topic: technical/training
- impact_reason: A strong statement suggesting that the emergent intelligence of well-trained
    models surpasses human ability to manually engineer complex, optimal workflows.
  relevance_score: 9
  source: llm_enhanced
  text: The second [problem with human-designed workflows] is just that I think I
    am borrowing this idea from an old idea from Andrej Karpathy, but good models
    are just much better at this than designing these types of systems.
  topic: strategy/predictions
- impact_reason: 'Poses the central strategic question for the future of AI agents:
    will agentic capability be a generalized feature of all large models, or will
    specialized agent models emerge?'
  relevance_score: 9
  source: llm_enhanced
  text: 'Do you—how do we get to a more generalized agentic model that is easier for
    your users to build their own models with? And maybe that is the general question.
    A sub-question is: are all models going to get better at agentic capabilities—this
    error correction, instruction following melee that you just referenced—or should
    we expect to see agent-specific types of models?'
  topic: predictions
- impact_reason: Identifies reasoning capability as a critical, non-negotiable component
    for successful agentic behavior, emphasizing step-by-step correctness.
  relevance_score: 9
  source: llm_enhanced
  text: And I think the other feature of models for agentic use cases that is really
    valuable is reasoning, because a lot of agentic tasks have this quality where
    there is a range in difficulty levels of solving the task, and doing the right
    thing at each step of the task is very important to make sure that the overall
    task succeeds.
  topic: technical
- impact_reason: Suggests that dynamic allocation of 'thinking time' or computational
    effort based on step difficulty is key to efficient and effective agent performance.
  relevance_score: 9
  source: llm_enhanced
  text: And so letting the model choose how much reasoning effort it wants to apply
    to figure out the current step over the workflow, to me, it feels like a pretty
    important component of what is going to make these systems work well.
  topic: technical
- impact_reason: 'Describes a crucial feature for advanced agentic systems: proactive,
    mid-process human feedback loops to course-correct long-running tasks.'
  relevance_score: 9
  source: llm_enhanced
  text: Or could come back and, like in Deep Research, there is this phase in the
    beginning where it will ask you a few follow-up questions. But I think eventually
    it should be able to just come back to you in the middle of its research and say,
    'Hey, here is what I am finding so far. I am going to keep going, but is there
    any other—is there any feedback? Do you have any feedback on this? Is this what
    you are imagining?'
  topic: technical
- impact_reason: 'Reveals a practical workflow pattern: using smaller, faster models
    as ''scaffolding'' or consultants to refine complex prompts before engaging a
    powerful, resource-intensive agent.'
  relevance_score: 9
  source: llm_enhanced
  text: And one thing that we have seen a lot of people do is to use a one or now
    O3 or a four mini to help craft the question. So if there is a topic where you
    do not even really know enough to frame a good question, a lot of times folks
    will have a conversation with a smaller model and then they will use that to sort
    of flesh out all the details of the question that they want to research...
  topic: strategy
- impact_reason: Categorizes specific products (Operator, Deep Research, Codex CLI)
    under the 'agentic system' umbrella, grounding the abstract definition in concrete
    examples.
  relevance_score: 9
  source: llm_enhanced
  text: So yeah, Operator, Deep Research, and Codex CLI, I think, are all good examples
    of agentic systems.
  topic: technical
- impact_reason: Highlights the critical role of 'power users' in discovering initial
    utility for nascent, complex AI technologies.
  relevance_score: 9
  source: llm_enhanced
  text: But even on day one with GPT-3, there were a bunch of people where they played
    around with it a lot, and they got to the point where they figured out how to
    make it really useful for them.
  topic: business
- impact_reason: 'Excellent analogy explaining the core challenge of grounding AI
    agents: the lack of inherent context when interacting with novel interfaces.'
  relevance_score: 9
  source: llm_enhanced
  text: If you are imagining Operator visiting a website for the first time, it is
    kind of like you are seeing this website for the first time without any context
    of the world or who the user is.
  topic: technical
- impact_reason: Directly links providing context/instructions to measurable improvements
    in agent performance (reliability/speed).
  relevance_score: 9
  source: llm_enhanced
  text: But you can provide instructions that help the model understand how to use
    this site to solve their problem, and that tends to make it a lot more reputable
    and a lot faster.
  topic: technical
- impact_reason: Details the crucial feature of observability in agentic systems—the
    ability to watch the agent execute tasks in a virtual environment—which builds
    trust.
  relevance_score: 9
  source: llm_enhanced
  text: You can watch in a virtual browser the agent kind of navigate to the web page,
    click around the web page, and do the task that you asked it to do.
  topic: technical
- impact_reason: Directly links detailed instruction/context provision to improved
    agent reliability ('reputable') and speed.
  relevance_score: 9
  source: llm_enhanced
  text: You can provide instructions that help the model understand how to use this
    site to solve their problem, and that tends to make it a lot more reputable and
    a lot faster.
  topic: technical
- impact_reason: Emphasizes the significant engineering and research challenge involved
    in creating reliable, general-purpose AI agents capable of complex web interaction.
  relevance_score: 9
  source: llm_enhanced
  text: Operator, I would say, is like the technology to make Operator work really
    well is an incredibly difficult thing to build.
  topic: technical/business
- impact_reason: 'Poses the fundamental question for maximizing AI agent utility:
    it requires shifting the user''s mental model of problem-solving to align with
    the agent''s capabilities.'
  relevance_score: 9
  source: llm_enhanced
  text: How do I need to think about the world or my problem or Operator in order
    to make it work?
  topic: strategy/adoption
- impact_reason: 'Reveals a critical technical feature for improving agent performance:
    providing context-specific guidance to overcome the model''s lack of inherent
    site knowledge.'
  relevance_score: 9
  source: llm_enhanced
  text: There is a way to add site-specific instructions, add or customize site-specific
    instructions.
  topic: technical/deployment
- impact_reason: Confirms the enduring strategic importance of being 'model-driven,'
    even if the method of model creation (internal vs. external) has changed.
  relevance_score: 8
  source: llm_enhanced
  text: The core idea was that in order to be competitive, businesses would need to
    become model-driven. This core idea of pulling patterns out of data and putting
    them into operational workflows in order to make decisions faster and more accurately
    than humans could was a key element of what ML was offering folks.
  topic: strategy
- impact_reason: Counters the idea that agents are purely futuristic, providing evidence
    that current, specialized agentic products (like Deep Research) are already delivering
    tangible utility across diverse domains.
  relevance_score: 8
  source: llm_enhanced
  text: You can use real, working, actual useful agents now. And Deep Research, I
    think, has been incredibly useful for a lot of people. People are using it for
    business and research workflows, but also scientific research, travel and shopping,
    programming.
  topic: predictions/business
- impact_reason: 'Poses a critical architectural question for the future: will agentic
    skills become a generalized feature of all foundation models, or will specialized
    agent models dominate certain workflows?'
  relevance_score: 8
  source: llm_enhanced
  text: Are all models going to get better at agentic capabilities—this error correction,
    instruction following melee that you just referenced—or should we expect to see
    agent-specific types of models?
  topic: technical/future trends
- impact_reason: Highlights the significant gap in capability between large foundational
    model creators (like OpenAI) and typical development teams when building advanced
    agentic systems, setting the stage for discussion on accessibility.
  relevance_score: 8
  source: llm_enhanced
  text: When you think about applying that idea broadly among developer teams writing
    software in startups and enterprises—the ability, as you alluded to earlier, for
    OpenAI to create a model that is designed to do these things that improves these
    things—is very different from a startup or an enterprise academic institution.
  topic: strategy
- impact_reason: 'Indicates a clear trend: improved base model performance (like O3)
    directly lowers the barrier to entry for building complex, multi-step automated
    workflows.'
  relevance_score: 8
  source: llm_enhanced
  text: I do think it is very much the case that as the models get better, building
    these types of workflows will be a lot easier. Already, I think O3 is quite good
    compared to older models at understanding the level of complexity of instructions
    that you often have to have to automate a process or build a complicated workflow.
  topic: technical
- impact_reason: Discusses the trade-off between model size and capability, suggesting
    that while small models can be optimized, large models retain an edge in generalization,
    crucial for unforeseen tasks.
  relevance_score: 8
  source: llm_enhanced
  text: I do not think we have really exhausted our limit of how good we can make
    small models. But I think the advantages that large models have are that large
    models tend to be better at generalization.
  topic: technical
- impact_reason: 'Illustrates the power of generalization: an agent designed for research
    unexpectedly excels at coding due to the availability of relevant training data
    (public code).'
  relevance_score: 8
  source: llm_enhanced
  text: But some of the other things that people are using it for, which were initially
    surprising to us, are coding. So it turns out, even though we did not really design
    the model for this use case, there is a lot of publicly available code on the
    internet.
  topic: technical
- impact_reason: 'Articulates the ideal future state of AI interaction: seamless,
    context-aware tool selection without explicit user instruction.'
  relevance_score: 8
  source: llm_enhanced
  text: At some point, I might want the model to just know if my question calls for
    Deep Research and just do it, right?
  topic: predictions
- impact_reason: Frames advanced, complex agent technology (like Operator) as a 'technology
    preview' or early access product, managing user expectations about immediate mass
    utility.
  relevance_score: 8
  source: llm_enhanced
  text: Operator is not intended to be the thing that every single person in the world
    uses every day on day one. It is meant to be kind of an early launch of the technology
    so that people could get value from it and could also just get a feel for where
    this is going.
  topic: business
- impact_reason: 'A key insight for user adoption: complex AI tools require user effort
    (work) to unlock personalized value, contrasting with ''instant utility'' products.'
  relevance_score: 8
  source: llm_enhanced
  text: You get a lot of value from it if you put in the work to figure out it is
    useful for you.
  topic: business
- impact_reason: Suggests that clarifying the *goal* and *process* (intent) is more
    effective than overly granular UI instructions for agent prompting.
  relevance_score: 8
  source: llm_enhanced
  text: Yeah, I find mostly just helping to clarify the intent, like, 'If I want to
    book a flight, here is how you do that,' that kind of thing.
  topic: technical
- impact_reason: Emphasizes the psychological impact of watching an agent work, suggesting
    that transparency in execution is key to user acceptance of complex automation.
  relevance_score: 8
  source: llm_enhanced
  text: So it is really, really cool. It is super fun to watch because you can feel
    the intelligence and the thinking as you watch the model click through the web
    much like you would.
  topic: strategy
- impact_reason: Highlights the significant engineering challenge involved in building
    reliable, real-world interacting AI agents.
  relevance_score: 8
  source: llm_enhanced
  text: The technology to make Operator work really well is an incredibly difficult
    thing to build.
  topic: technical
- impact_reason: Identifies the 'power user' segment as the initial driver for adoption
    and utility discovery in nascent, complex AI technologies.
  relevance_score: 8
  source: llm_enhanced
  text: Even on day one with GPT-3, there were a bunch of people where they played
    around with it a lot, and they got to the point where they figured out how to
    make it really useful for them. I think Operator is kind of more at that stage
    of model development, where there are power users who love it, but it is not for
    everyone yet.
  topic: business
- impact_reason: Suggests that clarifying the high-level goal/intent, alongside UI
    specifics, is crucial for agent success.
  relevance_score: 8
  source: llm_enhanced
  text: I find mostly just helping to clarify the intent, like, 'If I want to book
    a flight, here is how you do that,' that kind of thing.
  topic: technical
- impact_reason: Highlights the intuitive and human-like interaction experience of
    advanced web-navigating AI agents, making the technology tangible and engaging
    for users.
  relevance_score: 8
  source: llm_enhanced
  text: It is really, really cool. It is super fun to watch because you can feel the
    intelligence and the thinking as you watch the model click through the web much
    like you would.
  topic: technical/user experience
- impact_reason: Provides a realistic assessment of current agent maturity (not yet
    'generally useful') while confirming the trajectory toward easier custom agent
    creation.
  relevance_score: 7
  source: llm_enhanced
  text: I still think there is a way to go before that is a generally useful agent.
    But I think the yeah, as the models get better, building custom agents is going
    to get dramatically easier.
  topic: predictions
- impact_reason: Confirms that model improvement includes better meta-cognition—the
    ability to self-regulate the depth of processing required for a task.
  relevance_score: 7
  source: llm_enhanced
  text: It is not new, but we are continuously getting better at making models that
    are smarter and knowing how much to think.
  topic: technical
- impact_reason: 'Highlights a powerful, non-obvious capability: retrieving highly
    specific, obscure information, moving beyond simple summarization.'
  relevance_score: 7
  source: llm_enhanced
  text: And then I think the other underrated use of Deep Research is for finding
    very rare facts on the internet. So I think people—probably the bulk of what I
    think most people use Deep Research for is going broad and then synthesizing...
    But the model is also quite good at finding information that is just buried in
    the corner of the internet somewhere.
  topic: technical
- impact_reason: 'Clarifies the intended market positioning for advanced research
    tools: an upgrade path for users needing depth beyond standard conversational
    AI.'
  relevance_score: 7
  source: llm_enhanced
  text: We found that mostly the kind of use case that we were imagining for Deep
    Research was kind of your in-chat GPT for something that you normally use ChatGPT
    for, and then there is something where you just really want a much more thorough
    answer than you get out of the box of ChatGPT.
  topic: business
- impact_reason: 'Offers practical advice for prompt engineering in agentic systems:
    upfront clarity on desired output structure significantly improves complex results.'
  relevance_score: 7
  source: llm_enhanced
  text: The quality of the results that you get are very sensitive to—they are not
    very sensitive, but you get better results if you put time up front into thinking
    about what you really want to see at the end, because the model is very good at
    adhering to those things...
  topic: business
- impact_reason: Shows that key agentic features (like proactive clarification) are
    often derived from empirical observation of user behavior rather than purely initial
    design.
  relevance_score: 7
  source: llm_enhanced
  text: The upfront questions were something that we added after the fact, as from
    observing the way that users interacted with the model.
  topic: strategy
- impact_reason: Describes the typical adoption curve for groundbreaking but difficult-to-master
    AI technology, emphasizing the role of early power users in proving viability.
  relevance_score: 7
  source: llm_enhanced
  text: I think Operator is kind of more at that stage of model development, where
    there are power users who love it, but it is not for everyone yet.
  topic: strategy
- impact_reason: Identifies early, real-world use cases for autonomous agents, which
    often revolve around economic arbitrage or efficiency gains.
  relevance_score: 7
  source: llm_enhanced
  text: I have seen some examples of like—I think the theme that I have seen the most
    is like arbitrage. Like, 'I am going to have this Operator find a bunch of stuff
    on eBay that I can sell for more on Craigslist,' or find Airbnbs and message all
    the hosts to try to get a discount or something like that.
  topic: predictions
- impact_reason: Describes the product architecture and user experience integration
    strategy for advanced tools (embedding specialized apps within a general chat
    interface).
  relevance_score: 7
  source: llm_enhanced
  text: Operator is also a service inside of chat, and so you can go to Operator—there
    is a link to it from chat—but it is a separate kind of web app that works a lot
    like chat.
  topic: business
- impact_reason: Captures the qualitative experience of observing complex AI reasoning/action
    in real-time, suggesting a shift in user interaction paradigms.
  relevance_score: 7
  source: llm_enhanced
  text: It is super fun to watch because you can feel the intelligence and the thinking
    as you watch the model click through the web much like you would.
  topic: strategy
- impact_reason: 'Defines the expected use case for advanced research agents: deep
    synthesis from multiple sources.'
  relevance_score: 6
  source: llm_enhanced
  text: I think what people think about Deep Research, they think about using it for
    market research and scientific literature review and kind of other tasks where
    the model just has to go out and think and read a lot of documents to come back
    with a synthesized answer.
  topic: business
- impact_reason: Acknowledges the established value proposition of research agents
    while probing for novel, surprising applications.
  relevance_score: 6
  source: llm_enhanced
  text: I think probably everyone listening gets the core value proposition thesis
    behind Deep Research. Are there things that you find that surprise folks that
    it can do that you know folks might not know...
  topic: business
source: Unknown Source
summary: '## Podcast Summary: How OpenAI Builds AI Agents That Think and Act with
  Josh Tobin - #730


  This episode of the Twomol AI podcast features Sam Charrington in conversation with
  **Josh Tobin**, a Member of Technical Staff at OpenAI, focusing on the research
  and development behind OpenAI''s agentic products, such as Operator and Deep Research.
  The discussion centers on the shift from manually designed, multi-step LLM workflows
  to end-to-end trained, robust AI agents capable of complex, real-world task execution.


  ---


  ### 1. Focus Area

  The primary focus is **AI Agent Development and Architecture** at OpenAI. Key areas
  covered include:

  *   The limitations of traditional, human-designed, multi-step LLM workflows (compounding
  errors).

  *   The necessity of **end-to-end training** using reinforcement learning (RL) to
  enable agents to learn recovery mechanisms from failures during multi-step processes.

  *   The role and application of OpenAI''s agentic products (Deep Research, Operator,
  Codex CLI).

  *   The evolution of the ML infrastructure landscape following the rise of powerful
  foundation models.


  ### 2. Key Technical Insights

  *   **Agentic Training Paradigm:** The core technical challenge in building reliable
  agents is moving beyond sequential LLM calls governed by human-designed rules. True
  agentic capability requires training models **end-to-end** on the entire workflow,
  rewarding success, which allows the model to learn recovery strategies (e.g., correcting
  a bad search term) that brittle, pre-designed workflows cannot handle.

  *   **Compounding Error Mitigation:** Traditional workflows suffer from error propagation
  across multiple steps. RL-trained agents overcome this by learning to recognize
  and self-correct deviations during execution, leading to significantly higher reliability
  in long, complex tasks.

  *   **Reasoning and Model Size:** Larger models generally exhibit better generalization
  capabilities, which is crucial for novel agentic tasks that developers did not explicitly
  anticipate. Furthermore, the ability for models to dynamically allocate **reasoning
  effort** (i.e., deciding how much "thinking" time to spend on a step) is a valuable
  component for robust agent performance.


  ### 3. Business/Investment Angle

  *   **Foundation Model Dominance:** The era of every company building custom models
  is largely over. Foundation models (like those from OpenAI) are now so capable that
  businesses should exhaust all possibilities with off-the-shelf commercial models
  before investing in proprietary training infrastructure.

  *   **Agentic Products as Technology Previews:** Early agentic offerings like Operator
  serve as crucial technology previews. While not immediately mass-market useful for
  everyone (similar to early GPT-3 API access), they demonstrate the direction of
  AI and provide early value to power users and developers.

  *   **Shifting MLOps Landscape:** The business model for ML infrastructure startups
  focused on model training (pre-ChatGPT) became less feasible as general-purpose
  models absorbed much of the need for bespoke model development.


  ### 4. Notable Companies/People

  *   **Josh Tobin (OpenAI):** Leads the agents research team, responsible for models
  powering agentic products. Previously co-founded the ML infrastructure startup **Gantry**.

  *   **OpenAI Agentic Products:** **Deep Research** (for thorough literature review/synthesis),
  **Operator** (for real-world interaction via a virtual browser, e.g., booking reservations),
  and **Codex CLI**.

  *   **Andrej Karpathy:** Mentioned regarding the idea that good models often outperform
  manually designed systems.


  ### 5. Future Implications

  The industry is moving toward **co-working entities** where the AI assistant (like
  an evolved ChatGPT) intuitively knows when to provide a quick answer versus when
  to autonomously execute complex, multi-step tasks (like Deep Research) on the user''s
  behalf. The goal is to evolve ChatGPT into a natural partner that manages task delegation,
  including knowing when to pause research to ask clarifying questions.


  ### 6. Target Audience

  This episode is highly valuable for **AI Researchers, Machine Learning Engineers,
  Product Managers building AI applications, and Technology Strategists** interested
  in the practical deployment and next generation of LLM capabilities beyond simple
  chat interfaces.'
tags:
- artificial-intelligence
- generative-ai
- ai-infrastructure
- startup
- openai
title: 'How OpenAI Builds AI Agents That Think and Act with Josh Tobin - #730'
topics:
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 96
  prominence: 1.0
  topic: artificial intelligence
- keywords:
  - generative ai
  - genai
  - chatgpt
  - gpt
  - claude
  - text generation
  - image generation
  mentions: 30
  prominence: 1.0
  topic: generative ai
- keywords:
  - gpu
  - tensor
  - training
  - inference
  - model deployment
  - vector database
  mentions: 8
  prominence: 0.8
  topic: ai infrastructure
- keywords:
  - startup
  - entrepreneur
  - founder
  - venture
  mentions: 5
  prominence: 0.5
  topic: startup
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-10-05 19:43:42 UTC -->
