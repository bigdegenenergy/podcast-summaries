---
actionable_items:
- action: potentially
  category: investigation
  full_context: 'you could potentially '
  priority: medium
companies:
- category: unknown
  confidence: medium
  context: Hello everybody and welcome to the CIM Marketing Podcast, and today we're
    starting the season with AI Ques
  name: CIM Marketing Podcast
  position: 35
- category: unknown
  confidence: medium
  context: Podcast, and today we're starting the season with AI Question Time. Delighted
    to say we're joined by two expert gues
  name: AI Question Time
  position: 99
- category: unknown
  confidence: medium
  context: lighted to say we're joined by two expert guests, Kerry Harrison, who was
    an AI trainer and AI consultant and, in
  name: Kerry Harrison
  position: 169
- category: unknown
  confidence: medium
  context: ultant and, in fact, founder of the world's first AI Gin. Hello Kerry,
    how are you? I'm good, thank you ve
  name: AI Gin
  position: 268
- category: unknown
  confidence: medium
  context: nd, in fact, founder of the world's first AI Gin. Hello Kerry, how are
    you? I'm good, thank you very good. It's
  name: Hello Kerry
  position: 276
- category: unknown
  confidence: medium
  context: eat to have you on the show. We're also joined by Duncan Smith, who is
    a fellow of the CIM and is a data protect
  name: Duncan Smith
  position: 442
- category: unknown
  confidence: medium
  context: ', like, how do I get the most out of these tools? So I think it does make
    a huge difference. There''s a r'
  name: So I
  position: 1970
- category: unknown
  confidence: medium
  context: s a really great prompting methodology called the GCSE Prompting methodology,
    which I think came out of Microsoft,
  name: GCSE Prompting
  position: 2069
- category: tech
  confidence: high
  context: Prompting methodology, which I think came out of Microsoft, and it's really
    great, which talks about the imp
  name: Microsoft
  position: 2123
- category: unknown
  confidence: medium
  context: f. So you don't actually even have to go to them. And I wonder over time
    if maybe we'll have to think abo
  name: And I
  position: 3867
- category: unknown
  confidence: medium
  context: ulatory bodies. So in my instance, it's often the Information Commissioner's
    Office, and I don't recognize the quote. I know
  name: Information Commissioner
  position: 5266
- category: tech
  confidence: high
  context: are. And I've had it on a notebook I learned from Google where it's actually
    said, I can't answer that que
  name: Google
  position: 6697
- category: tech
  confidence: high
  context: don't use that on a regular basis. I tend to use OpenAI's tools. I haven't
    used Claude as much as I've us
  name: Openai
  position: 8636
- category: unknown
  confidence: medium
  context: at an un-phobic, would come out slightly better. But I think the fact that
    it just can hallucinate is th
  name: But I
  position: 9205
- category: unknown
  confidence: medium
  context: ily. And so I think it depends what you're doing. If I always just say
    if it's anything statistical or f
  name: If I
  position: 11736
- category: unknown
  confidence: medium
  context: ', and you know, what happened with replicants and Philip K. Dick''s writing
    and things. And immediately that'
  name: Philip K
  position: 12917
- category: tech
  confidence: high
  context: that process do I put that we call it pulling the domino? So if you set
    dominoes up in a room and somebody
  name: Domino
  position: 22310
- category: unknown
  confidence: medium
  context: ll the ads and thinking like, I wouldn't do that. Say I generated and I
    saw this really lovely one actual
  name: Say I
  position: 23545
- category: unknown
  confidence: medium
  context: lack of humanness, the spotting the replicant as Blade Runner would have
    us, that we're very good at doing it.
  name: Blade Runner
  position: 25168
- category: unknown
  confidence: medium
  context: eric, boring, vanilla, like everyone else output. Custom GPT is one of
    the great things is you can give it ins
  name: Custom GPT
  position: 31899
- category: unknown
  confidence: medium
  context: h AI. So this would be my byline would become not Ben Walker, but Ben Walker
    and AI, Ben Walker and my mate, t
  name: Ben Walker
  position: 39984
- category: tech
  confidence: high
  context: mark it as AI generated. So I'll say generated on Midjourney or generated
    with Google or whatever it might be.
  name: Midjourney
  position: 40596
- category: unknown
  confidence: medium
  context: or generated with Google or whatever it might be. Because I don't ever
    want someone to come into my newslette
  name: Because I
  position: 40657
- category: unknown
  confidence: medium
  context: think so important. Just get that out of the way. Do I think enough people
    have that conversation at the
  name: Do I
  position: 45464
- category: unknown
  confidence: medium
  context: ny training on ethics other than perhaps watching Hot Fuzz and realizing
    that was all about ethics, you know
  name: Hot Fuzz
  position: 54543
- category: unknown
  confidence: medium
  context: course, we all know that. It's a load of rubbish. Some FDs get it, some
    FDs don't probably. I think if you s
  name: Some FDs
  position: 55593
- category: unknown
  confidence: medium
  context: of the risks. We might, for example, what was it, Air Canada, I think?
    Air Canada is one of those stories that
  name: Air Canada
  position: 58374
- category: unknown
  confidence: medium
  context: changing is the likelihood part of the equation. Does AI increase the likelihood?
    Yes. At this point, most
  name: Does AI
  position: 60866
- category: Professional Organization/Media
  confidence: high
  context: The podcast is named the 'CIM Marketing Podcast' and the guest is a 'fellow
    of the CIM'. CIM likely stands for the Chartered Institute of Marketing.
  name: CIM
  source: llm_enhanced
- category: Consultancy/Tech Services
  confidence: high
  context: Duncan Smith is the founder of iComply, which is a data protection and
    compliance consultancy.
  name: iComply
  source: llm_enhanced
- category: tech
  confidence: high
  context: Mentioned in relation to the 'GCSE Prompting methodology' which is said
    to have come out of Microsoft.
  name: Microsoft
  source: llm_enhanced
- category: tech
  confidence: high
  context: Frequently mentioned as the most common AI tool being discussed, used for
    generating answers and content.
  name: ChatGPT
  source: llm_enhanced
- category: Government/Regulatory
  confidence: high
  context: Mentioned as a regulatory body whose quotes ChatGPT has fabricated.
  name: Information Commissioner's Office
  source: llm_enhanced
- category: tech
  confidence: high
  context: Mentioned in comparison to ChatGPT regarding AI answers when entering a
    search query.
  name: Google
  source: llm_enhanced
- category: tech
  confidence: high
  context: Mentioned as another AI model whose performance in research was compared
    to ChatGPT.
  name: Gemini
  source: llm_enhanced
- category: tech
  confidence: high
  context: The company behind ChatGPT; the speaker mentions tending to use 'OpenAI's
    tools'.
  name: OpenAI
  source: llm_enhanced
- category: tech
  confidence: high
  context: Mentioned as an AI model that the speaker has used less than ChatGPT, but
    which reportedly fared slightly better in some hallucination research.
  name: Claude
  source: llm_enhanced
- category: Government/Regulatory
  confidence: high
  context: The Financial Conduct Authority, mentioned as the regulatory body setting
    rules for finance advertising copy that AI might fail to include.
  name: FCA
  source: llm_enhanced
- category: N/A (Individual/Theory)
  confidence: medium
  context: Mentioned in the context of lateral thinking tools that the speaker tried
    to apply to AI, though he is an author/theorist, not a company.
  name: Edward de Bono
  source: llm_enhanced
- category: media/travel
  confidence: high
  context: Cited as a case study where their chatbot mishandled a grieving customer,
    leading to reputational and legal costs.
  name: Air Canada
  source: llm_enhanced
- category: retail
  confidence: high
  context: Mentioned as an example of a company that recently experienced a cyber
    attack.
  name: Marks and Spencer (M&S)
  source: llm_enhanced
- category: tech/customer service
  confidence: high
  context: Referenced via the 'Clarner effect,' describing a situation where a brand
    devolved too much customer service to an AI bot, leading to negative customer
    experience and embarrassment.
  name: Clarner
  source: llm_enhanced
date: 2025-10-02 03:30:00 +0000
duration: 74
has_transcript: false
insights:
- actionable: true
  confidence: medium
  extracted: be training
  text: we should be training.
  type: recommendation
- actionable: true
  confidence: medium
  extracted: be talking to marketers about the reality check of we're not living in
    the world of enterprise million-pound budgets
  text: we should be talking to marketers about the reality check of we're not living
    in the world of enterprise million-pound budgets.
  type: recommendation
- actionable: true
  confidence: medium
  extracted: be watermarking content
  text: we should be watermarking content.
  type: recommendation
- actionable: true
  confidence: medium
  extracted: be thinking a bit deeper about this
  text: we should be thinking a bit deeper about this.
  type: recommendation
layout: episode
llm_enhanced: true
original_url: https://audio.listennotes.com/e/p/c656125e249340e99db5b9a5f8667aa7/
processing_date: 2025-10-06 04:13:05 +0000
quotes:
- length: 217
  relevance_score: 5
  text: It's the idea of where in a process from a marketer's perspective, if you
    start engaging with AI, if you start and really getting to grips with the tool,
    you have to think about how it fits into the marketing workflow
  topics:
  - market
- length: 237
  relevance_score: 5
  text: That's one of the, if you start introducing AI into things like customer service
    chatbots, the one thing that you have to do is almost like adding salt sugar in
    a recipe is you have to balance that up perhaps with more sentiment analysis
  topics: []
- length: 181
  relevance_score: 4
  text: And there is, from the homogenization, there is that sort of very philosophical
    thing that says, at some point in the not too distant future, AI is training itself
    on its own output
  topics: []
- length: 218
  relevance_score: 4
  text: What marketer has had any training on ethics other than perhaps watching Hot
    Fuzz and realizing that was all about ethics, you know, that, you know, that idea
    that's for the greater good, or is it, am I following rules
  topics:
  - market
- length: 114
  relevance_score: 4
  text: It's a hard ask to spend money on that kind of training because the return
    on investment is not immediate for sure
  topics:
  - investment
- length: 82
  relevance_score: 3
  text: One of the biggest stumbling blocks I've had to using AIs is for that exact
    reason
  topics: []
- length: 67
  relevance_score: 3
  text: If I took it into ChatGPT, for example, say, "Here's what we've got
  topics: []
- length: 71
  relevance_score: 3
  text: But the reality is it just ain't going to happen for most of the public
  topics: []
- length: 111
  relevance_score: 3
  text: So I think having those conversations, yes, it is a person or you have to
    take personal responsibility for that
  topics: []
- length: 154
  relevance_score: 3
  text: And I think the responsibility there is for the employer to recognize that
    you have to bring those people through, otherwise there is a thing in your body
  topics: []
- impact_reason: Provides a specific, actionable framework (GCSE) for effective prompt
    engineering, which is vital for maximizing LLM utility.
  relevance_score: 10
  source: llm_enhanced
  text: There's a really great prompting methodology called the GCSE Prompting methodology,
    which I think came out of Microsoft, and it's really great, which talks about
    the importance of having a goal, some context, some sources, so giving it some
    kind of example, and then E, which is expectations, which is setting expectations
    of what you want them all to deliver for you.
  topic: Technology
- impact_reason: 'Identifies a critical strategic shift for web development and marketing:
    optimizing content for both human consumption and algorithmic agent parsing (dual
    purpose).'
  relevance_score: 10
  source: llm_enhanced
  text: As agents become more commonplace, we're going to have to think about how
    can we make our websites relevant, not just to people, but also how can we make
    sure that the agents that people send out on their behalf get the information
    that we want them to get.
  topic: Business/Technology
- impact_reason: 'Pinpoints the most dangerous aspect of hallucinations: the authoritative
    presentation of false regulatory or factual claims.'
  relevance_score: 10
  source: llm_enhanced
  text: I think what's really challenging for anybody looking at the response is when
    it makes those things up, the fact that it puts it in a rotation block and cites
    the source... when it quotes a regulatory source and says the regulator says it's
    okay to do that, that is just plain dangerous.
  topic: Business/Compliance
- impact_reason: 'Offers a powerful, relatable analogy for the current state of using
    AI for high-stakes tasks: the time saved on drafting is often lost on rigorous
    fact-checking, sometimes making scratch work faster.'
  relevance_score: 10
  source: llm_enhanced
  text: A very mean analysis of that is it's a bit like having an untrained intern
    in the office and asking them to do a professional task. Legal, regulatory compliance,
    and you know, journalistic pieces of publications that very often if you're marking
    their homework, if you're checking their work, it is quicker and more reliable
    to do it from scratch yourself.
  topic: Business/Productivity
- impact_reason: 'A core strategic insight: success with AI depends on understanding
    both human capabilities and technological boundaries.'
  relevance_score: 10
  source: llm_enhanced
  text: I think it's about knowing one's own limits and the limits of the technology.
  topic: Strategy/Technology Limits
- impact_reason: 'Defines the optimal, powerful use case for current AI: as a springboard
    or idea generator, not a final authority.'
  relevance_score: 10
  source: llm_enhanced
  text: If you use it within the limits of what it can do as an idea generation tool
    as a springboard, it can be incredibly powerful, but you've got to know the limits
    of it and yourself.
  topic: Technology/Usage Strategy
- impact_reason: 'Articulates the winning formula: the synergy between deep human
    expertise and AI capabilities.'
  relevance_score: 10
  source: llm_enhanced
  text: Leaning into your expertise in your field, I think is really important with
    AI. And that kind of combination of deep expertise, human expertise and AI, I
    think is like a really brilliant combination.
  topic: Strategy/Human-AI Collaboration
- impact_reason: Presents a significant long-term philosophical/technical warning
    about model drift and content quality degradation (AI training on AI output).
  relevance_score: 10
  source: llm_enhanced
  text: At some point in the not too distant future, AI is training itself on its
    own output. And of course, if we allow that to happen, then content is going to
    become pretty dull and early and inaccurate.
  topic: Technology/Future Trends
- impact_reason: Introduces a specific, actionable framework ('AI Sandwich') for maintaining
    quality and authenticity in AI-assisted content creation.
  relevance_score: 10
  source: llm_enhanced
  text: I have this methodology. It's called the AI sandwich, which I created at the
    beginning of 2024. And it's this idea that to get the best kind of content out
    of AI, as authentic as we can get, we need a combination of a sort of three-part
    process of human, AI, and then human.
  topic: Strategy/Workflow
- impact_reason: 'Crucial advice for leveraging custom AI tools: success depends on
    deeply understanding and deconstructing one''s own expert workflow first.'
  relevance_score: 10
  source: llm_enhanced
  text: I think it's just about breaking down your own processes. So I've created
    custom GPTs, for example, that write LinkedIn posts for me. And in order to do
    that, I had to almost go back to my, like, when I write LinkedIn posts, what do
    I do? What process do I move through?
  topic: Startups/Productivity/Prompt Engineering
- impact_reason: Details the critical enterprise features (on-premise options, data
    isolation/no-training clauses) necessary for handling sensitive data.
  relevance_score: 10
  source: llm_enhanced
  text: The enterprise versions, the paid-for versions will give you the possibility
    of on-premises. They'll certainly give you a ring fence around it, so you can
    have a no-training command.
  topic: Business/Enterprise AI
- impact_reason: A powerful illustration of the confidentiality risk associated with
    using public LLMs for proprietary work.
  relevance_score: 10
  source: llm_enhanced
  text: If I took it into ChatGPT, for example, say, 'Here's what we've got. Can you
    give us some ideas for some three other case studies which are on this theme?'
    I don't do that, because I think I've just given you all of that information,
    which you're now going to disseminate to the world and her wife.
  topic: Business/Confidentiality Risk
- impact_reason: 'Addresses the critical ''Shadow AI'' problem: banning official use
    drives employees to unmonitored, non-compliant personal tools.'
  relevance_score: 10
  source: llm_enhanced
  text: It also makes a very strong message that we do have a shadow AI, which is
    a huge problem in terms of compliance, which is if you don't implement AI, half
    the team have got it on their phone anyway, and they're using, of course, the
    free version to do what you would like them to do on the paid version.
  topic: Business/Risk Management
- impact_reason: Defines the necessary human oversight model for AI usage, emphasizing
    accountability over blind adoption.
  relevance_score: 10
  source: llm_enhanced
  text: Human, AI, human, we've got to be the guardians. We've got to be in charge
    of what we're doing ourselves. It comes down to personal responsibility.
  topic: technology/ethics
- impact_reason: A powerful, personal example of maintaining audience trust through
    explicit disclosure of AI-generated assets.
  relevance_score: 10
  source: llm_enhanced
  text: I always mark it as AI generated. So I'll say generated on Midjourney or generated
    with Google or whatever it might be. Because I don't ever want someone to come
    into my newsletter and say, is that Kerry really on a merry-go-round in Oxford...
    or is that an AI generated thing of Kerry? I just never want that to be a thing.
  topic: ethics/business
- impact_reason: 'Forces a fundamental business decision: valuing process/authenticity
    versus valuing pure functional output.'
  relevance_score: 10
  source: llm_enhanced
  text: What is it you attach the value to? Is it authentic content or is it content
    that does a job? If the content does the job and it was written by AI, do I have
    a problem?
  topic: business/strategy
- impact_reason: 'Provides a strong counter-argument to job loss fears: AI output
    is inherently flawed (homogenous, hallucinatory), necessitating human intervention.'
  relevance_score: 10
  source: llm_enhanced
  text: The machines are going to take our jobs... if you devolve your work to machines,
    it will pretty much be homogenous and inauthentic. There's a high risk of it.
    It will be littered with hallucinations, slash errors, slash lies...
  topic: industry trends/technology
- impact_reason: This is a core warning about relying too heavily on AI for content
    creation, highlighting risks like homogeneity, hallucinations, and brand inauthenticity.
  relevance_score: 10
  source: llm_enhanced
  text: If you devolve your work to machines, it will pretty much be homogenous and
    inauthentic. There's a high risk of it. It will be littered with hallucinations,
    slash errors, slash lies, or there's a great risk of it. And it will be, it risks
    being inauthentic for your brand.
  topic: Technology/Marketing
- impact_reason: Identifies the critical long-term talent pipeline problem created
    by AI automating entry-level tasks.
  relevance_score: 10
  source: llm_enhanced
  text: The real risk is thinking, how do we maintain a flow of marketers new to the
    profession going through and becoming valuable enough to survive the cut?
  topic: Startups/Talent Management
- impact_reason: A surprising and highly relevant statistic indicating the current
    premium employers place on demonstrable AI proficiency over general experience.
  relevance_score: 10
  source: llm_enhanced
  text: 73% of employers would be, would hire someone with AI skills and less experience
    than hire someone with more experience without them.
  topic: Industry Trends/Hiring
- impact_reason: A clear, logical breakdown of risk assessment in the AI context,
    showing that AI primarily increases the *likelihood* of negative outcomes if unchecked.
  relevance_score: 10
  source: llm_enhanced
  text: The severity hasn't changed. We still gave bad advice. The human gave bad
    advice, the machine gave bad advice. So that hasn't changed. So the only factor
    that's changing is the likelihood part of the equation. Does AI increase the likelihood?
    Yes.
  topic: Risk Management/Technology
- impact_reason: 'A direct, actionable insight into the risk equation of AI adoption:
    AI often increases the *likelihood* of error unless mitigated by human oversight.'
  relevance_score: 10
  source: llm_enhanced
  text: Is AI going to increase the likelihood of that [bad outcome] or reduce the
    likelihood of that? And the answer is often it increases the likelihood of it
    unless we have this human check in the process.
  topic: Technology/Risk Management
- impact_reason: Provides a clear, finance-friendly framework (Severity x Likelihood)
    for justifying investment in human checks by demonstrating how AI shifts the risk
    profile.
  relevance_score: 10
  source: llm_enhanced
  text: So from a really simple risk equation, which your FD will get eaten instantly,
    is there's the severity and likelihood. The severity hasn't changed... So the
    only factor that's changing is the likelihood part of the equation. Does AI increase
    the likelihood? Yes.
  topic: Business/Risk Management
- impact_reason: A powerful anecdote illustrating the real-world failure of over-automating
    nuanced tasks, serving as a cautionary tale for workforce planning.
  relevance_score: 10
  source: llm_enhanced
  text: They got rid of 700 staff members and saying, 'Okay, AI is going to do our
    job for us... And now in 2025, we're slowly bringing those people back in because
    it's not nuanced enough. It's not human enough.'
  topic: Startups/Workforce Planning
- impact_reason: This metaphor highlights that the quality of the input (prompting)
    directly dictates the quality of the AI output, a crucial concept for practical
    AI application.
  relevance_score: 9
  source: llm_enhanced
  text: The difference between a bog-standard AI Gin and an award-winning one.
  topic: Technology/Startups
- impact_reason: A clear warning against lazy prompting, emphasizing that effort in
    input yields significantly better, non-generic results.
  relevance_score: 9
  source: llm_enhanced
  text: I think if you just obviously with these tools, one of the great things is
    you can just rock up and give it one-sentence prompt, and it will deliver something
    for you, but I think what we get with that is a very sort of vanilla, quite mediocre
    output, and actually taking the time for prompting makes that output much more
    valuable.
  topic: Technology
- impact_reason: A direct prediction about the evolution of web interaction, shifting
    from direct user browsing to automated agent interaction.
  relevance_score: 9
  source: llm_enhanced
  text: I think in terms of websites, what will change will probably be the greater
    use of AI agents.
  topic: Industry Trends
- impact_reason: A strong, clear definition and critique of LLM hallucinations, framing
    them as a significant reliability risk, especially in professional contexts.
  relevance_score: 9
  source: llm_enhanced
  text: One thing that ChatGPT, the most common tool, has been criticized probably
    fairly for, is what IT people call hallucinations, which is what every other normal
    person on the planet calls errors. I call it lies.
  topic: Technology
- impact_reason: A powerful anecdote illustrating the model's tendency to fabricate
    information when challenged, underscoring the need for adversarial testing.
  relevance_score: 9
  source: llm_enhanced
  text: I have a folder now on ChatGPT, which is all the time I've had an argument
    with it... And ultimately it says, you got me. It's a very polite liar. It is.
  topic: Technology
- impact_reason: Emphasizes the severe professional liability difference between human
    error and AI-generated error in regulated fields.
  relevance_score: 9
  source: llm_enhanced
  text: I would have been fired 20 years ago if I did, if I'd ever did that in my
    profession.
  topic: Business/Compliance
- impact_reason: 'The core cautionary advice: the mere *possibility* of error mandates
    constant vigilance, regardless of the measured error rate.'
  relevance_score: 9
  source: llm_enhanced
  text: I think the fact that it just can hallucinate is the issue, isn't it? It's
    like whether it's 70% at time or 10% at the time, it's just the fact that we have
    to be aware. So there's a possibility. And therefore we have to be on guard whenever
    we use that.
  topic: Technology
- impact_reason: Specific example (FCA compliance in finance ads) demonstrating where
    human oversight is non-negotiable due to regulatory constraints.
  relevance_score: 9
  source: llm_enhanced
  text: If you're in finance and you ask it to create the copy for a finance ad, but
    we know there are rules that the FCA puts around us as to what needs to be said,
    your APIs and things have to be in there. And if the ChatGPT or whatever doesn't
    put those in, somebody has to check them.
  topic: Business/Compliance
- impact_reason: 'Provides a pragmatic segmentation strategy: fact-check high-stakes,
    data-heavy content; use freely for low-stakes creative ideation.'
  relevance_score: 9
  source: llm_enhanced
  text: I always just say if it's anything statistical or fact-tolerant, of course,
    it's bringing about like you say something from some papers somewhere, then yeah,
    you need to fact-check it, but there's often times in marketing where you wouldn't
    necessarily need to go through that process because it sounds quite like, you
    know, the way you say it sounds quite laborious.
  topic: Technology/Marketing
- impact_reason: 'Defines the primary, undisputed value proposition of generative
    AI in creative workflows: overcoming initial inertia and serving as an idea generator.'
  relevance_score: 9
  source: llm_enhanced
  text: It takes out that initial sort of, oh, that's initially brain fog. I've got
    to get in and try and find a load of examples to start me off. So fabulous springboard.
  topic: Startups/Productivity
- impact_reason: 'Poses the central productivity paradox of current AI tools: do the
    time savings outweigh the time required for verification?'
  relevance_score: 9
  source: llm_enhanced
  text: I think that leads neatly into the, you know, is actually the use of AI valuable
    to us when we make time savings? But then do we have to use that time saving to
    then check the output of everything that comes out?
  topic: Business/Productivity
- impact_reason: Highlights the critical necessity of human oversight (editors/fact-checkers)
    when using AI-generated content to mitigate errors and hallucinations.
  relevance_score: 9
  source: llm_enhanced
  text: The danger I think is that you take that content as read and you run with
    it and you don't fact-check it. And that's why it's to have a copyright or an
    editor that really knows their stuff is vital.
  topic: Technology/Content Integrity
- impact_reason: Provides a clear boundary for AI application, warning against using
    it for high-level, lateral, conceptual creativity.
  relevance_score: 9
  source: llm_enhanced
  text: I think it's important to know when not to use it. So, for example, I think
    for highly conceptual creative work, I just don't think you can do it and believe
    me, I've tried everything.
  topic: Technology/Creative Work
- impact_reason: Quantifies AI's strength in volume generation (100 ideas in seconds)
    versus human limitations, advocating for task-specific deployment.
  relevance_score: 9
  source: llm_enhanced
  text: It's super helpful for us to know where it can work. So yeah, and I think
    in terms of our own limitations, I guess, the certain things that I can do better,
    you know, it's very good. You can get 100 ideas from it in a matter of seconds
    to stop content ideas, for example.
  topic: Business/Productivity
- impact_reason: Identifies 'homogenization' as a major business risk when relying
    too heavily on AI for creative output.
  relevance_score: 9
  source: llm_enhanced
  text: Another flaw that marketers have encountered very quickly is this idea of
    homogenization, that if you devolve your creative work to an AI, it will generate
    for you pretty much what it's going to generate for every other marketer in the
    world.
  topic: Business/Marketing Risk
- impact_reason: 'Details the three stages of the ''AI Sandwich'': customized prompting,
    AI generation, and expert refinement/fact-checking.'
  relevance_score: 9
  source: llm_enhanced
  text: The promptings that we create are as customized as they can be. Then we get
    the AI to do its thing, which is amazing. And then afterwards we've got the human
    again. And this is where we send check it, we fact-check it, and we also add our
    own deep expertise...
  topic: Technology/Prompt Engineering
- impact_reason: 'A direct, urgent warning against the most common pitfall: unedited
    copy-pasting.'
  relevance_score: 9
  source: llm_enhanced
  text: Please don't copy and paste output and just use it. Like, please add something
    of yourself into it because it's so important for that authenticity side of things.
  topic: Content Integrity
- impact_reason: Emphasizes the necessity of integrating AI strategically into existing
    operational workflows, not just using it ad-hoc.
  relevance_score: 9
  source: llm_enhanced
  text: It's the idea of where in a process from a marketer's perspective, if you
    start engaging with AI, if you start and really getting to grips with the tool,
    you have to think about how it fits into the marketing workflow.
  topic: Business/Workflow Integration
- impact_reason: Provides a concrete definition of 'Human in the Loop'—it's about
    accountability and specific checkpoints, not just general oversight.
  relevance_score: 9
  source: llm_enhanced
  text: That idea that they call people talk a lot about human in the loop, what does
    it actually mean? It means I have to think about who presses send on a particular
    article to go to the editor or whatever and who does the checking and who has
    checked that the check took place.
  topic: Technology/Process Control
- impact_reason: 'Predicts a widening gap: AI will create a sea of generic content,
    making genuine, hard-earned creativity highly valuable and differentiating.'
  relevance_score: 9
  source: llm_enhanced
  text: I think we will see more of that homogeneity. I also feel like if you can
    be creative and you can actually be bothered to do the hard work, you will also
    really stand out.
  topic: Industry Trends/Competition
- impact_reason: Highlights the current inability of machines to replicate genuine
    human values, empathy, and authenticity, which humans can easily detect.
  relevance_score: 9
  source: llm_enhanced
  text: And human values, machines are struggling with human values. And why is it
    that a human can recognize another? What is it in that text that goes, ah, thankfully,
    that's not AI.
  topic: Technology/Ethics & Emotion
- impact_reason: Defines the appropriate business use case for high-volume AI content
    generation, contingent on having a dedicated editorial team for quality control.
  relevance_score: 9
  source: llm_enhanced
  text: If I've got a task where volume of content is important to me or the organization,
    of course, I'm going to use AI to generate a lot of that content. And I'm going
    to have a team of editors who are looking at that content specifically.
  topic: Business/Scale
- impact_reason: 'A concise statement on the current fundamental limitation of AI:
    the inability to grasp nuanced human values.'
  relevance_score: 9
  source: llm_enhanced
  text: Machines are struggling with human values.
  topic: Technology
- impact_reason: 'Offers actionable advice on prompt engineering: identifying and
    explicitly banning common AI stylistic tics to enhance authenticity.'
  relevance_score: 9
  source: llm_enhanced
  text: Tell your persona to never use M-dash, to never have five bullet points at
    the end that says this is what, it's just, they are so AI, you know, we can do
    that.
  topic: Technology/Prompt Engineering
- impact_reason: Clearly contrasts poor prompting with expert prompting, highlighting
    the necessity of providing context, tone, and examples.
  relevance_score: 9
  source: llm_enhanced
  text: The difference between turning it with a one-sentence problem, 'Write me a
    blog on,' versus 'Write me a blog on, you know, here's my information. These are
    the kind of, this is a tone of voice that I'd like you to adopt. Here's some examples
    of tone or style that I'd like you to follow.'
  topic: Technology/Prompt Engineering
- impact_reason: Highlights Custom GPTs/Projects as the key feature in paid tiers
    that moves output away from generic 'vanilla' results toward proprietary value.
  relevance_score: 9
  source: llm_enhanced
  text: Custom GPT is one of the great things is you can give it instructions, you
    can give it knowledge. So what it's generating is not what everyone else is generating.
  topic: Technology/Customization
- impact_reason: 'Strong argument for proactive adoption: since shadow IT is inevitable,
    formalizing usage via enterprise agreements is safer.'
  relevance_score: 9
  source: llm_enhanced
  text: The same as now happening. We shadow AI that doesn't matter how many rules
    you have in an organization, people can go on a lunch break and use a shadow AI
    and there's no way of stopping it. So better to embrace it, we think, probably
    worthwhile getting an enterprise version.
  topic: Business/Strategy
- impact_reason: 'Provides a pragmatic reality check: high-end, perfectly secure enterprise
    solutions are inaccessible for the majority of businesses (SMEs/consultants).'
  relevance_score: 9
  source: llm_enhanced
  text: There is, there is technically, theoretically a solution where you have a
    sort of locked-up enterprise solution... But the reality is it just ain't going
    to happen for most of the public.
  topic: Business/SME Reality
- impact_reason: A direct statement grounding the discussion in the financial reality
    for most tech professionals and marketers who rely on COTS (Commercial Off-The-Shelf)
    software.
  relevance_score: 9
  source: llm_enhanced
  text: We're not living in the world of enterprise million-pound budgets.
  topic: Business/Budget Constraints
- impact_reason: 'Highlights the immediate reality for most businesses: reliance on
    accessible, COTS/web-based AI (like ChatGPT) rather than expensive, bespoke enterprise
    solutions.'
  relevance_score: 9
  source: llm_enhanced
  text: The reality check is for the vast majority of people that you and I train,
    it's just not going to happen. We're going to be taking commercial off-the-shelf
    software. We're going to be looking at the, what we can literally access straight
    from the web.
  topic: business/technology
- impact_reason: Illustrates the critical need for explicit client consent and transparency
    regarding AI usage, as client comfort levels vary widely.
  relevance_score: 9
  source: llm_enhanced
  text: I always say to them, are you happy for me to use AI with this? And some are
    just like, yeah, put everything in, I don't care... And other ones, actually,
    this is still in barcode, or this is what hasn't gone out to the public yet.
  topic: business/ethics
- impact_reason: Connects the utility of generative AI directly to the emerging necessity
    of content provenance tracking (watermarking).
  relevance_score: 9
  source: llm_enhanced
  text: AI is going to be a very valuable tool for content creation. But it does segue
    into this issue about transparency and provenance and whether we should be watermarking
    content.
  topic: technology/industry trends
- impact_reason: Provides an actionable framework for professionals to negotiate the
    *degree* of AI usage with clients, moving beyond a simple yes/no.
  relevance_score: 9
  source: llm_enhanced
  text: I would always have a conversation and say, what, where are you happy for
    me to use it? Where are you not? Are you okay for me to use it for research and
    initial thoughts? Do you want me to write with it?
  topic: business/actionable advice
- impact_reason: Elevates client trust as the single most critical factor threatened
    by opaque AI adoption.
  relevance_score: 9
  source: llm_enhanced
  text: I do think we have to have those awkward conversations with clients because
    the trust, I think, is such an important part of a relationship. And I think with
    AI, people, if you lose trust with your clients, long-standing clients, that could
    be super detrimental.
  topic: business
- impact_reason: Reframes the AI discussion from a binary choice to a nuanced conversation
    about contribution level.
  relevance_score: 9
  source: llm_enhanced
  text: The discussions you have is around the extent to which you have used it and
    to the extent which it has contributed to your final output. So you're transparent
    about it and you're having a conversation about the gray areas in the middle that
    matter of degree.
  topic: business/ethics
- impact_reason: Suggests integrating the AI usage discussion into the initial project
    scoping/briefing phase, normalizing the conversation.
  relevance_score: 9
  source: llm_enhanced
  text: We sort of reached the side of actually putting it in the brief, you know,
    having the conversation with the client at brief stage and saying, where are we
    going to use AI for this?
  topic: business/actionable advice
- impact_reason: Casts significant doubt on the reliability of current AI detection
    tools by referencing the failure of the original creator's own attempt.
  relevance_score: 9
  source: llm_enhanced
  text: I remember the first one that the chat, OpenAI created one, didn't they originally
    and then shut it out because they couldn't make it work. And it's just like, if
    OpenAI can't make a detection tool that's reliable enough of them to run it, then
    I just thought, well, who can't?
  topic: technology/reliability
- impact_reason: Reiterates the optimal workflow model (Human-in-the-Loop) for quality
    assurance in marketing content.
  relevance_score: 9
  source: llm_enhanced
  text: The answer to this is human, AI, human, a human being the marketer at the
    end of the, at the start and the end of the process.
  topic: technology/strategy
- impact_reason: A blunt prediction about job displacement in areas heavily reliant
    on statistical analysis and programmatic execution.
  relevance_score: 9
  source: llm_enhanced
  text: I think the writing's on the wall when it comes to anything that has large
    volumes of statistical data input analysis, programmatic marketing, those kind
    of things. I think some of the agencies that are involved in programmatic and
    some of the jobs that are currently done by people, the machine does it better.
  topic: Industry Trends/Business
- impact_reason: 'Actionable advice for professionals: the focus shifts from performing
    the task to mastering and controlling the tool.'
  relevance_score: 9
  source: llm_enhanced
  text: The marketer has to retrain, rethink. So we need to be understanding what
    the tool does and then how do I use the tool? So I need to be the person that's
    controlling the tool.
  topic: Career Development/Technology
- impact_reason: 'A strategic recommendation for employers: intentionally retaining
    entry-level human roles, even if machines *could* do the work, to build future
    expertise.'
  relevance_score: 9
  source: llm_enhanced
  text: In order for organizations to protect their pipeline... they're going to have
    to tolerate the fact that at their entry level, sometimes the task could be done
    by machines and it just let human beings do them.
  topic: Business/Talent Management
- impact_reason: Provides two excellent, concise phrases for job candidates to use
    when discussing AI, emphasizing critical evaluation.
  relevance_score: 9
  source: llm_enhanced
  text: What's really important is the human in the loop sandwich or 'What's really
    important is the ability to critically think the output.'
  topic: Career Development/Technology
- impact_reason: Gives a concrete example of how ethics training translates into practical,
    critical analysis of existing technology (like CRMs).
  relevance_score: 9
  source: llm_enhanced
  text: If you're taught about those [ethics] and then you suddenly see a CRM system
    that is not binning people because they don't come from the right postcode, you
    go, 'What is second, that looks a little biased.'
  topic: Ethics/Technology
- impact_reason: A strategic warning against prioritizing immediate ROI over long-term
    talent sustainability when adopting AI.
  relevance_score: 9
  source: llm_enhanced
  text: We're very good at thinking short term about the immediate impact of AI and
    how it can help us to improve our bottom line. But we also need to be thinking
    about that side of things as well [long-term talent development].
  topic: Strategy/Business
- impact_reason: 'Provides a strategic framing technique: linking investment in human
    training/ethics to established concepts like cyber risk management to gain buy-in
    from finance.'
  relevance_score: 9
  source: llm_enhanced
  text: If I'm talking to the finance director about this, then I'm going to be saying
    to him or her, just expand out a little bit. It's the same when you have spending
    money on cyber risk and cyber security.
  topic: Business/Finance
- impact_reason: Emphasizes the power of using real-world failure case studies (like
    Air Canada's chatbot error) to justify preventative spending on training and risk
    mitigation.
  relevance_score: 9
  source: llm_enhanced
  text: Look at Air Canada, look at M&S. You can use case studies of where things
    have gone wrong. It's much easier to make a medium-term and long-term case, isn't
    it?
  topic: Risk Management/Case Studies
- impact_reason: Connects the technical risk of AI directly to a persuasive argument
    for budget allocation for human oversight.
  relevance_score: 9
  source: llm_enhanced
  text: If we make that case [about increased risk], then suddenly the argument for
    human checkers, humans in the loops becomes a lot more powerful when we're talking
    to finance departments.
  topic: Strategy/Finance
- impact_reason: 'A concise summary of the dual nature of scaling with AI: enhanced
    throughput coupled with amplified risk exposure.'
  relevance_score: 9
  source: llm_enhanced
  text: It increases our ability to do things at volume. But it also increases risk.
  topic: Technology/Strategy
- impact_reason: This is a foundational risk assessment question that should precede
    any major technology implementation, forcing leaders to focus on core business
    vulnerabilities.
  relevance_score: 9
  source: llm_enhanced
  text: What's the worst thing that could happen to this organization? Never mind
    AI, what's the worst thing that could happen?
  topic: Business/Risk Management
- impact_reason: 'Summarizes the core trade-off in AI adoption: massive scaling benefits
    balanced directly against increased operational risk.'
  relevance_score: 9
  source: llm_enhanced
  text: We can use AI, but we manage that risk process in the ROI. It helps us rapidly
    scale, Kerry. It increases our ability to do things at volume. But it also increases
    risk.
  topic: Business/Strategy
- impact_reason: Offers a strategic argument for maintaining human oversight, framed
    in terms that resonate with financial stakeholders (ROI and risk management).
  relevance_score: 9
  source: llm_enhanced
  text: And if we make that case, then suddenly the argument for human checkers, humans
    in the loops becomes a lot more powerful when we're talking to finance departments.
  topic: Business/Strategy
- impact_reason: 'Provides a specific, actionable mitigation strategy: pairing automation
    with enhanced human-centric monitoring tools like sentiment analysis.'
  relevance_score: 9
  source: llm_enhanced
  text: If you start introducing AI into things like customer service chatbots, the
    one thing that you have to do is almost like adding salt sugar in a recipe is
    you have to balance that up perhaps with more sentiment analysis.
  topic: Technology/Implementation
- impact_reason: 'Highlights a fundamental limitation of current LLMs: the inability
    to express genuine uncertainty or admit lack of knowledge, leading to fabrication.'
  relevance_score: 8
  source: llm_enhanced
  text: I don't think it's capable of saying, 'that's a tough one, Duncan. You know,
    I don't know.'
  topic: Technology
- impact_reason: Suggests that applying pressure or constraints (like demanding conciseness
    on a complex topic) increases the likelihood of the model generating false information.
  relevance_score: 8
  source: llm_enhanced
  text: Actually, they're more likely to loosen when you, when you put them into a
    corner.
  topic: Technology
- impact_reason: Provides a (though potentially dated) statistic on hallucination
    rates and notes that model iteration (like GPT-5) is actively targeting this weakness.
  relevance_score: 8
  source: llm_enhanced
  text: Some of that suggests that they can hallucinate up to 75%, but I think that's
    getting lit. I think the ChatGPT 5, one of the things that they celebrated in
    the release of that was the lowering of hallucination rates.
  topic: Technology
- impact_reason: A concrete example of AI providing novel, cross-disciplinary conceptual
    leaps that break conventional thinking patterns.
  relevance_score: 8
  source: llm_enhanced
  text: I always talk about how do you springboard ideas in meetings and everybody
    sits around and goes, right, we need to we need to come up with an idea for a
    white paper, an article or something. And that content, it recently I did an article
    similarly and it just said, have you thought about science fiction and AI and,
    and you know, what happened with replicants and Philip K. Dick's writing and things.
  topic: Technology/Creativity
- impact_reason: 'A concise summary of AI''s best use case: surfacing latent or unexpected
    connections.'
  relevance_score: 8
  source: llm_enhanced
  text: It's a great surfacing tool for ideas.
  topic: Technology
- impact_reason: A cautionary tale regarding data protection and compliance failures
    in daily operations (likely referencing a recent data breach incident).
  relevance_score: 8
  source: llm_enhanced
  text: Don't put everybody's email in the two box, say nothing else. Oh, okay, we'll
    leave that there, but it's a lesson learned for some time.
  topic: Compliance/Business
- impact_reason: 'A critical methodological warning for tech professionals: anecdotal
    evidence about model performance is insufficient; scientific validation is required.'
  relevance_score: 8
  source: llm_enhanced
  text: I think you need to be careful about personal experience versus something
    which is rigorous, peer-reviewed, scientific research.
  topic: Technology
- impact_reason: Reinforces the context-dependent utility of AI, differentiating between
    creative/ideation tasks and factual reporting tasks.
  relevance_score: 8
  source: llm_enhanced
  text: I think it also depends on the kind of what you're creating with it as well,
    though. So for me, because I work mainly in copying content, it's actually, you
    don't necessarily, the things that it's generating, you don't necessarily have
    to factor, because it might be some ideas or a starting point or it might be some
    social media posts, but there's no stats or facts or statistics.
  topic: Marketing/Technology
- impact_reason: Reinforces the value of traditional, human-centric methods (pen and
    paper) for tasks where AI fundamentally fails (conceptual thinking).
  relevance_score: 8
  source: llm_enhanced
  text: I have to be aware that it's a generative tool. And so now I just don't go
    that I just sit down with a notepad and a pen, which I've done for the last 20
    years of any kind of conceptual work, because I know that there's no point in
    going.
  topic: Strategy/Workflow
- impact_reason: Links the misuse of AI directly to the loss of crucial brand authenticity.
  relevance_score: 8
  source: llm_enhanced
  text: We're not going to have that brand authenticity, which is what we all crave
    as marketers, if we do, as Duncan says, and not as Duncan recommends, as Duncan
    describes, and devolve this sort of process to an AI.
  topic: Business/Branding
- impact_reason: Uses an analogy from food manufacturing (HACCP) to illustrate the
    need for critical control points (human checks) in high-risk processes like content
    deployment.
  relevance_score: 8
  source: llm_enhanced
  text: The last thing you want is a blue elastoplast in your donor. So there's something
    that checks for that before it goes out. So the food industry knows it needs to
    check. There's high risk involved in it.
  topic: Strategy/Risk Management
- impact_reason: Gives a practical example of AI failure in sensitive areas like customer
    service, where lack of empathy is immediately apparent.
  relevance_score: 8
  source: llm_enhanced
  text: We might test its emotional empathy and we go, that's not written by a human.
    And so when we get responses back from customer complaints, for example, and we
    read it and we go, oh, that is so written by a bot.
  topic: Business/Customer Experience
- impact_reason: Specific warning against using AI for high-stakes, truly original
    advertising concepts requiring lateral thinking.
  relevance_score: 8
  source: llm_enhanced
  text: If you're doing above-the-line advertising where you need to go something
    really quite off the wall, really like lateral thinking, it just can't do it.
  topic: Marketing/Creativity
- impact_reason: 'A pragmatic assessment of task delegation: use AI for high-volume,
    low-complexity idea generation where humans cannot compete on speed.'
  relevance_score: 8
  source: llm_enhanced
  text: I can get 100 ideas from it in a matter of seconds... So I guess it's knowing
    where actually that might be better than me, because I'm not going to come up
    with 100 ideas in two seconds.
  topic: Productivity/Delegation
- impact_reason: Predicts a bifurcation in content quality due to AI, separating the
    mediocre from the truly valuable/beautiful work.
  relevance_score: 8
  source: llm_enhanced
  text: There'll be the stuff that's very generic that we just kind of pass over.
    And then there'll be the stuff that's really beautiful. And I think that that's
    where we'll get the most from.
  topic: Technology/Industry Trends
- impact_reason: Points to the innate human ability to detect inauthenticity, posing
    a challenge for AI adoption in customer-facing roles.
  relevance_score: 8
  source: llm_enhanced
  text: Why is it that a human can recognize another? What is it in that text that
    goes, ah, thankfully, that's not AI. We're very capable of spotting that.
  topic: Technology/Human-AI Interaction
- impact_reason: Uses a strong cultural reference ('Blade Runner') to illustrate how
    easily users can spot synthetic, unempathetic communication.
  relevance_score: 8
  source: llm_enhanced
  text: That insincerity, that lack of empathy, that lack of humanness, the spotting
    the replicant as Blade Runner would have us, that we're very good at doing it.
  topic: Business/Brand Authenticity
- impact_reason: Identifies a recognizable 'language' or pattern in generic AI output
    that brands must actively avoid.
  relevance_score: 8
  source: llm_enhanced
  text: There has to be a sort of AI ease, hasn't there, sort of a language of AI
    that has become a bit too easy to spot, certainly from the off-the-shelf AI.
  topic: Technology/AI Output
- impact_reason: Emphasizes that AI training requires a foundational, granular understanding
    of the creative process itself, not just the desired output.
  relevance_score: 8
  source: llm_enhanced
  text: What does it take to write great copy or great content or, you know, a great
    image or whatever it might be.
  topic: Technology/Content Creation
- impact_reason: Introduces the advanced technique of cross-model prompt iteration
    for refinement and improvement.
  relevance_score: 8
  source: llm_enhanced
  text: Somebody advised me the other day to, when you're talking about prompts and
    improving prompts... was to take the prompt from one engine and put it in another.
    So you write a prompt and it comes back and then you say, 'Oh, Claude, could you
    take a look at these prompts that have come out of chat? Can you improve those?'
  topic: Technology/Prompt Engineering
- impact_reason: Addresses the value proposition of paid subscriptions, suggesting
    that the primary benefit is avoiding usage caps rather than a massive leap in
    quality.
  relevance_score: 8
  source: llm_enhanced
  text: Are the premium versions any better, less for modernists, more accurate, more
    authentic? Is it worth it? I think the reason to upgrade would be more around
    usage limits.
  topic: Business/Technology Adoption
- impact_reason: 'Manages expectations: paying for premium tiers does not automatically
    solve core AI problems like hallucination.'
  relevance_score: 8
  source: llm_enhanced
  text: I don't think it's necessary, we're going to, like, cut hallucinations or
    necessarily get over some of the issues that we've been talking about [with paid
    versions].
  topic: Technology/AI Limitations
- impact_reason: Identifies compliance/safety concerns as a major bottleneck slowing
    down enterprise AI adoption.
  relevance_score: 8
  source: llm_enhanced
  text: One of the ways we can move forward faster is to think about the compliance
    issue, if it's being blocked. So somebody's saying, 'Well, we're just going to
    go slowly because we're not sure if it's safe yet.'
  topic: Business/Compliance
- impact_reason: Reiterates that data security concerns are not minor details but
    primary obstacles to adoption.
  relevance_score: 8
  source: llm_enhanced
  text: I don't think it's super little tall. I think that's one of the stumbling
    blocks. One of the biggest stumbling blocks I've had to using AIs is for that
    exact reason [data security].
  topic: Business/Adoption Barriers
- impact_reason: A strong warning about the regulatory lag concerning AI and intellectual
    property rights.
  relevance_score: 8
  source: llm_enhanced
  text: We're way, way, way behind in terms of copyright legislation. It's a can that's
    being kicked down the road at the moment very definitely.
  topic: industry trends/ethics
- impact_reason: Provides a concrete example (EU legislation) showing that provenance
    tracking is moving from theoretical discussion to regulatory requirement.
  relevance_score: 8
  source: llm_enhanced
  text: Legislation coming forward. Already we see legislation coming forward. It's
    already in EU co-supractors that says in terms of the provenance of content, it's
    so important that the rest of us understand where it came from.
  topic: industry trends/ethics
- impact_reason: 'Offers a counter-intuitive insight: clients may welcome transparency
    because they are also uncertain about the value proposition of AI-assisted work.'
  relevance_score: 8
  source: llm_enhanced
  text: I should imagine that clients are probably quite relieved that that conversation's
    happening because it's probably awkward for them as well to go, 'Oh, have they
    used AI or haven't they used AI? And should they still be paying them the same
    amount if they've used it?'
  topic: business
- impact_reason: Uses a memorable, cautionary anecdote to highlight the severe risks
    of using raw machine translation/localization tools without native human review.
  relevance_score: 8
  source: llm_enhanced
  text: I mean, you only have to Google, just Google mistakes that AI makes in localization,
    and you'll very soon find the Spanish one and the diarrhea pills. It's just, you
    know, cause light will never forget that one.
  topic: technology/risk
- impact_reason: Directly links unchecked AI output in specialized areas (like localization)
    to professional malpractice.
  relevance_score: 8
  source: llm_enhanced
  text: If you've used the machine language learning tools and not checked yourself
    as that native Spanish speaker or native English speaker, then you are short-changing
    the client.
  topic: ethics/business
- impact_reason: Highlights the employer's responsibility to provide ethics training
    specifically related to new technologies like AI.
  relevance_score: 8
  source: llm_enhanced
  text: I think nurturing employers have a real responsibility here to think about
    nurturing those people with the training that they can give on ethics.
  topic: Business/Ethics
- impact_reason: Addresses the persistent perception challenge marketing departments
    face within organizations, especially when justifying new investments.
  relevance_score: 8
  source: llm_enhanced
  text: Marketers already have marketing. Already has an issue that it's seen as a
    cost center. You know, it's a department in a business that spends money.
  topic: Business/Strategy
- impact_reason: 'Offers the most straightforward, measurable ROI metric for new tool
    implementation: time saved.'
  relevance_score: 8
  source: llm_enhanced
  text: If you're implementing any tools and you want to get someone to side with
    you from that point of view, I guess it would be looking at how long did this
    job take us before, how long does it take us now, and what's the cost of that.
  topic: Business/ROI
- impact_reason: 'Identifies the ''hidden'' ROI of AI implementation: freeing up time
    for higher-value strategic and creative work.'
  relevance_score: 8
  source: llm_enhanced
  text: What's the value of the strategic or creative thinking that they now get to
    do that maybe they didn't have time to do before?
  topic: Strategy/Technology
- impact_reason: Expresses concern that the traditional apprenticeship model for developing
    deep expertise is being threatened by automation of junior tasks.
  relevance_score: 8
  source: llm_enhanced
  text: If you're further in your career and you have the deep expertise... I'm not
    sure whether the young people today will have those opportunities [traditional
    training paths].
  topic: Talent Management/Career Development
- impact_reason: A direct call to action for balancing automation with necessary foundational
    training for the next generation of professionals.
  relevance_score: 8
  source: llm_enhanced
  text: We can't just get AI to do all the basic jobs. We do need to be training junior
    members of the team as well.
  topic: Startups/Talent Management
- impact_reason: 'Actionable advice for early-career professionals: proactive adoption
    and understanding of AI is essential for survival.'
  relevance_score: 8
  source: llm_enhanced
  text: I think such a difficult question. I feel like for young people or people
    in their early stage of their career, it's just really a good idea to just get
    on top of AI and just to see how it can help you.
  topic: Career Development
- impact_reason: Introduces a named concept ('Clarner effect') for the phenomenon
    of brand damage resulting from excessive reliance on unnuanced AI customer service.
  relevance_score: 8
  source: llm_enhanced
  text: I read some recent news called it the Clarner effect. And I just thought it
    was quite interesting... They devolved too much of the customer service to a bot,
    any AI, and into the customer's effect, really.
  topic: Technology/Customer Experience
- impact_reason: Highlights the necessity of proactive monitoring for negative externalities
    (like customer frustration leading to public backlash) when deploying customer-facing
    AI.
  relevance_score: 8
  source: llm_enhanced
  text: So start thinking about social media scanning and sentiment analysis, but
    they're, they're having a go at you online because they can't get through, the
    bot won't let you do this. Then so introducing that technology means you also
    need to be thinking about any harm that comes out of that.
  topic: Technology/Risk Management
- impact_reason: Expresses surprise when an LLM *does* admit inability, reinforcing
    how deeply ingrained the 'always answer' training bias is.
  relevance_score: 7
  source: llm_enhanced
  text: I was so excited. Actually, that's impressive. Because they never ever say,
    no, I can't do that.
  topic: Technology
- impact_reason: Captures the sudden, overwhelming industry shift toward AI adoption
    and the resulting uncertainty among practitioners.
  relevance_score: 7
  source: llm_enhanced
  text: We're going to learn many lessons today about how to use AI in marketing,
    which I think has become something of an obsession for marketers. It was not there,
    and then suddenly it was there.
  topic: Industry Trends
- impact_reason: Highlights the walled-garden nature of current proprietary LLMs,
    suggesting future tools must offer greater external access.
  relevance_score: 7
  source: llm_enhanced
  text: You ask a question to ChatGPT, and your answer is then bound limited by ChatGPT.
  topic: Technology
- impact_reason: Suggests drawing best practices for safety and rigorous checking
    from highly regulated industries (aviation, medical) for AI workflows.
  relevance_score: 7
  source: llm_enhanced
  text: We can learn how those people keep us safe and take a little bit of that learning
    and put it into our workflows. It's great advice.
  topic: Strategy/Process Improvement
- impact_reason: Illustrates the power of AI to cross-pollinate disparate concepts
    (e.g., sci-fi and AI) to generate novel content angles.
  relevance_score: 7
  source: llm_enhanced
  text: It recently I did an article similarly and it just said, have you thought
    about science fiction and AI and, and you know, what happened with replicants
    and Philip K. Dick's writing and things. And immediately that I did, you know,
    I hadn't really thought of that. But then when you go away and think about that,
    it suddenly becomes an article.
  topic: Content Strategy
- impact_reason: Provides a real-world anecdote demonstrating user frustration with
    obvious, templated AI responses, even from major companies.
  relevance_score: 7
  source: llm_enhanced
  text: I accuse somebody of Microsoft the other day of being a bot... And it came
    back and said, I'm not a bot. I said, yeah, but you could clearly say that. Clearly
    using AI, as Kerry said, they're cutting and pasting answers into my response.
  topic: Business/Customer Experience
- impact_reason: A cautionary note about AI's tendency to always suggest changes,
    even when the original output is sufficient, leading to potential over-optimization.
  relevance_score: 7
  source: llm_enhanced
  text: The only thing is, I think, again, going back to the thing we talked about
    earlier, because you, it's never going to say no, it will always find an improvement.
  topic: Technology
- impact_reason: 'Details a specific prompt strategy: explicitly naming the source
    model to encourage competitive critique from the receiving model.'
  relevance_score: 7
  source: llm_enhanced
  text: I always make sure that I tell the other one where it came from. Yeah. So
    just guess what it is. So it's like, 'Okay, it came from ChatGPT, come on, Claude,
    what can you do?'
  topic: Technology/Prompt Engineering
- impact_reason: Draws a historical parallel between the introduction of mobile phones
    and the current resistance/adoption curve of AI.
  relevance_score: 7
  source: llm_enhanced
  text: I remember the days when mobile phones first came out, you weren't allowed
    to have a mobile phone at your desk in theory. So everyone put it in the pocket
    or the handbag and nobody knew.
  topic: Industry Trends/History
- impact_reason: Highlights the immediate, real-world consequence of unreliable detection
    tools in high-stakes environments like education.
  relevance_score: 7
  source: llm_enhanced
  text: It's worrying, isn't it, when university and teachers are marking your work
    and they're saying it's plagiarized or AI written and it's wrong. I wrote it.
  topic: industry trends/risk
- impact_reason: Offers direct, encouraging advice to early-career professionals regarding
    engagement with new technology, despite job fears.
  relevance_score: 7
  source: llm_enhanced
  text: I feel like for young people or people in their early stage of their career,
    it's just really a good idea to just ge[t started]...
  topic: startups/actionable advice
- impact_reason: A humorous but pointed critique on the current lack of formal ethics
    training in marketing departments.
  relevance_score: 7
  source: llm_enhanced
  text: What marketer has had any training on ethics other than perhaps watching Hot
    Fuzz and realizing that was all about ethics...
  topic: Ethics/Marketing
- impact_reason: A cautionary note on the current unreliability of AI detection tools,
    relevant for academic and content integrity contexts.
  relevance_score: 7
  source: llm_enhanced
  text: History is littered with examples of people being accused of plagiarism when
    they're not plagiarists. So even the tool, the detection tools aren't, aren't
    up to scratch.
  topic: Technology/Integrity
- impact_reason: Highlights the 'poaching' risk associated with investing in training,
    suggesting a systemic challenge for smaller firms or startups.
  relevance_score: 7
  source: llm_enhanced
  text: It might be the same problem that you let somebody else do that training and
    then whip them out of that other organization. So let one of the larger entrepreneurs,
    you know, let one of the larger, huge blue chips train them up and then take those
    people on.
  topic: Business/Talent Strategy
- impact_reason: Articulates the core financial hurdle for investing in non-immediate,
    strategic training (like ethics or deep expertise development).
  relevance_score: 7
  source: llm_enhanced
  text: It's a hard ask to spend money on that kind of training because the return
    on investment is not immediate for sure.
  topic: Business/Finance
- impact_reason: References a specific, well-known legal/AI failure (Air Canada case)
    as a valuable, free learning resource for other companies.
  relevance_score: 7
  source: llm_enhanced
  text: Air Canada slightly missed it. We're glad they did because now Gidges is a
    useful case study.
  topic: Technology/Legal Precedent
- impact_reason: 'A concise summary of the failure point in many AI rollouts: neglecting
    to explicitly account for human value and potential harm.'
  relevance_score: 7
  source: llm_enhanced
  text: Never made a case for the human beings. Risk harm factors.
  topic: Strategy/Human Element
source: Unknown Source
summary: '## Comprehensive Summary of CIM Marketing Podcast: AI Question Time


  This episode of the CIM Marketing Podcast, titled "AI Question Time," featured experts
  **Kerry Harrison** (AI Trainer/Consultant and founder of the AI Gin) and **Duncan
  Smith** (Data Protection and Compliance Expert, founder of iComply) to discuss the
  practical, strategic, and ethical challenges of integrating Generative AI into marketing
  workflows.


  ### 1. Main Narrative Arc and Key Discussion Points


  The discussion moved chronologically through the AI usage lifecycle: starting with
  **prompt engineering** as the foundation for good output, transitioning to the critical
  issue of **AI hallucinations (errors)**, and concluding with strategic frameworks
  for maintaining **authenticity and quality** in the age of mass AI content generation.
  The central tension explored was balancing AI''s efficiency gains against the risks
  of mediocrity, inaccuracy, and homogenization.


  ### 2. Major Topics, Themes, and Subject Areas Covered


  *   **Prompt Engineering:** The necessity of detailed prompts for valuable output
  versus generic, "vanilla" results from simple prompts.

  *   **AI Reliability and Hallucinations:** The significant danger of LLMs fabricating
  facts, especially when citing regulatory or legal sources (Duncan Smith’s personal
  experience arguing with ChatGPT).

  *   **Website Evolution:** How the rise of AI agents will necessitate websites having
  a "hybrid dual purpose"—serving both human users and automated agents.

  *   **Content Quality and Homogenization:** The risk that over-reliance on AI leads
  to dull, inauthentic content that trains future AI models on their own mediocre
  output.

  *   **Strategic Application:** Identifying where AI excels (idea generation, volume
  content) versus where human expertise remains irreplaceable (conceptual creativity,
  strategic oversight).


  ### 3. Technical Concepts, Methodologies, or Frameworks Discussed


  *   **GCSE Prompting Methodology:** A recommended structure for creating effective
  prompts, emphasizing **G**oal, **C**ontext, **S**ources (examples), and **E**xpectations.

  *   **AI Agents:** Future tools built into platforms like ChatGPT that can execute
  complex tasks by visiting websites on the user''s behalf.

  *   **The AI Sandwich (Human-AI-Human):** Kerry Harrison’s proprietary methodology
  designed to maintain authenticity by sandwiching the AI generation step between
  rigorous human input (prompting) and critical human oversight (editing/fact-checking).

  *   **HACCP (Hazard Analysis Critical Control Point):** Analogized from the food
  industry to emphasize the need for defined "critical control points" in marketing
  workflows to prevent high-risk errors (like hallucinations) from reaching the public.


  ### 4. Business Implications and Strategic Insights


  *   **Risk Management:** For regulated industries (Finance, Compliance), the risk
  of AI hallucinations citing non-existent regulatory guidance is "plain dangerous"
  and warrants stringent human oversight, similar to professional standards 20 years
  ago.

  *   **Competitive Advantage:** Companies that resist homogenization by investing
  in hard work, deep expertise, and conceptual creativity will stand out significantly
  against the flood of generic AI content.

  *   **Workflow Integration:** Marketers must strategically map where AI fits into
  their existing workflows, defining who is responsible for the final check ("who
  presses send").


  ### 5. Key Personalities, Experts, or Thought Leaders Mentioned


  *   **Kerry Harrison:** AI consultant, proponent of the AI Sandwich methodology.

  *   **Duncan Smith:** Data protection expert, provided cautionary tales regarding
  AI''s unreliability in compliance matters.

  *   **Edward de Bono:** Mentioned in the context of lateral thinking tools, highlighting
  areas where AI currently struggles to match human conceptual creativity.


  ### 6. Predictions, Trends, or Future-Looking Statements


  *   AI agents will become commonplace, forcing marketers to design websites to be
  easily parsed by these automated visitors.

  *   There is a philosophical concern that AI training itself on its own output will
  lead to content that is increasingly dull, inaccurate, and inauthentic over time.

  *   A significant divide will emerge between generic, easily ignored AI content
  and high-quality, human-crafted work.


  ### 7. Practical Applications and Real-World Examples


  *   **Idea Generation:** AI is excellent as a "springboard" or "ideas listing tool"
  to overcome initial brainstorming fog (e.g., suggesting a science fiction angle
  for an article).

  *   **Volume Content:** AI is invaluable for generating high volumes of content
  (like social media posts) where speed is prioritized, provided a team of editors
  is employed for quality control.

  *   **Personalized Training:** Users can train specific personas within LLMs (e.g.,
  instructing it never to make up quotes).


  ### 8. Controversies, Challenges, or Problems Highlighted


  *   **Hallucinations:** The primary challenge, especially when AI presents fabricated
  information with authoritative formatting (quotation blocks, citations). Duncan
  Smith noted that LLMs are trained to be helpful and rarely admit ignorance, often
  "lying" when cornered.

  *   **Homogenization:** The risk that using AI for creative tasks results in output
  that is indistinguishable from every other marketer using the same tool.

  *   **Wasted Time:** Spending hours trying to force an LLM to perform highly conceptual
  or lateral thinking tasks that it is fundamentally incapable of doing.


  ### 9. Solutions, Recommendations, or Actionable Advice Provided


  1.  **Use Detailed Prompting:** Employ structures like the GCSE methodology to elevate
  output quality beyond "vanilla."

  2.  **Adopt the AI Sandwich:** Always structure work as Human Input $\rightarrow$
  AI Generation $\rightarrow$ Human Review/Enhancement to ensure authenticity and
  accuracy.

  3.  **Know the Limits:** Recognize that AI struggles with highly conceptual, off-the-wall'
tags:
- artificial-intelligence
- generative-ai
- ai-infrastructure
- startup
- investment
- microsoft
- google
- openai
title: 'Artificial Intelligence for marketers: Your top questions answered by the
  experts'
topics:
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 223
  prominence: 1.0
  topic: artificial intelligence
- keywords:
  - generative ai
  - genai
  - chatgpt
  - gpt
  - claude
  - text generation
  - image generation
  mentions: 53
  prominence: 1.0
  topic: generative ai
- keywords:
  - gpu
  - tensor
  - training
  - inference
  - model deployment
  - vector database
  mentions: 16
  prominence: 1.0
  topic: ai infrastructure
- keywords:
  - startup
  - entrepreneur
  - founder
  - venture
  mentions: 3
  prominence: 0.3
  topic: startup
- keywords:
  - investment
  - funding
  - valuation
  - ipo
  - acquisition
  mentions: 1
  prominence: 0.1
  topic: investment
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-10-06 04:13:05 UTC -->
