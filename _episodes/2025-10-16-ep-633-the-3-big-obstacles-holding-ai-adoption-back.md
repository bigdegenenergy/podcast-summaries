---
companies:
- category: unknown
  confidence: medium
  context: This is the Everyday AI Show, the everyday podcast where we simplify AI
    and br
  name: Everyday AI Show
  position: 12
- category: unknown
  confidence: medium
  context: t's exactly what we're going to be doing today on Everyday AI. What's going
    on, y'all? Welcome to Everyday AI.
  name: Everyday AI
  position: 898
- category: unknown
  confidence: medium
  context: they're looking for when it comes to AI adoption. So I'm excited for today's
    show. So live stream audien
  name: So I
  position: 1944
- category: unknown
  confidence: medium
  context: ots that intelligently answered questions for us. And I think if you look
    between three years ago and now
  name: And I
  position: 3254
- category: unknown
  confidence: medium
  context: ryone that works with Cisco, how can you keep up? Because I think that's
    what's worrying so many people late
  name: Because I
  position: 4700
- category: tech
  confidence: high
  context: city in the world in the GPUs that companies like Nvidia and AMD may be
    able to do that. And then you don'
  name: Nvidia
  position: 7641
- category: tech
  confidence: high
  context: world in the GPUs that companies like Nvidia and AMD may be able to do
    that. And then you don't have e
  name: Amd
  position: 7652
- category: tech
  confidence: high
  context: talking $500 billion projects, the Stargate with OpenAI and Oracle and
    SoftBank, and Google and Microsoft
  name: Openai
  position: 10157
- category: tech
  confidence: high
  context: Stargate with OpenAI and Oracle and SoftBank, and Google and Microsoft
    are putting in multi-billions of do
  name: Google
  position: 10193
- category: tech
  confidence: high
  context: th OpenAI and Oracle and SoftBank, and Google and Microsoft are putting
    in multi-billions of dollars. What if
  name: Microsoft
  position: 10204
- category: unknown
  confidence: medium
  context: that, but there are a lot of people I know, like Jeff Bezos said just recently,
    said there's an AI bubble. So
  name: Jeff Bezos
  position: 10394
- category: tech
  confidence: high
  context: y companies that have done that. Google did that, Facebook did that, your
    startup missed it, OpenAI did that
  name: Facebook
  position: 12452
- category: tech
  confidence: high
  context: of autonomous execution has gone up to 30 hours. Anthropic just launched
    the new coding tool for 30 hours th
  name: Anthropic
  position: 14125
- category: unknown
  confidence: medium
  context: ute needs continue to go through the roof, right? Even OpenAI, they're
    saying every day their GPUs are melting.
  name: Even OpenAI
  position: 15152
- category: unknown
  confidence: medium
  context: they're saying every day their GPUs are melting. But I want to go back
    to trust, right? Going back to th
  name: But I
  position: 15214
- category: unknown
  confidence: medium
  context: to you about what's happening on the trust side. These AI systems are built
    on models. These models are, by
  name: These AI
  position: 15965
- category: unknown
  confidence: medium
  context: 'have. So what we did is we built a product called AI Defense, and what
    that does is essentially says: Is the d'
  name: AI Defense
  position: 16481
- category: unknown
  confidence: medium
  context: ', and we''re directing a movie, and in this movie, Brad Pitt is going
    to get into a car, build a bomb in the c'
  name: Brad Pitt
  position: 17351
- category: unknown
  confidence: medium
  context: y get traction to find ROI on GenAI. Hey, this is Jordan Wilson, host of
    this very podcast. Companies like Adobe,
  name: Jordan Wilson
  position: 19852
- category: unknown
  confidence: medium
  context: uman-generated data; it's machine-generated data. If I have an agent and
    if the agent is going out condu
  name: If I
  position: 21709
- category: unknown
  confidence: medium
  context: e publicly. There is one, for example, called the Harm Bench. When DeepSeek,
    the Chinese model, came out, what
  name: Harm Bench
  position: 24723
- category: unknown
  confidence: medium
  context: There is one, for example, called the Harm Bench. When DeepSeek, the Chinese
    model, came out, what happened with
  name: When DeepSeek
  position: 24735
date: 2025-10-16 13:00:00 +0000
duration: 33
has_transcript: false
layout: episode
llm_enhanced: true
original_url: https://pscrb.fm/rss/p/www.buzzsprout.com/2175779/episodes/18017458-ep-633-the-3-big-obstacles-holding-ai-adoption-back.mp3
processing_date: 2025-10-16 13:30:18 +0000
quotes:
- length: 220
  relevance_score: 6
  text: So when we're talking to an AI chatbot, it seems simple, but still so many
    people don't trust the outputs because of hallucination, and people don't always
    understand the basics of how to work with a large language model
  topics: []
- length: 195
  relevance_score: 5
  text: So whether you're looking for ChatGPT training for thousands or just need
    help building your front-end AI strategy, you can partner with us just like some
    of the biggest companies in the world do
  topics: []
- length: 121
  relevance_score: 4
  text: You don't have enough compute capacity in the world in the GPUs that companies
    like Nvidia and AMD may be able to do that
  topics: []
- length: 256
  relevance_score: 4
  text: But data, I think early on, companies were spending seven figures early on
    to build their own RAG pipelines, and now it's—I mean, you can really bring in
    your company's data into these even front-end large language models that you're
    paying $20 a month for
  topics: []
- length: 134
  relevance_score: 4
  text: Maybe your company has been tinkering with large language models for a year
    or more but can't really get traction to find ROI on GenAI
  topics: []
- length: 103
  relevance_score: 3
  text: 'So the first phase was exactly that: it was these chatbots that intelligently
    answered questions for us'
  topics: []
- length: 155
  relevance_score: 3
  text: And I can only imagine, someone in your position, how much you have to try
    to look into the future to prepare, but it's so hard with the rate of innovation
  topics: []
- length: 114
  relevance_score: 3
  text: '" What we found was the ones doing really well with it are the ones that
    actually started early in experimentation'
  topics: []
- length: 133
  relevance_score: 3
  text: And so you have to make sure that you figure out a way that these safety and
    security concerns that people have with AI are addressed
  topics: []
- length: 160
  relevance_score: 3
  text: I mean, we're talking $500 billion projects, the Stargate with OpenAI and
    Oracle and SoftBank, and Google and Microsoft are putting in multi-billions of
    dollars
  topics: []
- length: 75
  relevance_score: 3
  text: Google did that, Facebook did that, your startup missed it, OpenAI did that
  topics: []
- length: 121
  relevance_score: 3
  text: And the second thing is Nvidia is making money hand over fist because they're
    actually being very profitable selling GPUs
  topics: []
- length: 60
  relevance_score: 3
  text: Even OpenAI, they're saying every day their GPUs are melting
  topics: []
- length: 162
  relevance_score: 3
  text: And so you have to have a way of assessing for safety and security proactively
    to know if the model is going to behave the way that you think it's going to behave
  topics: []
- length: 218
  relevance_score: 3
  text: Yeah, no, it does, and I'm glad that you brought up the fact that large language
    models are not deterministic because so many people, especially if you're not
    technical, you think that they just work like Google, right
  topics: []
- length: 95
  relevance_score: 3
  text: And you have to know when is the hallucination good, when is the hallucination
    not good for you
  topics: []
- length: 186
  relevance_score: 3
  text: So we're going to do a lot of data to do is every single time you retrain
    the model, the model gets more vulnerable, and you have to make sure that you
    actually then redo that test again
  topics: []
- length: 130
  relevance_score: 3
  text: But here's what I would say would be something that might be worth leaving
    your audience with, which is overhyped in AI, right now
  topics: []
- impact_reason: 'Defines the critical shift in the AI landscape: the transition from
    simple generative tools (Phase 1) to autonomous agents capable of complex workflow
    automation (Phase 2). This is a key trend insight.'
  relevance_score: 10
  source: llm_enhanced
  text: We're now moving to the second phase of AI, which is moving from these chatbots
    to agents that can get tasks and jobs done almost fully autonomously. So it's
    no longer just about I ask you a question, I get back an answer; it's now about
    making sure that you can have full-fledged workflows within companies that are
    automated. We're moving from a world of individual productivity to workflow automation.
  topic: AI technology trends
- impact_reason: A stark strategic warning about the bifurcation of the market based
    on AI dexterity, emphasizing that AI proficiency is becoming a prerequisite for
    relevance, not just an advantage.
  relevance_score: 10
  source: llm_enhanced
  text: 'The ability to keep up in this market is actually a massive superpower if
    you can do it because there''s so much that''s changing and the ability to kind
    of tie these things together and fundamentally change how your business operates,
    because I think there are only going to be two kinds of companies in the world:
    there will be companies that are very dexterous with the use of AI, and then there
    will be companies that will really struggle for relevance because it''s—and I
    think that will apply to individuals as well.'
  topic: strategy
- impact_reason: 'Identifies the primary physical bottleneck to scaling AI: the triad
    of power/electricity, compute (GPUs), and network bandwidth. This is a crucial
    limiting factor for future growth.'
  relevance_score: 10
  source: llm_enhanced
  text: The first big impediment is we simply don't have enough infrastructure in
    the world to power the needs of AI. What does infrastructure mean? You don't have
    enough power in the world, enough electricity, to be able to fuel these data centers
    that are going to be needed for AI. That's number one. You don't have enough compute
    capacity in the world in the GPUs... And then you don't have enough network bandwidth
    in the world. So the first constraint is infrastructure.
  topic: limitations
- impact_reason: Uses the OpenAI pricing history (raising price 10x while still losing
    money due to overwhelming usage) as definitive proof of sustained, massive underlying
    demand, refuting the 'bubble' argument.
  relevance_score: 10
  source: llm_enhanced
  text: When does a company lose money at $200 where the demand signal is so strong
    that people keep coming back and they're using it so much that even after you
    increase the price by a factor of 10, you're not able to satisfy the demand, and
    you're still losing money because people are using it even more than that? So
    what are they going to do? They're going to come up with a plan for $2,000, and
    then they're going to come up for $20,000.
  topic: business/predictions
- impact_reason: 'This clearly defines the critical shift from current Q&A chatbots
    to the next phase: autonomous, persistent AI agents capable of performing complex
    tasks.'
  relevance_score: 10
  source: llm_enhanced
  text: You go from asking a question and getting an answer to these agents that can
    conduct work 24/7 on your behalf.
  topic: AI technology trends
- impact_reason: This provides concrete, quantifiable evidence of the massive leap
    in AI capability—the increase in sustained, unsupervised work duration—which is
    a key technical breakthrough.
  relevance_score: 10
  source: llm_enhanced
  text: The duration of autonomous execution used to be 20 minutes. Now the duration
    of autonomous execution has gone up to 30 hours. Anthropic just launched the new
    coding tool for 30 hours this system worked by itself without any human intervention,
    just going out writing code for 30 hours.
  topic: technical/breakthroughs
- impact_reason: 'This explains the core technical challenge in deploying LLMs in
    enterprise settings: reconciling the inherent non-deterministic nature of the
    models with the enterprise requirement for predictable, reliable outputs.'
  relevance_score: 10
  source: llm_enhanced
  text: These AI systems are built on models. These models are, by definition, what
    they call non-deterministic, which means they're unpredictable. Every single time
    you ask an AI chatbot a question, you get a slightly different answer, right?
    But you're trying to build predictable systems on unpredictable models.
  topic: technical/limitations
- impact_reason: 'This details the proactive methodology for AI security: adversarial
    testing (jailbreaking) to discover failure modes, followed by implementing specific
    algorithmic guardrails to correct behavior.'
  relevance_score: 10
  source: llm_enhanced
  text: You have to algorithmically jailbreak these models, figure out when a model
    doesn't behave the way you want it to behave, and then when it doesn't behave
    the way you want it to behave, you have to be able to put guardrails around that
    saying, 'Whenever a question like this gets asked, here's how the model needs
    to behave.'
  topic: safety/technical
- impact_reason: This addresses the critical 'data exhaustion' problem facing large-scale
    model training, signaling a necessary pivot in data sourcing for future foundational
    models.
  relevance_score: 10
  source: llm_enhanced
  text: Up until today, these models have been trained with freely available data
    that's publicly available on the internet, right? And it's largely human-generated
    data. What's happened... over the course of the past three years... is we are
    virtually out of publicly available data on the internet to train these models.
    We have exhausted all the data.
  topic: AI technology trends/limitations
- impact_reason: This highlights a massive, untapped data resource (machine data)
    that is growing rapidly but is currently outside the training scope of existing
    LLMs, presenting a major opportunity for differentiation.
  relevance_score: 10
  source: llm_enhanced
  text: 55% of the growth of data in the world is not human-generated data; it's machine-generated
    data. And machine data is something that these AI models have not been trained
    on. It's basically time-series data that says, 'At this time this happened, at
    this time this happened...'
  topic: AI technology trends/data
- impact_reason: 'Crucial insight into the continuous nature of AI security: retraining
    models can reintroduce or amplify vulnerabilities, necessitating a continuous
    testing loop.'
  relevance_score: 10
  source: llm_enhanced
  text: We need to just make sure that we can actually provide a constant level of
    oversight and a continuous value. So we're going to do a lot of data to do is
    every single time you retrain the model, the model gets more vulnerable, and you
    have to make sure that you actually then redo that test again.
  topic: safety/technical
- impact_reason: Provides a clear, three-phase roadmap for AI evolution (LLMs -> Agents
    -> Physical Embodiment) and flags the unique safety challenges of the physical
    domain.
  relevance_score: 10
  source: llm_enhanced
  text: The third phase of AI will be physical AI, robotics, humanoids, and how you
    go out and deal with safety and security, and that will have a whole different
    set of implications.
  topic: predictions
- impact_reason: 'Offers a balanced perspective: AI won''t eliminate jobs entirely,
    but it will fundamentally change *how* every job is performed, emphasizing reconfiguration
    over replacement.'
  relevance_score: 10
  source: llm_enhanced
  text: Human creativity is nowhere near gone. We are actually going to have so much
    value to add to society, and so I don't believe AI is going to take every single
    job away, and we're nothing to do. However, every job will get reconfigured with
    AI; that's important.
  topic: predictions/strategy
- impact_reason: Highlights the massive gap between AI intent (priority) and actual
    execution (adoption), framing the core problem the podcast aims to address.
  relevance_score: 9
  source: llm_enhanced
  text: Most studies show that AI adoption is a priority to more than 90% of enterprise
    leaders, yet the very same studies show that less than 10% of enterprises have
    adopted AI across their entire organization. Why?
  topic: business
- impact_reason: 'Actionable business advice for AI adoption: prioritize early, imperfect
    experimentation to build necessary organizational instinct, countering the paralysis
    caused by the rapid pace of innovation.'
  relevance_score: 9
  source: llm_enhanced
  text: 'My one piece of advice would be: don''t wait for this technology to get perfected;
    start experimenting so that you can get a feel for how the market is evolving.
    You can get an instinct because that instinct is going to be really important
    as this technology gets more and more sophisticated, because the longer you wait,
    the harder it is to catch up.'
  topic: business advice
- impact_reason: Elevates AI compute capacity (token generation) from a business concern
    to a matter of national security and economic sovereignty, highlighting geopolitical
    importance.
  relevance_score: 9
  source: llm_enhanced
  text: Your ability to generate tokens, which is the mechanism for—what I'm talking
    about—the mechanism for predicting the next word, your ability to generate tokens
    is going to be directly tied to economic prosperity as well as national security.
  topic: predictions
- impact_reason: Articulates the 'Trust Deficit' as the second major adoption hurdle,
    focusing specifically on data privacy and misuse concerns within the enterprise
    context.
  relevance_score: 9
  source: llm_enhanced
  text: The second big constraint is what we call a trust deficit, but people just
    don't trust these systems. And if I use AI, is it going to use my data in the
    wrong way? Is it going to misuse anything that I tell it to do?
  topic: safety/ethics
- impact_reason: This provides a strong, practical metric for assessing the true success
    and stickiness of a technology platform (like generative AI), contrasting it with
    mere hype. It highlights OpenAI's achieved product-market fit.
  relevance_score: 9
  source: llm_enhanced
  text: It's very hard to build a product that people keep coming back to and using
    it for hours a day. It's a very hard thing to do. There are not that many companies
    that have done that. Google did that, Facebook did that, your startup missed it,
    OpenAI did that.
  topic: business/strategy
- impact_reason: A strong prediction emphasizing the vast, untapped potential for
    AI automation across the economy, suggesting current usage is minimal compared
    to the future state.
  relevance_score: 9
  source: llm_enhanced
  text: We have just hit the tip of the iceberg yet if every workflow in every business
    starts to get automated.
  topic: predictions
- impact_reason: 'A crucial strategic insight: the market can simultaneously contain
    a speculative bubble (overinflated companies) while resting on a fundamental,
    transformative technological shift.'
  relevance_score: 9
  source: llm_enhanced
  text: 'One thing to keep in mind: your question is, you can have overinflated companies,
    and you can have one of the largest platform shifts ever known to humankind, and
    both those conditions can hold true.'
  topic: strategy
- impact_reason: 'This outlines the three essential pillars for establishing AI trust
    and safety in production environments: visibility, validation, and runtime enforcement.'
  relevance_score: 9
  source: llm_enhanced
  text: 'Can we actually validate the model that it''s behaving the way that we want
    it to behave? And number three: Once you know it''s behaving the way you want
    it to behave, can you put runtime enforcement guardrails around it?'
  topic: safety/ethics
- impact_reason: This provides a concise, powerful framework for understanding AI
    failure modes based on context—hallucination is context-dependent, requiring use-case
    specific evaluation.
  relevance_score: 9
  source: llm_enhanced
  text: Hallucination is a feature when you're writing poetry; it's a bug when you're
    trying to think about security software, right? And you have to know when is the
    hallucination good, when is the hallucination not good for you.
  topic: safety/strategy
- impact_reason: This is a concrete example demonstrating the speed and ease with
    which new models can be compromised (jailbroken) and introduces a specific industry
    benchmark (Harm Bench) for measuring safety.
  relevance_score: 9
  source: llm_enhanced
  text: When DeepSeek, the Chinese model, came out, what happened with DeepSeek is
    in the first 48 hours, we were able to at Cisco jailbreak that model, not just
    one time, but 100% of times in the top 50 categories in a benchmark called Harm
    Bench.
  topic: safety/technical
- impact_reason: 'This suggests the next frontier in AI value creation: integrating
    machine-generated operational data with existing human-generated knowledge bases
    to unlock new capabilities.'
  relevance_score: 9
  source: llm_enhanced
  text: If you can take that machine data and correlate it with human data, you can
    start to see magic happening.
  topic: strategy/predictions
- impact_reason: This summarizes the three fundamental constraints (Infrastructure,
    Trust, Data Pipeline Readiness) that must be overcome for any company to achieve
    meaningful differentiation using AI.
  relevance_score: 9
  source: llm_enhanced
  text: 'If you can do those three things: provide the right amount of infrastructure,
    create enough trust in the system, and make sure that you''ve got all the tooling
    to get organizations to get their data pipeline ready to train AI models, every
    company could really differentiate themselves in a meaningful way.'
  topic: business/strategy
- impact_reason: This perfectly frames the context-dependency of LLM 'hallucinations,'
    distinguishing between creative use cases where it's beneficial and critical use
    cases (like security) where it's a failure mode.
  relevance_score: 9
  source: llm_enhanced
  text: Is the model hallucinating when it should not be hallucinating? Because hallucination
    is a feature when you're writing poetry; it's a bug when you're trying to think
    about security software, right?
  topic: safety/limitations
- impact_reason: Highlights the necessity of rigorous testing and algorithmic determination
    of model failure modes specific to the intended application, moving beyond general
    performance metrics.
  relevance_score: 9
  source: llm_enhanced
  text: You have to know when is the hallucination good, when is the hallucination
    not good for you. So what kind of use cases? So you basically have to figure out
    these behaviors in a model that might exist that are not exactly ideal for what
    you're trying to do with the model and be able to algorithmically determine and
    figure out and jailbreak the model to know this is when the model fails, right?
  topic: safety/technical
- impact_reason: Shifts focus from current LLM challenges (Phase 1) to the anticipated,
    unaddressed problems arising from autonomous AI agents (Phase 2).
  relevance_score: 9
  source: llm_enhanced
  text: what do you think might be the next biggest obstacle that hasn't hit yet because
    of phase two, because of agentics?
  topic: predictions
- impact_reason: Directly counters the most common societal fear regarding AI adoption,
    offering a more nuanced view on job displacement.
  relevance_score: 9
  source: llm_enhanced
  text: What's overhyped in AI is all of us are going to lose our jobs; everyone's
    just going to be staring at the ocean and not have enough to do because the AIs
    are going to do everything. I think that's nonsense.
  topic: safety/predictions
- impact_reason: Identifies the shift from AI as a summarization/aggregation tool
    to a genuine source of novel, original insights as the most underestimated future
    capability.
  relevance_score: 9
  source: llm_enhanced
  text: What's underhyped about AI is that we're going to have—and you're starting
    to see this already in some meaningful ways—original insights.
  topic: predictions
- impact_reason: Identifies the 'Data Gap'—not just lack of data, but the failure
    to properly organize and leverage proprietary data—as the third critical barrier
    to unlocking AI potential.
  relevance_score: 8
  source: llm_enhanced
  text: 'The third area is a data gap. Most companies, Jordan, think that their data
    is their most unique differentiator. And so that''s the third area that needs
    to get solved: you need to make sure that you use data well.'
  topic: business advice
- impact_reason: Provides a staggering, specific figure ($5T) for projected data center
    CapEx, underscoring the massive scale of the infrastructure investment required
    for AI.
  relevance_score: 8
  source: llm_enhanced
  text: Firstly, there's about a $5 trillion spend that is currently projected for
    data center capacity buildout, $5 trillion, not $500 billion.
  topic: business/limitations
- impact_reason: Cites Nvidia's profitability as a second key indicator that the AI
    investment is generating real, measurable value, supporting the argument against
    a bubble.
  relevance_score: 8
  source: llm_enhanced
  text: And the second thing is Nvidia is making money hand over fist because they're
    actually being very profitable selling GPUs. Why is that? Once again, because
    people are willing to pay great prices for GPUs because there's enough value to
    be had.
  topic: business
- impact_reason: 'Connects the shift to AI agents with the fundamental change in operational
    capacity: increasing the duration and scope of autonomous work, which drives future
    infrastructure demand.'
  relevance_score: 8
  source: llm_enhanced
  text: When you have an agent that's working 24/7 around the clock, what that's doing
    is the duration of autonomous execution is actually increasing.
  topic: AI technology trends
- impact_reason: This links the high demand for AI infrastructure (GPUs) directly
    to perceived value creation, suggesting the current investment wave is underpinned
    by real utility, not just speculation.
  relevance_score: 8
  source: llm_enhanced
  text: Nvidia is making money hand over fist because they're actually being very
    profitable selling GPUs. Why is that? Once again, because people are willing to
    pay great prices for GPUs because there's enough value to be had.
  topic: business/strategy
- impact_reason: 'Direct business advice: external safety testing necessitates implementing
    specific, application-layer guardrails to mitigate risks before deployment, protecting
    brand integrity.'
  relevance_score: 8
  source: llm_enhanced
  text: And so if you happen to be using this model, these are the guardrails you're
    going to need to put in the middle of the screen so you can use this model in
    a place, otherwise you will find that this could actually be damaging to your
    brand as a company.
  topic: business/safety
- impact_reason: 'Illustrates a key business model for AI infrastructure providers:
    abstracting away security/safety complexity so application developers can focus
    purely on innovation.'
  relevance_score: 8
  source: llm_enhanced
  text: So the developers do? They will just use our AI product to say, "Oh, I'm just
    going to use this Cisco product, call an API," so that while I'm building an application,
    I can innovate furiously because Cisco takes care of the security side of things.
  topic: business/strategy
- impact_reason: 'Clearly defines the current limitation of most deployed AI systems:
    they are sophisticated pattern matchers and aggregators of existing knowledge,
    not true originators.'
  relevance_score: 8
  source: llm_enhanced
  text: Up until now, AI has been used as an aggregation mechanism, like I'm going
    to be able to do it; I'm going to be the right answer based on the things that
    I've trained it on
  topic: limitations
- impact_reason: 'Defines the operational requirement for modern AI governance: security
    is not a one-time check but a perpetual operational process.'
  relevance_score: 7
  source: llm_enhanced
  text: And that's a continuous loop that keeps happening on an ongoing basis, and
    that's what we're doing for customers.
  topic: strategy
source: Unknown Source
summary: '## Podcast Episode Summary: Ep 633: The 3 Big Obstacles Holding AI Adoption
  Back


  This episode of the Everyday AI Show features **G2 Patel, President and Chief Product
  Officer of Cisco**, discussing why, despite high executive interest, actual enterprise-wide
  AI adoption remains low. The conversation centers on the transition from the initial
  "chatbot phase" of Generative AI to the more complex "agentic phase," and identifies
  three critical roadblocks preventing widespread success.


  ---


  ### 1. Focus Area

  The discussion focuses on the **practical challenges of scaling Artificial Intelligence
  (AI) adoption within large enterprises**, specifically examining the transition
  from basic generative AI tools (like ChatGPT) to autonomous AI agents capable of
  performing complex workflows. Key areas covered include infrastructure requirements,
  AI security/trust, and data strategy for next-generation models.


  ### 2. Key Technical Insights

  *   **Shift to Agentic AI:** The industry is moving from Phase 1 (intelligent chatbots
  providing answers) to Phase 2 (autonomous agents executing multi-step tasks 24/7),
  exemplified by tools like Anthropic’s coding agent operating autonomously for 30
  hours.

  *   **Non-Deterministic Models Require Guardrails:** LLMs are inherently non-deterministic
  (unpredictable output), necessitating proactive security measures. Solutions involve
  visibility into training data, validation of model behavior, and implementing runtime
  enforcement guardrails to prevent misuse (e.g., algorithmic "jailbreaking" attempts).

  *   **The Rise of Machine-Generated Data:** Publicly available, human-generated
  training data is becoming exhausted. Future AI differentiation will rely heavily
  on leveraging **machine-generated data** (time-series data from automated tasks)
  and correlating it with human data.


  ### 3. Business/Investment Angle

  *   **Infrastructure as an Economic Imperative:** The massive projected $5 trillion
  data center buildout is driven by sustained, escalating demand, not a bubble, as
  evidenced by companies like OpenAI raising prices tenfold while demand still outstrips
  capacity. Infrastructure capability (compute, power, bandwidth) is now tied directly
  to national economic prosperity and security.

  *   **The Cost of Waiting:** Companies that started early experimentation with GenAI
  are seeing success, while those waiting for perfection are struggling to catch up.
  Early adoption builds crucial "instinct" for navigating the rapid evolution.

  *   **KPIs for Trust:** Enterprise success metrics must shift to measuring model
  reliability. Key performance indicators (KPIs) involve algorithmically determining
  when a model "hallucinates" (which is a feature in creative tasks but a critical
  bug in security or operational tasks) using benchmarks like the **Harm Bench**.


  ### 4. Notable Companies/People

  *   **G2 Patel (Cisco):** The featured expert, providing the enterprise perspective
  from a leading networking and infrastructure company.

  *   **OpenAI:** Mentioned as the catalyst for the current AI phase and as an example
  of extreme demand signals (raising prices 10x while still losing money on the service).

  *   **Anthropic:** Cited for demonstrating advanced agentic capabilities with a
  coding tool running autonomously for 30 hours.

  *   **Nvidia/AMD:** Referenced as key suppliers whose profitability signals sustained
  demand for high-end GPUs.


  ### 5. Future Implications

  The future of AI adoption hinges on solving the three identified obstacles. Success
  will create a world where companies dexterous with AI will thrive, while others
  will struggle for relevance. The industry is moving toward a platform shift where
  **autonomous agents** will fundamentally refactor nearly every business workflow,
  requiring robust, secure, and data-rich environments.


  ### 6. Target Audience

  This episode is highly valuable for **Enterprise Technology Leaders (CIOs, CTOs),
  AI Strategy Executives, Infrastructure Planners, and IT Security Professionals**
  who are responsible for scaling AI initiatives beyond pilot projects and need a
  strategic framework for overcoming adoption hurdles.'
tags:
- artificial-intelligence
- generative-ai
- ai-infrastructure
- startup
- nvidia
- openai
- google
- microsoft
title: 'Ep 633: The 3 Big Obstacles Holding AI Adoption Back'
topics:
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 138
  prominence: 1.0
  topic: artificial intelligence
- keywords:
  - generative ai
  - genai
  - chatgpt
  - gpt
  - claude
  - text generation
  - image generation
  mentions: 18
  prominence: 1.0
  topic: generative ai
- keywords:
  - gpu
  - tensor
  - training
  - inference
  - model deployment
  - vector database
  mentions: 5
  prominence: 0.5
  topic: ai infrastructure
- keywords:
  - startup
  - entrepreneur
  - founder
  - venture
  mentions: 1
  prominence: 0.1
  topic: startup
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-10-16 13:30:18 UTC -->
