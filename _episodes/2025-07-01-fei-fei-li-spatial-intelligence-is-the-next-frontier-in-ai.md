---
companies:
- category: unknown
  confidence: medium
  context: t hunker down and build. That is my comfort zone. So I'm super excited
    here to have Dr. Feifei Li. She h
  name: So I
  position: 354
- category: unknown
  confidence: medium
  context: mfort zone. So I'm super excited here to have Dr. Feifei Li. She has such
    a long career in AGI. I'm sure a lo
  name: Feifei Li
  position: 392
- category: unknown
  confidence: medium
  context: starting from the founding fathers of AGI, right? John McCarthy, and then
    we go through people like Jeff Hinton.
  name: John McCarthy
  position: 1631
- category: unknown
  confidence: medium
  context: John McCarthy, and then we go through people like Jeff Hinton. I think
    we just had an AGI dream. We really, rea
  name: Jeff Hinton
  position: 1681
- category: unknown
  confidence: medium
  context: no one had data at that time in computer vision. And I was the first generation
    of grad students who was
  name: And I
  position: 2592
- category: unknown
  confidence: medium
  context: workshop in that year's ICCV in Florence, Italy. And Alex Krizhevsky came,
    and many people came. I remember Young Akog
  name: And Alex Krizhevsky
  position: 5829
- category: unknown
  confidence: medium
  context: Krizhevsky came, and many people came. I remember Young Akogos came. And
    now the world knows this moment as the
  name: Young Akogos
  position: 5888
- category: unknown
  confidence: medium
  context: you had a lot of the work with your students like Andrej Karpathy being
    able to describe the scenes. Tell us about
  name: Andrej Karpathy
  position: 6571
- category: unknown
  confidence: medium
  context: earning took off, and then Andrej, and then later Justin Johnson entered
    my lab. We started to see signals of natu
  name: Justin Johnson
  position: 7848
- category: unknown
  confidence: medium
  context: ing a professor to now being a founder and CEO of World Labs. Tell us about
    what World is. It's even harder th
  name: World Labs
  position: 9716
- category: unknown
  confidence: medium
  context: ments of my career where I'm looking for the next North Star problem to
    solve. I ask myself, what is what evol
  name: North Star
  position: 10815
- category: unknown
  confidence: medium
  context: 'ng but world-class technologists: Justin Johnson, Ben Mildenhall, and
    Christoph Laster. And we are just going to t'
  name: Ben Mildenhall
  position: 13032
- category: unknown
  confidence: medium
  context: 'echnologists: Justin Johnson, Ben Mildenhall, and Christoph Laster. And
    we are just going to try to solve, in my opi'
  name: Christoph Laster
  position: 13052
- category: unknown
  confidence: medium
  context: ator of Pulsar, which was the initial seed before Gaussian Splatting, that
    we were a little differentiable rendering.
  name: Gaussian Splatting
  position: 13272
- category: unknown
  confidence: medium
  context: some of the applications that you're envisioning? Because I think you listed
    everything from perception to ge
  name: Because I
  position: 17893
- category: unknown
  confidence: medium
  context: inceton. So I started a good dry cleaning shop in Silicon Valley. Language,
    I fundraised. I was the founder, CEO.
  name: Silicon Valley
  position: 20103
- category: tech
  confidence: high
  context: So I wasn't afraid of that. And then I did go to Google to learn a lot
    about business in Google Cloud and
  name: Google
  position: 21038
- category: unknown
  confidence: medium
  context: did go to Google to learn a lot about business in Google Cloud and B2B
    and all those. And then I started a start
  name: Google Cloud
  position: 21078
- category: unknown
  confidence: medium
  context: ot of legendary researchers like Andrej Karpathy, Jim Fan who's at NVIDIA,
    Jia Deng, who's your co-author f
  name: Jim Fan
  position: 22150
- category: tech
  confidence: high
  context: esearchers like Andrej Karpathy, Jim Fan who's at NVIDIA, Jia Deng, who's
    your co-author for ImageNet. The
  name: Nvidia
  position: 22167
- category: unknown
  confidence: medium
  context: rs like Andrej Karpathy, Jim Fan who's at NVIDIA, Jia Deng, who's your
    co-author for ImageNet. They've all g
  name: Jia Deng
  position: 22175
- category: unknown
  confidence: medium
  context: know, the greatest disseminator of AI knowledge. But I think there is one
    thing that unifies them, and I
  name: But I
  position: 22964
- category: unknown
  confidence: medium
  context: student, I would recommend you to look for those North Stars that are not
    on the collision course of problems
  name: North Stars
  position: 24865
- category: unknown
  confidence: medium
  context: sibilities. Thank you so much, Feifei. Thank you, Professor Lee. And congratulations
    again on your honorary docto
  name: Professor Lee
  position: 25935
- category: unknown
  confidence: medium
  context: in 1956 in Dartmouth, you know, John McCarthy and Marvin Minsky of them,
    they wanted to solve the problem of mach
  name: Marvin Minsky
  position: 26677
- category: unknown
  confidence: medium
  context: that can think. And that's a problem that Turing, Alan Turing, also put
    forward a few years earlier, 10 years o
  name: Alan Turing
  position: 26795
- category: ai_startup
  confidence: high
  context: Feifei Li's new company focused on solving spatial intelligence, creating
    3D world models, and going beyond flat pixels and language.
  name: World Labs
  source: llm_enhanced
- category: ai_research_group
  confidence: high
  context: The team name for Jeff Hinton's group that developed the convolutional
    neural network (which became AlexNet) that won the 2012 ImageNet challenge.
  name: SuperVision
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: The convolutional neural network developed by Alex Krizhevsky's team (SuperVision)
    that dramatically improved performance in the 2012 ImageNet challenge, marking
    a turning point for deep learning.
  name: AlexNet
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as the generative model that 'blasted open the door' for truly
    working generative models in November 2022, inspiring the move toward spatial
    intelligence.
  name: ChatGPT
  source: llm_enhanced
- category: ai_research_project
  confidence: high
  context: A foundational dataset created by Feifei Li and her team, which kicked
    off the data-driven leg of AGI development.
  name: ImageNet
  source: llm_enhanced
- category: ai_conference
  confidence: medium
  context: Mentioned as the venue where the initial ImageNet poster was published
    in 2009.
  name: CVPR
  source: llm_enhanced
- category: ai_conference
  confidence: high
  context: Mentioned as the venue where the ImageNet challenge workshop (featuring
    AlexNet's breakthrough) was presented in 2012.
  name: ICCV
  source: llm_enhanced
- category: ai_research
  confidence: low
  context: Implied affiliation, as Feifei Li is a major figure associated with Stanford,
    though the lab name itself is not explicitly stated, the context points to major
    academic research centers.
  name: Stanford AI Lab
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: Feifei Li's former institution where she started her work on ImageNet as
    a first-year assistant professor.
  name: Princeton
  source: llm_enhanced
- category: ai_pioneer
  confidence: high
  context: Referenced as one of the 'founding fathers of AGI.'
  name: John McCarthy
  source: llm_enhanced
- category: ai_pioneer
  confidence: high
  context: Referenced as a key figure in AGI development, whose team created SuperVision/AlexNet.
  name: Jeff Hinton
  source: llm_enhanced
- category: ai_researcher
  confidence: high
  context: Mentioned as the person who presented the AlexNet results at the ImageNet
    challenge workshop.
  name: Alex Krizhevsky
  source: llm_enhanced
- category: ai_researcher
  confidence: high
  context: Mentioned as someone who attended the 2012 ImageNet challenge workshop.
  name: Young Akogos
  source: llm_enhanced
- category: ai_researcher
  confidence: high
  context: Feifei Li's former student, involved in early work on image captioning/storytelling,
    and later involved in the generative AI shift.
  name: Andrej Karpathy
  source: llm_enhanced
- category: ai_researcher/founder
  confidence: high
  context: Former student of Feifei Li, co-founder of World Labs, known for work on
    real-time neural style transfer.
  name: Justin Johnson
  source: llm_enhanced
- category: ai_researcher/founder
  confidence: high
  context: Co-founder of World Labs, author of the NeRF paper.
  name: Ben Mildenhall
  source: llm_enhanced
- category: ai_researcher/founder
  confidence: high
  context: Co-founder of World Labs, creator of Pulsar (initial seed before Gaussian
    Splatting).
  name: Christoph Laster
  source: llm_enhanced
- category: ai_research_paper/technique
  confidence: high
  context: Mentioned as the paper authored by Ben Mildenhall, related to 3D representation.
  name: NeRF
  source: llm_enhanced
- category: ai_technique
  confidence: high
  context: Mentioned in relation to Christoph Laster's work (Pulsar being the initial
    seed before it).
  name: Gaussian Splatting
  source: llm_enhanced
date: 2025-07-01 14:17:12 +0000
duration: 44
has_transcript: false
layout: episode
llm_enhanced: true
original_url: https://anchor.fm/s/8c1524bc/podcast/play/104885941/https%3A%2F%2Fd3ctxlq1ktw2nl.cloudfront.net%2Fstaging%2F2025-6-1%2F403125095-44100-2-3e6a68d004ee.mp3
processing_date: 2025-10-05 05:26:29 +0000
quotes:
- length: 192
  relevance_score: 6
  text: While computer vision, as a computer vision scientist, we're seeing this incredible
    growth, you know, from image to image captioning, to image generation using some
    of the diffusion techniques
  topics:
  - growth
- length: 142
  relevance_score: 5
  text: If you're working in machine learning, you have to respect that generalization
    is the core mathematical foundation or goal of machine learning
  topics: []
- length: 145
  relevance_score: 5
  text: Now, following this trend of the arc of intelligence for computer vision,
    ImageNet was really the seed to solve the concept of object recognition
  topics:
  - seed
- length: 124
  relevance_score: 4
  text: And as I was obsessively developing machine learning algorithms, at that time
    we did try neural networks, but it didn't work
  topics: []
- length: 128
  relevance_score: 4
  text: It was also the first time that two GPUs were put together by Alex and his
    team and were used for the computing of deep learning
  topics: []
- length: 125
  relevance_score: 4
  text: Is it fair to say that what you're building at World Labs is these whole new
    foundation models where the output are 3D worlds
  topics: []
- length: 41
  relevance_score: 3
  text: And you have to appreciate how hard it is
  topics: []
- length: 104
  relevance_score: 3
  text: So you have to—this is why humans and animals have multi-sensors—and then
    you have to solve that problem
  topics: []
- length: 102
  relevance_score: 3
  text: So, and then there are many, many related industries from marketing to entertainment
    to even metaphors
  topics:
  - market
- length: 95
  relevance_score: 3
  text: And then I did go to Google to learn a lot about business in Google Cloud
    and B2B and all those
  topics:
  - b2b
- impact_reason: 'This clearly states the speaker''s current, highly ambitious North
    Star problem: spatial intelligence as a prerequisite for AGI, positioning it as
    the next frontier beyond current LLM/vision capabilities.'
  relevance_score: 10
  source: llm_enhanced
  text: My entire career is going after problems that are just so hard, bordering
    delusional. To me, AGI will not be complete without spatial intelligence, and
    I want to solve that problem.
  topic: predictions/strategy
- impact_reason: A concise summary of the 'AlexNet moment' (2012), identifying the
    three essential ingredients that ignited the modern deep learning revolution.
  relevance_score: 10
  source: llm_enhanced
  text: It was really the first moment of data, GPUs, and neural network coming together.
  topic: technical
- impact_reason: A powerful comparative analysis between the evolutionary timelines
    of language and vision, used to justify why spatial intelligence (vision) is the
    harder, more fundamental problem for AGI.
  relevance_score: 10
  source: llm_enhanced
  text: The development of human language in evolution took about... less than half
    a million years. But think about vision... That journey took evolution 540 million
    years.
  topic: predictions/strategy
- impact_reason: Defines the scope of 'spatial intelligence' as the next major challenge,
    encompassing understanding, generation, reasoning, and action in 3D space.
  relevance_score: 10
  source: llm_enhanced
  text: For me, solving a problem of spatial intelligence to understand the 3D world,
    to generate the 3D world, to reason about the 3D world, to do things in the 3D
    world is a fundamental problem of AI.
  topic: predictions/technical
- impact_reason: 'This defines the technical goal of the new venture (World Labs):
    building world models grounded in 3D structure, moving past 2D image processing
    and pure language models.'
  relevance_score: 10
  source: llm_enhanced
  text: World models that go beyond flat pixels, world models that go beyond language,
    world models that truly capture the 3D structure and the spatial intelligence
    of the world.
  topic: technical/predictions
- impact_reason: This clearly states a core belief that spatial reasoning (3D understanding)
    is a necessary, missing component for achieving true AGI, contrasting with the
    current focus primarily on language models.
  relevance_score: 10
  source: llm_enhanced
  text: To me, AGI will not be complete without spatial intelligence, and I want to
    solve that problem.
  topic: predictions/strategy
- impact_reason: A provocative comparison suggesting the complexity of 3D vision/spatial
    reasoning surpasses the complexity of 1D sequential language modeling, which is
    a key technical argument.
  relevance_score: 10
  source: llm_enhanced
  text: Vision is actually harder than LLM to some extent. Maybe this is a controversial
    thing to say because LLMs are basically 1D, but you're talking about understanding
    a lot of the 3D structures.
  topic: technical
- impact_reason: 'Explains the core mathematical challenge of vision: inverting a
    3D-to-2D projection, which is inherently ill-posed, requiring inference and multi-sensor
    fusion.'
  relevance_score: 10
  source: llm_enhanced
  text: Second, the sensing, the reception of the visual world is a projection. Whether
    it's your eye, your retina, or a camera, it's always collapsing 3D to 2D. And
    you have to appreciate how hard it is. It's mathematically ill-posed.
  topic: technical
- impact_reason: Identifies 'intellectual fearlessness'—the courage to embrace hard
    problems—as the single most important trait in successful AI researchers and hires.
  relevance_score: 10
  source: llm_enhanced
  text: 'But I think there is one thing that unifies them [legendary students], and
    I would encourage every single one of you to think about this: I look for intellectual
    fearlessness.'
  topic: strategy/hiring
- impact_reason: A powerful statement on the current theoretical deficit in AI, pointing
    directly to explainability and causality as crucial unsolved theoretical problems.
  relevance_score: 10
  source: llm_enhanced
  text: The AI capability has 100% outrun theory. We don't know how—you know, we don't
    have explainability. We don't know how to figure out the causality. There's just
    so much in the models we don't understand that one could push forward.
  topic: technical
- impact_reason: Challenges the modern industry framing of AGI as something fundamentally
    'beyond AI,' arguing it's the original, core goal of the field (thinking machines).
  relevance_score: 10
  source: llm_enhanced
  text: 'I struggle with this definition of AGI, to be honest. Here''s why: The founding
    fathers of AGI who came together in 1956 in Dartmouth... they wanted to solve
    the problem of machines that can think. And that''s a problem that Turing... also
    put forward... So I don''t really know how to differentiate that founding question
    of AI versus this new word AGI. To me, they''re the same thing.'
  topic: safety/philosophy
- impact_reason: A foundational philosophical statement on the importance of vision,
    framing it not just as pattern recognition but as active world understanding,
    crucial for AGI.
  relevance_score: 9
  source: llm_enhanced
  text: Seeing is such a cornerstone of intelligence. Visual intelligence is not just
    perceiving; it's really understanding the world and doing things in the world.
  topic: safety/strategy
- impact_reason: This captures the strategic pivot that led to ImageNet—the realization
    that algorithmic progress alone was insufficient and data was the necessary catalyst.
  relevance_score: 9
  source: llm_enhanced
  text: We have to take a bold bet. We have to bet that there needs to be a paradigm
    shift in machine learning, and that paradigm shift has to be led by data-driven
    methods.
  topic: strategy
- impact_reason: Illustrates the profound, long-term personal commitment to solving
    scene understanding (captioning), showing the depth of ambition required for major
    AI milestones.
  relevance_score: 9
  source: llm_enhanced
  text: I thought it was a hundred-year dream, which is storytelling of the world...
    I literally, when I graduated as a graduate student, I told myself on my deathbed,
    if I can create an algorithm that can tell the story of a scene, I've succeeded.
  topic: strategy
- impact_reason: A fascinating historical anecdote showing the early conceptualization
    of text-to-image generation (now solved by diffusion models) years before the
    technology made it feasible.
  relevance_score: 9
  source: llm_enhanced
  text: I actually joked with him, I said, 'Hey, Andrej, why don't we do the reverse?
    Take a sentence and generate an image.' And of course, he knew I was joking, and
    he said, 'Haha, I'm out of here.' The world was just not ready.
  topic: predictions/technical
- impact_reason: 'Clearly delineates the three necessary components for the deep learning
    breakthrough: Data (ImageNet), Compute (GPUs), and Algorithms (CNNs).'
  relevance_score: 9
  source: llm_enhanced
  text: 'And it took a while until there were algorithms that were promising. It wasn''t
    until 2012 when AlexNet came out. And that was the second part of the equation
    with getting to AI: was getting the compute and throwing enough at it and algorithms.'
  topic: technical
- impact_reason: 'Articulates the clear progression of computer vision research goals:
    from object recognition (ImageNet) to scene description (storytelling).'
  relevance_score: 9
  source: llm_enhanced
  text: ImageNet was solving the problem of your present, your present with the image,
    and then you call out objects... But ever since I was a graduate student entering
    the field of AI, I had a dream... which is storytelling of the world.
  topic: technical/strategy
- impact_reason: Identifies the pursuit of solving spatial intelligence as the 'hardest
    problem in AI right now,' setting a high bar for the mission of the new venture
    (World Labs).
  relevance_score: 9
  source: llm_enhanced
  text: And we are just going to try to solve, in my opinion, the hardest problem
    in AI right now. Which is incredible talent.
  topic: strategy
- impact_reason: Provides a concise, fundamental distinction between language (1D,
    purely generative signal) and the physical world, justifying why vision/spatial
    AI is harder.
  relevance_score: 9
  source: llm_enhanced
  text: Language is fundamentally 1D, right? Syllables come in sequence... language
    is purely generative. There's no language in nature. You don't touch language,
    you don't see language.
  topic: technical
- impact_reason: Defines the continuum of spatial intelligence models, spanning from
    pure generation (like current generative models) to reconstruction/understanding
    of the real world (physics constraints).
  relevance_score: 9
  source: llm_enhanced
  text: And third, the world is not purely generative. Yes, we could generate virtual
    3D worlds; it still has to obey physics and all that. But there is also a real
    world out there. You are now suddenly dialing between generation and reconstruction
    in a very fluid way.
  topic: technical
- impact_reason: 'Identifies the critical data bottleneck for spatial AI: the lack
    of easily accessible, large-scale, labeled 3D/spatial data compared to the abundance
    of text data.'
  relevance_score: 9
  source: llm_enhanced
  text: And of course, the elephant in the room is, there's a lot of data on the internet
    for language, and where is the data for spatial intelligence? You know, it's all
    in our head, of course, but it's not as easily accessible as language.
  topic: technical/business
- impact_reason: 'Defines the core product vision of World Labs: creating 3D world
    foundation models, analogous to LLMs for text.'
  relevance_score: 9
  source: llm_enhanced
  text: Is it fair to say that what you're building at World Labs is these whole new
    foundation models where the output are 3D worlds?
  topic: business
- impact_reason: A critical observation on the current state of AI research, noting
    the resource disparity (compute/data) between industry and academia.
  relevance_score: 9
  source: llm_enhanced
  text: Academia no longer has most of the AI resources. It's very different from
    my time, right? The compute and the data are really low in terms of resourcing
    academia.
  topic: strategy/business
- impact_reason: 'Specific advice for PhD students: focus research on fundamental
    problems that cannot be solved purely by scaling industry resources.'
  relevance_score: 9
  source: llm_enhanced
  text: As a PhD student, I would recommend you to look for those North Stars that
    are not on the collision course of problems that industry can solve better using
    better compute, better data, and team science.
  topic: strategy
- impact_reason: Identifies a key, high-impact research direction for academia where
    fundamental breakthroughs, rather than sheer compute power, drive progress.
  relevance_score: 9
  source: llm_enhanced
  text: Interdisciplinary AI to me is a really, really exciting area in academia,
    especially for scientific discovery.
  topic: strategy
- impact_reason: Provides a clear, foundational definition of the ultimate goal of
    AI research, linking it directly to human-level (or greater) intelligence.
  relevance_score: 9
  source: llm_enhanced
  text: But fundamentally, I think the size of AI is the size of intelligence, is
    to create machines that can think and do things as intelligently or even more
    intelligently as humans.
  topic: philosophy
- impact_reason: Uses the structure of the human brain as a counter-argument to the
    monolithic vs. multi-agent AGI debate, suggesting complexity and specialization
    exist even in a unified system.
  relevance_score: 9
  source: llm_enhanced
  text: If you look at the brain, it's one thing; you know, you can call it monolithic,
    but it does have different functionalities. And you can even—there's a prefrontal
    cortex for language, there's a visual cortex, there's a motor cortex. And so I
    don't really know how to answer that question [monolithic vs. multi-agent AGI].
  topic: technical/philosophy
- impact_reason: A strong piece of entrepreneurial advice emphasizing focus, resilience,
    and execution over past achievements or external validation.
  relevance_score: 8
  source: llm_enhanced
  text: Forget about what you have done in the past. Forget about what others think
    of you. Just hunker down and build. That is my comfort zone.
  topic: business/strategy
- impact_reason: A fundamental reminder of the core objective in ML, often overshadowed
    by performance metrics on specific benchmarks.
  relevance_score: 8
  source: llm_enhanced
  text: If you're working in machine learning, you have to respect that generalization
    is the core mathematical foundation or goal of machine learning.
  topic: technical
- impact_reason: Highlights the critical strategic decision to open-source ImageNet,
    which accelerated community adoption and subsequent breakthroughs.
  relevance_score: 8
  source: llm_enhanced
  text: We believed from the get-go we have to open-source this to the entire research
    community for everybody to work on this.
  topic: business/strategy
- impact_reason: Describes the bleak state of computer vision/AI research just before
    the data-driven paradigm shift, highlighting the low expectations of the time.
  relevance_score: 8
  source: llm_enhanced
  text: There was very little data. Algorithms, at least in computer vision, did not
    work. There was no industry, as far as the public was concerned, the world AGI
    doesn't exist.
  topic: strategy
- impact_reason: Acknowledges the parallel, explosive growth of LLMs (post-Nov 2022)
    as a major inspiration for pursuing the next frontier (spatial intelligence).
  relevance_score: 8
  source: llm_enhanced
  text: While this is happening in a very exciting way, we also have another extremely
    exciting thread, which is language, which is LLMs, which is that really 2022,
    November, ChatGPT blasted open the door of truly working generation models that
    can basically pass the Turing test and all that.
  topic: AI technology trends
- impact_reason: 'Reveals the speaker''s methodology for identifying breakthrough
    research problems: grounding them in biological and evolutionary precedents.'
  relevance_score: 8
  source: llm_enhanced
  text: I find myself in many moments of my career where I'm looking for the next
    North Star problem to solve. I ask myself, what is what evolution has done or
    what brain development has done?
  topic: strategy
- impact_reason: Highlights the combinatorial complexity inherent in 3D/4D data structures
    compared to sequential data.
  relevance_score: 8
  source: llm_enhanced
  text: The real world is 3D, and if you add time, it's 4D, but just let's just confine
    ourselves within space. It's fundamentally 3D. So that by itself is a much more
    combinatorially harder problem.
  topic: technical
- impact_reason: Suggests that spatial world models may require more structured priors
    or explicit supervision than the brute-force self-supervision successful in LLMs.
  relevance_score: 8
  source: llm_enhanced
  text: Constructive world model might be a little more nuanced. The world is more
    structured. There might be signals that we need to use to guide it. You can call
    it in the shape of a prior; you can call it supervision in your data, whatever
    it is.
  topic: technical
- impact_reason: Outlines the vast potential applications of spatial AI, spanning
    creative industries (design, gaming) and physical interaction (robotics).
  relevance_score: 8
  source: llm_enhanced
  text: The utility of spatial intelligence models or world models is really, really
    big. So, and then there are many, many related industries from creation... all
    the way to robotics, robotic learning.
  topic: predictions/business
- impact_reason: Articulates a strong ethical and human-centered mission guiding the
    speaker's work, contrasting technological progress with human values.
  relevance_score: 8
  source: llm_enhanced
  text: AI became a human problem. Humanity will always advance our technology, but
    we cannot lose our humanity. And I really care about creating a beacon of light
    in the progress of AI and try to imagine how AI can be human-centered, how we
    can create AI to help humanity.
  topic: safety/ethics
- impact_reason: Suggests interdisciplinary AI research as a high-potential area for
    academia, leveraging AI for scientific breakthroughs outside of core commercial
    applications.
  relevance_score: 8
  source: llm_enhanced
  text: First of all, interdisciplinary AI to me is a really, really exciting area
    in academia, especially for scientific discovery.
  topic: strategy
- impact_reason: Suggests that even in mature fields like computer vision, fundamental
    issues like representation learning and small-data regimes remain open research
    questions.
  relevance_score: 8
  source: llm_enhanced
  text: In computer vision, there's still representational problems. We have small
    data. That's another really interesting domain.
  topic: technical
- impact_reason: Frames current 'AGI' progress as a natural, quantitative progression
    of narrow AI capabilities, rather than a qualitative leap to a new paradigm.
  relevance_score: 8
  source: llm_enhanced
  text: If we say today's AGI-ish system performs better than the narrower AI systems
    in the '80s, '70s, '90s, or whatever, I think that's right. That's just the progression
    of the field.
  topic: predictions
- impact_reason: 'Defines the essential, non-negotiable prerequisite for pursuing
    graduate research: overwhelming, self-driven curiosity.'
  relevance_score: 8
  source: llm_enhanced
  text: I really think graduate school is the four or five years where you have burning
    curiosity. You're led by curiosity, and that curiosity is so strong that there's
    no better other place to do it.
  topic: strategy
- impact_reason: Draws a sharp contrast between the motivations driving academic research
    (pure curiosity) versus commercial ventures (commercial goals), offering business
    context.
  relevance_score: 8
  source: llm_enhanced
  text: It's different from a startup because a startup cannot be just led by curiosity.
    Your investors will be mad at you. A startup has a more focused commercial goal,
    and some part of it is curiosity, but it's not just curiosity.
  topic: business
- impact_reason: Provides a specific evolutionary anchor point (540 MYA) for the origin
    of vision and its role as the primary driver of subsequent animal intelligence
    development.
  relevance_score: 7
  source: llm_enhanced
  text: The first trilobite developed a sense of vision underwater 540 million years
    ago. Since then, really vision was the reason that set off this evolutionary arms
    race.
  topic: strategy
- impact_reason: Provides a concrete historical benchmark for early ImageNet challenge
    results, illustrating the massive performance leap achieved by AlexNet.
  relevance_score: 7
  source: llm_enhanced
  text: The performance was in the 30% error rate. It wasn't zero or I mean, it wasn't
    completely random, but it wasn't that great.
  topic: technical
- impact_reason: Offers a specific, lesser-known detail about the winning 2012 entry
    (SuperVision team name), adding historical color to the AlexNet moment.
  relevance_score: 7
  source: llm_enhanced
  text: It was a convolutional neural network—something. It wasn't called AlexNet
    at that time. That team that Jeff Hinton's team was called SuperVision.
  topic: technical
- impact_reason: Highlights the potential of AR/VR (metaphors) as a key future application
    for spatial AI, contingent on future hardware improvements.
  relevance_score: 7
  source: llm_enhanced
  text: I'm actually really, really excited by metaphors. I know so many people are
    kind of still like, 'It's still not working.' I know it's still not working. That's
    why I'm excited because I think the convergence of hardware and software will
    be coming.
  topic: predictions
- impact_reason: 'Offers strategic career advice: sometimes blazing a new trail in
    an unestablished field is necessary, even without established mentorship.'
  relevance_score: 7
  source: llm_enhanced
  text: I chose to go to departments where I was the first computer vision professor,
    and that was against a lot of advice. As a young professor, you should go to a
    place where there is a community and senior mentors. Of course, I would love to
    have senior mentors, but if they're not there, I still have to blaze my trail,
    find my way.
  topic: strategy
- impact_reason: Establishes the speaker's high credibility and status within the
    AGI community.
  relevance_score: 6
  source: llm_enhanced
  text: I'm super excited here to have Dr. Feifei Li. She has such a long career in
    AGI. I'm sure a lot of you know her, right? Raise your hand. I know you too. She's
    been named one of the godmothers of AGI.
  topic: general
- impact_reason: Provides context on the long incubation period of foundational AI
    projects and the speaker's early career commitment.
  relevance_score: 6
  source: llm_enhanced
  text: ImageNet was, yeah, you're right. We actually conceived that almost 18 years
    ago... Time really flies. I was a first-year assistant professor at Princeton.
  topic: technical
- impact_reason: A personal reflection on finding fulfillment in tackling seemingly
    impossible, high-impact problems.
  relevance_score: 6
  source: llm_enhanced
  text: I feel I'm the luckiest person in the world because my entire career is going
    after problems that are just so hard, bordering delusional.
  topic: general
source: Unknown Source
summary: "## Podcast Summary: Fei-Fei Li: Spatial Intelligence is the Next Frontier\
  \ in AI\n\nThis 44-minute episode features Dr. Fei-Fei Li, a foundational figure\
  \ in AI known for creating ImageNet, discussing her career trajectory, the evolution\
  \ of computer vision, and her current focus on **Spatial Intelligence** as the next\
  \ major frontier for achieving Artificial General Intelligence (AGI).\n\nThe conversation\
  \ traces Li’s journey from the early days of AI, emphasizing that AGI requires more\
  \ than just language understanding; it demands a deep comprehension of the 3D world.\
  \ She frames her current venture, **World Labs**, as an attempt to solve this \"\
  delusional\" but necessary problem.\n\n---\n\n1. **Focus Area**: The primary focus\
  \ is the evolution of AI, specifically computer vision, moving from **object recognition\
  \ (ImageNet)** to **scene understanding (image captioning)**, and finally to the\
  \ current pursuit of **Spatial Intelligence** (3D world modeling) as the missing\
  \ piece for AGI. Secondary themes include the entrepreneurial spirit in AI research\
  \ and the importance of intellectual fearlessness.\n\n2. **Key Technical Insights**:\n\
  \    * **ImageNet's Role**: ImageNet (conceived around 2007, breakthrough in 2012\
  \ with AlexNet) proved the paradigm shift toward **data-driven methods** in deep\
  \ learning, combining large datasets, neural networks (CNNs), and GPU compute.\n\
  \    * **Vision vs. Language Difficulty**: Spatial intelligence is argued to be\
  \ fundamentally harder than current LLM research because the real world is **3D\
  \ (or 4D with time)**, visual sensing involves an **ill-posed 3D-to-2D projection**,\
  \ and the data is less readily available/purely generative than language.\n    *\
  \ **World Models**: The next step involves building **foundation models** whose\
  \ output is a coherent, physics-aware **3D world model**, necessary for advanced\
  \ robotics, simulation, and interaction.\n\n3. **Business/Investment Angle**:\n\
  \    * **Spatial Intelligence Market**: The utility of spatial intelligence models\
  \ spans creation (design, architecture, gaming), simulation, and critical applications\
  \ like **robotics and autonomous systems**.\n    * **Entrepreneurial Drive**: Li\
  \ highlights her comfort zone in starting from \"ground zero,\" having successfully\
  \ launched initiatives in academia (HAI), industry (Google), and now a new venture\
  \ (World Labs).\n    * **Hiring Signal**: The key trait sought in talent for World\
  \ Labs is **intellectual fearlessness**—the courage to embrace and commit fully\
  \ to extremely hard, unsolved problems.\n\n4. **Notable Companies/People**:\n  \
  \  * **Dr. Fei-Fei Li**: Central figure, \"Godmother of AGI,\" founder of World\
  \ Labs.\n    * **ImageNet Team**: Mentioned the importance of open-sourcing and\
  \ the ImageNet Challenge.\n    * **AlexNet/SuperVision Team (Alex Krizhevsky, Jeff\
  \ Hinton)**: Credited with the 2012 breakthrough moment.\n    * **Andrej Karpathy\
  \ & Justin Johnson**: Key students involved in the transition to image captioning.\n\
  \    * **World Labs Founding Team**: Justin Johnson, Ben Mildenhall (NeRF author),\
  \ and Christoph Laster (Pulsar/differentiable rendering precursor).\n\n5. **Future\
  \ Implications**: The industry is moving beyond 2D perception and pure language\
  \ generation toward **embodied AI** that understands and reasons about the physical,\
  \ 3D world. AGI, in Li’s view, is contingent upon solving this spatial intelligence\
  \ challenge, which will require new model architectures that move beyond the current\
  \ LLM paradigm.\n\n6. **Target Audience**: **AI/ML Researchers, Deep Learning Engineers,\
  \ Technology Founders, Venture Capitalists, and Executives** interested in the long-term\
  \ roadmap for AGI and the next wave of foundation models beyond LLMs."
tags:
- artificial-intelligence
- startup
- generative-ai
- ai-infrastructure
- google
- nvidia
title: 'Fei-Fei Li: Spatial Intelligence is the Next Frontier in AI'
topics:
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 72
  prominence: 1.0
  topic: artificial intelligence
- keywords:
  - startup
  - entrepreneur
  - founder
  - venture
  mentions: 14
  prominence: 1.0
  topic: startup
- keywords:
  - generative ai
  - genai
  - chatgpt
  - gpt
  - claude
  - text generation
  - image generation
  mentions: 4
  prominence: 0.4
  topic: generative ai
- keywords:
  - gpu
  - tensor
  - training
  - inference
  - model deployment
  - vector database
  mentions: 3
  prominence: 0.3
  topic: ai infrastructure
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-10-05 05:26:29 UTC -->
