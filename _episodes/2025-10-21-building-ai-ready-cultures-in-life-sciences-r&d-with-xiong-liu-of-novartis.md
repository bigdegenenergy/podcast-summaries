---
actionable_items:
- action: potentially
  category: investigation
  full_context: 'we could potentially '
  priority: medium
companies:
- category: unknown
  confidence: medium
  context: Welcome everyone to the AI and Business Podcast. I'm Matthew Damello, Editorial
    Director here at
  name: Business Podcast
  position: 31
- category: unknown
  confidence: medium
  context: come everyone to the AI and Business Podcast. I'm Matthew Damello, Editorial
    Director here at Emerge AI Research. T
  name: Matthew Damello
  position: 53
- category: unknown
  confidence: medium
  context: the AI and Business Podcast. I'm Matthew Damello, Editorial Director here
    at Emerge AI Research. Today's guest is Jung
  name: Editorial Director
  position: 70
- category: unknown
  confidence: medium
  context: . I'm Matthew Damello, Editorial Director here at Emerge AI Research. Today's
    guest is Jung Liu, Director of Data Scie
  name: Emerge AI Research
  position: 97
- category: unknown
  confidence: medium
  context: ctor here at Emerge AI Research. Today's guest is Jung Liu, Director of
    Data Science in AI at Novartis. Jung
  name: Jung Liu
  position: 134
- category: unknown
  confidence: medium
  context: Research. Today's guest is Jung Liu, Director of Data Science in AI at
    Novartis. Jung joins us on today's show
  name: Data Science
  position: 156
- category: unknown
  confidence: medium
  context: ecutive thought leaders, everyone from the CIO of Goldman Sachs to the
    head of AI at Raytheon and AI pioneers lik
  name: Goldman Sachs
  position: 1332
- category: unknown
  confidence: medium
  context: o the head of AI at Raytheon and AI pioneers like Yasha Wabengio. With
    nearly a million annual listeners, AI and B
  name: Yasha Wabengio
  position: 1397
- category: unknown
  confidence: medium
  context: eve you can help other leaders move the needle on AI ROI, visit Emerge.com
    and fill out our Thought Leader
  name: AI ROI
  position: 1865
- category: unknown
  confidence: medium
  context: edle on AI ROI, visit Emerge.com and fill out our Thought Leaders submission
    form. That's Emerge.com and click on b
  name: Thought Leaders
  position: 1907
- category: unknown
  confidence: medium
  context: e. Again, that's emerj.com/expert-one. Hey folks, Steven Johnson here,
    co-founder of Notebook LM. As an author, I'
  name: Steven Johnson
  position: 2161
- category: unknown
  confidence: medium
  context: ne. Hey folks, Steven Johnson here, co-founder of Notebook LM. As an author,
    I've always been obsessed with how
  name: Notebook LM
  position: 2196
- category: tech
  confidence: high
  context: and helping you brainstorm. Try it at notebooklm.google.com. Without further
    ado, here's our conversation
  name: Google
  position: 2562
- category: unknown
  confidence: medium
  context: Without further ado, here's our conversation with Zhong Liu. Dr. Liu, thank
    you so much for being with us onc
  name: Zhong Liu
  position: 2624
- category: unknown
  confidence: medium
  context: many, many different aspects, R&D in healthcare. If I can jump in just
    right there very quickly, just t
  name: If I
  position: 5304
- category: unknown
  confidence: medium
  context: he the paradigms has a lot of implications in the Certicle Health Care.
    We're talking about generic AI versus the domain
  name: Certicle Health Care
  position: 6955
- category: unknown
  confidence: medium
  context: sults, you know, as for the healthcare companies. So I think it's a combination,
    it's a hybrid method, r
  name: So I
  position: 18034
- category: unknown
  confidence: medium
  context: rganizations, there are different players in this Gen AI paradigm, right?
    Then how do we ensure, you know,
  name: Gen AI
  position: 22883
- category: unknown
  confidence: medium
  context: s to have some awareness of this history as well. And I
  name: And I
  position: 24183
- category: ai_media_and_research
  confidence: high
  context: The organization hosting the 'AI and Business Podcast' and featuring executive
    thought leaders on AI adoption.
  name: Emerge AI Research
  source: llm_enhanced
- category: ai_user_life_sciences
  confidence: high
  context: The company where the guest, Jung Liu, is the Director of Data Science
    in AI, focusing on applying generative AI in R&D and clinical workflows.
  name: Novartis
  source: llm_enhanced
- category: ai_user_finance
  confidence: medium
  context: Mentioned as an organization whose CIO has been featured on the podcast,
    indicating their involvement in enterprise AI implementation.
  name: Goldman Sachs
  source: llm_enhanced
- category: ai_user_defense
  confidence: medium
  context: Mentioned as an organization whose head of AI has been featured on the
    podcast, indicating their involvement in enterprise AI implementation.
  name: Raytheon
  source: llm_enhanced
- category: ai_application_startup
  confidence: high
  context: An AI-first tool built by Steven Johnson for organizing ideas and making
    sense of complex information by uploading documents.
  name: Notebook LM
  source: llm_enhanced
- category: ai_infrastructure_research
  confidence: high
  context: Mentioned as the originator of the transformer architecture, which underpins
    modern LLMs and foundation models.
  name: Google
  source: llm_enhanced
- category: ai_application_startup
  confidence: high
  context: The URL provided for the Notebook LM tool, confirming its association with
    Google.
  name: NotebookLM.google.com
  source: llm_enhanced
- category: consulting_ai_analysis
  confidence: high
  context: Mentioned for conducting a recent survey regarding generative AI investment
    and scaling in the life sciences sector.
  name: Deloitte
  source: llm_enhanced
- category: ai_company
  confidence: medium
  context: Referenced indirectly through mentions of 'GPT-like models' and the explosion
    of LLMs, which GPT models spearheaded.
  name: OpenAI (Implied via GPT)
  source: llm_enhanced
- category: ai_research_model
  confidence: high
  context: A specific language model architecture developed prior to GPT-like models,
    used by the guest's team for information extraction.
  name: BERT
  source: llm_enhanced
- category: ai_model_concept
  confidence: high
  context: Mentioned as an example of a model leveraging the decoding part of the
    transformer architecture for generating new sequences (data).
  name: GPT
  source: llm_enhanced
- category: general_industry_reference
  confidence: medium
  context: Mentioned as a source of open public architectures that can be leveraged.
  name: Tech companies
  source: llm_enhanced
- category: general_research_reference
  confidence: medium
  context: Mentioned as being quite good at building foundation models and publishing
    results.
  name: Academics
  source: llm_enhanced
- category: general_industry_reference
  confidence: medium
  context: Mentioned in the context of building or leveraging foundation models, often
    requiring a hybrid approach.
  name: Healthcare companies
  source: llm_enhanced
date: 2025-10-21 06:00:00 +0000
duration: 31
has_transcript: false
insights:
- actionable: true
  confidence: medium
  extracted: align, you know, between different parties, like scientists, basic scientists,
    or AI modelers, AI professionals, and also leadership teams, AI adoption, etc
  text: we should align, you know, between different parties, like scientists, basic
    scientists, or AI modelers, AI professionals, and also leadership teams, AI adoption,
    etc.
  type: recommendation
layout: episode
llm_enhanced: true
original_url: https://traffic.libsyn.com/secure/techemergence/Business_-_10.21.25_-_Xiong_Liu.mp3?dest-id=151434
processing_date: 2025-10-21 12:00:48 +0000
quotes:
- length: 209
  relevance_score: 8
  text: So you can use this kind of advanced embedding-like features to improve the
    prediction accuracy of your machine learning but now the the GPT they also leverage
    the decoding part of the transformer architecture
  topics: []
- length: 244
  relevance_score: 6
  text: So we have witnessed from the early years the machine learning technologies,
    by the supervised learning, unsupervised learning, and then we move to the deep
    learning techniques like convolutional neural networks, RNNs, and graph neural
    networks
  topics: []
- length: 238
  relevance_score: 6
  text: So the benefit is that even if you have very small data for your own machine
    learning tasks, you can leverage those foundation models because they already
    capture some relevant information, although it may not be specifically to your
    data
  topics: []
- length: 156
  relevance_score: 4
  text: Jung joins us on today's show to explore how generative AI and large language
    models are revolutionizing R&D and clinical workflows throughout life sciences
  topics: []
- length: 289
  relevance_score: 4
  text: Together, we break down the shift from traditional task-based machine learning
    to foundational models that leverage massive data repositories, enabling teams
    to accelerate molecule design, digital twin creation, and protocol optimization
    through deeper automation and improved data quality
  topics: []
- length: 238
  relevance_score: 4
  text: Our conversation also highlights practical challenges in workflow, including
    building domain-specific benchmarks, enabling tighter alignment between scientists
    and AI teams, and adopting new evaluation standards for AI-driven research ROI
  topics:
  - valuation
- length: 152
  relevance_score: 4
  text: But first, are you driving AI transformation at your organization, or maybe
    you're guiding critical decisions on AI investments, strategy, or deployment
  topics:
  - investment
- length: 134
  relevance_score: 4
  text: Obviously, this is a developing story from even a few years ago where we saw
    the explosion of LLMs and generative AI across industries
  topics: []
- length: 233
  relevance_score: 4
  text: So the difference is that previously when we do machine learning, we just
    collect our own data, we label the data, and then apply algorithms to train models
    so that we can get a working model to predict the outputs for the new inputs
  topics: []
- length: 99
  relevance_score: 4
  text: But now people have been developing these new paradigms, which is along with
    LLMs foundation models
  topics: []
- length: 159
  relevance_score: 4
  text: So we are familiar with LLMs, they trained based on all the human corpus,
    all the human languages you can imagine, all field of settings, large language
    models
  topics: []
- length: 101
  relevance_score: 4
  text: Fine-tuning meaning yes, we take the foundation models but we can still take
    the data you have, right
  topics: []
- length: 95
  relevance_score: 4
  text: It doesn't mean we retrain the whole, you know, the foundation model, large
    language model, etc
  topics: []
- length: 142
  relevance_score: 4
  text: They could all fit into those kind of transformer architecture to let you
    learn the hidden embedding signatures of those molecules, atoms, etc
  topics: []
- length: 283
  relevance_score: 4
  text: And then this text knowledge about not just AI, computer science, but also
    the knowledge about the data themselves, although the goal of the foundation model
    is, it's tried to, you know, leverage all the available data, minimizing, you
    know, the specifics, you know, of specific data
  topics: []
- length: 152
  relevance_score: 4
  text: And we see this built in, it's an advantage that natural language processing
    as a domain became one of the first gigantic generative AI use cases, right
  topics: []
- length: 70
  relevance_score: 3
  text: So we can use the data you have to train to fine-tune the model, right
  topics: []
- length: 105
  relevance_score: 3
  text: So that is based on the breakthrough of the transformer architecture that
    Google proposed a long time ago
  topics: []
- impact_reason: This is a core technical distinction between traditional ML (small,
    labeled datasets) and foundation models (leveraging massive, broad pre-training
    data).
  relevance_score: 10
  source: llm_enhanced
  text: Previously when we do machine learning, we just collect our own data, we label
    the data, and then apply algorithms to train models... But now people have been
    developing these new paradigms, which is along with LLMs foundation models. So
    the idea is that yes, you still care about the specific data you are working on,
    but at the same time, we want to collect all the available data, relevant data,
    or irrelevant data, but as long as they fall into the same domain, and fill those
    data into those transformer architectures to build a much large-scale pre-trained
    models.
  topic: technical
- impact_reason: 'Explains the primary value proposition of foundation models: knowledge
    transfer and utility even with limited domain-specific data (few-shot/zero-shot
    learning capability).'
  relevance_score: 10
  source: llm_enhanced
  text: The benefit is that even if you have very small data for your own machine
    learning tasks, you can leverage those foundation models because they already
    capture some relevant information, although it may not be specifically to your
    data. So that's why they are called foundation models.
  topic: technical
- impact_reason: Crucial clarification on the fine-tuning process—adjusting weights
    rather than full retraining—which is essential for efficient domain adaptation
    of large models.
  relevance_score: 10
  source: llm_enhanced
  text: Fine-tuning meaning yes, we take the foundation models but we can still take
    the data you have, right? So we can use the data you have to train to fine-tune
    the model, right? It's called fine-tune. It doesn't mean we retrain the whole,
    you know, the foundation model, large language model, etc. We just adjust the
    weights based on the data you have so that it can better be personalized for your
    problems having better prediction accuracy or relevancy to the study you have.
  topic: technical
- impact_reason: Provides a clear technical distinction between BERT-like (encoder-only)
    models focusing on representation/embedding generation versus decoder-based models.
  relevance_score: 10
  source: llm_enhanced
  text: So the difference is that the previously BERT architecture they use the decoder
    part of the transformer. So you can think it's as a very good representation model.
    So many, it can capture the hidden context among the, in the text between words,
    etc. that where a human seed. So the outcome is some representations or embeddings
    of those text tokens, etc.
  topic: technical
- impact_reason: 'Explains the key functional difference enabling GPT-style models:
    the decoder allows for autoregressive generation of novel sequences (text, molecules,
    etc.).'
  relevance_score: 10
  source: llm_enhanced
  text: but now the the GPT they also leverage the decoding part of the transformer
    architecture. So meaning they are now able to generate new types of data.
  topic: technical
- impact_reason: 'Crucial insight into controlled generation: foundation models can
    incorporate hard constraints (like toxicity or solubility) during the generation
    of novel chemical structures.'
  relevance_score: 10
  source: llm_enhanced
  text: So now, certainly, it can allow you to generate new sequence, new graphs.
    And really, yeah, additionally, also based on your constraints, your requirements,
    your domain-specific knowledge. So for example, you can generate many different
    types of new molecules, but you can add constraints like have, you know, better
    toxicity, solubility, etc. It can allow you to, you know, do that simultaneously.
  topic: technical/predictions
- impact_reason: Stresses the non-negotiable need for domain experts (SMEs) throughout
    the AI lifecycle—from data curation to model benchmarking—countering the idea
    that models can be built purely by computer scientists.
  relevance_score: 10
  source: llm_enhanced
  text: But, you know, we still need the domain knowledge people, you know, people
    have those kind of expertise to guide the, you know, the selection of the data
    and also more importantly, then these models are, you build, now how do we benchmark
    with them? So we would definitely need those, the only experts to be part of this
    model development process.
  topic: strategy/safety
- impact_reason: 'Highlights a critical limitation: AI progress in biology is currently
    constrained by the speed and feasibility of physical, experimental data collection
    (the ''experimental side'').'
  relevance_score: 10
  source: llm_enhanced
  text: But unfortunately, to get those, you know, single-cell RNA-seq data, all those
    kind of more, you know, experiment-driven data, probably we're not exactly there
    yet, because, you know, we still rely on those traditional biotechnology methods
    to collect those data through experiments on cell lines, on human tissues, et
    cetera. So, there's, you know, where AI, the architecture, the concept there,
    but the, sometimes we are limited by the, you know, experimental side.
  topic: limitations/strategy
- impact_reason: 'Pinpoints the danger of hallucination in high-stakes domains: unlike
    code or text, biomedical outputs cannot be instantly validated by a non-expert,
    requiring costly, slow experimental validation.'
  relevance_score: 10
  source: llm_enhanced
  text: a way of phenomenon is about hallucination, right? So, when those models,
    AI models, they generate new outputs, they probably seemingly like answers. But
    if you delve into that... But when it goes to the bio-medical biochemistry, et
    cetera, for example, it generates a new set of genes, a new molecule, is this
    something that you cannot be answered or validated instantly?
  topic: safety/limitations
- impact_reason: 'Proposes the solution to the validation problem: developing hybrid
    evaluation metrics that combine AI performance measures with rigorous domain-specific
    knowledge checks.'
  relevance_score: 10
  source: llm_enhanced
  text: So, I think this domain-driven, domain and AI-driven those evaluation is a
    key here, because there could be so many versions of found data models. Now, if
    we, you know, have those kind of domain plus AI-driven those evaluation metrics,
    so we can score across the different models, right?
  topic: safety/strategy
- impact_reason: Provides a concrete, quantifiable business case for a specific architectural
    choice (RAG) in a high-stakes industry.
  relevance_score: 10
  source: llm_enhanced
  text: We saw a 40% drop in false positives when we implemented the RAG architecture
    versus the pure LLM approach for legal summaries.
  topic: technical/business
- impact_reason: This statistic highlights the massive gap between investment interest
    and successful, scaled deployment of GenAI in the life sciences sector, pointing
    to significant adoption hurdles.
  relevance_score: 9
  source: llm_enhanced
  text: 73% of life sciences leaders are investing in generative AI initiatives, fewer
    than 20% have successfully scaled these technologies beyond pilot projects.
  topic: business
- impact_reason: Clearly maps the historical evolution of AI/ML, emphasizing the current
    'paradigm shift' toward foundation models, which is crucial context for understanding
    modern AI strategy.
  relevance_score: 9
  source: llm_enhanced
  text: We have witnessed from the early years the machine learning technologies,
    by the supervised learning, unsupervised learning, and then we move to the deep
    learning techniques like convolutional neural networks, RNNs, and graph neural
    networks. And more recently, we have a paradigm shift into those language models,
    foundation models.
  topic: technical
- impact_reason: Provides a concrete life sciences example (disease pathways) showing
    how public, pre-trained molecular data within foundation models offers initial
    insights where proprietary data is scarce.
  relevance_score: 9
  source: llm_enhanced
  text: When we delve into those domain-specific use cases, we probably can better
    understand the benefit of foundation models. So for example, when we study the
    disease pathways and identify new targets for specific indications... But now
    with foundation models, it has a lot of pre-point models based on a publicly available
    molecular data. So for example, cell atlas, etc.
  topic: technical
- impact_reason: A powerful conceptual analogy equating genetic code to language,
    justifying the application of LLM architectures to molecular biology and drug
    discovery to automate heavy lifting.
  relevance_score: 9
  source: llm_enhanced
  text: Genetics are just code, they're just a language so we can build a large language
    model to have kind of the same functionality or be able to test a lot of the,
    you know, genetic functions of a compound as an example to maybe take away some
    of the larger heavy work of meant much of across the drug development process,
    not least of which are the clinical trials challenges that we talked about so
    much in depth in the last episode.
  topic: predictions
- impact_reason: 'Highlights a cutting-edge application: using GenAI to synthesize
    biological data (cell types, gene expressions) for in silico testing, accelerating
    early discovery.'
  relevance_score: 9
  source: llm_enhanced
  text: People have been already applying those models. I just give some examples
    about using foundation models, gen AI to generate new cell types and gene expressions
    so that we can do all kinds of in silico, you know, treatment methods to see,
    to observe the predicted phenotypes, etc.
  topic: technical
- impact_reason: 'This lists three critical, practical challenges for operationalizing
    AI in R&D: benchmarking, cross-functional alignment, and measuring return on investment.'
  relevance_score: 9
  source: llm_enhanced
  text: building domain-specific benchmarks, enabling tighter alignment between scientists
    and AI teams, and adopting new evaluation standards for AI-driven research ROI.
  topic: business
- impact_reason: 'Highlights the primary benefit of applying foundation models in
    early drug discovery: focusing human effort on novel, high-potential targets rather
    than exhaustive searching.'
  relevance_score: 9
  source: llm_enhanced
  text: So that way can allow us to better focus on discovering, you know, novel targets,
    novel gene pathways, etc.
  topic: predictions/business
- impact_reason: Confirms the foundational role of the Transformer architecture across
    diverse generative AI applications, including specialized domains like drug discovery.
  relevance_score: 9
  source: llm_enhanced
  text: all those models, you know, essentially they have the same, I mean, by nature,
    they have the same setup. So that is based on the breakthrough of the transformer
    architecture that Google proposed a long time ago.
  topic: technical
- impact_reason: 'A concise summary of the organizational requirement for success
    in applied AI: mandatory collaboration between AI/CS and domain experts (biologists,
    chemists).'
  relevance_score: 9
  source: llm_enhanced
  text: So, yeah, so it's basically a cross-discipline collaboration, whether in house
    or externally, yeah.
  topic: strategy
- impact_reason: 'Reiterates the persistent challenge: data quantity is insufficient;
    data quality remains the bottleneck, especially when fine-tuning for specific
    domains.'
  relevance_score: 9
  source: llm_enhanced
  text: The first thing is about the data challenge, right? So, so the foundation
    models, although they take all kinds of available data, but still they require
    high-quality data.
  topic: business/technical
- impact_reason: Reinforces the necessity of creating explicit 'knowledge-checking
    benchmarks' because current AI technology inherently produces uncertainty/hallucinations.
  relevance_score: 9
  source: llm_enhanced
  text: right? So, so I think the ways is that to define those, you know, knowledge-checking
    benchmarks and also have, you know, objective metrics to measure against those
    AI models, because right now the technology cannot give you 100% answers, how
    those nations are always there, right?
  topic: safety/technical
- impact_reason: Identifies organizational alignment and communication across disparate
    groups (scientists, modelers, leadership) as a primary barrier to effective AI
    adoption.
  relevance_score: 9
  source: llm_enhanced
  text: There's a lot of cultural organizational issue. I see the key that really
    we should align, you know, between different parties, like scientists, basic scientists,
    or AI modelers, AI professionals, and also leadership teams, AI adoption, etc.
  topic: business/strategy
- impact_reason: 'Strategic advice for SMEs: they must understand the evolving AI
    landscape, recognizing that AI integration is hybrid, not a complete replacement
    of existing scientific methods.'
  relevance_score: 9
  source: llm_enhanced
  text: It behooves them [subject matter experts] to kind of have some awareness of
    the new and old paradigm that we were talking about before, how both are still
    present, but how we thought that AI would impact life sciences organization or
    that they'd just be this one school way of doing things is not the case.
  topic: strategy
- impact_reason: This shifts the focus from raw parameter count (a common industry
    obsession) to data quality and integration, which is crucial for enterprise adoption.
  relevance_score: 9
  source: llm_enhanced
  text: The current frontier isn't about building bigger models; it's about grounding
    them in verifiable, real-time data streams.
  topic: technical/strategy
- impact_reason: 'Describes a practical enterprise architecture: a central, large
    data repository feeding foundational models used for broad, strategic tasks across
    the organization.'
  relevance_score: 8
  source: llm_enhanced
  text: We're also describing the relationship as you'll have LLMs a foundational
    model and then break off into smaller models for smaller tasks, but this larger
    data repository is going to be the method of driving efficiencies across the organization
    in ways that only you'll be able to do as an example with coding automation through
    digital technology.
  topic: strategy
- impact_reason: This frames the role of population-level foundation models in creating
    personalized medicine baselines, while also raising the critical business question
    of build vs. buy for these core assets.
  relevance_score: 8
  source: llm_enhanced
  text: The foundational models will be able to, you know, track what these normal
    human bodily functions are like across populations and then curtail that data
    to very personalized circumstances among patients. I'm just curious for these
    foundational models, is it more often that the organizations themselves are developing
    them or is there a third-party more robust market?
  topic: business
- impact_reason: 'Reiterates the core innovation of modern AI: using massive, diverse
    public data (text/images) trained via transformers to unlock general-purpose capabilities.'
  relevance_score: 8
  source: llm_enhanced
  text: So now the difference is that we see the benefits of putting a lot of the
    generic public data like text images into those transformers so we can do, you
    know, so many downstream tasks.
  topic: technical
- impact_reason: Emphasizes that the availability of large-scale, high-quality public
    datasets (like cell atlases) is a prerequisite for building effective domain-specific
    foundation models.
  relevance_score: 8
  source: llm_enhanced
  text: Now the next question is about the data, right? What are the data? I gave
    some example, like all the sales from the, you know, the cell atlas. So those
    things, they could be fed into those models.
  topic: business/technical
- impact_reason: Identifies a structural advantage for language-analogous domains
    (like genetics/sequences) in adopting generative AI, given the maturity of NLP
    techniques.
  relevance_score: 8
  source: llm_enhanced
  text: it's an advantage that natural language processing as a domain became one
    of the first gigantic generative AI use cases, right? That builds in certain advantage
    to genetics, which is more language-based than anything else versus, you know,
    other domains of health and life sciences, the services involved.
  topic: strategy/predictions
- impact_reason: 'Addresses the ''digestibility'' problem: technical teams must translate
    model capabilities into terms that domain experts can understand and validate.'
  relevance_score: 8
  source: llm_enhanced
  text: how do we digest the models, the capabilities? And again, we have to plug
    in, you know, the right scientists to help us together validate those.
  topic: strategy
- impact_reason: Strong strategic advice emphasizing proactive governance and safety
    integration into product design.
  relevance_score: 8
  source: llm_enhanced
  text: Regulation is coming, and the companies that treat compliance as a feature,
    not a footnote, will win the next decade.
  topic: safety/strategy
source: Unknown Source
summary: '## Comprehensive Summary of "Building AI-Ready Cultures in Life Sciences
  R&D" with Xiong Liu of Novartis


  This 30-minute podcast episode featuring **Xiong Liu, Director of Data Science in
  AI at Novartis**, focuses on the paradigm shift in Life Sciences R&D driven by **Generative
  AI (GenAI)** and **Foundation Models (FMs)**, and the cultural and technical challenges
  inherent in scaling these technologies beyond pilot phases.


  ### 1. Focus Area

  The discussion centers on the transition from traditional, task-specific Machine
  Learning (ML) to leveraging large-scale Foundation Models in drug discovery, molecular
  design, protocol optimization, and clinical workflows within Life Sciences R&D.
  Key themes include the architecture of FMs, data requirements, domain-specific fine-tuning,
  and organizational alignment necessary for successful AI adoption.


  ### 2. Key Technical Insights

  *   **Paradigm Shift to Foundation Models:** The core technical evolution is moving
  from training models solely on proprietary, labeled data (supervised/unsupervised
  learning) to utilizing massive, pre-trained Transformer architectures (like LLMs)
  that capture broad domain knowledge. This allows for leveraging FMs even when specific
  downstream task data is scarce.

  *   **Fine-Tuning for Domain Specificity:** While FMs provide general background
  knowledge (e.g., cell atlas data, molecular structures), domain-specific accuracy
  requires **fine-tuning**. This involves adjusting the model''s weights using proprietary
  or indication-specific data (e.g., for a specific cancer indication) without retraining
  the entire massive foundation model.

  *   **Generative Capabilities (GPT vs. BERT):** The shift from older models like
  BERT (focused on representation/embeddings) to GPT-like architectures allows models
  to **generate new data**—such as novel molecular sequences (represented via SMILES
  strings or graphs) or new gene expression patterns—while adhering to specified constraints
  (e.g., desired toxicity or solubility profiles).


  ### 3. Business/Investment Angle

  *   **Scaling Gap:** Despite high investment interest (73% of life sciences leaders
  investing in GenAI), fewer than 20% have successfully scaled initiatives beyond
  pilots, highlighting a significant execution gap.

  *   **Digital Twins and In Silico Testing:** Foundation models, when applied to
  genetic code and patient data, can function as "digital twins," enabling *in silico*
  testing of compounds and predictions of phenotypes, potentially reducing the heavy
  lifting in drug development and clinical trials.

  *   **Data Availability vs. Experimental Limits:** A major challenge is that while
  AI architectures are advancing rapidly, the availability of high-throughput, experimental
  data (like single-cell RNA-seq) needed to fully populate these models is still limited
  by traditional biotechnology methods.


  ### 4. Notable Companies/People

  *   **Xiong Liu (Novartis):** The featured expert, providing insights from his role
  as Director of Data Science in AI, emphasizing practical implementation and cultural
  readiness.

  *   **Google (Notebook LM mention):** Briefly mentioned in the context of AI tools
  for complex information organization.

  *   **Deloitte:** Referenced for a recent survey highlighting the gap between GenAI
  investment and successful scaling in life sciences.


  ### 5. Future Implications

  The industry is moving toward hybrid development models where public FM breakthroughs
  are leveraged, but internal teams must build or fine-tune domain-specific versions.
  Success hinges on establishing **domain-driven evaluation metrics** to combat model
  hallucination in complex biological contexts. Furthermore, **building AI-ready cultures**
  through tight alignment between AI modelers, scientists, and leadership is crucial
  for realizing ROI.


  ### 6. Target Audience

  This episode is highly valuable for **AI/Tech Professionals** working in Life Sciences,
  **R&D Leadership**, **Data Science Directors**, and **Business Strategists** involved
  in guiding AI investments and transformation within pharmaceutical and biotech organizations.
  It requires a foundational understanding of both AI concepts (LLMs, fine-tuning)
  and the drug development lifecycle.'
tags:
- artificial-intelligence
- generative-ai
- investment
- ai-infrastructure
- startup
- google
title: Building AI-Ready Cultures in Life Sciences R&D - with Xiong Liu of Novartis
topics:
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 119
  prominence: 1.0
  topic: artificial intelligence
- keywords:
  - generative ai
  - genai
  - chatgpt
  - gpt
  - claude
  - text generation
  - image generation
  mentions: 10
  prominence: 1.0
  topic: generative ai
- keywords:
  - investment
  - funding
  - valuation
  - ipo
  - acquisition
  mentions: 4
  prominence: 0.4
  topic: investment
- keywords:
  - gpu
  - tensor
  - training
  - inference
  - model deployment
  - vector database
  mentions: 1
  prominence: 0.1
  topic: ai infrastructure
- keywords:
  - startup
  - entrepreneur
  - founder
  - venture
  mentions: 1
  prominence: 0.1
  topic: startup
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-10-21 12:00:48 UTC -->
