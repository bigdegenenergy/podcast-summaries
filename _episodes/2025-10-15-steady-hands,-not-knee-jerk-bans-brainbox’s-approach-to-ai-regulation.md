---
companies:
- category: unknown
  confidence: medium
  context: degrees, your weekly dive into the issues shaping New Zealand's digital
    future. I'm Peter Griffin, and today's
  name: New Zealand
  position: 95
- category: unknown
  confidence: medium
  context: issues shaping New Zealand's digital future. I'm Peter Griffin, and today's
    episode tackles the big debate in te
  name: Peter Griffin
  position: 129
- category: unknown
  confidence: medium
  context: e regulate artificial intelligence? I'm joined by Tom Barraclough, tech
    policy expert and co-founder of the Brainbo
  name: Tom Barraclough
  position: 288
- category: unknown
  confidence: medium
  context: aclough, tech policy expert and co-founder of the Brainbox Institute, who's
    been at the forefront of local and global
  name: Brainbox Institute
  position: 346
- category: unknown
  confidence: medium
  context: ust patchwork of legislation, everything from the Privacy Act to the Crimes
    Act, that's more than capable of ha
  name: Privacy Act
  position: 685
- category: unknown
  confidence: medium
  context: gislation, everything from the Privacy Act to the Crimes Act, that's more
    than capable of handling the challen
  name: Crimes Act
  position: 704
- category: unknown
  confidence: medium
  context: on, for example, where with the Department of the Prime Minister and Cabinet,
    I led a global multi-state coalition
  name: Prime Minister
  position: 3182
- category: unknown
  confidence: medium
  context: sparency, particularly in a social media context. And I've also really
    leaned into this topic of how to t
  name: And I
  position: 3327
- category: unknown
  confidence: medium
  context: tively, and that's through another company called Sunkipate Lab. Yeah,
    it's great work that you've been doing in
  name: Sunkipate Lab
  position: 3657
- category: unknown
  confidence: medium
  context: lot of this stuff used to be done a little bit by Internet New Zealand;
    they had a really good policy arm that sort of f
  name: Internet New Zealand
  position: 3904
- category: unknown
  confidence: medium
  context: e got the EU having legislation in place now, the AI Act. What's your take
    on where it's all going at the
  name: AI Act
  position: 4816
- category: unknown
  confidence: medium
  context: g artificial intelligence, and that is really the European Union approach,
    and it's not just the AI Act. It's also
  name: European Union
  position: 5080
- category: unknown
  confidence: medium
  context: done with the open letter under the leadership of Lenson McGavin and Chris
    and Andrew there is fantastic because i
  name: Lenson McGavin
  position: 10721
- category: unknown
  confidence: medium
  context: a slightly heavier touch. If you look through the Responsible AI Guidance
    for Businesses that accompanies the AI strategy,
  name: Responsible AI Guidance
  position: 13335
- category: unknown
  confidence: medium
  context: biometric code that came out of the Office of the Privacy Commissioner.
    It was quite a thorough process. There was a tri
  name: Privacy Commissioner
  position: 14800
- category: unknown
  confidence: medium
  context: thorough process. There was a trial running with Foodstuffs North Island
    at the same time, which actually gave some real-l
  name: Foodstuffs North Island
  position: 14886
- category: unknown
  confidence: medium
  context: . There's an argument that that is covered by the Harmful Digital Communications
    Act and the Crimes Act. Unfortunately, Parliament has
  name: Harmful Digital Communications Act
  position: 18502
- category: unknown
  confidence: medium
  context: t, and that will potentially be a case before the Human Rights Act, so
    that's applicable to that. We've got privacy,
  name: Human Rights Act
  position: 19067
- category: unknown
  confidence: medium
  context: yright legislation in New Zealand, quite a strong Copyright Act. So, technically,
    if you wanted to chase OpenAI u
  name: Copyright Act
  position: 19984
- category: tech
  confidence: high
  context: ight Act. So, technically, if you wanted to chase OpenAI under New Zealand
    copyright law, you could take t
  name: Openai
  position: 20039
- category: tech
  confidence: high
  context: that. The information issue is that we can go and replicate that, or we
    can basically share the results of th
  name: Replicate
  position: 21185
- category: tech
  confidence: high
  context: has thought to themselves, "I really want to sue Anthropic or OpenAI about
    this," has not gone to their loca
  name: Anthropic
  position: 21472
- category: unknown
  confidence: medium
  context: rives this discussion and approach to regulation. What I've found over
    the years, anything tech-related, p
  name: What I
  position: 22457
- category: unknown
  confidence: medium
  context: for soft power, as such. Then you get the rest of New Zealand Inc., which
    only if it really affects their business—
  name: New Zealand Inc
  position: 22891
- category: unknown
  confidence: medium
  context: soft power, as such. Then you get the rest of New Zealand Inc., which only
    if it really affects their business—
  name: Zealand Inc
  position: 22895
- category: unknown
  confidence: medium
  context: as we speak, one of the big ones in New Zealand, IT Professionals, has
    just gone bust, gone into liquidation, an or
  name: IT Professionals
  position: 23465
- category: unknown
  confidence: medium
  context: of the members of our steering group was from the Carnegie Endowment for
    International Peace, founded by Andrew Carneg
  name: Carnegie Endowment
  position: 24251
- category: unknown
  confidence: medium
  context: teering group was from the Carnegie Endowment for International Peace,
    founded by Andrew Carnegie, the Elon Musk of his
  name: International Peace
  position: 24274
- category: unknown
  confidence: medium
  context: gie Endowment for International Peace, founded by Andrew Carnegie, the
    Elon Musk of his time, with just an enormous
  name: Andrew Carnegie
  position: 24306
- category: unknown
  confidence: medium
  context: ernational Peace, founded by Andrew Carnegie, the Elon Musk of his time,
    with just an enormous endowment just
  name: Elon Musk
  position: 24327
- category: unknown
  confidence: medium
  context: amazing to kind of walk down think tank alley in Washington D.C. and go
    to the Brookings Institution and stuff
  name: Washington D
  position: 24501
- category: unknown
  confidence: medium
  context: think tank alley in Washington D.C. and go to the Brookings Institution
    and stuff like that. So, I've thought about this
  name: Brookings Institution
  position: 24531
- category: unknown
  confidence: medium
  context: trying to do at Brainbox with my co-director, Dr. Ellen Strickland, who
    was at Internet New Zealand for a long time
  name: Ellen Strickland
  position: 26072
- category: unknown
  confidence: medium
  context: different groups. We've had some funding from the Internet Society Foundation
    internationally to do that. So, it's a really coo
  name: Internet Society Foundation
  position: 26460
- category: unknown
  confidence: medium
  context: a nation, and what should it be for New Zealand? The US, as I said at the
    start, they want to have suprem
  name: The US
  position: 27206
- category: unknown
  confidence: medium
  context: tional security issue. That's why Trump is in the White House every second
    week with Oracle and OpenAI, 500 bil
  name: White House
  position: 27373
- category: unknown
  confidence: medium
  context: nd I saw, really, this is kind of a free plug for Straker AI, a pretty
    amazing New Zealand company who I think
  name: Straker AI
  position: 30366
- category: tech
  confidence: high
  context: or billing software, whatever it was. So, we are adept at taking those
    existing technologies that billio
  name: Adept
  position: 32038
- category: unknown
  confidence: medium
  context: more about this than me, I keep reading about the Knowledge Wave conference
    back in 2001, I think it was. And I as
  name: Knowledge Wave
  position: 32299
- category: ai_research
  confidence: high
  context: Tech policy expert Tom Barraclough's think tank and consultancy focused
    on tech policy, including AI regulation and deepfakes.
  name: Brainbox Institute
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: A company established by Tom Barraclough focused on building tools for
    policy work, specifically turning law/regulation into code instruction data.
  name: Sunkipate Lab
  source: llm_enhanced
- category: ai_research
  confidence: medium
  context: Mentioned as an organization that previously had a good policy arm relevant
    to the current AI policy discussion landscape, which has since faded.
  name: Internet New Zealand
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: Mentioned in the context of producing the 'biometric code,' a potential
    model for AI regulation codes of practice.
  name: Office of the Privacy Commissioner
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: Mentioned as a company that ran a trial using facial recognition technology,
    providing real-life data for regulatory consideration.
  name: Foodstuffs North Island
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned in the context of copyright litigation risk under New Zealand
    law and as a major player whose material has been scraped.
  name: OpenAI
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as a company that copyright holders might consider suing under
    New Zealand law.
  name: Anthropic
  source: llm_enhanced
- category: ai_infrastructure
  confidence: medium
  context: Mentioned in relation to US investment in AI acceleration alongside Trump.
  name: Oracle
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: A New Zealand company proposed to offer fine-tuned models as a service.
  name: Straker AI
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: The organization established by one of the speakers in 2018, focused on
    international tech policy and filling the non-industry/non-government/non-academic
    voice space.
  name: Brainbox
  source: llm_enhanced
- category: ai_research
  confidence: medium
  context: Mentioned as an example of a well-endowed international think tank.
  name: Carnegie Endowment for International Peace
  source: llm_enhanced
- category: ai_research
  confidence: medium
  context: Mentioned as an example of a think tank in Washington D.C.
  name: Brookings Institution
  source: llm_enhanced
- category: ai_research
  confidence: medium
  context: Provided funding for Brainbox's project on internet resilience.
  name: Internet Society Foundation
  source: llm_enhanced
date: 2025-10-15 16:43:00 +0000
duration: 38
has_transcript: false
layout: episode
llm_enhanced: true
original_url: https://audio.listennotes.com/e/p/d974ec2b837b4075b8ac6f0dda31a3e2/
processing_date: 2025-10-16 10:16:27 +0000
quotes:
- length: 147
  relevance_score: 3
  text: 'I''m Peter Griffin, and today''s episode tackles the big debate in tech policy
    at the moment: how and when should we regulate artificial intelligence'
  topics: []
- length: 207
  relevance_score: 3
  text: I'm joined by Tom Barraclough, tech policy expert and co-founder of the Brainbox
    Institute, who's been at the forefront of local and global discussions about how
    we manage the rise of artificial intelligence
  topics: []
- length: 209
  relevance_score: 3
  text: So, something that is sort of at the interface of government, research, business,
    and what actually is working is great, and particularly for artificial intelligence,
    which you've been increasingly focusing on
  topics: []
- length: 253
  relevance_score: 3
  text: My top-line take would be, and I think this is really relevant for local discussions,
    even if you take kind of the most strident approach to regulating artificial intelligence,
    and that is really the European Union approach, and it's not just the AI Act
  topics: []
- length: 227
  relevance_score: 3
  text: Obviously, the academics that work in and around artificial intelligence came
    out a couple of months ago quite stridently in an open letter to the Prime Minister
    and the Minister of Technology saying, "You need to regulate this
  topics: []
- length: 127
  relevance_score: 3
  text: That's why Trump is in the White House every second week with Oracle and OpenAI,
    500 billion investment here, 600 billion there
  topics:
  - investment
- impact_reason: 'Highlights the key bottleneck in AI governance: implementation and
    coordination across existing laws, rather than legislative creation.'
  relevance_score: 10
  source: llm_enhanced
  text: He argues what we're missing isn't more laws, but the coordination and practical
    understanding to apply them effectively.
  topic: strategy/regulation
- impact_reason: 'Highlights a critical gap in current governance: the ease of deploying
    low-barrier AI applications without mandatory pre-deployment risk assessment.'
  relevance_score: 10
  source: llm_enhanced
  text: But anyone could launch a chatbot tomorrow, and there's no risk assessment
    of it. Is that going to be governed by any piece of legislation?
  topic: safety/regulation
- impact_reason: This is a direct critique of the gap between stated policy intent
    (risk-based approach) and current enforcement reality for low-threshold AI deployment.
  relevance_score: 10
  source: llm_enhanced
  text: If someone wants to launch a chatbot in New Zealand, our government has said,
    'We want a light-touch, proportional, and risk-based system.' But anyone could
    launch a chatbot tomorrow, and there's no risk assessment of it.
  topic: regulation/safety
- impact_reason: 'Identifies the three core systemic barriers to effective policy
    engagement and analysis regarding emerging tech: Information, Coordination, and
    Economics (resource scarcity). Highly relevant for advocacy groups.'
  relevance_score: 10
  source: llm_enhanced
  text: The information problem. If you can't coordinate and work more effectively
    with others, that's the coordination problem. And then today, I've just shared
    another one on what I'm calling the economic problem, which is effectively it
    takes time and energy to do this. It's pretty hard to do it for free.
  topic: strategy
- impact_reason: Offers specific examples where existing criminal law (fraud, non-consensual
    imagery) may already cover harms caused by generative AI like deepfakes, countering
    the narrative that these are entirely new legal vacuums.
  relevance_score: 10
  source: llm_enhanced
  text: fraud through deepfakes is already a criminal offense. The other example of
    this is non-consensual sexual imagery as well. There's an argument that that is
    covered by the Harmful Digital Communications Act and the Crimes Act.
  topic: safety/predictions
- impact_reason: Identifies the critical marginalization of under-resourced civil
    society groups in tech policy discussions, leading to an unbalanced regulatory
    debate dominated by industry and government/academia.
  relevance_score: 10
  source: llm_enhanced
  text: But the ones that are really left out are civil society and those groups that
    are really poorly resourced... my concern is that we're going to miss increasingly
    in this discussion really important dialogue with the public and researchers who
    work on behalf of the public.
  topic: safety/strategy
- impact_reason: Signals a significant shift in perception regarding AI's importance,
    moving from optional to 'critically important,' and highlights the need for national
    strategic alignment.
  relevance_score: 10
  source: llm_enhanced
  text: What I do think we are missing is a single coordinating vision for what New
    Zealand needs from AI. I think there is recognition that it's very, very important,
    and I think in fact it is important. Probably if you'd asked me maybe even a year
    ago, I would have been on the fence about that, but I'm not now. I think it's
    critically important.
  topic: Strategy/Predictions
- impact_reason: Provides a pragmatic definition of 'Sovereign AI,' shifting focus
    from building proprietary foundational models to ensuring infrastructure, literacy,
    and access.
  relevance_score: 10
  source: llm_enhanced
  text: this isn't about having like NZGPT that's trained on all the data in New Zealand
    and speaks with a Kiwi accent and all that kind of thing. It can be as simple
    as talking about meaningful AI literacy, or it could be as simple as making sure
    that we do have resilient digital infrastructure for access and deployment of
    AI systems.
  topic: Technical/Strategy
- impact_reason: Emphasizes the critical importance of MLOps, validation, reliability,
    and security layers *on top* of powerful base models.
  relevance_score: 10
  source: llm_enhanced
  text: they're only as good as your systems for making sure that what they're doing
    is good and reliable and not a hallucination and takes into account all the data
    that it needs to, and that all the code that it's produced can actually be tested
    for security purposes and works.
  topic: Technical/Safety
- impact_reason: This is a core argument against immediate, bespoke AI regulation,
    suggesting existing legal frameworks (like Privacy Act, Crimes Act) are sufficient,
    shifting the focus to enforcement and coordination.
  relevance_score: 9
  source: llm_enhanced
  text: He points out that we already have a robust patchwork of legislation, everything
    from the Privacy Act to the Crimes Act, that's more than capable of handling the
    challenges AI brings.
  topic: strategy/regulation
- impact_reason: Offers a positive, actionable strategic vision for a smaller nation
    in the AI race, focusing on human capital and reliability rather than just technology
    creation.
  relevance_score: 9
  source: llm_enhanced
  text: 'New Zealand''s potential competitive advantage with AI: the ability to be
    the world''s smartest, most reliable employers of AI systems, if we focus on capability,
    digital literacy, and a coordinated national vision for AI.'
  topic: business/strategy
- impact_reason: A highly technical and forward-looking insight into bridging the
    gap between legal requirements and computational implementation (RegTech/LegalTech).
  relevance_score: 9
  source: llm_enhanced
  text: I've also really leaned into this topic of how to turn law and regulation
    into code instruction data.
  topic: technical/regulation
- impact_reason: Demystifies major regulatory efforts like the EU AI Act, noting that
    high-level laws require extensive secondary instruments (delegated acts, guidance)
    to become operational.
  relevance_score: 9
  source: llm_enhanced
  text: even if you take kind of the most strident approach to regulating artificial
    intelligence, and that is really the European Union approach... what you find
    is the top-level legislation can be quite general.
  topic: regulation
- impact_reason: Clearly lists the core high-stakes risks associated with current
    AI deployment that existing laws must address.
  relevance_score: 9
  source: llm_enhanced
  text: We have issues already around algorithmic bias in AI systems, the potential
    for mass surveillance, autonomous decision-making in critical services. So, does
    our legislation deal with that sort of thing?
  topic: safety/ethics
- impact_reason: A crucial reminder that regulation is evolutionary, built upon existing
    statutes and requiring long implementation cycles.
  relevance_score: 9
  source: llm_enhanced
  text: It's not a binary exercise for all of this. It's not like we're just going
    to say, 'Let's regulate AI,' and then tomorrow AI will be regulated from a starting
    point.
  topic: strategy/regulation
- impact_reason: Highlights the need for established, informed civil society capability
    to temper reactive, populist regulatory responses to new technologies like AI.
  relevance_score: 9
  source: llm_enhanced
  text: we want to have this base level of capability so when there is this kind of
    really populist swell to do something, what somebody does something, that we've
    got a handbrake on that where we can at least have an informed discussion about
    it.
  topic: safety/strategy
- impact_reason: Provides a concrete, actionable insight that existing legislation
    already impacts AI deployment, challenging the perception that entirely new laws
    are needed from scratch. Useful for compliance officers.
  relevance_score: 9
  source: llm_enhanced
  text: If you look through the Responsible AI Guidance for Businesses that accompanies
    the AI strategy, it's a really fantastic starting point for thinking about these
    issues because what it does is it rips through a table of at least 10 different
    statutes that already have some bearing on AI and the way that it's used in New
    Zealand.
  topic: business/strategy
- impact_reason: Suggests a pragmatic, existing regulatory model (like the biometric
    code) as a template for addressing novel AI issues like deepfakes, favoring specialized,
    trusted bodies over broad legislation.
  relevance_score: 9
  source: llm_enhanced
  text: Is potentially coming up with these codes from trusted offices like the Privacy
    Commissioner a potentially good way to deal with some of these emerging issues
    with AI? I think it is.
  topic: safety/strategy
- impact_reason: A surprising endorsement of self-regulation, reframing it as a necessary,
    fast-moving 'trial run' for complex technologies before formal government codification.
  relevance_score: 9
  source: llm_enhanced
  text: I do think there's a really interesting case for basically even self-regulatory
    approaches. So, self-regulation always sounds like this flimsy cop-out option,
    and it can be like that. But what it can be also is a really good trial run for
    how something's actually going to work because how it's going to work is quite
    complicated.
  topic: strategy
- impact_reason: Connects existing, high-stakes regulatory frameworks (like Health
    and Safety) directly to AI deployment (chatbots), demonstrating immediate, tangible
    liability risks for businesses.
  relevance_score: 9
  source: llm_enhanced
  text: Let's say you're deploying a chatbot for your employees or something like
    that, or people coming onto your workspace—you're essentially already required
    to think about the risks of deploying that, and you can be liable for really significant
    financial consequences if you're deploying that chatbot in that context and something
    bad happens.
  topic: business/safety
- impact_reason: Exposes the common lobbying tactic where large tech firms push localized,
    pre-packaged compliance documents to governments, often bypassing deeper engagement
    with local civil society.
  relevance_score: 9
  source: llm_enhanced
  text: you get the big tech giants who basically do a cookie-cutter version of their
    overseas policies that they should put a lot of time and money into crafting.
    They localize that, they serve that up to our government, and then they sort of
    cozy up with the Netsafes and those sorts of organizations for soft power, as
    such.
  topic: business/strategy
- impact_reason: Argues for the necessity of a distinct, action-oriented 'fourth pillar'
    of voice (independent think tanks/advocacy) separate from the traditional industry,
    government, and academic silos.
  relevance_score: 9
  source: llm_enhanced
  text: It is critical to be able to have a non-industry, non-government, and I'd
    say non-academic voice on all of this, too, because academia is fantastic, but
    can also operate like a very large institution...
  topic: strategy
- impact_reason: Provides a historical model for multi-stakeholder governance (internet
    governance) that can be applied to emerging technologies like AI.
  relevance_score: 9
  source: llm_enhanced
  text: When you govern the internet, it's never been about just governments doing
    it by themselves. It's always been about a blend of industry, academia, and research,
    and then the people using the internet—the civil society.
  topic: Strategy/Governance
- impact_reason: Clearly articulates the US national strategy for AI—geopolitical
    supremacy driven by massive capital investment.
  relevance_score: 9
  source: llm_enhanced
  text: 'The US, as I said at the start, they want to have supremacy in AI because
    it is geopolitically significant. It''s a national security issue. That''s why
    Trump is in the White House every second week with Oracle and OpenAI, 500 billion
    investment here, 600 billion there. For them, it''s about brute force: how much
    can we spend to accelerate our lead?'
  topic: Predictions/Strategy
- impact_reason: 'A crucial point on AI utility: capability without proper application
    or guidance leads to stagnation.'
  relevance_score: 9
  source: llm_enhanced
  text: It's all very well and good having really powerful computers and fantastic
    models, but if everyone's using them for the wrong thing, we're not going forward
    in any meaningful way.
  topic: Strategy/Business
- impact_reason: Indicates the emergence and growing consideration of 'Sovereign AI'
    as a viable national strategy, even for skeptics.
  relevance_score: 9
  source: llm_enhanced
  text: I was talking about this at a seminar a little while ago where somebody raised
    for me this concept of sovereign AI, and my initial reaction at the moment was,
    'What? What are you even talking about?' But it's kind of warmed its way into
    my head quite a bit, and I've been thinking about what it might actually mean
    for New Zealand.
  topic: Strategy/Technical
- impact_reason: Identifies model fine-tuning as a likely and immediate competitive
    path for smaller economies, highlighting a specific business model (fine-tuning
    as a service).
  relevance_score: 9
  source: llm_enhanced
  text: And in all likelihood, it probably means fine-tuning models that already exist.
    And I saw, really, this is kind of a free plug for Straker AI, a pretty amazing
    New Zealand company who I think have now proposed to offer fine-tuned models as
    a service, pretty interesting for your listeners, I'm sure.
  topic: Business/Technical
- impact_reason: Highlights the strategic consensus around 'deployment expertise'
    as a national AI edge, even if the overall strategy is criticized.
  relevance_score: 9
  source: llm_enhanced
  text: I actually do agree with what they said in the AI strategy, which is a pretty
    unpopular position to hold to say anything nice about the AI strategy, but what
    they did say was, 'We can be experts in deploying AI systems.'
  topic: Strategy
- impact_reason: Proposes a pragmatic, iterative approach to governance, using soft
    law (codes of practice) as a testing ground before hard legislation.
  relevance_score: 8
  source: llm_enhanced
  text: why Tom believes that codes of practice and even industry self-regulation
    can serve as a useful trial run before legislation catches up.
  topic: strategy/regulation
- impact_reason: Sets realistic expectations about the timeline for effective regulation,
    emphasizing that implementation lag is inevitable, even with aggressive initial
    legislation.
  relevance_score: 8
  source: llm_enhanced
  text: even if we did decide to just really kick things off and go hard, it would
    still be a pretty long process of trying to work out what a lot of this regulatory
    stuff means.
  topic: predictions/regulation
- impact_reason: Points out the critical role of non-jurisdictional international
    standards bodies in shaping compliance and convergence, which is vital for global
    tech companies.
  relevance_score: 8
  source: llm_enhanced
  text: The other thing to be aware of is just the scale of all the different regulatory
    approaches out there is just enormous. And there's another piece to think about...
    which is around international standards.
  topic: strategy/regulation
- impact_reason: Uses a specific, contemporary example (Australia's social media ban)
    to warn against hasty, potentially harmful regulation driven by populist pressure.
  relevance_score: 8
  source: llm_enhanced
  text: We've seen in Australia with the looming introduction of the under-16 social
    media ban, for instance, and why Tom believes that codes of practice and even
    industry self-regulation can serve as a useful trial run before legislation catches
    up.
  topic: safety/regulation
- impact_reason: Highlights the speed advantage of industry/sector-specific codes
    over slow-moving government regulation, a key strategic consideration for rapid
    tech deployment.
  relevance_score: 8
  source: llm_enhanced
  text: The other benefit of taking that code-based approach is you can move really
    quick. You can move away faster than any government agency can.
  topic: strategy
- impact_reason: 'Provides a pathway for industry standards to influence future regulation:
    successful self-regulation provides the blueprint for effective government enforcement.'
  relevance_score: 8
  source: llm_enhanced
  text: If you can basically demonstrate that you've got a code that works and it's
    well thought through, it's much, much easier for an agency to just pick that up
    and give it some teeth if it worked well.
  topic: business/strategy
- impact_reason: Critiques the current governmental posture in New Zealand (and implicitly
    elsewhere) as being too passive ('muted') regarding AI enforcement, relying on
    vague calls for 'responsibility' rather than active oversight.
  relevance_score: 8
  source: llm_enhanced
  text: We've just sort of said, 'Look, the laws are there to handle this. Let's see
    what happens.' It's not as though the government is really thumping the desk on
    any particular issue around AI, just sort of saying in general, 'You've got to
    do it responsibly.'
  topic: strategy
- impact_reason: Directly addresses the 'information problem' by advocating for the
    sharing of specialized legal/technical analysis (e.g., copyright risk assessment
    for OpenAI) to reduce systemic inefficiency.
  relevance_score: 8
  source: llm_enhanced
  text: The information issue is that we can go and replicate that [legal analysis],
    or we can basically share the results of that analysis, and that would be really
    valuable. It would basically mean that we don't have to duplicate that over and
    over again.
  topic: strategy
- impact_reason: Summarizes the evolving, often conflicted, regulatory stance of the
    EU regarding AI innovation versus control.
  relevance_score: 8
  source: llm_enhanced
  text: Europe is sort of pivoted a little bit between regulation first to we don't
    want to miss the AI revolution by strangling our companies with red tape, so we
    need to accommodate that as well.
  topic: Safety/Regulation
- impact_reason: Broadens the scope of national AI strategy beyond just model development
    to include foundational infrastructure and public literacy.
  relevance_score: 8
  source: llm_enhanced
  text: It's not just the AI side of things; it's also that broader digital sovereignty,
    digital infrastructure, kind of internet infrastructure, and then also the literacy
    and capability aspects of that, too.
  topic: Strategy
- impact_reason: 'Points out a crucial, often overlooked, competitive advantage for
    certain nations in the AI race: sustainable and affordable energy for compute-intensive
    data centers.'
  relevance_score: 8
  source: llm_enhanced
  text: I know that other people are also thinking about the fact that we have a lot
    of renewable energy generation, so when it comes to housing data centers, we have
    a lot of capability there as well.
  topic: Strategy/Business
- impact_reason: Reinforces the idea that expertise in *application and integration*
    (deployment) is a more achievable and valuable niche than foundational model creation
    for many nations.
  relevance_score: 8
  source: llm_enhanced
  text: So, I actually do think this competitive advantage around being the world's
    smartest deployers of AI systems is something that I'm obviously pretty interested
    in, and I'd like to see that taken further.
  topic: Strategy
- impact_reason: Shows alignment between government strategy and advocacy groups on
    the *method* (risk-based approach), differing only on the *degree* of lightness/heaviness.
  relevance_score: 7
  source: llm_enhanced
  text: We need to be talking about the actual practicalities of some of this, too.
    One thing that I've thought about quite a bit is if you sit down and you look
    at the AI strategy and you look at the light-touch, proportionate, and risk-based
    approach that has been advocated for, that is also the approach that the open
    letter has advocated for, except maybe a little bit less light-touch, a slightly
    heavier touch.
  topic: strategy/regulation
- impact_reason: Emphasizes the need for informed civil society capacity to act as
    a 'handbrake' against rushed, populist regulatory responses.
  relevance_score: 7
  source: llm_enhanced
  text: what somebody does something, that we've got a handbrake on that where we
    can at least have an informed discussion about it.
  topic: strategy/safety
- impact_reason: 'Identifies the foundational ''information problem'' in policy making:
    fragmented, non-current, and non-standardized data about the existing regulatory
    landscape.'
  relevance_score: 7
  source: llm_enhanced
  text: The task of going and answering all of that is really tough, and that's what
    the first post is about. It's about we've got information everywhere. We don't
    know whether it's current. It's not all tied in one place, and it kind of relates
    to a lot of different things, and it might be quite non-specific anyway. So, there's
    an information problem that needs to be grappled with.
  topic: strategy
- impact_reason: 'Defines the strategic role of independent policy institutes: bridging
    gaps between government, sectors, and research, acting as non-political conveners.'
  relevance_score: 7
  source: llm_enhanced
  text: We've had one of your colleagues on in the past, but just in case people don't
    really know what Brainbox Institute actually is and does, give us the lowdown.
    I have a background in law and public policy, and what I concluded from working
    in other areas of policy was that there was a really cool space to be occupied
    for organizations that are not government, so that sit outside government and
    coordinate with other parties in a particular policy area—not political parties,
    I mean sector groups—to kind of lead a bit of a conversation.
  topic: strategy
- impact_reason: Illustrates the integration of policy thinking (think tank) with
    practical tool-building (consultancy/lab), suggesting a holistic approach to solving
    governance challenges.
  relevance_score: 7
  source: llm_enhanced
  text: The Brainbox Institute is the think tank and a consultancy company, but I
    also spend a lot of my time thinking about how to build the tools for doing this
    work more effectively, and that's through another company called Sunkipate Lab.
  topic: business/strategy
- impact_reason: 'A fundamental challenge for any regulator or policy maker: the lack
    of a centralized, verified repository of existing legal obligations.'
  relevance_score: 7
  source: llm_enhanced
  text: We have fantastic information everywhere. We don't know whether it's current.
    It's not all tied in one place, and it kind of relates to a lot of different things,
    and it might be quite non-specific anyway. So, there's an information problem
    that needs to be grappled with.
  topic: strategy
- impact_reason: Provides a balanced view on industry involvement, acknowledging their
    role in providing useful ideas while recognizing their inherent motivation to
    protect their financial interests.
  relevance_score: 7
  source: llm_enhanced
  text: There is a place for industry at the table to be advocating and sharing good
    ideas that make for better policy, but also have an impact on that bottom line.
  topic: business
- impact_reason: 'Defines a specific niche for think tanks: bridging policy gaps with
    actionable insights, rather than purely theoretical research.'
  relevance_score: 7
  source: llm_enhanced
  text: The space that I've tried to really fill with Brainbox is to have that really
    action-oriented capability to deal with all of those groups.
  topic: Business/Strategy
- impact_reason: Provides a historical analogue (SaaS leveraging the cloud) for how
    a nation can build economic value by mastering the deployment of foundational
    technologies created elsewhere.
  relevance_score: 7
  source: llm_enhanced
  text: We didn't invent cloud computing, but we've got some great software-as-a-service
    companies that use the cloud to improve accounting or billing software, whatever
    it was. So, we are adept at taking those existing technologies that billions of
    dollars have gone into and actually making them really useful.
  topic: Strategy/Business
- impact_reason: A strategic reflection on past national tech ambitions, suggesting
    a need to evaluate historical failures before launching new, potentially similar,
    AI strategies.
  relevance_score: 7
  source: llm_enhanced
  text: I keep reading about the Knowledge Wave conference back in 2001, I think it
    was. And I ask myself, that was probably the last time that we went, 'We're going
    to be a genius tech economy.' And one of the questions I'd love to see asked and
    answered is, what happened with that? Did it work? Is that what we are now, or
    did it fail?
  topic: Strategy
- impact_reason: 'Describes the necessary mindset for effective tech policy work:
    synthesis, efficiency, and practicality.'
  relevance_score: 6
  source: llm_enhanced
  text: I like thinking about tech policy, I like reading about it, I like trying
    to synthesize everything together, and I like trying to find a way through that's
    kind of productive and efficient and useful in all of these spaces.
  topic: strategy
- impact_reason: 'A key efficiency principle for government and policy work: avoiding
    redundant analysis by leveraging existing research.'
  relevance_score: 6
  source: llm_enhanced
  text: part of this coordination problem is how can we make sure that we're just
    reusing that rather than starting afresh?
  topic: strategy
- impact_reason: Highlights experience in coordinating international efforts on tech
    governance, relevant for global AI standards.
  relevance_score: 6
  source: llm_enhanced
  text: I led a global multi-state coalition around technology company transparency,
    particularly in a social media context.
  topic: strategy
- impact_reason: Notes the vacuum in practical, non-academic tech policy analysis
    in the local landscape, justifying the role of organizations like Brainbox.
  relevance_score: 6
  source: llm_enhanced
  text: A lot of this stuff used to be done a little bit by Internet New Zealand;
    they had a really good policy arm that sort of faded in recent years. The academics
    do their thing, but it's very much through the academic lens.
  topic: strategy
source: Unknown Source
summary: '## Podcast Summary: Steady Hands, Not Knee-Jerk Bans: Brainbox’s Approach
  to AI Regulation


  This 37-minute episode of "The Business of Tech" features Peter Griffin in conversation
  with **Tom Barraclough**, tech policy expert and co-founder of the **Brainbox Institute**,
  focusing on a pragmatic, measured approach to regulating Artificial Intelligence
  in New Zealand. Barraclough strongly advocates against the immediate introduction
  of new, AI-specific legislation, arguing instead for the effective coordination
  and application of existing statutes.


  ---


  ### 1. Focus Area

  The primary focus is **AI Regulation Policy**, specifically contrasting the global
  trend toward rapid, specific AI legislation (like the EU AI Act) with a New Zealand-centric
  approach emphasizing leveraging existing legal frameworks (Privacy Act, Crimes Act,
  Health and Safety legislation) and developing practical, non-legislative tools like
  codes of practice. Secondary themes include the challenges of policy development
  (information asymmetry, economic barriers) and the role of independent think tanks.


  ### 2. Key Technical Insights

  *   **Existing Legal Coverage:** Many potential AI harms (e.g., fraud via deepfakes,
  discrimination by chatbots) are already covered by existing, "open-textured" legislation
  like the Crimes Act and the Human Rights Act, though clarification and enforcement
  guidance are needed.

  *   **The Regulatory Cascade:** Even the most stringent legislation (like the EU
  AI Act) is only the top layer; effective regulation relies on a lengthy cascade
  of delegated acts, guidance documents, and institutional infrastructure to define
  practical compliance.

  *   **Self-Regulation as a Proving Ground:** Industry self-regulation or codes of
  practice (like the Biometric Code) can serve as a crucial, fast-moving "trial run"
  to test practical compliance mechanisms before formal legislation is enacted.


  ### 3. Business/Investment Angle

  *   **Competitive Advantage in Reliability:** New Zealand has a potential competitive
  edge by aiming to become the world''s smartest and most reliable employer/user of
  AI systems, focusing on capability and digital literacy rather than just restrictive
  laws.

  *   **Risk of Hasty Policy:** Knee-jerk regulation, exemplified by the proposed
  under-16 social media ban in Australia, risks implementing policies that cause unintended
  harm without addressing the core issues effectively.

  *   **Resource Imbalance in Policy Advocacy:** There is a significant concern that
  policy discussions are dominated by well-resourced entities (Big Tech, large law
  firms), leaving under-resourced civil society and public interest groups marginalized.


  ### 4. Notable Companies/People

  *   **Tom Barraclough (Brainbox Institute):** Central figure advocating for coordination,
  leveraging existing law, and addressing the "information problem" in policy development.

  *   **Brainbox Institute:** A non-government think tank/consultancy focused on coordinating
  policy discussions at the interface of government, research, and business.

  *   **Sunkipate Lab:** Barraclough''s company focused on building tools to translate
  law and regulation into code/data instructions.

  *   **Lenson McGavin, Chris, and Andrew:** Mentioned as leaders behind the open
  letter urging immediate AI regulation, which Barraclough views as a positive catalyst
  for discussion.

  *   **Carnegie Endowment for International Peace / Brookings Institution:** Used
  as examples of well-endowed, influential international think tanks.


  ### 5. Future Implications

  The industry is heading toward a complex, multi-layered regulatory environment where
  international standards will heavily influence local compliance, even if specific
  national legislation is slow to materialize. The immediate future in New Zealand
  will likely involve more focus on **codes of practice** and **guidance** (like the
  Responsible AI Guidance for Businesses) to bridge the gap until formal legislation
  is deemed necessary. There is a critical need to solve the **information coordination
  problem** to ensure policy development is efficient and informed by existing legal
  analysis.


  ### 6. Target Audience

  This episode is most valuable for **Tech Policy Professionals, Government Regulators,
  Legal Counsel specializing in Technology, and Business Leaders** navigating the
  compliance landscape for AI deployment in New Zealand and similar jurisdictions.'
tags:
- artificial-intelligence
- startup
- investment
- generative-ai
- openai
- anthropic
title: 'Steady hands, not knee-jerk bans: Brainbox’s approach to AI regulation'
topics:
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 69
  prominence: 1.0
  topic: artificial intelligence
- keywords:
  - startup
  - entrepreneur
  - founder
  - venture
  mentions: 2
  prominence: 0.2
  topic: startup
- keywords:
  - investment
  - funding
  - valuation
  - ipo
  - acquisition
  mentions: 2
  prominence: 0.2
  topic: investment
- keywords:
  - generative ai
  - genai
  - chatgpt
  - gpt
  - claude
  - text generation
  - image generation
  mentions: 1
  prominence: 0.1
  topic: generative ai
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-10-16 10:16:27 UTC -->
