---
companies:
- category: unknown
  confidence: medium
  context: Today I want to talk about GPT-5. This model was met with
  name: Today I
  position: 0
- category: unknown
  confidence: medium
  context: ificial intelligence had been coined. We'll go to Alan Turing, he was doing
    all that breakthrough work in crypt
  name: Alan Turing
  position: 646
- category: unknown
  confidence: medium
  context: chine intelligence that later on got known as the Turing Test. The test
    was reasonably simple, right? If the ou
  name: Turing Test
  position: 832
- category: unknown
  confidence: medium
  context: tty explicit. But here's the thing. Back in 2014, Eugene Gussman at computer
    program won the Turing Test. It persu
  name: Eugene Gussman
  position: 1237
- category: unknown
  confidence: medium
  context: the Turing Test. It persuaded judges at Britain's Royal Institution that
    it was human years before ChatGPT. And so we
  name: Royal Institution
  position: 1326
- category: unknown
  confidence: medium
  context: fting goalposts has been noticed since the 1970s. Rodney Brooks, who is
    a professor of computer science and robot
  name: Rodney Brooks
  position: 1989
- category: unknown
  confidence: medium
  context: that progress makes the gaps stand out much more. And I think for many
    people who are using large languag
  name: And I
  position: 3105
- category: tech
  confidence: high
  context: so wow, we've got the hallucination rate down as OpenAI has the GPT-5,
    enough to say we don't need to att
  name: Openai
  position: 4603
- category: tech
  confidence: high
  context: arantee that GPT-5 or GPT-6 or any new model from Anthropic or from Google
    or DeepMind will probably feel les
  name: Anthropic
  position: 5265
- category: tech
  confidence: high
  context: or GPT-6 or any new model from Anthropic or from Google or DeepMind will
    probably feel less revolutionary
  name: Google
  position: 5283
- category: ai_application
  confidence: high
  context: Mentioned in relation to GPT-5 and the success/impact of ChatGPT.
  name: OpenAI
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as a company that will release new models alongside Google and
    DeepMind.
  name: Anthropic
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Mentioned as a company that will release new models alongside Anthropic
    and DeepMind.
  name: Google
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: Mentioned as a company that will release new models alongside Anthropic
    and Google.
  name: DeepMind
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: Rodney Brooks, a professor of computer science and robotics there, is quoted
    regarding AI progress.
  name: MIT
  source: llm_enhanced
date: 2025-10-03 21:39:18 +0000
duration: 7
has_transcript: false
insights:
- actionable: false
  confidence: high
  source: llm_enhanced
  text: ''
  type: general
- actionable: false
  confidence: high
  source: llm_enhanced
  text: ''
  type: general
- actionable: false
  confidence: medium
  source: llm_enhanced
  text: ''
  type: general
- actionable: false
  confidence: medium
  source: llm_enhanced
  text: ''
  type: general
- actionable: false
  confidence: high
  source: llm_enhanced
  text: ''
  type: general
layout: episode
llm_enhanced: true
original_url: https://afp-444457-injected.calisto.simplecastaudio.com/ea6da43b-cf32-4bb2-a71f-d5ad709d858f/episodes/67938c45-c044-42fd-8a2a-d8106cb84e0e/audio/128/default.mp3?aid=rss_feed&awCollectionId=ea6da43b-cf32-4bb2-a71f-d5ad709d858f&awEpisodeId=67938c45-c044-42fd-8a2a-d8106cb84e0e&feed=e_GRxR9a
processing_date: 2025-10-03 21:39:18 +0000
quotes:
- length: 268
  relevance_score: 5
  text: If the output of a computer system and machine was indistinguishable to other
    humans, from the outputs from other humans, you've got a machine that is exhibiting
    some type of thinking and the Turing Test became the thing people measured towards
    artificial intelligence
  topics: []
- length: 128
  relevance_score: 4
  text: And I think for many people who are using large language models today through
    these chatbots, there are these concrete contrasts
  topics: []
- length: 96
  relevance_score: 3
  text: And they do give us a clue to how we're going to react to ever improving artificial
    intelligence
  topics: []
- length: 78
  relevance_score: 3
  text: Actually back to 1950, before the term artificial intelligence had been coined
  topics: []
- length: 98
  relevance_score: 3
  text: He says, every time we figure out a piece of this, artificial intelligence,
    it stops being magical
  topics: []
- impact_reason: This sets up the core thesis of the discussion, explaining why incremental
    improvements (like GPT-5) often lead to underwhelmed reactions, which is crucial
    for understanding public perception of AI progress.
  relevance_score: 9
  source: llm_enhanced
  text: GPT-5 could never have impressed us. It's because it falls between two paradoxes
    of progress.
  topic: strategy
- impact_reason: This succinctly describes the 'shifting goalposts' phenomenon, a
    key psychological barrier to recognizing AI breakthroughs, directly referencing
    Rodney Brooks' observation.
  relevance_score: 10
  source: llm_enhanced
  text: Every time we figure out a piece of this, artificial intelligence, it stops
    being magical. People say, hey, that's just computation.
  topic: safety/strategy
- impact_reason: This defines the second major paradox, explaining why even significant
    improvements in reliability (like lower hallucination rates) highlight the remaining,
    more critical gaps (like long-term memory or generalization).
  relevance_score: 9
  source: llm_enhanced
  text: The paradox of negative space is that progress makes the gaps stand out much
    more.
  topic: strategy
- impact_reason: This is a powerful, quantitative illustration of the negative space
    paradox applied to reliability engineering in AI workflows. It shows how small
    error rates become unacceptable in complex, chained processes.
  relevance_score: 10
  source: llm_enhanced
  text: But that 1% hallucination rate will show up time and again. Or consider a
    series of individual steps chained one to another. Imagine you've got a process
    with 25 steps. Well, a 1% hallucination rate means that each step succeeds 99
    times out of 100. But across a chain of 25, it will mean one in five times. That
    chain will fail.
  topic: technical/business
- impact_reason: This is the summary statement combining both paradoxes, providing
    a framework for interpreting future AI releases.
  relevance_score: 9
  source: llm_enhanced
  text: Shifting goal posts mean we redefine success as soon as it's achieved. Negative
    space means every improvement makes what is still missing even more obvious.
  topic: strategy
- impact_reason: A direct prediction about the market perception of future state-of-the-art
    models based on the established paradoxes.
  relevance_score: 8
  source: llm_enhanced
  text: Together they guarantee that GPT-5 or GPT-6 or any new model from Anthropic
    or from Google or DeepMind will probably feel less revolutionary than perhaps
    it really is.
  topic: predictions
- impact_reason: This offers a nuanced prediction about the path to AGI, suggesting
    it will be gradual rather than a single, sudden event, challenging common narratives.
  relevance_score: 8
  source: llm_enhanced
  text: This probably means that we're not going to have a before and after artificial
    general intelligence moment. Rather improvements will get delivered on a smooth-ish
    curve to have a moment of awe, a sense of before and after.
  topic: predictions
- impact_reason: This is a strong call to action for researchers and developers, suggesting
    that incremental scaling is insufficient for achieving the next major leap in
    utility.
  relevance_score: 9
  source: llm_enhanced
  text: I think we will need a paradigm shift in the way we build and deliver AI models
    and in what they can actually do.
  topic: strategy
- impact_reason: This highlights that true paradigm shifts (like the initial ChatGPT
    release) are often unexpected, even to the creators, contrasting them with expected
    evolutionary updates.
  relevance_score: 7
  source: llm_enhanced
  text: There is a before ChatGPT and after ChatGPT moment but that moment came about
    by something that was rather surprising and surprising to OpenAI itself, which
    was ChatGPT and how effective it was and how it delivered a new paradigm.
  topic: strategy
- impact_reason: This historical context demonstrates that the Turing Test benchmark
    was surpassed long ago, justifying why it is no longer a meaningful measure of
    modern AI capability.
  relevance_score: 7
  source: llm_enhanced
  text: Back in 2014, Eugene Gussman at computer program won the Turing Test. It persuaded
    judges at Britain's Royal Institution that it was human years before ChatGPT.
  topic: technical
source: Azeem Azhar's Exponential View
summary:
- key_takeaways:
  - GPT-5 felt evolutionary rather than revolutionary because human expectations constantly
    shift as AI capabilities improve.
  - The Turing Test is no longer a valid measure of machine intelligence because LLMs
    have easily surpassed it, leading to 'shifting goalposts' where solved problems
    cease to impress.
  - Rodney Brooks' observation highlights that once a piece of AI is understood, it
    is dismissed as mere computation, removing the 'magic'.
  - The negative space paradox dictates that as models become more reliable (e.g.,
    dropping error rates from 10% to 1%), the remaining small gaps become more noticeable
    and frustrating.
  - A small error rate (like 1% hallucination) becomes highly problematic when applied
    across long, chained workflows, preventing full automation despite overall improvement.
  - Future major AI breakthroughs will likely require a paradigm shift in model building,
    not just incremental scaling, to generate a genuine 'before and after' moment.
  - The current trajectory suggests improvements will continue on a smooth curve,
    meaning users will likely remain unimpressed until a fundamentally new AI flavor
    arrives.
  overview: 'The underwhelming reception of GPT-5 stems from two inherent paradoxes
    of technological progress: the shifting goalposts of what constitutes intelligence
    and the negative space paradox, where improvements highlight remaining deficiencies.
    These dynamics ensure that even significant advancements, like GPT-5, are perceived
    as evolutionary rather than revolutionary because success redefines the benchmark.
    Consequently, true moments of awe in AI will likely require a fundamental paradigm
    shift in model architecture, similar to the impact of ChatGPT.'
  themes:
  - The Paradoxes of Progress in AI
  - Shifting Benchmarks and Expectations (Turing Test)
  - The Negative Space Paradox and Reliability Gaps
  - The Nature of Revolutionary vs. Evolutionary AI Improvement
  - The Requirement for a Paradigm Shift in AI Architecture
tags:
- artificial-intelligence
- generative-ai
- openai
- anthropic
- google
title: Why GPT-5 was never going to impress you
topics:
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 21
  prominence: 1.0
  topic: artificial intelligence
- keywords:
  - generative ai
  - genai
  - chatgpt
  - gpt
  - claude
  - text generation
  - image generation
  mentions: 17
  prominence: 1.0
  topic: generative ai
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-10-03 21:39:18 UTC -->
