---
companies:
- category: unknown
  confidence: medium
  context: ing long-form outputs. This is 20 Product with me Harry Stemings. Now 20
    Product is a monthly show where we sit do
  name: Harry Stemings
  position: 639
- category: unknown
  confidence: medium
  context: the best product teams. Joining me today we have Ateesh Nayak, Head of
    Product at Harvey, one of the hottest st
  name: Ateesh Nayak
  position: 837
- category: unknown
  confidence: medium
  context: Product at Harvey, one of the hottest startups in Silicon Valley where
    he oversees product vision, strategy, desig
  name: Silicon Valley
  position: 909
- category: tech
  confidence: high
  context: aving previously held product leadership roles at Scale AI from 40 to 800
    people and Shield AI from 20 to 10
  name: Scale Ai
  position: 1110
- category: unknown
  confidence: medium
  context: rship roles at Scale AI from 40 to 800 people and Shield AI from 20 to
    100 people. But before we dive into th
  name: Shield AI
  position: 1145
- category: unknown
  confidence: medium
  context: struggling to beat model benchmarks or implement Gen AI in your product?
    If so, you need Churing. Churing
  name: Gen AI
  position: 1275
- category: unknown
  confidence: medium
  context: cture company backed by incredible investors like Foundation Capital and
    Westbridge Capital. And they do two things. N
  name: Foundation Capital
  position: 1401
- category: unknown
  confidence: medium
  context: incredible investors like Foundation Capital and Westbridge Capital. And
    they do two things. Number one, they help le
  name: Westbridge Capital
  position: 1424
- category: tech
  confidence: high
  context: leading companies in AI labs like Salesforce and Anthropic and Meta enhance
    their LLMs with advanced reasoni
  name: Anthropic
  position: 1539
- category: tech
  confidence: high
  context: nies in AI labs like Salesforce and Anthropic and Meta enhance their LLMs
    with advanced reasoning, codin
  name: Meta
  position: 1553
- category: tech
  confidence: high
  context: ave time? With over a billion meetings processed, Otter.ai is the ultimate
    AI meeting productivity tool. It
  name: Otter.Ai
  position: 2404
- category: unknown
  confidence: medium
  context: dcast. Dude, it is so special to do it in person. Now I wanted to start
    when I was chatting to some of ou
  name: Now I
  position: 4015
- category: unknown
  confidence: medium
  context: kill set growth. And early on, I think I had read Sam Altman's post on
    how to be successful. This was before S
  name: Sam Altman
  position: 4779
- category: unknown
  confidence: medium
  context: t manager. It's so funny, it makes me think about Shoshana Zuboff. She's
    clocked out all the way. She says, don't d
  name: Shoshana Zuboff
  position: 5950
- category: unknown
  confidence: medium
  context: erent AI movements over the last five, six years. And I think one thing
    we did really well was listening
  name: And I
  position: 6928
- category: unknown
  confidence: medium
  context: u have conviction that everyone else will follow. Can I just dive in on
    that? Founders are often told, do
  name: Can I
  position: 7925
- category: tech
  confidence: high
  context: You know, another example is Scale partnered with OpenAI very, very early
    on before ChatGPT came out. This
  name: Openai
  position: 8738
- category: unknown
  confidence: medium
  context: Reddit passages. And then maybe two years later, OpenAI Super Head, two
    years later, everyone started asking a lot o
  name: OpenAI Super Head
  position: 9118
- category: unknown
  confidence: medium
  context: o have customers, and that gives them confidence. If I'm a PM and I currently
    consider myself the glue a
  name: If I
  position: 11708
- category: unknown
  confidence: medium
  context: ways find that funny. You know what I find funny? The CEO is the CEO of
    the product. Exactly what it is. It
  name: The CEO
  position: 12889
- category: unknown
  confidence: medium
  context: working on LLMs or at Waymo or Tesla or whatever. But I think it's really
    important to find a market that
  name: But I
  position: 14513
- category: unknown
  confidence: medium
  context: nd a market that is huge before you are too late. So I think that's like
    what they're doing. Do you thin
  name: So I
  position: 14602
- category: unknown
  confidence: medium
  context: government, where, if you remember, back in 2019, Project Maven was a thing,
    and the DOD was starting to curate a
  name: Project Maven
  position: 15420
- category: unknown
  confidence: medium
  context: e's that whole Uber saga, there's a lot of chaos. But Uber is standing
    and is profitable, and obviously cred
  name: But Uber
  position: 17062
- category: unknown
  confidence: medium
  context: y, and Satya even said this. The reason the image Studio Ghibli stuff really
    up is because they have a mobile app
  name: Studio Ghibli
  position: 19456
- category: unknown
  confidence: medium
  context: ing products is something called the IKEA effect. The IKEA effect is like
    when IKEA started going super vira
  name: The IKEA
  position: 20479
- category: unknown
  confidence: medium
  context: re growing a sales team alongside a product team. And Winston put me in
    charge of it, so now I'm figuring that
  name: And Winston
  position: 22910
- category: unknown
  confidence: medium
  context: ortant? So I believe in benevolent dictatorships. So Singapore, that's
    an example. I totally agree. I think it's
  name: So Singapore
  position: 24770
- category: tech
  confidence: high
  context: us technical debt? Well, I interviewed the CTO of Microsoft, and he said
    that basically his most exciting app
  name: Microsoft
  position: 33676
- category: unknown
  confidence: medium
  context: re a structured time every week for post-mortems? Like Monday, 5 p.m.,
    we do post-mortems? Is there an ad hoc b
  name: Like Monday
  position: 35966
- category: tech
  confidence: high
  context: structured time every week for post-mortems? Like Monday, 5 p.m., we do
    post-mortems? Is there an ad hoc b
  name: Monday
  position: 35971
- category: unknown
  confidence: medium
  context: hings that cause the problems? You know, it's the Mike Tyson, you know,
    kind of getting punched in the face or
  name: Mike Tyson
  position: 37826
- category: unknown
  confidence: medium
  context: and suggest like, "Okay, here are the 10 things. Am I on the right track?"
    and you know, check, check,
  name: Am I
  position: 40836
- category: unknown
  confidence: medium
  context: er experience is the AI should just pick for you. The AI should just know
    what the user query and intent i
  name: The AI
  position: 43672
- category: unknown
  confidence: medium
  context: it's preposterous that we're choosing our models. Whenever I'm on Anthropic,
    I'm like, "What the fuck are they
  name: Whenever I
  position: 43973
- category: unknown
  confidence: medium
  context: e public evals that are done on benchmarks? I had Tom O'Malley, the CPO
    and President of Clean, on the sh
  name: Tom O
  position: 45425
- category: unknown
  confidence: medium
  context: ht thing. And so we created this benchmark called Big Law Bench. It consists
    of tasks that are real billable work
  name: Big Law Bench
  position: 46048
- category: unknown
  confidence: medium
  context: nd say, "Here's how legal work actually happens." Because I'm not a lawyer.
    I come from AI. I don't know what
  name: Because I
  position: 47036
- category: unknown
  confidence: medium
  context: ay they like Cursor's agent mode much better than VS Code. Some people
    have said the opposite. So it's like
  name: VS Code
  position: 50418
- category: unknown
  confidence: medium
  context: because Replit takes care of deployment for you. Like I don't want to mess
    with deployment in front-end,
  name: Like I
  position: 51467
- category: unknown
  confidence: medium
  context: bably so much greater when you're speaking to it. And AI—final one—why
    do agents need humans more than hum
  name: And AI
  position: 55978
- category: ai_model
  confidence: high
  context: Mentioned as a model being evaluated for legal reasoning capabilities.
  name: Claude 3.5 Sonnet
  source: llm_enhanced
- category: ai_startup
  confidence: high
  context: A 'hyper-growth AI unicorn' where the interviewee (Ateesh Nayak) is the
    Head of Product, focusing on AI applications (likely legal tech).
  name: Harvey
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: The interviewee held a product leadership role here during hyper-growth;
    Scale is a major data labeling and AI infrastructure company.
  name: Scale AI
  source: llm_enhanced
- category: ai_startup
  confidence: high
  context: The interviewee held a product leadership role here during hyper-growth;
    Shield AI is known for defense/military AI applications.
  name: Shield AI
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: Described as an 'AGI infrastructure company' that enhances LLMs and deploys
    AI systems.
  name: Churing
  source: llm_enhanced
- category: big_tech
  confidence: medium
  context: Mentioned as a leading company whose LLMs are enhanced by Churing.
  name: Salesforce
  source: llm_enhanced
- category: ai_company
  confidence: high
  context: Mentioned as a leading company whose LLMs are enhanced by Churing.
  name: Anthropic
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Mentioned as a leading company whose LLMs are enhanced by Churing. Also
    mentioned later regarding e-commerce data labeling.
  name: Meta
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: A company utilizing Churing's deployed cutting-edge AI systems.
  name: Rivian
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: A company utilizing Churing's deployed cutting-edge AI systems. Also mentioned
    later regarding data used for RLHF training.
  name: Reddit
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: An AI meeting productivity tool providing transcripts and summaries.
  name: Otter.ai
  source: llm_enhanced
- category: ai_company
  confidence: high
  context: Scale partnered with them very early on for RLHF training on GPT-2.
  name: OpenAI
  source: llm_enhanced
- category: ai_startup
  confidence: high
  context: An early customer of Scale, heavily involved in self-driving (LiDAR and
    pedestrian labeling).
  name: Nuro
  source: llm_enhanced
- category: ai_company
  confidence: high
  context: Mentioned as one of the successful companies in the capital-intensive self-driving
    market.
  name: Waymo
  source: llm_enhanced
- category: ai_company
  confidence: high
  context: Mentioned as one of the successful companies in the capital-intensive self-driving
    market.
  name: Tesla
  source: llm_enhanced
- category: organization
  confidence: medium
  context: Mentioned in relation to Project Maven, driving AI investments and data
    curation needs.
  name: DOD (Department of Defense)
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: Mentioned as a source of e-commerce data labeled by Scale.
  name: Instacart
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: Mentioned as a source of e-commerce data labeled by Scale.
  name: DoorDash
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: Used as an example of a company where a great market (ridesharing) masked
    execution problems.
  name: Uber
  source: llm_enhanced
- category: individual_influence
  confidence: low
  context: Mentioned for his early post on success, relevant to career advice, though
    he is an individual, his association with OpenAI/YC is relevant context.
  name: Sam Altman
  source: llm_enhanced
- category: investment_firm
  confidence: high
  context: An investor backing the AGI infrastructure company Churing.
  name: Foundation Capital
  source: llm_enhanced
- category: investment_firm
  confidence: high
  context: An investor backing the AGI infrastructure company Churing.
  name: Westbridge Capital
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as the previous employer of the speaker, where they learned to
    avoid 'feature factories.' Implies Scale AI.
  name: Scale
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: The CTO of Microsoft was interviewed regarding AI's use in demolishing
    technical debt.
  name: Microsoft
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned alongside Anthropic as a model provider whose users shouldn't
    have to choose between models.
  name: Grok
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as one of the models users are currently choosing between, implying
    OpenAI's involvement.
  name: GPT-4o
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: Mentioned via its CPO/President (Tom O'Malley) discussing differences between
    public benchmarks and their internal evaluations.
  name: Clean
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: A model family (developed by Anthropic) being explored by Harvey, specifically
    Claude 3.5 Sonnet, noted for better long-form legal reasoning.
  name: Claude
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as a highly popular AI coding tool/startup, often compared to
    Codium, noted for its agent mode UX.
  name: Cursor
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as an AI coding tool/startup, noted for focusing on enterprise
    data and knowledge architecture within existing codebases.
  name: Codium
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned for its 'agent mode,' which is praised for handling deployment
    tasks, making it attractive for prototyping.
  name: Replit
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: Mentioned alongside Replit agent mode as a potentially attractive tool
    for the speaker's target audience (likely referring to an AI agent/tool).
  name: Bolt
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: Mentioned as a model used by the speaker for emotional advice/therapy,
    though noted as less empathetic than Claude.
  name: ChatGPT
  source: llm_enhanced
date: 2025-04-11 07:07:00 +0000
duration: 65
has_transcript: false
insights:
- actionable: true
  confidence: medium
  extracted: do certain things at certain times
  text: we should do certain things at certain times.
  type: recommendation
- actionable: true
  confidence: medium
  extracted: do more of it
  text: we should do more of it.
  type: recommendation
- actionable: true
  confidence: medium
  extracted: do for the next month
  text: we should do for the next month.
  type: recommendation
- actionable: true
  confidence: medium
  extracted: have done it a little more
  text: We should have done it a little more.
  type: recommendation
- actionable: false
  confidence: medium
  extracted: product that you think a lot about in your leadership role today? In
    a world where, you know, prototyping and the actual execution of ideas
  text: the future of product that you think a lot about in your leadership role today?
    In a world where, you know, prototyping and the actual execution of ideas is much
    cheaper, the ideas will matter a lot more.
  type: prediction
- actionable: false
  confidence: medium
  extracted: 'AI, but you said some really interesting comments that I do have to
    touch on for a quick fire. You said humans are a bottleneck to AI. Why? Yeah,
    everything in Silicon Valley thinks that AI will just happen. You''ll see a lot
    of GDP growth, and everyone will live happily ever after, you''ll be AI, whatever.
    I think realistically, you will run into cultural, legal, and regulatory barriers
    to actually wide-scale adoption of AI. Like, breaking each one down: if you end
    up, again, AGI, you assume it can do really high-level tasks, like advising on
    a merger, advising as a board member—if you can see you—what are the governance
    frameworks for regulating an AGI that'
  text: 'the future of AI, but you said some really interesting comments that I do
    have to touch on for a quick fire. You said humans are a bottleneck to AI. Why?
    Yeah, everything in Silicon Valley thinks that AI will just happen. You''ll see
    a lot of GDP growth, and everyone will live happily ever after, you''ll be AI,
    whatever. I think realistically, you will run into cultural, legal, and regulatory
    barriers to actually wide-scale adoption of AI. Like, breaking each one down:
    if you end up, again, AGI, you assume it can do really high-level tasks, like
    advising on a merger, advising as a board member—if you can see you—what are the
    governance frameworks for regulating an AGI that is running a company? Like, no
    one knows yet, and that''s going to take time to happen.'
  type: prediction
- actionable: false
  confidence: medium
  extracted: open-ended tasks
  text: The problem with open-ended tasks is like, how do you evaluate them consistently
    across tasks? Like if you're saying, "Harvey, generate a chronology," that is
    very different than, you know, "Draft me a motion for summary judgment," which
    is, you know, another kind of litigation task.
  type: problem_identification
layout: episode
llm_enhanced: true
original_url: https://traffic.libsyn.com/secure/thetwentyminutevc/20Product-_Aatish_Nayak__Harvey.mp3?dest-id=240976
processing_date: 2025-10-06 14:59:19 +0000
quotes:
- length: 182
  relevance_score: 6
  text: Number one, they help leading companies in AI labs like Salesforce and Anthropic
    and Meta enhance their LLMs with advanced reasoning, coding, multilinguality,
    multimodality, and more
  topics: []
- length: 97
  relevance_score: 4
  text: So maybe defining hypergrowth is every three to six months, let's say your
    revenue is more than 1
  topics:
  - revenue
  - growth
- length: 158
  relevance_score: 4
  text: It's better at long-form legal reasoning and drafting long-form outputs, so
    a whole section of a merger agreement, for example, and making it super consistent
  topics:
  - merger
- length: 93
  relevance_score: 4
  text: And so if all your revenue comes from inference and developers, it's not an
    ideal place to be
  topics:
  - revenue
- length: 109
  relevance_score: 3
  text: The first thing you have to do is, is it actually the best thing for the company
    for me to do everything I do
  topics: []
- length: 165
  relevance_score: 3
  text: This is also his third hyper-growth AI unicorn, having previously held product
    leadership roles at Scale AI from 40 to 800 people and Shield AI from 20 to 100
    people
  topics:
  - growth
- length: 147
  relevance_score: 3
  text: Number two, they combine human and artificial intelligence expertise to deploy
    cutting-edge AI systems for awesome companies like Rivian and Reddit
  topics: []
- length: 112
  relevance_score: 3
  text: Yeah, so another one was, I think you have to reduce the distance between
    the customer need and the code written
  topics: []
- length: 109
  relevance_score: 3
  text: The first thing you have to do is, is it actually the best thing for the company
    for me to do everything I do
  topics: []
- length: 49
  relevance_score: 3
  text: You have to spend a lot of money upfront to do it
  topics: []
- length: 116
  relevance_score: 3
  text: But the problem is it can get you really far, but it doesn't ultimately last
    if you don't follow that with substance
  topics: []
- length: 131
  relevance_score: 3
  text: When you think about writing as a skill for product people, is it the most
    important skill for a product person to be a good writer
  topics: []
- length: 299
  relevance_score: 3
  text: I think the most important skill is communication of your ideas, whether that
    happens in a written way, whether that happens—you know, probably people love
    slides—whether it happens in slides, whether it happens if, you know, nowadays
    you can build prototypes very quickly and communicate your ideas
  topics: []
- length: 196
  relevance_score: 3
  text: And then what it does also include is kind of like a straw man user journey
    of like, "Here's what the user should do, step by step, here's how it'll work,"
    and ideally including different personas
  topics: []
- length: 168
  relevance_score: 3
  text: And so the biggest thing when you've written a PRD is get everyone in a room
    who's going to get involved in it, who's ever even going to touch it, debate it,
    discuss it
  topics: []
- length: 280
  relevance_score: 3
  text: The important thing is if something breaks or something goes wrong or something
    goes slower than necessary because you have to refactor something and it didn't
    work in a certain way, it's really important to do a post-mortem on that and say,
    "What could we have done to avoid that
  topics: []
- length: 153
  relevance_score: 3
  text: When you say, "Okay, we're going to work on technical debt because of X, Y,
    and Z," you have to be very, very crisp about what does the outcome look like
  topics: []
- length: 132
  relevance_score: 3
  text: So retros, retros are, you want to look back at some period of time and say,
    "Here's what we did well, here's what we didn't do well
  topics: []
- length: 43
  relevance_score: 3
  text: Here's what we should do for the next month
  topics: []
- length: 125
  relevance_score: 3
  text: What have been the biggest mistakes you made in user testing, or biggest mistakes
    you see other people making in user testing
  topics: []
- length: 82
  relevance_score: 3
  text: What's the biggest product mistake that you've made, and how did you learn
    from it
  topics: []
- length: 37
  relevance_score: 3
  text: And so here's what you should do here
  topics: []
- length: 119
  relevance_score: 3
  text: The biggest problem with these models, and we have this problem, is just like
    the capabilities are very ill-constrained
  topics: []
- length: 240
  relevance_score: 3
  text: It's like, this is getting a little in the weeds on legal, but if you're getting
    the indemnification cap on a share purchase agreement, you have to reason over
    four or five different clauses because that cap is not a named thing in the deal
  topics: []
- length: 110
  relevance_score: 3
  text: You have to reason over the dependencies of four different clauses in that
    agreement and then extract that out
  topics: []
- impact_reason: 'Highlights a critical trend in specialized AI/ML product development:
    the increasing necessity of domain expertise over generalist product management
    to successfully integrate complex models into professional workflows.'
  relevance_score: 10
  source: llm_enhanced
  text: Domain experts are driving more of the product decisions. You need to bridge
    the gap between what the model and the UX is to how you actually apply it to a
    certain profession. Those ideas domain experts will matter a lot more.
  topic: AI/ML product strategy
- impact_reason: 'Crucial business advice for AI startups: prioritize ''frontier customers''
    whose needs will define the future market, even if it requires custom work initially.'
  relevance_score: 10
  source: llm_enhanced
  text: I think whenever you're at these cutting-edge markets, and today's world is
    definitely the case, find the customers who are really good at what they do and
    then chase them, even over a fit to them, as long as you have conviction that
    everyone else will follow.
  topic: business advice/strategy
- impact_reason: Historical insight into the early application and necessity of Reinforcement
    Learning from Human Feedback (RLHF) predating the public LLM boom, showing its
    foundational role.
  relevance_score: 10
  source: llm_enhanced
  text: Scale partnered with OpenAI very, very early on before ChatGPT came out. This
    is like very early on RLHF when they were trying to tune models to summarize better
    based off of Reddit passages. And this is on GPT-2.
  topic: AI technical history/RLHF
- impact_reason: A memorable metaphor defining the relationship between distribution
    (brute force/speed) and product (substance/longevity).
  relevance_score: 10
  source: llm_enhanced
  text: If distribution is king, then product is president.
  topic: strategy
- impact_reason: 'Crucial distinction in the AI era: foundational models are infrastructure,
    but the moat lies in the user-facing product built on top (e.g., OpenAI''s pivot
    to consumer apps).'
  relevance_score: 10
  source: llm_enhanced
  text: I don't think the foundational models are products. You're seeing this with
    OpenAI right now. They're more pivoting to a product company...
  topic: AI/ML/business
- impact_reason: A strong prediction about the immaturity of current AI interfaces
    (chat), positioning it as a temporary, foundational step (like MS-DOS) rather
    than the final destination.
  relevance_score: 10
  source: llm_enhanced
  text: Do you think chat is the right interface? Definitely not. It's the command
    line starting point of this new frontier, like MS-DOS was way back when.
  topic: AI/ML/predictions
- impact_reason: A strong recommendation for an iterative workflow, specifically calling
    out the necessity of prototyping early in the context of establishing new UX patterns
    in AI products.
  relevance_score: 10
  source: llm_enhanced
  text: I actually always say prototype before the PRD. Whenever you have an idea,
    whether it's engineers, designers, PMs, whatever, you should do the prototype
    before because you're not going to really know how to build the product or what
    the exact UX actually should be, particularly like again, with AI when these new
    patterns are being established, without actually having, you know, you play with
    it...
  topic: technical/strategy
- impact_reason: 'A significant prediction/insight regarding AI''s immediate, practical
    value: using AI tools (like coding assistants) to automate the cleanup of legacy
    codebases.'
  relevance_score: 10
  source: llm_enhanced
  text: I interviewed the CTO of Microsoft, and he said that basically his most exciting
    application for AI today and moving forward is how AI will be used to basically
    demolish technical debt.
  topic: AI/ML predictions
- impact_reason: Strong argument for abstracting model choice away from the end-user,
    suggesting that the best UX hides the underlying complexity (a key trend in advanced
    AI products).
  relevance_score: 10
  source: llm_enhanced
  text: But that is an example where the right user experience is the AI should just
    pick for you. The AI should just know what the user query and intent is, or it
    should ask you questions to understand it better, and then should just route you
    to the best system for the job and not have the user think about what that, what
    they should do.
  topic: technical
- impact_reason: A bold prediction that model selection will disappear entirely within
    five years, driven by the cognitive load of choice overload.
  relevance_score: 10
  source: llm_enhanced
  text: You will never have, in five years' time, you will not have a choice of which
    model, right? Yeah, exactly. And is user choice good? If you think about the paradox
    of choice, users get confused when they have too much choice. If you're just told,
    I think humans are lazy, just tell them which one.
  topic: predictions
- impact_reason: Critiques the limitations of standard multiple-choice benchmarks
    for evaluating complex, real-world professional tasks like legal work.
  relevance_score: 10
  source: llm_enhanced
  text: To what extent are your evals the same as the public evals that are done on
    benchmarks? ... A lot of public legal benchmarks and then even things like, you
    know, Scale's humanities, last exam, they're all multiple choice. I would love
    if legal work was multiple choice, but any lawyer will tell you there are like
    a million options of what you could do.
  topic: technical
- impact_reason: Details the creation of a domain-specific, open-ended evaluation
    benchmark, setting a standard for how specialized AI should be tested.
  relevance_score: 10
  source: llm_enhanced
  text: And so we created this benchmark called Big Law Bench. It consists of tasks
    that are real billable work tasks that lawyers do on a daily basis at our biggest
    customers in big law firms. The nature of these tasks are, they're very much open-ended.
  topic: technical
- impact_reason: This is a direct, recent competitive benchmark comparison, indicating
    Claude 3.5 Sonnet is surpassing OpenAI models in specific complex reasoning tasks
    (like legal extraction), which is highly relevant for the AI community tracking
    model performance.
  relevance_score: 10
  source: llm_enhanced
  text: For some of those types of extractions, Claude 3.5 Sonnet in particular is
    starting to get better. Every single model that's come out from OpenAI, from other
    competitors, we've benchmarked for since the beginning of time at Harvey. And
    3.5 Sonnet is really where we're starting to see some of the performance better
    than OpenAI.
  topic: technical
- impact_reason: This directly counters the overly optimistic 'AI will just happen'
    narrative, focusing on non-technical hurdles (culture, law, regulation) as the
    true bottlenecks.
  relevance_score: 10
  source: llm_enhanced
  text: I think realistically, you will run into cultural, legal, and regulatory barriers
    to actually wide-scale adoption of AI.
  topic: safety
- impact_reason: 'This articulates a crucial finding about AI adoption: the trust
    chain flows through a human intermediary. Consumers trust the human professional
    who leverages AI, not necessarily the raw AI output directly.'
  relevance_score: 10
  source: llm_enhanced
  text: Why do agents need humans more than humans need agents? ... Ultimately, I
    think the humans don't just always trust AI. They trust other humans using AI.
  topic: strategy
- impact_reason: Directly challenges the common PM trope of 'CEO of the Product,'
    advocating for humility and prioritizing company success over personal visibility,
    which is crucial for scaling teams.
  relevance_score: 9
  source: llm_enhanced
  text: PMs have a main character syndrome sometimes that they have to be the CEO
    of the product, be this face of the product. The first thing you have to do is,
    is it actually the best thing for the company for me to do everything I do?
  topic: strategy/role definition
- impact_reason: Provides a specific, current benchmark comparison for a leading LLM
    (Claude 3.5 Sonnet) in a high-stakes vertical (legal reasoning), indicating tangible
    model performance improvements.
  relevance_score: 9
  source: llm_enhanced
  text: Claude 3.5 Sonnet in particular for legal reasoning. It's better at long-form
    legal reasoning and drafting long-form outputs.
  topic: AI technology trends/benchmarks
- impact_reason: Provides nuance on handling custom client requests in high-growth
    tech—use them as R&D forcing functions, but maintain discipline to avoid feature
    bloat.
  relevance_score: 9
  source: llm_enhanced
  text: I think you really have to tease those two apart [custom requests] and use
    those customers as forcing functions to push what you want forward and say no
    to the things that are maybe too custom.
  topic: business advice/product management
- impact_reason: 'A core operational lesson for building effective tech products:
    minimizing information loss by embedding engineers directly into the customer
    feedback loop.'
  relevance_score: 9
  source: llm_enhanced
  text: Another one was, I think you have to reduce the distance between the customer
    need and the code written. [...] putting engineers right in front of customers,
    whether it's the customer like Nuro or the contributors, kind of the taskers who
    are actually doing the work.
  topic: building products/operations
- impact_reason: Strong metaphor redefining the PM role from 'glue' (a bottleneck)
    to 'WD-40' (an enabler), emphasizing facilitation over control.
  relevance_score: 9
  source: llm_enhanced
  text: If you're the glue, that's really bad because things will break down; you're
    just a single point of failure... But instead, you want to make sure everyone
    else can shine and be good at what they do and grease the skids.
  topic: role definition/leadership
- impact_reason: Provides a concrete example (Self-driving) illustrating that a seemingly
    'great' market can be fatally flawed due to high capital inefficiency and regulatory
    hurdles.
  relevance_score: 9
  source: llm_enhanced
  text: Self-driving is a great example where five, six, seven years ago, you could
    say, 'Oh my God, great market. Everyone's going to have robot taxis.' But it's
    extremely capital-inefficient, or inefficient.
  topic: predictions/business
- impact_reason: The counterpoint to the 'markets are everything' thesis, using Uber
    as an example where market demand masked significant internal execution issues.
  relevance_score: 9
  source: llm_enhanced
  text: great markets can hide execution problems.
  topic: business
- impact_reason: Explains the limitations of relying solely on distribution—it drives
    initial velocity but requires product substance for long-term stability.
  relevance_score: 9
  source: llm_enhanced
  text: Distribution can bring a lot of early traction by sheer amount of brute force...
    But the problem is it can get you really far, but it doesn't ultimately last if
    you don't follow that with substance.
  topic: strategy
- impact_reason: Identifies a fundamental limitation of current chat UX for complex,
    multi-step workflows, hinting at the need for more contextual and collaborative
    interfaces.
  relevance_score: 9
  source: llm_enhanced
  text: Chat is very linear and very one-shot... real work, you need to gather a lot
    of information to actually produce some work product, right?
  topic: AI/ML/technical
- impact_reason: 'Suggests a concrete design principle for next-generation AI interfaces:
    moving from reactive answering to proactive, iterative collaboration (mimicking
    a human coworker).'
  relevance_score: 9
  source: llm_enhanced
  text: how can the AI ask for more information or be like, 'Hey, I wrote this first
    draft of something, give me feedback on it before I continue,' like a real coworker
    would do.
  topic: AI/ML/strategy
- impact_reason: Argues for centralized, decisive leadership (benevolent dictatorship)
    in fast-moving environments like tech startups to avoid organizational gridlock.
  relevance_score: 9
  source: llm_enhanced
  text: I believe in benevolent dictatorships. So Singapore, that's an example. I
    totally agree. I think it's super important that you have very clear vision and
    execution from the top because otherwise you're going to end up in a tragedy of
    the commons.
  topic: strategy
- impact_reason: 'Provides a nuanced approach to leadership: maintain final authority
    but invest time in explaining the ''why'' to foster trust and buy-in, even when
    demanding compliance.'
  relevance_score: 9
  source: llm_enhanced
  text: I think it's super important to explain why you're doing certain things, even
    if at the end of the day, you're like, 'Please listen to me and please trust me,'
    because you need to build mutual respect with your team...
  topic: strategy
- impact_reason: Presents a clear, actionable strategic framework for product development
    and growth, highly relevant for SaaS and AI companies focused on customer retention.
  relevance_score: 9
  source: llm_enhanced
  text: 'This is one framework that we have at Harvey: land, expand, lock in. What
    things can we build to help us land new customers? What can we do to help us expand
    and grow usage? And then third is, how do we make ourselves a moat and very sticky
    with customers?'
  topic: business
- impact_reason: A powerful critique of waterfall-style product development (the 'feature
    factory'), advocating for compressed, cross-functional collaboration.
  relevance_score: 9
  source: llm_enhanced
  text: One thing you want to avoid is this idea of feature factories... Like, you
    have this very linear process... and that is how you make really bad products,
    and that's how you demotivate your whole team...
  topic: strategy
- impact_reason: 'Provides a data-driven approach to prioritizing technical debt:
    only address it when there is clear evidence of negative impact on business outcomes,
    not just abstract ''dirtiness.'''
  relevance_score: 9
  source: llm_enhanced
  text: It's really important to do a post-mortem on that and say, 'What could we
    have done to avoid that?' And if the answer is like, 'Oh, we could have spent
    one week in two sprints ago and said, let's clean this up before we do this thing,'
    that's great because then you actually want evidence of technical debt affecting
    revenue, affecting customer outcomes...
  topic: business
- impact_reason: Introduces the 'pre-mortem' technique as a proactive risk mitigation
    strategy, leveraging team anxiety to surface potential failures before execution
    begins.
  relevance_score: 9
  source: llm_enhanced
  text: Pre-mortems are, before you start something, like a big project or big initiative,
    you want to sit down with your team and say, 'What does success look like, and
    what will prevent us from achieving that, and what will go wrong? Give me all
    your worries.'
  topic: strategy
- impact_reason: Highlights the value of pre-mortems—a proactive risk assessment technique—as
    a tool for alignment and identifying potential failure points before execution.
  relevance_score: 9
  source: llm_enhanced
  text: One thing we're starting to do more of, and this is again, me learning as
    a product leader at Harvey, is pre-mortems. Pre-mortems are, before you start
    something, like a big project or big initiative, you want to sit down with your
    team and say, "What does success look like, and what will prevent us from achieving
    that, and what will go wrong? Give me all your worries."
  topic: strategy
- impact_reason: A powerful cautionary tale about the danger of demo-driven validation
    versus real-world usage testing, leading to features users don't actually need.
  relevance_score: 9
  source: llm_enhanced
  text: I think one of them is biasing the users for what you want them to think.
    This is most useful maybe with an example. So we built this product called Vault...
    And when we showed it to people, people were like, "Oh my God, wow, that's amazing."
    And then we didn't really put it into the hands of people for live matters, live
    use cases.
  topic: business
- impact_reason: Expresses intense frustration with the current state of model selection
    interfaces, validating the feeling of many non-technical users regarding model
    proliferation.
  relevance_score: 9
  source: llm_enhanced
  text: I think it's preposterous that we're choosing our models. Whenever I'm on
    Anthropic, I'm like, "What the fuck are they? What are these ridiculous names?"
    And I have no idea what any of them are, and Grok has them too. And I'm just like,
    this is—I think it's ridiculous.
  topic: business
- impact_reason: 'Identifies a core challenge in current LLM deployment: the ''ill-constrained''
    nature of model capabilities makes consistent routing and evaluation difficult.'
  relevance_score: 9
  source: llm_enhanced
  text: The biggest problem with these models, and we have this problem, is just like
    the capabilities are very ill-constrained. You don't know exactly which model
    is better for the job.
  topic: technical
- impact_reason: Emphasizes the critical necessity of deep domain expertise (lawyers)
    when building AI products in specialized fields, as technical intuition alone
    is insufficient.
  relevance_score: 9
  source: llm_enhanced
  text: It's really hard to do product management for sometimes, for something you
    don't know what good looks like. So it's really important to rely on that domain
    expertise.
  topic: strategy
- impact_reason: Illustrates the complexity of advanced legal reasoning required by
    LLMs—it's not simple extraction but multi-clause dependency reasoning.
  relevance_score: 9
  source: llm_enhanced
  text: If you're getting the indemnification cap on a share purchase agreement, you
    have to reason over four or five different clauses because that cap is not a named
    thing in the deal. You have to reason over the dependencies of four different
    clauses in that agreement and then extract that out.
  topic: technical
- impact_reason: Predicts a major shift where foundational model providers must evolve
    into full-fledged product companies to capture end-user value, rather than remaining
    API suppliers.
  relevance_score: 9
  source: llm_enhanced
  text: I think the model companies are going to have to start to become product companies
    way more.
  topic: predictions
- impact_reason: This is a strong strategic prediction about the evolution of foundational
    model providers, suggesting a necessary shift from being pure API/infrastructure
    providers to building end-user products to capture value.
  relevance_score: 9
  source: llm_enhanced
  text: When you think about the distribution of value and usage in the model landscape,
    what do you think that looks like in three to five years' time? Yeah, I think
    the model companies are going to have to start to become product companies way
    more.
  topic: business
- impact_reason: This highlights a critical business risk for companies relying solely
    on inference revenue, suggesting that model providers who build superior, integrated
    software (like Anthropic/Claude) will dominate margins, forcing others to pivot.
  relevance_score: 9
  source: llm_enhanced
  text: The Claude companies, they're going to run the best software, they're going
    to drive margins to the ground. And so competing on inference with the Claude
    companies is really hard over time. And so if all your revenue comes from inference
    and developers, it's not an ideal place to be.
  topic: business
- impact_reason: 'A key insight for product leadership: as execution cost drops due
    to AI, the value shifts dramatically toward novel ideas and proprietary domain
    knowledge.'
  relevance_score: 9
  source: llm_enhanced
  text: In a world where, you know, prototyping and the actual execution of ideas
    is much cheaper, the ideas will matter a lot more. And, you know, how you incorporate
    unique knowledge will matter more, like domain expertise.
  topic: strategy
- impact_reason: This raises a critical, unresolved governance question regarding
    AGI operating at the executive/board level, highlighting the regulatory vacuum.
  relevance_score: 9
  source: llm_enhanced
  text: If you end up, again, AGI, you assume it can do really high-level tasks, like
    advising on a merger, advising as a board member—if you can see you—what are the
    governance frameworks for regulating an AGI that is running a company? Like, no
    one knows yet, and that's going to take time to happen.
  topic: safety
- impact_reason: Presents surprising empirical evidence suggesting AI interaction
    can lead to better mental health outcomes than human interaction in certain contexts
    due to reduced fear of judgment.
  relevance_score: 9
  source: llm_enhanced
  text: I think everyone should have AI therapists. That should probably happen at
    some point. And there's actually a study done recently where someone did a study
    where they had a bunch of participants talk to like a bot... and I think like
    60 to 70% of them reported higher sentiment and more happiness after doing that
    for like four or five months compared to the control group who mostly talked to
    humans. And it's because people don't want to be judged by other humans...
  topic: predictions
- impact_reason: 'This provides a clear strategic framework for AI integration in
    professional services: augmentation of the producer (e.g., lawyer, accountant)
    rather than complete disintermediation of the service provider.'
  relevance_score: 9
  source: llm_enhanced
  text: I think again, depending on the domain, the right thing is more likely that
    the agent partners with the producer of the work to deliver for the consumer.
    I don't think anyone suspects that we're going to get rid of law firms and have
    direct consumer law for consumers, do they?
  topic: business
- impact_reason: 'Offers a powerful career development philosophy: prioritize skill
    acquisition and growth over rigid job titles, especially relevant in fast-moving
    tech fields like AI.'
  relevance_score: 8
  source: llm_enhanced
  text: One big thing I was always optimizing for is skill set growth. What are the
    skill sets you need to know? What are your skill sets I'm good at? What are your
    skill sets I want to get better at? Versus is my title product manager, is my
    title software engineer?
  topic: career strategy
- impact_reason: Presents a pragmatic counterpoint to the 'follow your passion' mantra,
    suggesting competence drives passion and long-term success.
  relevance_score: 8
  source: llm_enhanced
  text: Do what you're good at, and it compounds. And then most often, what you're
    good at, you do what you tend to love because you're good at it.
  topic: career strategy
- impact_reason: A concise summary of the shift from ego-driven product management
    to servant leadership focused purely on organizational outcomes.
  relevance_score: 8
  source: llm_enhanced
  text: I don't have to be the main character. I just have to make the product and
    the company succeed.
  topic: strategy/leadership
- impact_reason: A bold, strategic assertion often cited in venture capital circles,
    prioritizing market size and timing above all else in company success.
  relevance_score: 8
  source: llm_enhanced
  text: Markets are the only thing that matter.
  topic: strategy/venture
- impact_reason: Identifies prioritization chaos as the primary failure point for
    product teams during hypergrowth, stemming from overwhelming customer demand.
  relevance_score: 8
  source: llm_enhanced
  text: What are the first things to break [in product teams] as you move into hypergrowth?
    ... one, it becomes super hard to know what to actually prioritize.
  topic: business
- impact_reason: 'Describes organizational failure modes during rapid scaling: decision
    paralysis or diffusion of responsibility for critical, unowned tasks.'
  relevance_score: 8
  source: llm_enhanced
  text: you also get either too many people making a decision or not enough people
    making a decision. Like you get a lot of kind of tragedy of the commons.
  topic: business
- impact_reason: This is a provocative statement challenging the common wisdom of
    consensus-driven product development, emphasizing speed, which is critical in
    fast-moving tech sectors like AI.
  relevance_score: 8
  source: llm_enhanced
  text: I believe in bluntly dictatorships. I think they're much more efficient, and
    when in a world where speed is everything, they allow for much more efficient
    and speedy process.
  topic: strategy
- impact_reason: 'Highlights a critical scaling challenge: the shift from pure top-down
    command to needing context sharing as the team grows, relevant for rapidly scaling
    AI startups.'
  relevance_score: 8
  source: llm_enhanced
  text: I think, especially as you're hyper-growing, you end up with a lot of confusion,
    or maybe the details don't actually end up in the way you want if you don't bring
    your team along the journey.
  topic: business
- impact_reason: Broadens the definition of 'communication skill' beyond writing to
    include rapid prototyping, acknowledging the role of modern tools (like AI-assisted
    coding) in idea conveyance.
  relevance_score: 8
  source: llm_enhanced
  text: I think the most important skill is communication of your ideas, whether that
    happens in a written way, whether that happens—you know, probably people love
    slides—whether it happens in slides, whether it happens if, you know, nowadays
    you can build prototypes very quickly and communicate your ideas.
  topic: strategy
- impact_reason: Redefines the purpose of a Product Requirements Document (PRD) from
    a rigid specification to a tool for achieving team consensus, improving agility.
  relevance_score: 8
  source: llm_enhanced
  text: I view PRDs as alignment docs. It is not a Bible for how something should
    work or something should happen. It is an alignment or kickoff doc.
  topic: strategy
- impact_reason: Emphasizes the need to break down silos by physically or functionally
    bringing all stakeholders (PM, Design, Engineering) together early in the process.
  relevance_score: 8
  source: llm_enhanced
  text: It is super important to compress everyone together... It is super important
    to compress everyone together.
  topic: strategy
- impact_reason: Offers a structured, phased approach to product rollout and testing
    (concentric circles), crucial for enterprise products where adoption speed varies.
  relevance_score: 8
  source: llm_enhanced
  text: I think you need to let it bake depending on the customer base. The ideal
    thing, what we do, is you branch out user testing to concentric circles, and those
    consecutive circles get bigger and bigger.
  topic: business
- impact_reason: 'Illustrates a common AI product pitfall: over-engineering a complex
    AI interpretation layer when users simply need direct, tailored control over the
    output.'
  relevance_score: 8
  source: llm_enhanced
  text: The thing that we did wrong there was actually, people want to just make those
    terms in the grid itself. People don't want the AI to convert it. They just want
    to get really tailored with what each of those terms means and not have the AI,
    I guess, all 10 terms.
  topic: business
- impact_reason: Offers a clear strategic assessment of the differing business models
    and trajectories of major foundational model labs (OpenAI vs. Anthropic).
  relevance_score: 8
  source: llm_enhanced
  text: OpenAI has deliberately chosen is now going to be a consumer product company,
    $12.9 billion revenue consumer product company, I think very clearly. I think
    Anthropic not as much as they should be, but they're very much trying to be a
    developer-first and API company.
  topic: business
- impact_reason: This emphasizes the crucial role of enterprise context and proprietary
    data (RAG/fine-tuning) in making AI tools valuable, moving beyond generic model
    capabilities.
  relevance_score: 8
  source: llm_enhanced
  text: And then it's like data and governance, particularly in the enterprise. Like
    the models are only as good as the context you give it. And so any of these products,
    can you actually tap into knowledge that the enterprise has about its code, its
    products, its architecture, and use that in more helpful ways to tailor the outputs
    that do your engines, right?
  topic: technical
- impact_reason: This predicts a shift in product ownership, elevating domain experts
    (who understand the application gap) over purely technical product managers in
    specialized fields.
  relevance_score: 8
  source: llm_enhanced
  text: Maybe the future is lawyers, doctors, domain experts are driving more of the
    product decisions because you need to bridge the gap between what the model and
    the UX is to how you actually apply it to a certain profession.
  topic: predictions
- impact_reason: 'Pinpoints the immediate, practical legal challenge for enterprise
    AI adoption: liability and indemnification when autonomous systems cause real-world
    consequences.'
  relevance_score: 8
  source: llm_enhanced
  text: We're going to need some indemnification liability of all these different
    things that if AI autonomy starts to take actions in the world, what happens and
    who is responsible?
  topic: safety
- impact_reason: A specific comparative critique of model performance in the sensitive
    domain of emotional support, suggesting differences in alignment or training data
    leading to perceived empathy gaps.
  relevance_score: 8
  source: llm_enhanced
  text: Claude does [give good emotional output]. ChatGPT doesn't. Wow. Not as empathetic.
  topic: technical
- impact_reason: Reinforces the high-performance mindset advocated by key industry
    figures, emphasizing compounding effort in areas of natural aptitude and interest.
  relevance_score: 7
  source: llm_enhanced
  text: I had read Sam Altman's post on how to be successful... you want to try to
    strive for top 1% in what you do.
  topic: strategy/mindset
- impact_reason: Advocates for constructive dissent from product leaders to ensure
    robust strategy, provided the relationship foundation is strong.
  relevance_score: 7
  source: llm_enhanced
  text: I think it's super important to push back on founders, even for the sake of
    debate, to be honest.
  topic: strategy
- impact_reason: 'Provides tactical advice for PRD creation: proactively documenting
    known points of contention speeds up alignment during review meetings.'
  relevance_score: 7
  source: llm_enhanced
  text: You want to make sure you call out all the elephants in the room and all of
    the debates at the bottom of the PRD so that, you know, when you do the kickoff,
    you can start to get alignment very early on...
  topic: strategy
- impact_reason: 'Actionable advice for managing engineering scope: treat technical
    debt remediation like a feature with defined boundaries and timelines.'
  relevance_score: 7
  source: llm_enhanced
  text: You want to time-bound it like with any other feature because otherwise, engineers
    will love to just forever, you know, clean up code...
  topic: business
- impact_reason: A surprising observation about current developer sentiment, suggesting
    a potential fatigue with greenfield development or a strong desire for code quality
    in the startup environment.
  relevance_score: 7
  source: llm_enhanced
  text: My take is I think engineers would like to clean up code in startups more
    so than write new things right now.
  topic: general technology
- impact_reason: Clearly differentiates between retrospectives (periodic review) and
    post-mortems (incident-specific review), crucial for establishing effective operational
    feedback loops.
  relevance_score: 7
  source: llm_enhanced
  text: Post-mortems are when there's an incident or issue or we made the wrong decision.
    You want to value that very specific decision or event that happened.
  topic: strategy
- impact_reason: Provides a clear, actionable definition and cadence for retrospectives,
    a fundamental practice in agile and product development.
  relevance_score: 7
  source: llm_enhanced
  text: So retros, retros are, you want to look back at some period of time and say,
    "Here's what we did well, here's what we didn't do well." And retros should be,
    you know, generally more regular, like every month, for example...
  topic: strategy
- impact_reason: 'This provides a practical workflow insight: using high-level LLMs
    (Claude) for initial prototyping and agentic environments (Replit) that abstract
    away deployment complexity, indicating developer preference for reduced friction.'
  relevance_score: 7
  source: llm_enhanced
  text: I currently use actually Claude for prototyping because I actually don't want
    to deal too much with the very nuanced stuff that VS Code or Cursor has. And so
    I end up using Claude, and then I've actually been using also Replit agent mode.
    The reason being is because Replit takes care of deployment for you.
  topic: strategy
- impact_reason: This explores the cultural boundary of AI adoption, specifically
    noting the surprising willingness of some users to use LLMs for sensitive emotional
    support, challenging traditional views on AI's role.
  relevance_score: 7
  source: llm_enhanced
  text: What are the last domains where humans actually want AI involved? So, as an
    example, in Silicon Valley, I and many of my friends actually talk to Claude or
    ChatGPT for kind of therapy or like emotional advice...
  topic: safety
- impact_reason: This illustrates the complexity of high-value enterprise extraction
    tasks, requiring multi-step reasoning and synthesis across documents, which differentiates
    advanced LLMs from simple keyword matching.
  relevance_score: 7
  source: llm_enhanced
  text: The answer isn't a verbatim text in the agreement. It's like, this is getting
    a little in the weeds on legal, but if you're getting the indemnification cap
    on a share purchase agreement, you have to reason over four or five different
    clauses because that cap is not a named thing in the deal.
  topic: technical
- impact_reason: Humorous but pointed critique of the 'PM as CEO' analogy, suggesting
    the ultimate accountability rests with the actual CEO.
  relevance_score: 6
  source: llm_enhanced
  text: You know what I find funny? The CEO is the CEO of the product. Exactly what
    it is.
  topic: role definition
- impact_reason: 'A cynical but realistic observation on user behavior: sometimes
    feature confusion subsides not because it''s fixed, but because users adapt or
    give up complaining.'
  relevance_score: 6
  source: llm_enhanced
  text: And then we started solving this by enabling, saying, "This model was good
    for this reason, and the UX is good for this reason. And so here's what you should
    do here." And some of those complaints died down, but it was mostly because people
    just got tired of complaining in general.
  topic: business
- impact_reason: A contrasting strategic assessment of Anthropic's current market
    positioning relative to OpenAI.
  relevance_score: 6
  source: llm_enhanced
  text: I think Anthropic not as much as they should be, but they're very much trying
    to be a developer-first and API company.
  topic: business
- impact_reason: Highlights that in developer tools, user experience (UX) remains
    a key differentiator, even when underlying models might be similar.
  relevance_score: 6
  source: llm_enhanced
  text: I think it's like UX is super important. You know, I've heard some engineers
    say they like Cursor's agent mode much better than VS Code. Some people have said
    the opposite. So it's like, what is the most delightful UX?
  topic: strategy
- impact_reason: Acknowledges the significant, non-technical role of branding, networking,
    and social proof in enterprise software adoption within the tech community.
  relevance_score: 6
  source: llm_enhanced
  text: Cursor has a better developer brand. They do, they do. And, you know, Silicon
    Valley ever in talks, and so a lot of the Cursor folks are good friends and networks
    of a lot of our team. And so they tend to prefer Cursor, but again, I think time
    will tell.
  topic: business
source: Unknown Source
summary: '## Podcast Summary: 20Product: How Scale AI and Harvey Build Product with
  Aatish Nayak


  This 65-minute episode of 20 Product features Aatish Nayak, Head of Product at Harvey,
  discussing his experiences scaling product at hyper-growth AI unicorns like Scale
  AI and Harvey, and offering critical perspectives on the role of Product Managers
  (PMs) in the AI era.


  ### 1. Focus Area

  The discussion centers on **Product Leadership in Hyper-Growth AI Companies**, covering
  product strategy, organizational scaling, the evolution of the PM role amidst AI
  advancements, effective product processes (pre/post-mortems, PRDs), and the critical
  importance of market selection. Specific AI applications mentioned include leveraging
  LLMs (like Claude 3.5 Sonnet) for specialized tasks like legal reasoning and the
  shift from data labeling to application-layer AI products.


  ### 2. Key Technical Insights

  *   **LLM Evaluation for Specialized Tasks:** Claude 3.5 Sonnet was specifically
  noted for its superior performance in long-form legal reasoning and drafting compared
  to previous models.

  *   **Interface Evolution Beyond Chat:** The current chat interface is viewed as
  the "command line starting point" (like MS-DOS) for the new AI frontier. Future
  product interfaces must move beyond linear, one-shot interactions to support complex
  workflows, potentially incorporating feedback loops like an AI coworker asking for
  draft revisions (an application of the **IKEA Effect** in UX).

  *   **Reducing Customer-to-Code Distance:** A key lesson from Scale AI was the necessity
  of minimizing layers between customer needs and engineering execution, often achieved
  by embedding engineers directly with customers or data contributors to capture nuance
  lost through human intermediaries.


  ### 3. Business/Investment Angle

  *   **Market Selection is Paramount:** Nayak strongly advocates that finding a huge,
  emerging market is the single most important factor for success, citing how Scale
  AI successfully pivoted its data labeling services across booming sectors (self-driving,
  robotics, government) to stay ahead of the curve.

  *   **Great Markets Mask Execution Flaws:** Conversely, exceptionally large markets
  (like on-demand robotaxis for Uber) can sustain companies through periods of internal
  chaos, highlighting the market''s power over initial execution quality.

  *   **Distribution vs. Product Moat:** While distribution (marketing, sales) drives
  initial traction ("king"), product substance is required for long-term stability
  and longevity ("president"), as users eventually see through superficial offerings.


  ### 4. Notable Companies/People

  *   **Aatish Nayak:** Head of Product at Harvey; previously held leadership roles
  at Scale AI (scaling from 40 to 800 employees) and Shield AI.

  *   **Scale AI:** Highlighted for its success in listening to frontier customers
  (e.g., Nuro) and its strategic pivots across different data-intensive markets.

  *   **OpenAI:** Mentioned in the context of early RLHF work and the pivot toward
  becoming a product company leveraging existing distribution (e.g., mobile apps).


  ### 5. Future Implications

  The future of product management involves a shift away from the "CEO of the Product"
  mentality. PMs must become **"WD-40"**—lubricating organizational friction and enabling
  domain experts (engineers, designers) to interface directly with customers. In the
  AI landscape, longevity will be found not in foundational models, but in the **UX
  and application layer** built around them, requiring significant experimentation
  to define the next generation of interfaces beyond chat.


  ### 6. Target Audience

  This episode is highly valuable for **Product Leaders, VPs of Product, and experienced
  Product Managers** operating in or adjacent to the AI/ML space, especially those
  navigating hyper-growth environments or transitioning from engineering to product
  management. It is also relevant for **Venture Capitalists** interested in market
  dynamics and execution quality in deep-tech startups.'
tags:
- artificial-intelligence
- generative-ai
- startup
- ai-infrastructure
- investment
- anthropic
- meta
- openai
title: '20Product: How Scale AI and Harvey Build Product | Why PMs Are Wrong: They
  are not the CEOs of the Product | How to do Pre and Post Mortems Effectively and
  How to Nail PRDs | The Future of Product Management in a World of AI with Aatish
  Nayak'
topics:
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 135
  prominence: 1.0
  topic: artificial intelligence
- keywords:
  - generative ai
  - genai
  - chatgpt
  - gpt
  - claude
  - text generation
  - image generation
  mentions: 23
  prominence: 1.0
  topic: generative ai
- keywords:
  - startup
  - entrepreneur
  - founder
  - venture
  mentions: 23
  prominence: 1.0
  topic: startup
- keywords:
  - gpu
  - tensor
  - training
  - inference
  - model deployment
  - vector database
  mentions: 3
  prominence: 0.3
  topic: ai infrastructure
- keywords:
  - investment
  - funding
  - valuation
  - ipo
  - acquisition
  mentions: 1
  prominence: 0.1
  topic: investment
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-10-06 14:59:19 UTC -->
