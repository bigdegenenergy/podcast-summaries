---
companies:
- category: unknown
  confidence: medium
  context: Moin, du hörst im Produktkraft Podcast. Ich bin Jan Hope, Product Management
    und Product
  name: Produktkraft Podcast
  position: 18
- category: unknown
  confidence: medium
  context: Moin, du hörst im Produktkraft Podcast. Ich bin Jan Hope, Product Management
    und Product Leadership Coach,
  name: Jan Hope
  position: 48
- category: unknown
  confidence: medium
  context: hörst im Produktkraft Podcast. Ich bin Jan Hope, Product Management und
    Product Leadership Coach, sowie freiberuflich
  name: Product Management
  position: 58
- category: unknown
  confidence: medium
  context: Podcast. Ich bin Jan Hope, Product Management und Product Leadership Coach,
    sowie freiberufliche Produktkraft. Und ich lade
  name: Product Leadership Coach
  position: 81
- category: unknown
  confidence: medium
  context: uktmanagement zu sprechen. Mein heutiger Gast ist Till Schollich. Till
    ist Senior Product Manager im AI First Star
  name: Till Schollich
  position: 288
- category: unknown
  confidence: medium
  context: . Mein heutiger Gast ist Till Schollich. Till ist Senior Product Manager
    im AI First Startup Figus Health, wo er operativ
  name: Senior Product Manager
  position: 313
- category: unknown
  confidence: medium
  context: ill Schollich. Till ist Senior Product Manager im AI First Startup Figus
    Health, wo er operativ an der Bleeding Edge von dem arbe
  name: AI First Startup Figus Health
  position: 339
- category: unknown
  confidence: medium
  context: First Startup Figus Health, wo er operativ an der Bleeding Edge von dem
    arbeitet, das Generative AI uns heute erm
  name: Bleeding Edge
  position: 392
- category: unknown
  confidence: medium
  context: erativ an der Bleeding Edge von dem arbeitet, das Generative AI uns heute
    ermöglicht. Gleichzeitig kennt Till das
  name: Generative AI
  position: 428
- category: unknown
  confidence: medium
  context: genug, tritt Till zudem auf der Republic und dem Merantext Developer Day
    als Speaker auf, um den Diskurs um den realen Ein
  name: Merantext Developer Day
  position: 676
- category: unknown
  confidence: medium
  context: ker auf, um den Diskurs um den realen Einsatz von Large Language Models
    mitzubestimmen. Ein idealer Gesprächspartner also
  name: Large Language Models
  position: 758
- category: unknown
  confidence: medium
  context: immen. Ein idealer Gesprächspartner also, um über AI Product Management
    und Design, IWALS, Prompt Management, Model Upgra
  name: AI Product Management
  position: 839
- category: unknown
  confidence: medium
  context: um über AI Product Management und Design, IWALS, Prompt Management, Model
    Upgrades, Datenschutz und die Abhängigkeit
  name: Prompt Management
  position: 880
- category: unknown
  confidence: medium
  context: Management und Design, IWALS, Prompt Management, Model Upgrades, Datenschutz
    und die Abhängigkeit zur Grundlagenf
  name: Model Upgrades
  position: 899
- category: unknown
  confidence: medium
  context: e Abhängigkeit zur Grundlagenforschung der großen Model Provider zu sprechen.
    Los geht's! Ja, Moin Till, schön dic
  name: Model Provider
  position: 983
- category: unknown
  confidence: medium
  context: roßen Model Provider zu sprechen. Los geht's! Ja, Moin Till, schön dich
    hier zu haben. Moin Jan, danke für di
  name: Moin Till
  position: 1027
- category: unknown
  confidence: medium
  context: geht's! Ja, Moin Till, schön dich hier zu haben. Moin Jan, danke für die
    Einleitung. Ja, Klasse. Bevor wir
  name: Moin Jan
  position: 1064
- category: unknown
  confidence: medium
  context: rstes Praktikum in einem Start-up gemacht, so ein Business Development,
    und da habe ich gesehen, ich fühle mich super ge
  name: Business Development
  position: 1586
- category: unknown
  confidence: medium
  context: bei einem weiteren Start-up für ein paar Monate. Gute Wahl, Produkte einzusetzen.
    Das war wirklich sehr span
  name: Gute Wahl
  position: 1831
- category: unknown
  confidence: medium
  context: obilien-Plattform in Medellín, in Kolumbien, dies La Haus. Und da habe
    ich direkt auch mit einem Team von c
  name: La Haus
  position: 2102
- category: unknown
  confidence: medium
  context: an die University of Michigan für einen Master in Human Computer Interaction
    und Digital Health. Da habe ich dann auch meine M
  name: Human Computer Interaction
  position: 2927
- category: unknown
  confidence: medium
  context: ür einen Master in Human Computer Interaction und Digital Health. Da habe
    ich dann auch meine Masterarbeit darüber
  name: Digital Health
  position: 2958
- category: unknown
  confidence: medium
  context: en, als Forschungsassistent am Institut für Human-Centered AI in Stanford,
    haben wir ein Paper dazu geschrieben
  name: Centered AI
  position: 3231
- category: unknown
  confidence: medium
  context: tart-up Grid und der akademische Blick auf Mensch-Computer Interaktionen
    und AI. Ja, und jetzt bist du dem Thema treu gebl
  name: Computer Interaktionen
  position: 3473
- category: unknown
  confidence: medium
  context: ben. Genau, jetzt seit letzten Sommer bin ich bei Ficus Health, auch von
    Anfang an mit dabei, mit Benjamin Poche
  name: Ficus Health
  position: 3597
- category: unknown
  confidence: medium
  context: i Ficus Health, auch von Anfang an mit dabei, mit Benjamin Pochermalcio
    und Mario Elzner, als CTO, den du ja auch gut ken
  name: Benjamin Pochermalcio
  position: 3645
- category: unknown
  confidence: medium
  context: nfang an mit dabei, mit Benjamin Pochermalcio und Mario Elzner, als CTO,
    den du ja auch gut kennst. Und wir baue
  name: Mario Elzner
  position: 3671
- category: unknown
  confidence: medium
  context: relativ kurz gesagt. Genau, das ist kurz gesagt. Euer Produkt ist aber
    eins, das ziemlich viel darauf setzt, da
  name: Euer Produkt
  position: 3862
- category: unknown
  confidence: medium
  context: sammenfassen kann oder Dokumente, die reinkommen. Also LLMs sind ja auch
    multimodal, dass man wirklich da ein
  name: Also LLMs
  position: 6242
- category: unknown
  confidence: medium
  context: man die dann kombiniert, dann kommen wir mehr ins Thema Produktmanagement
    mit User Research und dann sich genau die Domäne
  name: Thema Produktmanagement
  position: 6811
- category: unknown
  confidence: medium
  context: n kommen wir mehr ins Thema Produktmanagement mit User Research und dann
    sich genau die Domäne oder die Industrie
  name: User Research
  position: 6839
- category: unknown
  confidence: medium
  context: die erste Zusammenfassung. Und wenn ich jetzt als Arzt Patient oder Patientin
    zum ersten Mal sehe, dann kann ich
  name: Arzt Patient
  position: 8101
- category: unknown
  confidence: medium
  context: ele Zuhörerinnen sind damit vertraut, dass man so User Journeys skizziert
    und dann zum Beispiel verschiedene UI-S
  name: User Journeys
  position: 8508
- category: unknown
  confidence: medium
  context: wie kann man das möglich machen, was ist möglich? Ein Metapher, die ich
    manchmal ganz gerne nutze, ist, dass die
  name: Ein Metapher
  position: 8972
- category: unknown
  confidence: medium
  context: en wir später auch noch drauf zu sprechen, so zum Thema Datenschutz, da
    muss man wirklich gucken, dass das von vorne
  name: Thema Datenschutz
  position: 9797
- category: unknown
  confidence: medium
  context: ue Schritte, immer wieder neue Herausforderungen. Und Thema Datensilos
    ist natürlich im Gesundheitswesen auch sehr, sehr
  name: Und Thema Datensilos
  position: 10507
- category: unknown
  confidence: medium
  context: Output und da schreibt man ja auch Tests in eine Quality Assurance, dass
    man sagt, man baut hier ein neues Feature u
  name: Quality Assurance
  position: 11402
- category: unknown
  confidence: medium
  context: opf drückt, dann soll genau das passieren, solche Dinge Fenster öffnen.
    Und das kann man auch sehr gut testen. Be
  name: Dinge Fenster
  position: 11541
- category: unknown
  confidence: medium
  context: er öffnen. Und das kann man auch sehr gut testen. Bei LLMs und dem ganzen
    Thema Prompts hat man einen probab
  name: Bei LLMs
  position: 11602
- category: unknown
  confidence: medium
  context: man auch sehr gut testen. Bei LLMs und dem ganzen Thema Prompts hat man
    einen probabilistischen Output, das heißt
  name: Thema Prompts
  position: 11626
- category: unknown
  confidence: medium
  context: s, wie evaluiert man sie, wie schreibt man solche Test Cases dafür, dass
    es so eine ganz neue Welt, die sich d
  name: Test Cases
  position: 12203
- category: unknown
  confidence: medium
  context: t noch mehr im Problem, weil dann die sogenannten Kontext Windows, also
    wie viel Text kann man im LLM mitgeben, war
  name: Kontext Windows
  position: 14694
- category: unknown
  confidence: medium
  context: te Punkt, der zweite Punkt ist, dass es bestimmte Best Practices schon
    gibt, da ist jetzt noch nicht so die Perfek
  name: Best Practices
  position: 14927
- category: tech
  confidence: high
  context: t noch nicht so die Perfekten, aber irgendwie von Anthropic oder von DeepMind,
    die haben so eigene Guides zum
  name: Anthropic
  position: 15015
- category: unknown
  confidence: medium
  context: s man gucken, was funktioniert für seinen eigenen Use Case und was kann
    man im besten benutzen. Wie oft bist
  name: Use Case
  position: 15748
- category: unknown
  confidence: medium
  context: ber dann war es doch schneller manuell zu machen. Herr Wermer bestimmt
    auch ein umgekehrtes Beispiel, wo ist ma
  name: Herr Wermer
  position: 16198
- category: tech
  confidence: high
  context: e hier zuhören, benutzen ihr Claude, benutzen ihr perplexity, ihr ChatGPT,
    ich will jetzt kein einzelnes Produ
  name: Perplexity
  position: 18655
- category: tech
  confidence: high
  context: also am Anfang, ganz am Anfang, haben wir das in Google Sheets gemacht,
    bis das wirklich nicht mehr auszu
  name: Google
  position: 19161
- category: unknown
  confidence: medium
  context: also am Anfang, ganz am Anfang, haben wir das in Google Sheets gemacht,
    bis das wirklich nicht mehr auszuhalten
  name: Google Sheets
  position: 19161
- category: unknown
  confidence: medium
  context: bisschen einfacher zu machen und vielleicht kurze Side Story zu Lengfuse
    auch so okay, wie denkt man AI-First?
  name: Side Story
  position: 20048
- category: ai_application
  confidence: high
  context: Till Schollichs aktueller Arbeitgeber, ein AI First Startup, das ein Produkt
    zur Vereinfachung der Dokumentation in deutschen Reha-Kliniken mithilfe von LLMs
    entwickelt.
  name: Figus Health
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: Ort, an dem Till Schollich als Forschungsassistent am Institut für Human-Centered
    AI tätig war und ein Paper über das Verhalten von Chatbots bei Gesprächen über
    mentale Gesundheit schrieb.
  name: Stanford
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: Universität, an der Till Schollich einen Master in Human Computer Interaction
    und Digital Health absolvierte und seine Masterarbeit über KI-Empfehlungen zur
    Diabetesdaten-Visualisierung schrieb.
  name: University of Michigan
  source: llm_enhanced
- category: ai_community/event
  confidence: medium
  context: Plattform, auf der Till Schollich als Speaker auftritt, um den Diskurs
    um den realen Einsatz von Large Language Models mitzubestimmen.
  name: Republic
  source: llm_enhanced
- category: ai_community/event
  confidence: medium
  context: Event, auf dem Till Schollich als Speaker auftritt, um den Diskurs um den
    realen Einsatz von Large Language Models mitzubestimmen.
  name: Merantext Developer Day
  source: llm_enhanced
- category: ai_technology
  confidence: high
  context: Generische Bezeichnung für die Technologie, auf die sich das Gespräch stark
    konzentriert, oft implizit auf Modelle von großen Anbietern bezogen.
  name: Large Language Models (LLMs)
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Konkretes LLM-Produkt, das als Beispiel für Experimente und als Maßstab
    für neue Entwicklungen genannt wird (kam 2023 raus).
  name: ChatGPT
  source: llm_enhanced
- category: ai_company
  confidence: high
  context: Genannt als Anbieter von Guides zum Prompten (Best Practices für LLMs).
  name: Anthropic
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: Genannt als Anbieter von Guides zum Prompten (Best Practices für LLMs).
  name: DeepMind
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: Akademisches Institut an der Stanford University, an dem Till Schollich
    als Forschungsassistent tätig war.
  name: Institut für Human-Centered AI
  source: llm_enhanced
- category: startup_general
  confidence: low
  context: Ehemaliger Arbeitgeber von Till Schollich (Immobilien-Plattform in Medellín,
    Kolumbien). Obwohl es ein Startup war, liegt der Fokus hier nicht explizit auf
    AI/ML-Kernarbeit, aber es dient als Kontext für seine PM-Erfahrung.
  name: La Haus
  source: llm_enhanced
- category: education
  confidence: low
  context: Universität, an der Till Schollich Wirtschaftswissenschaften studierte.
  name: Zeppelin-Uni in Friedrichshafen
  source: llm_enhanced
- category: ai_company_personnel
  confidence: medium
  context: Mitgründer/CTO von Figus Health (implizit ein Unternehmen, das AI-Produkte
    baut).
  name: Benjamin Pochermalcio
  source: llm_enhanced
- category: ai_company_personnel
  confidence: medium
  context: Mitgründer/CTO von Figus Health (implizit ein Unternehmen, das AI-Produkte
    baut).
  name: Mario Elzner
  source: llm_enhanced
- category: ai_startup
  confidence: high
  context: The company the speaker works for, which uses LLMs to create structured
    summaries of patient conversations for writing discharge reports.
  name: Ficus
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: A Berlin-based prompt management system used by Ficus for versioning, searching,
    and templating prompts. They are described as an 'AI-First' company.
  name: Lengfuse
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as an AI IDE and coding agent that quickly developed and deployed
    a feature (search bar) for Lengfuse within the same day.
  name: Kösar
  source: llm_enhanced
- category: ai_infrastructure
  confidence: medium
  context: Mentioned generally alongside Lengfuse as a type of prompt management/tooling
    system.
  name: Langsmith
  source: llm_enhanced
- category: technology_tool
  confidence: medium
  context: Mentioned in comparison to prompt management systems, suggesting a desired
    future level of version control functionality for prompts.
  name: Git
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as a widely used chatbot/LLM that the speaker and listeners likely
    use.
  name: Perplexity
  source: llm_enhanced
- category: ai_model
  confidence: high
  context: A specific model version from Anthropic that Ficus recently switched to,
    noting its improved instruction-following capabilities.
  name: Claude Sonnet 4
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: The platform through which the company accesses LLM models (like Anthropic's)
    in a data-privacy compliant way, hosted in Frankfurt, Germany.
  name: AWS Bedrock
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: The company providing AWS Bedrock services, with whom the speaker's company
    has a contract for compliant cloud hosting.
  name: Amazon
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Mentioned as an alternative major cloud provider (alongside Amazon and
    Microsoft) where one could potentially host LLM services compliantly.
  name: Google
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Mentioned as an alternative major cloud provider (alongside Amazon and
    Google) where one could potentially host LLM services compliantly.
  name: Microsoft
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: Mentioned in the context of massive investments in AI infrastructure, specifically
    the chips required to run large data centers and train models.
  name: Nvidia
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as one of the two biggest names in the open-source AI world and
    previously seen as a major AI hope for Germany/Europe, though their strategy seems
    to have shifted.
  name: Mistral
  source: llm_enhanced
- category: research_institution
  confidence: high
  context: Mentioned in reference to a report stating 95% of AI pilots fail due to
    process misalignment, and also in the context of the speaker's Master's thesis
    involving Diabetes data visualization and AI recommendations.
  name: MIT
  source: llm_enhanced
- category: ai_startup
  confidence: high
  context: An AI startup the speaker shares office space with at the Merantix AI Campus
    in Berlin. They develop a medical product that helps radiologists diagnose breast
    cancer using AI recommendations.
  name: Bewara
  source: llm_enhanced
- category: ai_ecosystem
  confidence: high
  context: The physical location in Berlin where the speaker's company shares office
    space with the AI startup Bewara.
  name: Merantix AI Campus
  source: llm_enhanced
date: 2025-10-15 05:00:00 +0000
duration: 84
has_transcript: false
layout: episode
llm_enhanced: true
original_url: https://audio.listennotes.com/e/p/8001cb7d994c45128e6bfadbe088bc4f/
processing_date: 2025-10-16 04:37:22 +0000
quotes:
- length: 129
  relevance_score: 4
  text: Also LLMs sind ja auch multimodal, dass man wirklich da eine gute Struktur
    aufbauen kann, um die Daten sehr gut nutzbar zu machen
  topics: []
- length: 213
  relevance_score: 4
  text: Jetzt könnte ich mir vorstellen, dass jemand, der nicht selbst mit LLMs, Large
    Language Models, jeden Tag arbeitet, jetzt sagt, ja, Moment, was unterscheidet
    denn jetzt unsere Datenstruktur von deren Datenstruktur
  topics: []
- length: 185
  relevance_score: 4
  text: Bei LLMs und dem ganzen Thema Prompts hat man einen probabilistischen Output,
    das heißt, man kann eine Antwort zehnmal generieren und jedes Mal kommt es um
    ein bisschen was anderes raus
  topics: []
- length: 121
  relevance_score: 4
  text: Man kann sich alle sagen, okay, Eval LLMs einfach speziell trainierte Large
    Language Models, die dann Evals machen sollen
  topics: []
- length: 137
  relevance_score: 4
  text: Und da vielleicht auch ein interessanter Punkt ist das sogenannte Shadow Use
    von LLM und Chatbots sehr hoch ist in ganz vielen Industrien
  topics: []
- length: 281
  relevance_score: 3
  text: Ich würde behaupten, an 100 Prozent der Leute, die hier zuhören, benutzen
    ihr Claude, benutzen ihr perplexity, ihr ChatGPT, ich will jetzt kein einzelnes
    Produkt hervorheben, aber so selbst in den Chatbot parallel am Laufen zu haben,
    das machen ja viele, gepromptet haben viele mal
  topics: []
- impact_reason: Lists the core, high-value topics to be covered, specifically highlighting
    key AI product management challenges like Prompt Management, Model Upgrades, and
    dependency on foundational model providers.
  relevance_score: 10
  source: llm_enhanced
  text: Ein idealer Gesprächspartner also, um über AI Product Management und Design,
    IWALS, Prompt Management, Model Upgrades, Datenschutz und die Abhängigkeit zur
    Grundlagenforschung der großen Model Provider zu sprechen.
  topic: Strategy/Topics
- impact_reason: 'Provides a clear differentiator between ''AI-First'' and legacy
    companies: the ability to structure data specifically for LLM consumption. This
    is a critical technical and strategic point.'
  relevance_score: 10
  source: llm_enhanced
  text: Also ich würde sagen, dass Unternehmen, die wirklich AI-First sind, sehr stark
    darauf gucken, wie Daten reinkommen, wie die modelliert werden und wie die dann
    auch von LLMs weiter verarbeitet werden können, während Unternehmen, die es schon
    länger gibt, haben Datenmodelle, wo es dann häufiger, häufiger schwieriger ist,
    diese Daten für LLMs verarbeitbar zu machen.
  topic: Strategy/Technical Insight
- impact_reason: 'Defines a new paradigm for product thinking in the AI era: simultaneously
    modeling the UI journey and the underlying data/AI processing journey (''the second
    level'').'
  relevance_score: 10
  source: llm_enhanced
  text: Ich meine, viele Zuhörerinnen sind damit vertraut, dass man so User Journeys
    skizziert und dann zum Beispiel verschiedene UI-Schritte visualisiert entlang
    dieser Nutzer-Journey. In dem Fall denkt ihr aber immer die zweite Ebene gleich
    mit, was kann hier datenseitig passieren? Und ihr denkt nicht nur, also ihr denkt
    wahrscheinlich auch an die AI-Ebene, ja, gerade an die UI-Ebene, aber eben nicht
    nur an die UI-Ebene, sondern auch was passiert an welchem Schritt datenseitig,
    wie kann man das möglich machen, was ist möglich?
  topic: Product Management/Strategy
- impact_reason: Crucially contrasts traditional deterministic software testing with
    the challenge of testing LLMs, which produce probabilistic outputs, defining the
    core difficulty in AI QA.
  relevance_score: 10
  source: llm_enhanced
  text: wenn man die mit Code baut, dann hat man meistens einen deterministischen
    Output und da schreibt man ja auch Tests in eine Quality Assurance, dass man sagt,
    man baut hier ein neues Feature und wenn man auf den Knopf drückt, dann soll genau
    das passieren, solche Dinge Fenster öffnen. Und das kann man auch sehr gut testen.
    Bei LLMs und dem ganzen Thema Prompts hat man einen probabilistischen Output,
    das heißt, man kann eine Antwort zehnmal generieren und jedes Mal kommt es um
    ein bisschen was anderes raus.
  topic: Technical/Product Management
- impact_reason: 'Provides a crucial analogy for product managers: treating an LLM
    prompt like a detailed engineering ticket, emphasizing the need for specificity.'
  relevance_score: 10
  source: llm_enhanced
  text: Prompt ist ja eine Anweisung an das LLM, was gemacht werden soll und da gibt
    es dann auch einige Leute, die, oder ich finde es generell hilfreich, sich so
    ein bisschen vorzustellen, dass LLM ist eine Entität wie eine andere Person, ohne
    es jetzt zu stark zu vermenschlichen, aber es ist quasi eine Anweisung an eine
    andere Person oder an das LLM und ich würde sagen, als Produktmanager ist man
    ganz gut dazu equipped, sage ich mal, so eine Anweisung zu schreiben, weil in
    unserem täglichen Arbeitsleben schreiben wir viele Tickets für Engineers, was
    genau das ist, also eine Anweisung an eine andere Person, was gemacht werden soll
    und da muss man auch sehr detailliert sein, weil wenn man dann bestimmte Dinge
    offen lässt, dann entscheidet die andere Person, beziehungsweise das LLM und das
    ist so der erste Punkt quasi.
  topic: strategy/technical
- impact_reason: Detailed description of a high-value, multi-stage AI workflow in
    a regulated industry (healthcare documentation), showing how LLMs aggregate information
    for a final output.
  relevance_score: 10
  source: llm_enhanced
  text: Was wir machen ist, zum einen kann man ein Patientengespräch aufnehmen mit
    einem Mikrofon, das wird dann transkribiert und dieses Transkript gibt man dann
    einem LLM, wo man dann eine strukturierte Zusammenfassung rausbekommt. Und dann
    hat man über diese Patientenreise hat man dann mehrere Zusammenfassungen von Gesprächen,
    man kann auch Dokumente hochladen und Zusammenfassungen davon bekommen und dann
    am Ende drückt man auf den Knopf, einen Entlassbericht schreiben und all diese
    Zusammenfassungen sind dann die Grundlage, um dann den finalen Entlassbericht
    für die Reha zu schreiben.
  topic: business/predictions
- impact_reason: 'Provides a clear roadmap for prompt management maturity: starting
    manual (Sheets) -> adopting dedicated tools (Lengfuse) for versioning, search,
    and templating, enabling atomic updates to production prompts.'
  relevance_score: 10
  source: llm_enhanced
  text: Wir haben tatsächlich, also am Anfang, ganz am Anfang, haben wir das in Google
    Sheets gemacht, bis das wirklich nicht mehr auszuhalten war und dann haben wir
    nach einem Produkt gesucht und wir nutzen aktuell Lengfuse. Weil man da Prompts
    auch versionieren kann, man kann die gut durchsuchen, man kann Templates verwenden,
    was auch sehr hilfreich ist, also dass man so ein bisschen modular denkt, weil
    viele Teile von Prompts sind wiederverwertbar, das heißt, man muss jetzt nicht
    immer den Prompt ganz von neu schreiben und dann ist es super hilfreich solche
    Templates zu haben, weil man dann einzelne Templates verbessern kann und dann
    auf Produktion die deployen kann quasi ein Update und dann haben auf einmal alle
    Kunden diese neue Version des Prompts.
  topic: business/strategy
- impact_reason: 'Crucial strategic insight: treating prompts as first-class code
    assets requiring version control, review, and collaboration mechanisms (like Git).'
  relevance_score: 10
  source: llm_enhanced
  text: Man muss auch sagen, das war natürlich ein kleines Feature und das hat dann
    auch gepasst, wahrscheinlich in der Roadmap, eine Sache, worauf wir noch warten
    und das vielleicht auch ein interessanter Punkt dazu, wie man mit Prompts arbeitet,
    ist ein Review und Kommentar Feature für Prompts, also ein bisschen wie in GitHub,
    weil wir auch gelernt haben über die Zeit, dass man Prompts wie Code mehr oder
    weniger behandeln sollte.
  topic: strategy/technical
- impact_reason: 'Identifies the core challenge of LLM development: non-determinism
    and the resulting difficulty in proving performance improvements.'
  relevance_score: 10
  source: llm_enhanced
  text: Du hast es vorhin schon angesprochen, es sind ja nicht deterministische Systeme,
    also da kommt immer was anderes raus. Wie geht man denn daran, wirklich sicherzustellen,
    dass man jetzt hier was verbessert hat oder nicht?
  topic: technical/safety
- impact_reason: Detailed explanation of a robust, human-in-the-loop evaluation framework
    (Question Answering over Summaries) to measure prompt performance against specific
    factual criteria, crucial for high-stakes applications.
  relevance_score: 10
  source: llm_enhanced
  text: Wir haben uns da auch einige Gedanken dazu gemacht und wie wir das machen
    jetzt zum Thema Zusammenfassung, also wie kann man die bewerten? Wir haben ein
    Datenset von Transkripten von Patientengesprächen, mit der Einwilligung der Leute
    und dann daraus generierte Zusammenfassungen und Ärztinnen haben dann kommentiert,
    in der Zusammenfassung fehlt das und das und dann haben wir eine Liste von Fragen
    erstellt für die Zusammenfassung, um dann zu sehen, okay, ist zum Beispiel das
    Medikament X Y Z genannt, gibt es Schmerzen am rechten Knie und dann hast du diese
    Liste von Fragen, die dann ein LLM beantworten kann und sagen wir mal, du hast
    dann 40 Fragen für diese Zusammenfassung, dann kannst du quasi sehen, werden die
    Fragen korrekt beantwortet und dann jedes Mal, wenn du deinen Prompt veränderst
    oder es ein neue
  topic: technical/safety
- impact_reason: Details a robust, domain-specific evaluation methodology using human-annotated
    ground truth and structured question sets for summarization tasks.
  relevance_score: 10
  source: llm_enhanced
  text: Wir haben ein Datenset von Transkripten von Patientengesprächen, mit der Einwilligung
    der Leute und dann daraus generierte Zusammenfassungen und Ärztinnen haben dann
    kommentiert, in der Zusammenfassung fehlt das und das und dann haben wir eine
    Liste von Fragen erstellt für die Zusammenfassung, um dann zu sehen, okay, ist
    zum Beispiel das Medikament X Y Z genannt, gibt es Schmerzen am rechten Knie und
    dann hast du diese Liste von Fragen, die dann ein LLM beantworten kann
  topic: technical/strategy
- impact_reason: Introduces the practical application of 'LLM-as-Judge' for automated,
    scalable quality assessment, reducing manual review load.
  relevance_score: 10
  source: llm_enhanced
  text: dann kannst du quasi sehen, werden die Fragen korrekt beantwortet und dann
    jedes Mal, wenn du deinen Prompt veränderst oder es ein neues Modell gibt, dann
    kannst du in dir eine neue Zusammenfassung erstellen lassen und dann einmal, das
    nennt sich LLM-as-Judge, drüber laufen lassen, um dann zu sehen, okay, von diesen
    40 Fragen, wie viele davon sind korrekt beantwortet.
  topic: technical/strategy
- impact_reason: Highlights the critical risk of model drift/quality degradation even
    without explicit version changes, emphasizing dependency risk on external providers.
  relevance_score: 10
  source: llm_enhanced
  text: Aber auch wenn die Prompts gleichbleiben, kann es sein, dass sich das Verhalten
    des Modells etwas verändert. Auch wenn es jetzt nicht von Version 3.8 auf 4.0
    zum Beispiel sich verändert, hast du vielleicht gesehen vor ein paar Wochen, hat
    Anthropic ein Statement rausgebracht, wo sich dafür entschuldigt haben, dass teilweise
    bei ihren Modellen die Qualität der Outputs schlechter war
  topic: safety/strategy
- impact_reason: 'A deep dive into prompt engineering difficulty: Formatting preferences
    can be deeply embedded in system prompts, requiring complex, multi-line instructions
    to override, rather than simple negation.'
  relevance_score: 10
  source: llm_enhanced
  text: An der ich vor ein paar Wochen saß, dann nach dem Update ist das anscheinend,
    ich denke mal, dem System Prompt von einem neuen Modell wird sehr viel Wert auf
    Formatierung gelegt, also dass die Überschriften mit so Sternchen sind und das
    ist anscheinend so tief im Modell verankert, dass ein einfacher Satz, wo sie sagt,
    bitte keine Sonderzeichen in den Überschriften verwenden, reicht nicht aus.
  topic: technical
- impact_reason: 'A critical statement on data privacy and security in regulated industries:
    ensuring data isolation and preventing model training on sensitive customer data.'
  relevance_score: 10
  source: llm_enhanced
  text: Und das ist uns und natürlich auch unseren Kunden sehr wichtig, dass diese
    sehr sensiblen Gesundheitsdaten nur durch Modelle verarbeitet werden, die da auch
    isoliert laufen und wo dann keine Daten zum Training von irgendwelchen neuen Modellen
    benutzt werden.
  topic: safety
- impact_reason: Provides a concrete, high-risk example of Shadow Use in healthcare,
    clearly explaining the mechanism of data leakage when using consumer-grade accounts
    for sensitive work.
  relevance_score: 10
  source: llm_enhanced
  text: Das heißt, dass ich jetzt als Arzt oder Ärztin meinen eigenen ChatGPT-Account
    habe und ich mache mir einige Notizen am Computer und dann habe ich alle die Notizen
    mit einem kurzen Prompt in ChatGPT und sage, bitte schreibt mir einen Entlassbericht
    daraus. Das Problem ist, wenn es mein privater ChatGPT-Account ist und da jetzt
    kein Enterprise dahinter steht, [...] dann gehen diese Daten direkt an die Provider
    und die können dann für das Training genutzt werden.
  topic: safety/ethics
- impact_reason: 'A critical lesson in AI product management: Success hinges not just
    on the model/product quality, but fundamentally on adapting the underlying business/operational
    processes.'
  relevance_score: 10
  source: llm_enhanced
  text: Man kann ein tolles AI-Produkt entwickeln und designen und es sieht super
    aus und es hat den Output, den man sich wünscht, aber was wir eine wirklich sehr,
    sehr große Lektion, die wir gelernt haben, war, dass das Produkt alleine nicht
    ausreicht, sondern man muss sich auch den Prozess anschauen.
  topic: business/strategy
- impact_reason: 'Pinpoints the root cause of the 95% failure rate: deploying AI tools
    without process redesign leads to increased friction and workload, rather than
    efficiency gains.'
  relevance_score: 10
  source: llm_enhanced
  text: Und der Grund war, dass in diesen Fällen die Prozesse nicht angepasst wurden
    und es wurde quasi einfach nur dieses Tool dahin geworfen und wurde den Leuten
    gesagt, bitte nutzt es. Aber dann wurde es quasi neben den bestehenden Prozessen
    genutzt und dann ist es eigentlich noch mehr Arbeit.
  topic: business/strategy
- impact_reason: 'A concise, critical statement on technology adoption: technology
    is an enabler, not the solution itself. It must serve the problem.'
  relevance_score: 10
  source: llm_enhanced
  text: Technologie darf nicht Front & Center erst mal da sein und dann wird sie schon
    automatisch funktionieren, sondern ja, sie muss helfen, Probleme zu lösen, dann
    funktioniert sie auch.
  topic: strategy
- impact_reason: Poses the critical challenge of maintaining human oversight ('Human
    in the Loop' - HITL) when LLMs make it easy for users to offload cognitive tasks.
  relevance_score: 10
  source: llm_enhanced
  text: Wie handelt man das in der Produktentwicklung dafür zu sorgen, dass das auf
    Nutzerseite nicht so leicht passiert an Stellen, wo man den Menschen haben möchte
    im LLUP?
  topic: safety/product development
- impact_reason: 'Defines the core tension in deploying current generative AI: balancing
    necessary user trust with the critical need for verification due to model fallibility.'
  relevance_score: 10
  source: llm_enhanced
  text: Ja, das ist sehr wichtig, die Balance zu finden von Vertrauen und Verifizierung,
    weil man will ja natürlich Vertrauen aufbauen in das Produkt, weil wenn ich dem
    Produkt nie vertraue, dann ist es auch nicht viel wert, aber auch nicht zu viel
    Vertrauen, weil wenn man immer nur sagt, okay, die Zusammenfassung passt, das
    ist alles richtig und man verifiziert es nie, dann kann es auch zu Problemen führen,
    weil wir aktuell auf einem Stand sind, wo diese KI-Modelle nicht immer 100% richtig
    liegen.
  topic: safety/technical
- impact_reason: Establishes the guest's credibility as someone working at the forefront
    ('Bleeding Edge') of Generative AI product management, setting the stage for practical
    insights.
  relevance_score: 9
  source: llm_enhanced
  text: Mein heutiger Gast ist Till Schollich. Till ist Senior Product Manager im
    AI First Startup Figus Health, wo er operativ an der Bleeding Edge von dem arbeitet,
    das Generative AI uns heute ermöglicht.
  topic: Strategy/Introduction
- impact_reason: Suggests that starting greenfield allows for proactive data modeling
    tailored to LLM capabilities (like summarization), which is difficult for established
    systems.
  relevance_score: 9
  source: llm_enhanced
  text: Und da würde ich sagen, hat man einen Vorteil als junges Unternehmen, was
    ein bisschen eine grüne Wiese ist, weil man sagen kann, okay, wir wollen, dass
    die Daten so aufgenommen werden und man hat schon bestimmte Funktionen im Kopf,
    um dann die Software genau so zu bauen, dass man zum Beispiel Gespräche nicht
    nur transkribieren, sondern auch zusammenfassen kann oder Dokumente, die reinkommen.
  topic: Business/Strategy
- impact_reason: Offers a concrete, high-impact application of GenAI in a regulated
    industry (healthcare), moving beyond simple digitization to active data generation
    and summarization via voice bots.
  relevance_score: 9
  source: llm_enhanced
  text: Also zum Beispiel, bevor der Patient oder die Patientin reinkommt, könnte
    man sagen, die Anamnese wird schon mal nicht nur von einem klassischen Anamnesebogen,
    der heute meistens handschriftlich gemacht wird. [...] wenn man jetzt in der Welt
    von KI denkt, könnte man auch sagen, man macht einen Voice-Chatbot, der einen
    anruft und dann das Gespräch aufzeichnet. Und da bekommt man schon mal die erste
    Zusammenfassung.
  topic: Predictions/Application
- impact_reason: 'Highlights a major deployment hurdle for AI in regulated sectors:
    data locality (on-premise vs. cloud) and the resulting complexity of local model
    deployment vs. cloud API calls.'
  relevance_score: 9
  source: llm_enhanced
  text: man muss da wirklich gucken, dass das von vorne rein mitgedacht ist, wie die
    KI an die Daten kommt, wo die liegen, wie die verarbeitet werden. Und wenn das
    eben zum Beispiel jetzt ist auch wieder ein Beispiel aus der Kliniklandschaft,
    viele Daten liegen lokal on-premise bei den Kliniken und sind jetzt nicht immer
    in der Cloud verfügbar. Und wenn das der Fall ist, dann ist es natürlich schwierig
    zum Beispiel ein KI-Modell lokal bei einer Klinik laufen zu lassen.
  topic: Deployment/Safety (Data Governance)
- impact_reason: Emphasizes the novelty of Prompt Engineering and Evaluation as a
    discipline, noting that the entire industry is learning simultaneously, leveling
    the playing field despite prior experience.
  relevance_score: 9
  source: llm_enhanced
  text: Und da muss man gucken, wie schreibt man die Prompts, wie evaluiert man sie,
    wie schreibt man solche Test Cases dafür, dass es so eine ganz neue Welt, die
    sich da gerade auftut, wo es dann neue Frameworks gibt und ja, wo alle eigentlich
    einen ähnlichen Wissensstand haben, weil eben ChatGPT kam 2023 raus und egal,
    wie lange man schon Produktmanagement macht, dann müssen wir alle so ein bisschen
    lernen.
  topic: Product Management/Learning Curve
- impact_reason: Offers a practical, multi-step prompting technique (chaining/decomposition)
    to manage complexity.
  relevance_score: 9
  source: llm_enhanced
  text: Es kann hilfreich sein, Prompts aufzuteilen, dass man sagt, okay, der erste
    Prompt guckt sich nur dieses Thema an oder zieht nur diese Informationen raus
    und jetzt zweite Prompt, die anderen Informationen.
  topic: technical
- impact_reason: 'Crucial boundary setting for AI in sensitive domains: focusing on
    documentation/abstraction rather than diagnosis, addressing regulatory/safety
    concerns.'
  relevance_score: 9
  source: llm_enhanced
  text: Wir stellen keine Diagnosen, wir sind kein Medizinprodukt, sondern wir dokumentieren
    nur und das, also die Zusammenfassung, da musste das LLM natürlich schon ein bisschen
    auch abstrahieren, quasi was sind gerade subjektive Beeinträchtigungen...
  topic: safety/business
- impact_reason: Confirms the emergence and formalization of the 'Prompt Engineer'
    role within tech teams.
  relevance_score: 9
  source: llm_enhanced
  text: Wir haben gerade diese Woche hat bei uns eine Werkstudentin angefangen als
    Prompt Engineer. Erst mal Prompt Engineer, später auch noch Software Engineering,
    aber das ist ja so eine ganz neue Rolle, die es so gibt...
  topic: strategy/business
- impact_reason: 'Highlights the core challenge in LLM development: reliably measuring
    improvement due to non-deterministic outputs, emphasizing the critical nature
    of ''Evaluation'' (Evaluierung).'
  relevance_score: 9
  source: llm_enhanced
  text: Wie geht man denn daran, wirklich sicherzustellen, dass man jetzt hier was
    verbessert hat oder nicht? Ja, das ist ein echtes ganz wichtiger Punkt und auch
    ein sehr dynamisches Feld aktuell, das ganze Thema Evaluierung
  topic: technical/strategy
- impact_reason: 'Crucial business/product strategy: Abstracting prompt complexity
    away from the end-user to improve usability and adoption, shifting the burden
    onto the provider.'
  relevance_score: 9
  source: llm_enhanced
  text: Aber wir haben uns dagegen entschieden, ein Chat-Interface zu machen im Produkt.
    Also, wir versuchen wirklich diese Komplexität des Promptens vor den Nutzen zu
    verstecken, dass es quasi, dass diese Last auf uns fällt.
  topic: business/strategy
- impact_reason: 'A key strategic insight for building successful B2B/enterprise AI
    products: maximizing user value by minimizing technical friction.'
  relevance_score: 9
  source: llm_enhanced
  text: Und das ist so ein bisschen das Geheimnis meiner Meinung nach, dass man die
    Komplexität für die Nutzerseite reduziert, aber trotzdem noch gute Prompts hat
  topic: strategy
- impact_reason: Directly addresses the vendor lock-in and quality monitoring challenge
    inherent in relying on third-party foundational models.
  relevance_score: 9
  source: llm_enhanced
  text: Aber das ist halt auch so eine gewisse Abhängigkeit von diesen Providern,
    weil auch wenn man vielleicht nichts ändert, vielleicht verändert sich trotzdem
    die Qualität und es wäre gut als KI-Unternehmen zu wissen, okay, wo stehen wir
    gerade, verschlechtert es sich eigentlich gerade im Hintergrund, obwohl wir gar
    nichts machen.
  topic: business/strategy
- impact_reason: Provides a concrete example of a model improvement (Claude Sonnet
    4) focusing on 'Instruction-Following' and defines this key technical metric.
  relevance_score: 9
  source: llm_enhanced
  text: Also zum Beispiel bei uns haben wir vor einigen Wochen, haben wir umgestellt
    auf Claude Sonnet 4 und da hat man gemerkt, dass es sehr viel besser im Instruction-Following
    ist und das ist ein Begriff, das man quasi sagt, hier ist der Prompt, das ist
    die Anweisung und das Instruction-Following ist, wie genau das LLM diese Anweisung
    befolgt
  topic: technical
- impact_reason: Illustrates how improved instruction following can break established
    product behaviors (e.g., format switching from bullet points to prose), requiring
    prompt rollback or adjustment.
  relevance_score: 9
  source: llm_enhanced
  text: Und gleichzeitig kann es dann auch dazu führen, dass die alten Prompts dann
    ein anderes Verhalten haben. Also das zum Beispiel ein Kapitel wohl im Stichpunkten
    geschrieben und jetzt mit dem neuen Modell war es dann im Fließtext und dann haben
    wir uns Kunden gesagt, ja, okay, warum, also wir wollen es nicht so, sondern bitte
    wieder zurückstellen
  topic: technical/strategy
- impact_reason: 'Defines the current era for AI startups: rapid value creation by
    leveraging pre-trained foundation models instead of building every component from
    scratch.'
  relevance_score: 9
  source: llm_enhanced
  text: Und auch für KI-Startups, wir konnten anfangen, wir konnten direkt dieses
    Modell einbinden und wir mussten jetzt nicht erstmal ein eigenes Speech-to-Text-Modell
    trainieren und dann noch ein eigenes LLM trainieren oder so. Also das ist natürlich
    eine neue Ära für Start-ups, gerade, dass man so schnell ein neues Produkt bauen
    kann, was auch Wert schafft.
  topic: business
- impact_reason: Details the infrastructure choice (AWS Bedrock) driven by strict
    compliance needs (data isolation) in sensitive sectors like healthcare, which
    introduces latency in accessing cutting-edge models.
  relevance_score: 9
  source: llm_enhanced
  text: Also wir zum Beispiel haben unsere Modelle beziehen wir über AWS Bedrock.
    Da laufen die isoliert, also datenschutzrechtlich compliant und da können wir
    jetzt nicht sagen, ja, wir schalten das neue Modell frei, sondern wir müssen halt
    darauf warten, dass es das für uns hier gibt.
  topic: business/safety
- impact_reason: Identifies the widespread, often unmanaged, 'Shadow Use' of public
    LLMs within professional settings, posing significant compliance and data leakage
    risks.
  relevance_score: 9
  source: llm_enhanced
  text: Da vielleicht auch ein interessanter Punkt ist das sogenannte Shadow Use von
    LLM und Chatbots sehr hoch ist in ganz vielen Industrien.
  topic: safety/business
- impact_reason: 'Highlights a critical economic concern: the ''value drain'' where
    European application builders send significant revenue to US-based cloud and model
    providers, impacting regional value capture.'
  relevance_score: 9
  source: llm_enhanced
  text: Die Sache ist, dass wenn man diese Modelle benutzt, ich habe ja die Vorteile
    genannt, es geht ziemlich viel von den Einnahmen an den Cloud-Provider und die
    Modell-Provider. Und das ist dann auch quasi Wertschöpfung, die aus Europa abgeleitet
    wird, weil natürlich alle großen Unternehmen sitzen, also Tech-Unternehmen, sitzen
    in den USA, die dann diese Wertschöpfung für sich vereint haben.
  topic: business/strategy
- impact_reason: A strong strategic call for Europe to secure its own foundational
    infrastructure (servers and chips) to ensure technological sovereignty and operational
    independence for AI.
  relevance_score: 9
  source: llm_enhanced
  text: Ja, also ich finde es schon wichtig, dass wir uns in Deutschland, Europa die
    technische Infrastruktur haben, um diese Modelle zu betreiben, also das sind eben
    die Server und die Chips.
  topic: strategy/predictions
- impact_reason: Cites a high-impact statistic (95% pilot failure rate) regarding
    AI adoption, immediately framing the subsequent discussion on *why* this happens.
  relevance_score: 9
  source: llm_enhanced
  text: Da gibt es auch eine interessante Studie zu, war vor einigen Wochen ein MIT-Bericht,
    wo drin stand, 95 Prozent der KI-Piloten sind Fehlschläge.
  topic: business/predictions
- impact_reason: 'Provides the solution to pilot failure: having the ''courage'' to
    fundamentally restructure processes, eliminate redundant steps, and align data
    flow with the new AI tool''s capabilities to realize true efficiency.'
  relevance_score: 9
  source: llm_enhanced
  text: Aber wenn man dann den nächsten Schritt geht und sagt, okay, man sieht hier
    eine Möglichkeit, sich effizienter aufzustellen, dann und dann auch, ich würde
    es auch nennen, Mut hat, seinen Prozess anzupassen und zu sagen, okay, von diesen
    zehn Prozessschritten können wir eigentlich irgendwie drei rausschneiden und die
    anderen stellen wir dann so um, dass dann kommen wir wieder zu den Daten, dass
    die Daten an die richtige Stelle kommen und die Leute sollten dann das Tool so
    benutzen und dann sieht man wirklich auch die Effizienzgewinne und auch mehr Zufriedenheit
    von Mitarbeitenden.
  topic: business/strategy
- impact_reason: 'A key differentiator for their AI product (AI Scribe): handling
    longitudinal data across multiple sessions, contrasting with standard single-session
    summarization tools.'
  relevance_score: 9
  source: llm_enhanced
  text: wo wir uns versuchen zu unterscheiden, ist, dass die Reha über mehrere Wochen
    geht und dass man Zusammenfassungen von den verschiedenen Gesprächen in einem
    Fall speichert und dann erst am Ende aus diesen Zusammenfassungen einen Entlassbericht
    generiert, weil eben so in den Kliniken gearbeitet wird.
  topic: technical/product differentiation
- impact_reason: Reiterates the fundamental truth of product management, warning against
    getting distracted by novel technology (like AI) at the expense of solving real
    user problems.
  relevance_score: 9
  source: llm_enhanced
  text: Denk darüber nach, wie sich das in das Leben der Leute einbindet und wie es
    dann wirklich ein Problem löst. Was ja eigentlich die Fundamentals von digitaler
    Produktarbeit sind.
  topic: strategy
- impact_reason: Draws a powerful historical analogy (the 'app for everything' mistake)
    to caution against using AI merely as a shiny wrapper without solving a genuine,
    context-specific problem.
  relevance_score: 9
  source: llm_enhanced
  text: Ähnlich wie damals, als die mobile Revolution war und jeder wollte eine App,
    wobei die Hälfte der Apps einfach irgendwie nur die Homepage von der Firma war.
    Niemand hat sich die App runtergeladen, weil das löst jetzt hier kein Problem,
    sich von unterwegs als App eine Homepage anzugucken.
  topic: strategy
- impact_reason: A pragmatic assessment of current LLM limitations, reinforcing the
    necessity of HITL mechanisms now, even while acknowledging future potential.
  relevance_score: 9
  source: llm_enhanced
  text: In Zukunft, wer weiß, aber aktuell ist es so, dass Fehler gemacht werden und
    dass es wichtig ist, die Menschen im LLUP zu behalten und da kann man verschiedene
    Wege finden, um den Menschen da einzubinden.
  topic: safety/predictions
- impact_reason: 'Suggests a concrete, low-friction implementation for HITL: a ''digital
    signature'' or explicit verification step that changes the user''s psychological
    engagement with the AI output.'
  relevance_score: 9
  source: llm_enhanced
  text: Also wir schauen uns gerade an ein sehr simples, so als ersten Schritt, eine
    Verifizierfunktion zu haben für eine Zusammenfassung oder einen Entlassbericht,
    dass man sagt, ich als Mensch habe das verifiziert, wie so eine digitale Unterschrift,
    damit man einfach auch psychologisch dann nochmal anders rangeht.
  topic: safety/product development
- impact_reason: Emphasizes the need for an explicit, conscious commitment from the
    human operator to validate AI-generated content, moving beyond passive acceptance.
  relevance_score: 9
  source: llm_enhanced
  text: ich muss an irgendeiner Stelle nochmal ganz klar sagen, ich als Mensch stehe
    dahinter, dass dieser Text in Ordnung ist und ich drücke nicht einfach nur speichern.
  topic: safety
- impact_reason: Highlights that 'AI-First' thinking extends beyond the customer-facing
    product into internal operational efficiency, a key strategic insight for adoption.
  relevance_score: 8
  source: llm_enhanced
  text: Also nicht nur im Produkt, sondern auch in unseren Prozessen intern, wie kann
    man AI-Tools gut nutzen, um sich selber auch effizienter und effektiver zu machen?
  topic: Business/Strategy
- impact_reason: Uses a powerful metaphor ('Data as Water') to explain the rigidity
    of legacy data structures versus the flexibility needed for modern AI integration.
  relevance_score: 8
  source: llm_enhanced
  text: Metapher, die ich manchmal ganz gerne nutze, ist, dass diese Daten wie Wasser
    sind und man kann es dann so, wie man möchte, umleiten in die richtigen Wege.
    Und wenn man eben ein kleines Unternehmen ist, dann kann man diese Wege noch ganz
    gut ausbauen, während wenn man über Jahrzehnte so ein Datenmodell aufgebaut hat,
    dann ist es schwierig, das irgendwie da rauszuziehen und ja, das sind auch für
    die KI einfach verarbeitbar zu machen.
  topic: Strategy/Technical Insight
- impact_reason: Sets the stage for practical advice on prompt engineering, a core
    skill in current LLM application.
  relevance_score: 8
  source: llm_enhanced
  text: Also, wie geht man daran? Lass uns mal durchgehen, vielleicht fangen wir bei
    guten Prompts an und kommen dann auf die anderen Stichworte zu sprechen, die es
    da gibt. Also ja, erstmal zum Thema, wie schreibt man einen guten Prompt?
  topic: technical/strategy
- impact_reason: 'A key strategic takeaway: best practices are starting points; empirical
    testing against the specific use case is paramount.'
  relevance_score: 8
  source: llm_enhanced
  text: Also man kann die ganzen Best Practices sich anschauen, aber im Endeffekt
    muss man gucken, was funktioniert für seinen eigenen Use Case und was kann man
    im besten benutzen.
  topic: strategy
- impact_reason: Direct, actionable business advice for scaling prompt-based applications.
  relevance_score: 8
  source: llm_enhanced
  text: Das ist wirklich, ja, das kann ich nur empfehlen, Templates nutzen, um sich
    die Arbeit da ein bisschen einfacher zu machen...
  topic: business
- impact_reason: Highlights the extreme speed of development possible when using advanced
    AI coding agents (like Kösar) for prototyping and deployment, even if for small
    features.
  relevance_score: 8
  source: llm_enhanced
  text: '...mit Kösar wirklich Production Ready Software innerhalb von einem Tag rauszupushen,
    sieht man nicht jeden Tag.'
  topic: predictions/business
- impact_reason: 'Advice on timing the adoption of formal prompt management tools:
    follow the pain, but start building the template library early for long-term efficiency.'
  relevance_score: 8
  source: llm_enhanced
  text: Also, da gibt es jetzt keine bestimmte Anzahl von Prompts, wo man sagen würde,
    jetzt muss ich zu Lengfuse oder irgendein anderes Tool, aber das mit den Templates,
    das kann man natürlich jetzt nicht einfach in Google Sheets machen und je früher
    man damit anfängt, desto hilfreicher ist es dann auch hinten raus, weil man dann
    eben schon früh diese Template-Bibliothek aufbauen kann...
  topic: business
- impact_reason: Describes a structured feedback loop where user requests are formalized
    into instructions for the LLM, which then feeds back into the evaluation pipeline
    for continuous improvement.
  relevance_score: 8
  source: llm_enhanced
  text: dass quasi ein Nutzer, eine Nutzerin uns als Ficus eine Anweisung gibt und
    wir geben dann dem LLM die Anweisung. Und die kann dann wieder in die Evaluationen
    einfließen, später, wenn man sich anguckt, wie gut es funktioniert.
  topic: strategy/technical
- impact_reason: 'Poses the central question for any company building on external
    LLMs: the rigor required for model migration and the expected breakage rate.'
  relevance_score: 8
  source: llm_enhanced
  text: Also ihr setzt, was muss man da testen, bevor man sagt, okay, jetzt sprechen
    wir tatsächlich die neue Modellversion an, und wie viel geht da in der Regel kaputt?
  topic: technical/strategy
- impact_reason: Acknowledges the massive capital investment fueling the AI boom and
    the leverage it provides to downstream startups ('building on the shoulders of
    giants').
  relevance_score: 8
  source: llm_enhanced
  text: Das Positive ist, dass sehr viel Geld in die Entwicklung von diesen Modellen
    gesteckt wird und wir davon profitieren, ohne diese Investments zu machen. Also
    sind ja wirklich Milliarden von Dollar, die jetzt gerade da reinfließen und immer
    größere Datencenter, Nvidia-Chips bis zum Gehtnichtmehr.
  topic: business/strategy
- impact_reason: Highlights geopolitical/regional friction in AI adoption, specifically
    the delay in model availability in Europe compared to the US.
  relevance_score: 8
  source: llm_enhanced
  text: Die negative Seite davon ist, dass man eben abhängig von diesen Providern
    ist. Also ich hatte eben das genannt mit Qualität geht vielleicht runter, obwohl
    man das gar nicht weiß und man muss auch darauf warten, dass die neuen Modelle
    kommen, was in Europa natürlich, was heißt natürlich, aber aktuell nicht immer
    selbstverständlich ist.
  topic: strategy/business
- impact_reason: Highlights the significant geographical lag and dependency for accessing
    the latest AI models (like those from Anthropic) in regions outside the US, impacting
    innovation speed.
  relevance_score: 8
  source: llm_enhanced
  text: in neues Modell angekündigt, dann kommt es erstmal in Amerika und dann warten
    wir hier Monate oder auch länger drauf.
  topic: strategy/deployment
- impact_reason: 'Defines the common European/German strategy: focusing on the application
    layer (software/UX) rather than building foundational models, leveraging existing
    infrastructure.'
  relevance_score: 8
  source: llm_enhanced
  text: Wir bauen so ein, das Application Layer und das sagt auch irgendwie viele
    Firmen in Deutschland, in Europa, okay, wir bauen keine eigenen Basismodelle,
    aber wir bauen sehr gute Software angepasst auf unsere Industrien, und das ist
    ja auch super.
  topic: strategy/business
- impact_reason: Expresses a significant geopolitical and regulatory concern regarding
    reliance on non-EU/US-based private entities for critical future infrastructure
    (AI).
  relevance_score: 8
  source: llm_enhanced
  text: Ich weiß nicht, wie gut das ist, die in rein privaten Händen außerhalb unseres
    Rechtsraums zu haben.
  topic: safety/strategy
- impact_reason: 'Provides a concrete, phased approach for AI adoption: start small,
    map existing data assets (especially V-framework data types), and build isolated
    sandboxes.'
  relevance_score: 8
  source: llm_enhanced
  text: Also da würde ich sagen, dass man am besten klein anfangen soll, nämlich,
    dass man sich anschaut, welche Daten habe ich wo und wie könnte man die nutzbar
    machen und dass man sich so klein mit Test wie so eine Sandbox baut und sagt,
    okay, ich habe jetzt es gibt sogenannte V-Frameworks, das sind Words, Images,
    Numbers und Sounds, die sich gut mit LLM verarbeiten lassen...
  topic: business/strategy
- impact_reason: 'A core principle of good product design: features must be integrated
    into the core problem-solving process, not bolted on as secondary elements.'
  relevance_score: 8
  source: llm_enhanced
  text: wenn du einfach ein Feature irgendwo neben den Kern des Prozesses, neben den
    Kern der Probleme, die man hier löst, irgendwas so als Altsatelliten daneben stellt,
    dann funktioniert das ja auch in klassischer UI in den seltensten Fällen, sondern
    man muss sich gut überlegen, ja, wie ist denn das jetzt hier eingebunden und wie
    macht das dann tatsächlich Sinn im Prozess?
  topic: strategy
- impact_reason: Illustrates deep domain-specific product adaptation (in healthcare/rehab)
    based on understanding nuanced user workflows, leading to better user acceptance.
  relevance_score: 8
  source: llm_enhanced
  text: Und das wollen wir jetzt auch noch weiter ausbauen, weil wir dann gesehen
    haben, okay, es werden zum Beispiel Diktate gemacht nach dem Aufnahmegespräch,
    das sind dann so was wie Vorbefunde oder die körperliche Untersuchung, die man
    jetzt vielleicht nicht während des Gesprächs diktieren möchte. Und dass man dieses
    Wissen und diese Prozesse dann auch ins Produkt einarbeitet, weil dann ich als
    Nutzer fühle mich dann natürlich auch mehr gehört und gesehen, wenn ich so ein
    Interface sehe.
  topic: business/product development
- impact_reason: Positions LLMs/AI as powerful tools, but emphasizes that superior
    UX/Software design remains the crucial differentiator, especially in legacy sectors
    like healthcare.
  relevance_score: 8
  source: llm_enhanced
  text: Da ist es, es sind im LLMs und KI eine weitere Technologie, die echt mächtig
    ist und die wir gut einsetzen können, aber gute Software und effizientes Design,
    da versuchen wir uns natürlich von abzusetzen von den anderen Systemen im Gesundheitswesen.
  topic: strategy/technical
- impact_reason: Provides an example of a 'nudge' mechanism (time-gated viewing) designed
    to enforce user engagement and prevent superficial processing of AI recommendations,
    even if bypassable.
  relevance_score: 8
  source: llm_enhanced
  text: Und die machen [KI-Empfehlungen] zum Beispiel so eine Funktion, dass man eine
    bestimmte Zeit lang auf das Bild schauen muss, bevor man aufs nächste gehen kann.
    Kann man natürlich aussagen, ja, man muss ja dann nicht wirklich hinschauen, aber
    solche kleinen Sachen, um die Leute dazu zu bringen, sich mit den Daten auseinanderzusetzen.
  topic: safety/product development
- impact_reason: Reinforces the fundamental principle of detailed instruction, especially
    when context is sparse.
  relevance_score: 7
  source: llm_enhanced
  text: Besonders wenn wenig Kontext da ist. Das auch noch. Genau, also das so der
    erste Punkt, dass man eine detaillierte Anweisung schreiben sollte.
  topic: technical
- impact_reason: Indicates the significant hurdle of cloud adoption within conservative
    sectors like German healthcare, requiring extensive trust-building and education.
  relevance_score: 7
  source: llm_enhanced
  text: Und auch Cloud ist vielleicht in anderen Bereichen schon weiter verbreitet,
    aber in der deutschen Gesundheitsbranche ist das für viele, auch zum Beispiel
    Ficus, die erste Cloud-Anwendung, die sie nutzen.
  topic: business
- impact_reason: 'Actionable business advice: Engage with cloud providers early for
    capacity, but only after clearly defining the specific use case and data requirements
    to avoid wasted effort.'
  relevance_score: 7
  source: llm_enhanced
  text: Also ich würde schon empfehlen, dass man bei diesen großen Cloud-Providern
    anfragt nach Kapazitäten, aber natürlich muss man erst mal schauen, was man genau
    macht, damit, also ich würde jetzt nicht einfach mal erst mal bei Bedrock Kapazitäten
    anfragen, ohne überhaupt zu wissen, was ich jetzt genau damit machen will.
  topic: business/deployment
- impact_reason: References a commonly cited (though perhaps debated) statistic about
    product feature failure, grounding the discussion in broader product management
    realities.
  relevance_score: 7
  source: llm_enhanced
  text: Witzigerweise ist gerade diese Zahl 95% Studie übrigens auch in den Shownotes
    verlinkt, aber diese Zahl 95% hat man ja früher auch gehört, 95% aller Produktfeatures
    scheitern...
  topic: business/strategy
- impact_reason: Demonstrates integrating regulatory/payer requirements (German Pension
    Insurance - DRV) directly into the workflow via a checklist feature, ensuring
    compliance and completeness.
  relevance_score: 7
  source: llm_enhanced
  text: Das heißt, wenn man einen DRV-Entlassbericht schreibt, dann kann man sich
    diese Checkliste anschauen und gucken, sind alle Punkte genannt, die in diesen
    Bericht genannt werden sollen.
  topic: business/compliance
source: Unknown Source
summary: '## Generative AI Product Management: Wie sieht LLM Product Management in
  der operativen Praxis aus? – Till Scholich zu Gast


  This podcast episode features Till Scholich, Senior Product Manager at the AI-first
  startup Ficus Health, discussing the practical realities of Product Management within
  an environment heavily reliant on Large Language Models (LLMs). Drawing from his
  operational experience and academic background (Stanford, University of Michigan),
  Scholich contrasts traditional deterministic product development with the probabilistic
  nature of GenAI-driven products, focusing heavily on prompt management, data structure,
  and the unique challenges in the health tech sector.


  ---


  ### 1. Focus Area

  The discussion centers on **Generative AI Product Management (LLM Product Management)**
  in an operational, AI-first context, specifically within the German healthcare/rehabilitation
  (Reha-Kliniken) documentation sector. Key themes include data architecture for LLMs,
  prompt engineering and management, model evaluation, and the strategic implications
  of being an "AI-First" company.


  ### 2. Key Technical Insights

  *   **Data Structure for LLMs:** AI-First companies gain an advantage by designing
  data models and structures from the ground up to be easily consumable by LLMs (e.g.,
  structuring data along a patient journey to enable AI functions at every step).
  Traditional systems often struggle due to legacy structures and on-premise data
  silos, making LLM integration complex.

  *   **Probabilistic Output Management:** Unlike deterministic software outputs,
  LLM results are probabilistic. This necessitates new testing frameworks and methodologies
  to ensure reliability and minimize variance in outputs, moving beyond traditional
  QA.

  *   **Prompt Management as Code:** Prompts must be treated similarly to code, requiring
  versioning, modularization (using **Templates**), and rigorous review processes
  to manage their significant impact on the final product experience.


  ### 3. Business/Investment Angle

  *   **AI-First Advantage:** Companies built around modern data architectures have
  a significant head start in leveraging LLMs compared to established firms needing
  to retrofit legacy systems.

  *   **Emerging Roles:** The necessity for structured prompt management is leading
  to the creation of new roles, such as the **Prompt Engineer** (as seen by Ficus
  Health hiring one), indicating a professionalization of prompt development.

  *   **Rapid Tool Development:** The ecosystem around LLM operations (LLMOps) is
  evolving rapidly, exemplified by tools like **Lengfuse** and **Kösar**, which are
  quickly developing features (like prompt versioning and rapid prototyping) based
  on direct user feedback.


  ### 4. Notable Companies/People

  *   **Till Scholich:** Guest, Senior PM at Ficus Health, bringing both startup operational
  experience and academic research insight (Stanford, UMich).

  *   **Ficus Health:** Till’s current company, building an AI-first product to simplify
  documentation in German Reha clinics using LLMs for summarizing patient conversations
  and generating discharge reports.

  *   **Lengfuse:** A prompt management tool utilized by Ficus Health for versioning,
  searching, and templating prompts.

  *   **Kösar:** An AI IDE/Coding Agent mentioned as an example of a tool that can
  rapidly prototype and deploy small features based on user requests, demonstrating
  fast iteration in the AI tooling space.


  ### 5. Future Implications

  The conversation suggests that successful AI product development hinges on treating
  prompt engineering as a core engineering discipline, requiring dedicated tooling
  (Prompt Management Systems) that mirrors software development practices like Git.
  The industry is moving toward standardized evaluation frameworks to manage the inherent
  uncertainty of LLM outputs, especially in high-stakes domains like healthcare.


  ### 6. Target Audience

  This episode is highly valuable for **AI/ML Product Managers, Technical Product
  Owners, Software Architects, and Founders** in AI-first startups or those leading
  digital transformation efforts in regulated industries (like HealthTech) who need
  practical insights on operationalizing LLMs beyond simple API calls.'
tags:
- artificial-intelligence
- generative-ai
- startup
- ai-infrastructure
- investment
- anthropic
- google
- microsoft
title: 'Generative AI Product Management: Wie sieht LLM Product Management in der
  operativen Praxis aus? – Till Scholich zu Gast (Product @ Ficus Health, ex Stanford
  Research Assistant)'
topics:
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 84
  prominence: 1.0
  topic: artificial intelligence
- keywords:
  - generative ai
  - genai
  - chatgpt
  - gpt
  - claude
  - text generation
  - image generation
  mentions: 28
  prominence: 1.0
  topic: generative ai
- keywords:
  - startup
  - entrepreneur
  - founder
  - venture
  mentions: 8
  prominence: 0.8
  topic: startup
- keywords:
  - gpu
  - tensor
  - training
  - inference
  - model deployment
  - vector database
  mentions: 3
  prominence: 0.3
  topic: ai infrastructure
- keywords:
  - investment
  - funding
  - valuation
  - ipo
  - acquisition
  mentions: 2
  prominence: 0.2
  topic: investment
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-10-16 04:37:22 UTC -->
