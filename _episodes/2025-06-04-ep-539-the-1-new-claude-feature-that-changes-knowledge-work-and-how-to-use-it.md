---
companies:
- category: unknown
  confidence: medium
  context: This is the Everyday AI Show, the everyday podcast where we simplify AI
    and br
  name: Everyday AI Show
  position: 12
- category: tech
  confidence: high
  context: o, you'll know that I'm sometimes kind of hard on Anthropic's Claude. I
    think in the past 15 to 18 months, it
  name: Anthropic
  position: 314
- category: unknown
  confidence: medium
  context: changes knowledge work and how to use it today on Everyday AI. What's going
    on, y'all? My name is Jordan Wilson
  name: Everyday AI
  position: 1092
- category: unknown
  confidence: medium
  context: n Everyday AI. What's going on, y'all? My name is Jordan Wilson, and I'm
    the host of Everyday AI. This thing, it'
  name: Jordan Wilson
  position: 1140
- category: unknown
  confidence: medium
  context: esday. I'm thinking about this new segment called AI Work on Wednesdays
    or something like that. All right,
  name: AI Work
  position: 2262
- category: unknown
  confidence: medium
  context: base Pro plan. So, if you are on the $20 a month Claude Pro plan, like
    I am, then you can go take advantage o
  name: Claude Pro
  position: 3995
- category: unknown
  confidence: medium
  context: emini plan, I'm on the $200 a month ChatGPT plan. With Claude, I've never
    been able to stomach anything more th
  name: With Claude
  position: 4214
- category: unknown
  confidence: medium
  context: e's a good chance it's going to just stop, right? And I don't edit this
    thing. So yeah, we'll see how it
  name: And I
  position: 5019
- category: tech
  confidence: high
  context: ou've used any of the deep research services from OpenAI, from Gemini,
    I think those are like 1A and 1B, p
  name: Openai
  position: 5470
- category: tech
  confidence: high
  context: neck. And then, you know, Grok has their version, Perplexity has their
    version, Microsoft Copilot has their ve
  name: Perplexity
  position: 5660
- category: tech
  confidence: high
  context: has their version, Perplexity has their version, Microsoft Copilot has
    their version as well. So, you know,
  name: Microsoft
  position: 5690
- category: unknown
  confidence: medium
  context: has their version, Perplexity has their version, Microsoft Copilot has
    their version as well. So, you know, everyone
  name: Microsoft Copilot
  position: 5690
- category: unknown
  confidence: medium
  context: thropic has created and obviously popularized the Model Context Protocol.
    Don't worry, we're going to do a probably someti
  name: Model Context Protocol
  position: 7048
- category: tech
  confidence: high
  context: their own as well. You know, you have A to A from Google, but MCP is probably
    the biggest, the most popula
  name: Google
  position: 7707
- category: unknown
  confidence: medium
  context: d them to you. And if I ever forget, just bug me. My LinkedIn DMs are not
    just, you know, reach out, you know, just
  name: My LinkedIn DMs
  position: 8635
- category: tech
  confidence: high
  context: ach out, you know, just poke me, right? It's like Facebook. It's like,
    hey, I shared this. Send this to me.
  name: Facebook
  position: 8727
- category: unknown
  confidence: medium
  context: mind Gemini 2.5 Pro, if you read our newsletter, Logan Killpatrick can
    confirm they're coming out with a new version
  name: Logan Killpatrick
  position: 10023
- category: unknown
  confidence: medium
  context: hat I was prompting, the inputs, and the outputs. But I'm going to start
    this one live. Then I'm going to
  name: But I
  position: 10653
- category: unknown
  confidence: medium
  context: he outputs. But I'm going to start this one live. Then I'm going to jump
    back into my slides that I usuall
  name: Then I
  position: 10691
- category: unknown
  confidence: medium
  context: marginal gain that you get from using Claude 4 or Claude Opus 4, which
    is the large version versus the medium v
  name: Claude Opus
  position: 11536
- category: unknown
  confidence: medium
  context: you'll see there's some direct ones here, such as Google Drive, Gmail,
    Google Calendar that have been there for
  name: Google Drive
  position: 12239
- category: unknown
  confidence: medium
  context: me direct ones here, such as Google Drive, Gmail, Google Calendar that
    have been there for a while, GitHub. And the
  name: Google Calendar
  position: 12260
- category: unknown
  confidence: medium
  context: er small. So, let me go ahead and open up a blank Google Doc. And, hopefully,
    y'all can see it this way. All r
  name: Google Doc
  position: 13016
- category: unknown
  confidence: medium
  context: t read it, why aren't you reading it, you should. As I said, it's human-written,
    right? But at the very
  name: As I
  position: 15061
- category: unknown
  confidence: medium
  context: hen there's three main points in a section called Try This. So, it's actionable
    tips based on, you know, the
  name: Try This
  position: 15245
- category: unknown
  confidence: medium
  context: ore, but can't really get traction to find ROI on Gen AI. Hey, this is
    Jordan Wilson, host of this very po
  name: Gen AI
  position: 16090
- category: tech
  confidence: high
  context: ery podcast. Companies like Adobe, Microsoft, and Nvidia have partnered
    with us because they trust our exp
  name: Nvidia
  position: 16190
- category: unknown
  confidence: medium
  context: a time. It finishes it and runs another process. A GPU can run parallel
    processes all at once. So, it is
  name: A GPU
  position: 22534
- category: tech
  confidence: high
  context: seen some rumors and brands. If you listen to our Monday show, this is
    going to be rolling out to other pl
  name: Monday
  position: 24198
- category: unknown
  confidence: medium
  context: went to your everydayai.com. Then it went back to Google Docs and it went
    through 83 documents. This is a proje
  name: Google Docs
  position: 24489
- category: unknown
  confidence: medium
  context: you how long this would take me to accurately do. Is Claude going to do
    it at an A grade? Probably not. For m
  name: Is Claude
  position: 24728
- category: unknown
  confidence: medium
  context: This task, I've been wanting to do it for years. Since I started, I've
    been doing Everyday AI for two and
  name: Since I
  position: 25840
- category: unknown
  confidence: medium
  context: f thousands of dollars to do it. Well, we'll see. Can Claude do it? And
    in general, this is the future of work
  name: Can Claude
  position: 26232
- category: unknown
  confidence: medium
  context: ere's what it does. It can research the web, your Google Workspace, including
    Calendar, Gmail, and Drive, which is h
  name: Google Workspace
  position: 26494
- category: unknown
  confidence: medium
  context: as and outlines. Okay. So, the first one, it says AI Agents Corporate Identity
    Crisis. And it says, I should combine a recent episode I
  name: AI Agents Corporate Identity Crisis
  position: 32883
- category: unknown
  confidence: medium
  context: ays, I should combine a recent episode I did with Sarah Bird from Microsoft
    and Ron Green from Kung Fu AI. And
  name: Sarah Bird
  position: 32978
- category: unknown
  confidence: medium
  context: episode I did with Sarah Bird from Microsoft and Ron Green from Kung Fu
    AI. And it gave me three episode tit
  name: Ron Green
  position: 33008
- category: unknown
  confidence: medium
  context: with Sarah Bird from Microsoft and Ron Green from Kung Fu AI. And it gave
    me three episode title options. Pret
  name: Kung Fu AI
  position: 33023
- category: unknown
  confidence: medium
  context: od job. Let's keep going. So, number two, it says The Great AI Coding Takeover.
    It didn't combine guests. It just combined topic
  name: The Great AI Coding Takeover
  position: 33436
- category: unknown
  confidence: medium
  context: of my recent episodes. So, not bad. Number three, AI Research Revolution
    from Garbage to Gold. Let's see. Same thing. Give
  name: AI Research Revolution
  position: 33673
- category: unknown
  confidence: medium
  context: ully, we get a couple more here. So, number four, The Job Security Deathmatch.
    Again, just one guest. So, yeah, unfortunately,
  name: The Job Security Deathmatch
  position: 34252
- category: unknown
  confidence: medium
  context: e's an episode for AI agents everywhere, The $100 Billion Workforce Revolution.
  name: Billion Workforce Revolution
  position: 36077
- category: ai_model_developer
  confidence: high
  context: Developer of the Claude LLM; mentioned regarding its new research feature
    rollout to the Pro plan and the Model Context Protocol (MCP).
  name: Anthropic
  source: llm_enhanced
- category: ai_model
  confidence: high
  context: The large language model developed by Anthropic, discussed in detail regarding
    its new research mode and integrations, and its $20/month Pro plan.
  name: Claude
  source: llm_enhanced
- category: ai_model
  confidence: high
  context: Mentioned as a major LLM competitor whose training/usage the host pays
    $200/month for, and as a tool for live demos.
  name: ChatGPT
  source: llm_enhanced
- category: ai_model
  confidence: high
  context: Google's LLM family (specifically 2.5 Pro and Flash); mentioned as a top-tier
    competitor to Claude, with the host paying $250/month for it.
  name: Gemini
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Microsoft's AI assistant/tool, mentioned as a platform for live demos and
    as a competitor in the deep research game.
  name: Copilot
  source: llm_enhanced
- category: ai_model
  confidence: high
  context: Mentioned as having its own version of deep research capabilities.
  name: Grok
  source: llm_enhanced
- category: ai_search_engine
  confidence: high
  context: Mentioned as having its own version of deep research capabilities.
  name: Perplexity
  source: llm_enhanced
- category: ai_model_developer
  confidence: high
  context: Mentioned regarding its deep research services, and as a company supporting
    Anthropic's Model Context Protocol (MCP).
  name: OpenAI
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Mentioned as a company whose AI offerings (Gemini, A2A protocol) compete
    with Anthropic's, and as a partner of Everyday AI.
  name: Google
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Mentioned as a company whose Copilot product is used for demos, and as
    a partner of Everyday AI.
  name: Microsoft
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: Mentioned as a company that has partnered with Everyday AI for education/expertise.
  name: Nvidia
  source: llm_enhanced
- category: software_company
  confidence: high
  context: Mentioned as a company that has partnered with Everyday AI for education/expertise.
  name: Adobe
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as an AI system used by the host to pull insights from transcripts.
  name: CastMagic
  source: llm_enhanced
- category: ai_integration_platform
  confidence: high
  context: Mentioned as one of the prebuilt integrations available within Claude.
  name: Zapier
  source: llm_enhanced
- category: saas_tool
  confidence: medium
  context: Mentioned as one of the prebuilt integrations available within Claude.
  name: Asana
  source: llm_enhanced
- category: saas_tool
  confidence: medium
  context: Mentioned as one of the prebuilt integrations available within Claude.
  name: Intercom
  source: llm_enhanced
- category: saas_tool
  confidence: medium
  context: Mentioned as one of the prebuilt integrations available within Claude.
  name: PayPal
  source: llm_enhanced
- category: saas_tool
  confidence: medium
  context: Mentioned as one of the prebuilt integrations available within Claude.
  name: Square
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: Mentioned as a company with upcoming integrations for Claude's agentic
    capabilities.
  name: Stripe
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as a company with upcoming integrations for Claude's agentic
    capabilities.
  name: GitLab
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as a company with upcoming integrations for Claude's agentic
    capabilities.
  name: Box
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: Mentioned as an application that can be integrated with Claude for expanded
    use cases.
  name: Jira
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: Mentioned as an application that can be integrated with Claude for expanded
    use cases.
  name: Confluence
  source: llm_enhanced
- category: ai_startup
  confidence: high
  context: Mentioned as the affiliation of Ron Green, suggesting it is an AI company
    or startup.
  name: Kung Fu AI
  source: llm_enhanced
date: 2025-06-04 13:00:00 +0000
duration: 49
has_transcript: false
insights:
- actionable: false
  confidence: medium
  extracted: work. Teams that are using this for faster and more comprehensive understanding
    of their current knowledge and their strategic decision-making. Right now, here's
    what it does. It can research the web, your Google Workspace, including Calendar,
    Gmail, and Drive, which
  text: the future of work. Teams that are using this for faster and more comprehensive
    understanding of their current knowledge and their strategic decision-making.
    Right now, here's what it does. It can research the web, your Google Workspace,
    including Calendar, Gmail, and Drive, which is huge, and any of those connected
    app data.
  type: prediction
layout: episode
llm_enhanced: true
original_url: https://pscrb.fm/rss/p/www.buzzsprout.com/2175779/episodes/17278657-ep-539-the-1-new-claude-feature-that-changes-knowledge-work-and-how-to-use-it.mp3
processing_date: 2025-10-05 12:30:47 +0000
quotes:
- length: 201
  relevance_score: 5
  text: So, whether you're looking for ChatGPT training for thousands or just need
    help building your front-end AI strategy, you can partner with us too, just like
    some of the biggest companies in the world do
  topics: []
- length: 117
  relevance_score: 4
  text: And then, you know, Grok has their version, Perplexity has their version,
    Microsoft Copilot has their version as well
  topics: []
- length: 119
  relevance_score: 4
  text: You know, you have A to A from Google, but MCP is probably the biggest, the
    most popular, and the most widely supported
  topics: []
- length: 157
  relevance_score: 4
  text: Companies like Adobe, Microsoft, and Nvidia have partnered with us because
    they trust our expertise in educating the masses around generative AI to get ahead
  topics: []
- length: 45
  relevance_score: 4
  text: Well, you have to be on a paid Anthropic plan
  topics: []
- length: 43
  relevance_score: 3
  text: But the biggest upgrade is the availability
  topics: []
- length: 71
  relevance_score: 3
  text: Even companies like Google, like OpenAI, are supporting Anthropic's MCP
  topics: []
- length: 25
  relevance_score: 3
  text: But here's what I'm doing
  topics: []
- length: 30
  relevance_score: 3
  text: Right now, here's what it does
  topics: []
- length: 51
  relevance_score: 3
  text: And the biggest thing here is it gains live context
  topics: []
- length: 64
  relevance_score: 3
  text: The problem is, is so many times you're working with static data
  topics: []
- length: 113
  relevance_score: 3
  text: I think one of the biggest problems that I'm not going to go off on a, you
    know, five-minute riff here, I promise
  topics: []
- length: 81
  relevance_score: 3
  text: One of the biggest problems with AI is people just run in, go with no destination
  topics: []
- impact_reason: Highlights a significant feature democratization—bringing high-value
    functionality to the entry-level paid tier—suggesting a major shift in accessibility
    and utility for everyday users.
  relevance_score: 10
  source: llm_enhanced
  text: there is one new feature in Anthropic's Claude base pay plan, the $20 a month
    plan, that is already going to, I think, change how I work and it will change
    how you work as well if you choose to use it
  topic: business
- impact_reason: 'Clearly identifies the core technological breakthrough being discussed:
    the synergy between advanced research capabilities and external tool integration.'
  relevance_score: 10
  source: llm_enhanced
  text: The new feature is the combination of a deep research mode inside Anthropic's
    Claude and the new and expanding integrations.
  topic: technical
- impact_reason: Quantifies the cost barrier removal for advanced features, making
    the research/integration capabilities accessible to a much wider paying audience
    ($20/month).
  relevance_score: 10
  source: llm_enhanced
  text: Previously, you had to be on their super expensive, you know, max plan that
    starts at $100 up to $200 a month in order to get this research and a lot of the
    integrations. However, now Anthropic has just rolled this out to their base Pro
    plan.
  topic: business
- impact_reason: 'States a primary benefit of deep research/web browsing capabilities:
    a significant reduction in model hallucinations, which is crucial for enterprise
    adoption.'
  relevance_score: 10
  source: llm_enhanced
  text: in doing that, that also reduces the rate of hallucinations exponentially.
  topic: safety
- impact_reason: Introduces and validates the Model Context Protocol (MCP) as a key
    enabling technology for LLM interoperability, positioning Anthropic as a standard-setter.
  relevance_score: 10
  source: llm_enhanced
  text: Anthropic is also rolling out an MCP mode that can work in their deep research
    mode. So, what that is, Anthropic has created and obviously popularized the Model
    Context Protocol.
  topic: technical
- impact_reason: Provides a powerful analogy (CPU vs. GPU) to explain the massive,
    exponential leap in capability that agentic tool use represents over basic chatbot
    functionality.
  relevance_score: 10
  source: llm_enhanced
  text: This is kind of the difference between like a CPU and a GPU. And this is why
    I've been losing my mind for the past, you know, couple of months when it comes
    to agentic tool use, I don't think people understand how big that is.
  topic: predictions
- impact_reason: Strong assertion that agentic tool use is the defining breakthrough
    of the current LLM generation, moving beyond simple conversational AI.
  relevance_score: 10
  source: llm_enhanced
  text: I think the same can be said about this big step up from going from a, you
    know, kind of an AI chatbot to an AI chatbot that has agentic tool use, right?
    It is absolutely wild.
  topic: technical
- impact_reason: Quantifies the massive time savings and productivity gains offered
    by agentic AI, even if the output isn't perfect (C grade vs. hundreds of hours
    of human labor).
  relevance_score: 10
  source: llm_enhanced
  text: This is a project I need done. Right. I could do it. I would probably be the
    best person to do it because I did all these shows. I cannot tell you how long
    this would take me to accurately do. Is Claude going to do it at an A grade? Probably
    not. For me to even do a C job on this would take hundreds of hours.
  topic: business
- impact_reason: Crucially identifies the limitation of many current custom AI tools
    (GPTs, Gems) as relying on static data, contrasting this with the value of live,
    agentic tool use for dynamic context.
  relevance_score: 10
  source: llm_enhanced
  text: And the biggest thing here is it gains live context. That's the downside with
    working with things inside Claude's Projects, or ChatGPT's Projects, or ChatGPT's
    custom GPTs, or Gemini's Gems, which don't work the best right now, even with
    Google's own products. The problem is, is so many times you're working with static
    data.
  topic: technical
- impact_reason: A vital strategic warning against aimless AI experimentation. Success
    requires defining a clear goal ('finish line') before implementation to ensure
    measurability and scaling.
  relevance_score: 10
  source: llm_enhanced
  text: One of the biggest problems with AI is people just run in, go with no destination.
    Okay? Before you start, before you even go and check, oh, do I have access to
    this? Well, you should. But before you do that, first listen to this episode again.
    Okay? Share this episode with your team. Then sit down and say, what are we going
    to pilot? What is our end goal? All right. Get a finish line before you start
    running, because then you'll know when to stop running and then you'll be able
    to measure it and then you'll be able to scale it.
  topic: strategy
- impact_reason: Identifies the critical challenge of hallucination/fabrication, especially
    when dealing with specific data requirements like verbatim quotes, emphasizing
    the need for explicit constraints in prompting.
  relevance_score: 10
  source: llm_enhanced
  text: Step two, here's the difficult thing. Can it build a legit script? And with
    actual quotes. And I did say you need to include at least 12 total quotes. I should
    have designated that these need to be actual non-fabricated quotes.
  topic: safety
- impact_reason: This is the central thesis statement, indicating a massive, quantifiable
    economic shift driven by AI agents impacting labor markets.
  relevance_score: 10
  source: llm_enhanced
  text: The $100 Billion Workforce Revolution.
  topic: Predictions
- impact_reason: This provides a strong, critical assessment of Claude's recent trajectory,
    suggesting a shift away from general utility towards specialized developer use,
    which is a key market observation.
  relevance_score: 9
  source: llm_enhanced
  text: I'm sometimes kind of hard on Anthropic's Claude. I think in the past 15 to
    18 months, it's gone from probably a top-tier large language model to almost a
    forgotten AI tool that's now almost exclusively for developers in the future.
  topic: strategy
- impact_reason: Provides a concrete, negative data point regarding Claude's rate
    limiting on the paid tier, serving as a warning for heavy users.
  relevance_score: 9
  source: llm_enhanced
  text: I hit my rate limits usually in about seven minutes when I'm really pushing
    it. So, I'm not going to push it intentionally too far.
  topic: technical
- impact_reason: Offers a competitive ranking of current deep research capabilities
    among major players (Gemini slightly ahead of OpenAI), providing market context.
  relevance_score: 9
  source: llm_enhanced
  text: if you've used any of the deep research services from OpenAI, from Gemini,
    I think those are like 1A and 1B, probably Gemini's a little ahead of OpenAI's
    deep research, but it's really neck and neck.
  topic: technical
- impact_reason: Defines the high-level business impact of the new feature set—bridging
    raw data access with actionable intelligence for teams.
  relevance_score: 9
  source: llm_enhanced
  text: This unlocks contextual business knowledge from apps and the web. And this
    transforms how teams can discover, analyze, and act on information.
  topic: predictions
- impact_reason: Provides a clear, accessible explanation for *why* protocols like
    MCP are necessary—LLMs lack native API functionality, requiring a standardized
    'language' for tool interaction.
  relevance_score: 9
  source: llm_enhanced
  text: AI in large language models can't use APIs. So, they needed essentially a
    language, a universal language to talk to each other.
  topic: technical
- impact_reason: Asserts the dominance and broad industry acceptance of Anthropic's
    MCP, suggesting it might become the de facto standard for LLM interoperability,
    despite competition from Google's A2A.
  relevance_score: 9
  source: llm_enhanced
  text: MCP is probably the biggest, the most popular, and the most widely supported.
    Even companies like Google, like OpenAI, are supporting Anthropic's MCP.
  topic: technical
- impact_reason: A forward-looking prediction suggesting that any current competitive
    advantage Claude holds in developer utility (like coding) will be quickly erased
    by the next iteration of Gemini.
  relevance_score: 9
  source: llm_enhanced
  text: Logan Killpatrick can confirm they're coming out with a new version [of Gemini
    2.5 Pro]. So, yeah, even if you're, you know, big into software development or
    anything like that, you know, oh, you know, hey, Claude gives me these couple
    of points of advantage, that's going to be gone pretty soon the next time Google
    updates Gemini 2.5.
  topic: predictions
- impact_reason: 'Offers crucial strategic advice for AI adoption: internal validation
    and custom use-case development are necessary for real business impact.'
  relevance_score: 9
  source: llm_enhanced
  text: I always encourage people, like, don't rely on other people's use cases, other
    people's benchmarks. You need to be developing your own internally.
  topic: strategy
- impact_reason: 'Crucial advice for AI adoption: internal testing and developing
    proprietary use cases are necessary to realize real ROI, rather than relying on
    generic examples.'
  relevance_score: 9
  source: llm_enhanced
  text: Don't rely on other people's use cases, other people's benchmarks. You need
    to be developing your own internally.
  topic: strategy
- impact_reason: Highlights the imminent standardization of advanced agentic capabilities
    across all major LLM platforms and stresses the importance of proactive, hands-on
    testing by users.
  relevance_score: 9
  source: llm_enhanced
  text: I would assume pretty soon this is going to be available to do in all major
    providers, ChatGPT, Gemini, Claude, Copilot, etc. So, you need to be building
    out these use cases, right? Don't just blindly use a tool. You need to be testing
    them, right?
  topic: strategy
- impact_reason: Distinguishes advanced models by emphasizing the role of 'reasoning
    models' that plan ahead, contrasting them with older, purely predictive (next-token)
    architectures.
  relevance_score: 9
  source: llm_enhanced
  text: And also an agentic chatbot that has, or sorry, a chatbot that has agentic
    tool use and is powered by a reasoning model, right? That's the other thing. This
    isn't powered by a quote unquote old-school transformer model that is essentially
    a next token prediction, right? Even though it is, but this is one that thinks
    and plans ahead like a human would.
  topic: technical
- impact_reason: 'Provides a concrete, observable example of an agentic loop: iterating
    between private data retrieval (Drive) and external web research to validate and
    synthesize information.'
  relevance_score: 9
  source: llm_enhanced
  text: This is going back and forth, right? This is the power of large language models
    that have agentic tool use. That means it's starting, as an example, it started
    in the Google Drive folder, right? And then it did some research on third-party
    sites. Okay. Multiple rounds. Then let's see, let's scroll down here. Then it
    went to your everydayai.com. Okay, then it went back into Google Drive probably
    to confirm some things, right?
  topic: technical
- impact_reason: 'Provides a concrete business case: AI solves problems that have
    been perpetually deferred due to high human cost or time investment.'
  relevance_score: 9
  source: llm_enhanced
  text: This task, I've been wanting to do it for years. Since I started, I've been
    doing Everyday AI for two and a half years. I had this idea a year and a half
    ago. I'm like, oh, I should start doing this. It's been on my to-do list for 18
    months. I didn't want to do it because either it was going to take me an ungodly
    amount of hours or I would have to probably pay a person or a company tens of
    thousands of dollars to do it.
  topic: business
- impact_reason: A clear statement positioning advanced AI capabilities (like Claude's
    multi-source analysis) as the defining characteristic of the future of knowledge
    work.
  relevance_score: 9
  source: llm_enhanced
  text: Well, we'll see. Can Claude do it? And in general, this is the future of work.
    Teams that are using this for faster and more comprehensive understanding of their
    current knowledge and their strategic decision-making.
  topic: predictions
- impact_reason: Details the critical shift from web-only research to deep integration
    within proprietary, personal/corporate data silos (Workspace), which is a major
    technical capability leap.
  relevance_score: 9
  source: llm_enhanced
  text: Right now, here's what it does. It can research the web, your Google Workspace,
    including Calendar, Gmail, and Drive, which is huge, and any of those connected
    app data.
  topic: technical
- impact_reason: 'A blunt assessment of current LLM limitations: while excellent at
    synthesis and research, they often fail at high-quality, nuanced creative writing
    (like micro-scripts), tempering hype.'
  relevance_score: 9
  source: llm_enhanced
  text: And then it gave me an angle. It gave me a micro-script. And this micro-script
    is garbage. Sorry. People love to think like Claude is some great content writer.
    It's extremely average.
  topic: limitations
- impact_reason: A clear example of AI fabricating sources by misattributing existing
    text as a direct quote, demonstrating a failure mode that requires strict verification.
  relevance_score: 9
  source: llm_enhanced
  text: So, yeah, I believe it made them up. So, what it did is it took my writing
    from the from the newsletter and it attributed that as a quote to the guest. So,
    again, not good because, yeah, not good.
  topic: safety
- impact_reason: Highlights the specific focus on 'AI Agents' as the key technology
    driving the revolution, suggesting a shift from static models to autonomous actors.
  relevance_score: 9
  source: llm_enhanced
  text: Here's an episode for AI agents everywhere.
  topic: AI Technology Trends
- impact_reason: Signals a fundamental, non-incremental change in how work is structured
    and performed, implying significant disruption and potential job transformation.
  relevance_score: 9
  source: llm_enhanced
  text: Workforce Revolution.
  topic: Predictions
- impact_reason: Offers a direct comparison of the host's spending habits across major
    AI platforms, highlighting the perceived poor value proposition of Claude's higher
    tiers due to rate limits.
  relevance_score: 8
  source: llm_enhanced
  text: I'm on the $250 a month Gemini plan, I'm on the $200 a month ChatGPT plan.
    With Claude, I've never been able to stomach anything more than the $20 a month
    Pro plan mainly because of the limits.
  topic: business
- impact_reason: Reiterates the host's long-standing critique of Claude's cost-to-performance
    ratio on the backend API, especially when compared to Google's offerings.
  relevance_score: 8
  source: llm_enhanced
  text: you always, you know, poo-poo on Claude, you know, for not being great on
    the front end. And you can use it on the back end. Yes, you can. It's terribly
    expensive compared to Gemini 2.5 Pro or Gemini 2.5 Flash.
  topic: business
- impact_reason: Describes a specific technique (enabling extended thinking) used
    to improve the quality and reliability of complex, multi-step reasoning tasks
    within the LLM.
  relevance_score: 8
  source: llm_enhanced
  text: I am going to enable the extended thinking mode inside Claude on it to force
    Claude to, you know, kind of think step by step, think logically, plan ahead,
    etc.
  topic: technical
- impact_reason: Lists key existing integrations, emphasizing Zapier's importance
    as a central hub for connecting Claude to a vast ecosystem of business software.
  relevance_score: 8
  source: llm_enhanced
  text: prebuilt integrations, which include things like Asana, Intercom, PayPal,
    Square, Zapier. Zapier is the huge one.
  topic: business
- impact_reason: Defines a cutting-edge, complex use case combining agentic capabilities
    (tool use) with deep, integrated RAG (Retrieval-Augmented Generation) across private
    and public data.
  relevance_score: 8
  source: llm_enhanced
  text: This is kind of an advanced one that I've kind of developed to test both agentic
    tool use in a hybrid model as well as deep research that is integrated with documents.
  topic: technical
- impact_reason: A clear, accessible explanation of parallel processing, used to frame
    the significance of agentic LLMs that can manage multiple, simultaneous tasks.
  relevance_score: 8
  source: llm_enhanced
  text: A CPU is a little slower. It's how computers run, right? And it runs one process
    at a time. It finishes it and runs another process. A GPU can run parallel processes
    all at once. So, it is infinitely more powerful.
  topic: technical
- impact_reason: Identifies the core inefficiency in knowledge work—manual data aggregation
    across disparate systems—that advanced AI tools are poised to eliminate.
  relevance_score: 8
  source: llm_enhanced
  text: Think of how long it takes to find that relevant information across different
    systems. It is super slow and inefficient to be able to have to go and gather
    that data manually, really.
  topic: business
- impact_reason: Demonstrates a multi-step, chained reasoning process where the output
    of one AI task (ideation/outlining) becomes the direct input for the next (content
    generation/assembly).
  relevance_score: 8
  source: llm_enhanced
  text: Step one is like writing an outline, right? Give me ideas. Here's the people
    that can be on it, but step two, I'm saying go look at step one and then actually
    put it together. Find the actual quotes, put the quotes together.
  topic: technical
- impact_reason: 'Showcases an advanced strategic use case: using historical data
    combined with external research to identify white space and generate novel, forward-looking
    content ideas.'
  relevance_score: 8
  source: llm_enhanced
  text: For step three, I'm saying find 10 new episode ideas. So, I'm saying, essentially
    based on all of this, right? So, you're going, you're looking at our last six
    months of episodes, you're doing additional research on your own, go find things
    we aren't covering and we haven't covered.
  topic: strategy
- impact_reason: Emphasizes the cognitive load and burnout associated with manual
    knowledge work, contrasting it with the potential of AI to handle the 'fetching
    and retrieving' phase.
  relevance_score: 8
  source: llm_enhanced
  text: Number one, it's exhausting for humans or teams of humans to do that. To manually
    go out and fetch and retrieve all this information, to summarize it, to paraphrase
    it, to pull key insights. To just do that, it empties a tank. But then to actually
    create something new out of all that information, it is nearly impossible.
  topic: business
- impact_reason: Highlights the strategic importance of integration layers (like Zapier/MCP)
    in breaking down the walled garden of proprietary AI models and connecting them
    to external data flows.
  relevance_score: 8
  source: llm_enhanced
  text: I'm especially excited about the MCP and the Zapier integration because that
    opens it up to essentially the entire internet.
  topic: technical
- impact_reason: 'Provides a clear, actionable 3-step framework for AI adoption: Identify
    time-sinks, connect core apps (especially Workspace), and leverage integration
    platforms (Zapier) for scale.'
  relevance_score: 8
  source: llm_enhanced
  text: You need to win back your time with generative AI. Then, connect the critical
    apps, right? Whatever that is to Claude. I would obviously start with Gmail, Google
    Drive, and Google Calendar if you are a Google Workspace organization. Zapier,
    for sure, because then you can connect to more than 6,000 or might have to be
    up to like 7,000 apps now.
  topic: business
- impact_reason: 'Crucial user advice on interacting with complex AI outputs: always
    inspect the underlying process/sources (even if the UI is poor) to enable effective
    iteration and debugging.'
  relevance_score: 8
  source: llm_enhanced
  text: 'y''all, please, please, please, always go and click. So, it''s this little
    box. I wish all the companies did a bad job at this. Like the UI is not good.
    Most people don''t even know they can go and click that, right? It''s this little
    box, right? With a little arrow, it''s so thin. Go click that because you essentially
    can read. It''s not the actual chain of thought, unfortunately, but at least shows
    the process that in this case, Claude went through because again, I always encourage
    people: look at the results, look at the steps, update your prompt, do it again.'
  topic: strategy
- impact_reason: Provides a realistic grading scale for complex AI outputs, acknowledging
    that poor results are often attributable to poor prompting rather than model failure.
  relevance_score: 8
  source: llm_enhanced
  text: I would probably give it like a C+ or B- on this. It did everything. Actually,
    I'll say I'll say a B because probably the things that I'm not liking were things
    that I could have done.
  topic: strategy
- impact_reason: Illustrates the inherent variability and non-determinism ('generative
    part') of LLMs, meaning the same prompt can yield vastly different quality results
    across runs.
  relevance_score: 8
  source: llm_enhanced
  text: So, yeah, unfortunately, this first or this most recent go-round did not do
    great. Let me do, let me just go ahead and share this previous one. So, I did
    run the exact same one right before. I thought it did a little better. But, you
    know, that's the generative part of generative AI.
  topic: technical
- impact_reason: Suggests ubiquitous deployment and integration of autonomous AI systems
    across all sectors of the economy.
  relevance_score: 8
  source: llm_enhanced
  text: AI agents everywhere.
  topic: Strategy
- impact_reason: Defines the core mission of the show, emphasizing practical leverage
    and career/business growth through AI knowledge, setting the tone for actionable
    content.
  relevance_score: 7
  source: llm_enhanced
  text: we do this every single day, a live stream podcast, and free daily newsletter,
    helping us all not just learn what's happening in AI, but how we can leverage
    it to get ahead, to grow our companies and our careers.
  topic: strategy
- impact_reason: Sets realistic expectations for the time commitment required for
    deep research tasks, contrasting with the near-instantaneous nature of standard
    LLM queries.
  relevance_score: 7
  source: llm_enhanced
  text: depending on the complexity of the query and depending on the integration
    type that you select, this could take up to 45 minutes.
  topic: technical
- impact_reason: Identifies Zapier as a critical integration point, signaling the
    importance of workflow automation platforms for scaling LLM adoption in business
    processes.
  relevance_score: 7
  source: llm_enhanced
  text: Zapier is the huge one [among prebuilt integrations].
  topic: business
- impact_reason: 'Highlights a practical limitation/pitfall in current agentic systems:
    the need for perfect data access and the resulting errors when permissions are
    misconfigured.'
  relevance_score: 7
  source: llm_enhanced
  text: I can always go in here and I can kind of look and see exactly the documents
    that it's looking at. It looks like there's a couple of errors. So, I don't know
    what those errors are. It could have been a permissions issue.
  topic: practical lessons
- impact_reason: Illustrates the complexity of synthesizing large volumes of proprietary
    content, a task that requires high-level structuring (intros, segues) beyond simple
    summarization.
  relevance_score: 7
  source: llm_enhanced
  text: I've probably had 10 hours of episodes on agents. So, it's like, I should
    be able to create a good show, right? But also, it requires more research in between.
    You know, it would require me to, you know, have intros and segues between all
    these pieces, right?
  topic: practical lessons
- impact_reason: Provides current market access details for advanced features (agentic
    tools/web search) and predicts rapid parity across competitors, suggesting enterprise/paid
    tiers are the initial gatekeepers.
  relevance_score: 7
  source: llm_enhanced
  text: You have to be on a paid Anthropic plan... Also, keep in mind, ChatGPT is
    going to be rolling this out in the same way very soon. They've already started
    to roll it out more on the team plan, unfortunately.
  topic: business
- impact_reason: Highlights the difficulty and value of high-fidelity, verbatim extraction
    from massive datasets, a task where current LLMs are still being heavily tested.
  relevance_score: 7
  source: llm_enhanced
  text: I'm telling Claude to go in and literally pull the best quotes verbatim. That
    is an extremely time-consuming task.
  topic: technical
- impact_reason: Signals specific, high-value enterprise integrations coming soon,
    indicating the direction of LLM platform expansion into finance (Stripe), development
    (GitLab), and document management (Box).
  relevance_score: 7
  source: llm_enhanced
  text: There's going to be some upcoming integrations, including Stripe, GitLab,
    and Box to expand some possibilities.
  topic: business
- impact_reason: Offers practical advice on managing expectations for complex agentic
    tasks (time estimation) and emphasizes the necessity of prompt iteration for quality
    results.
  relevance_score: 7
  source: llm_enhanced
  text: And then Claude says it can take up to 45 minutes. But as I said, depending
    on what you're having it do and how good your prompting is, never do it once,
    always iterate.
  topic: strategy
- impact_reason: Quantifies the scale of the AI's work (229 sources processed in ~11
    minutes), demonstrating the sheer volume of data synthesis possible in a short
    timeframe.
  relevance_score: 7
  source: llm_enhanced
  text: So, in total, it didn't go to any more sources from when I checked in at that,
    whatever it was, six and a half minutes. So, it ended up doing 229 total sources,
    11 minutes and 29 seconds.
  topic: technical
- impact_reason: Indicates a strategic pivot in content format (introducing live demos)
    based on audience feedback, showing responsiveness to user preferences for practical
    application.
  relevance_score: 6
  source: llm_enhanced
  text: I'm thinking about trying something new. All right, it's Wednesday. I'm thinking
    about this new segment called AI Work on Wednesdays or something like that. All
    right, I've heard from a lot of you all over the years that you love live demos.
  topic: strategy
- impact_reason: Offers immediate, actionable takeaways for the audience interested
    in applying this new technology.
  relevance_score: 6
  source: llm_enhanced
  text: I have put together a document on the seven best use cases for research integrations.
  topic: strategy
- impact_reason: Provides a clear instruction on how to identify and access the new
    feature for Pro plan users.
  relevance_score: 6
  source: llm_enhanced
  text: if you are on the Pro plan, you're going to see this new button here that
    says research, and it's in beta.
  topic: technical
- impact_reason: Detailed, step-by-step instruction on accessing the new integration
    management area within the Claude interface.
  relevance_score: 6
  source: llm_enhanced
  text: if you click the toggle the search and tools option here inside Claude, and
    then if you scroll to the bottom, there's a new section here that says add integrations.
  topic: technical
- impact_reason: Offers a balanced perspective on human-AI collaboration, showing
    how AI handles the initial heavy lifting (insights extraction) while the human
    expert retains control over the final, creative output.
  relevance_score: 6
  source: llm_enhanced
  text: I use AI to help me, obviously. So, I upload the transcript, you know, the
    AI system, we use CastMagic, other things, you know, it pulls out some insights,
    you know, pulls out some ideas, but, you know, I'm the one that actually goes
    through and types it. I type it. I love doing it. I'm a writer. I was a journalist
    before.
  topic: strategy
- impact_reason: Shows instances of AI 'over-delivering' or inferring related tasks
    beyond the explicit prompt, which can be beneficial but also highlights potential
    scope creep.
  relevance_score: 6
  source: llm_enhanced
  text: I've analyzed Jordan's Everyday AI newsletter archive. Also has cataloged
    500 podcast episodes, which I didn't even ask it to do, right? I just asked it
    to find the corresponding podcast episodes for the leverage newsletter documents.
    So, there's probably about 80 of those. So, when I had it, it did a little more
    work, which is great.
  topic: technical
- impact_reason: Provides a surprising metric about the podcast's reach and success
    within a highly competitive category, lending credibility to the host's insights.
  relevance_score: 5
  source: llm_enhanced
  text: we're usually a top 10 tech podcast on Spotify out of like 90,000.
  topic: business
source: Unknown Source
summary: '## Podcast Episode Summary: EP 539: The 1 new Claude feature that changes
  knowledge work and how to use it


  This episode focuses on a significant, newly accessible feature in Anthropic''s
  Claude AI that the host believes will fundamentally change knowledge work: the combination
  of **Deep Research Mode** with **expanded tool integrations**, now available on
  the **$20/month Claude Pro plan**.


  ---


  ### 1. Focus Area

  The primary focus is on **Applied Generative AI for Knowledge Work**, specifically
  detailing the capabilities of Anthropic''s Claude model when leveraging its integrated
  research and tool-use features. The discussion centers on moving beyond simple chatbot
  interactions to complex, multi-step, data-synthesis tasks.


  ### 2. Key Technical Insights

  *   **Research + Integration Synergy:** The key innovation is combining Claude’s
  "Research" mode (which performs deep, time-consuming web/data queries, reducing
  hallucinations) with direct integrations (like Google Drive, Gmail, GitHub).

  *   **Agentic Tool Use Paradigm Shift:** The host compares this capability to the
  difference between a CPU (sequential processing) and a GPU (parallel processing),
  arguing that agentic tool use—where the AI cycles between internal reasoning, external
  data retrieval, and cross-referencing—represents a massive leap in AI utility.

  *   **Model Context Protocol (MCP):** The episode briefly touches on Anthropic''s
  MCP, a universal language framework that allows LLMs to communicate with external
  services via APIs, suggesting this protocol will enable connections to virtually
  any data source.


  ### 3. Business/Investment Angle

  *   **Democratization of Advanced AI:** Making the powerful research and integration
  features available on the $20 Pro plan (instead of only the $100+ tier) significantly
  lowers the barrier to entry for advanced AI use cases for individual professionals
  and small teams.

  *   **ROI Focus:** The host emphasizes that companies must move beyond tinkering
  with LLMs to developing internal, complex use cases (like the one demonstrated)
  to find tangible Return on Investment (ROI) in Generative AI.

  *   **Competitive Landscape:** While Claude has taken a lead here, the host notes
  that competitors like OpenAI (ChatGPT) and Google (Gemini) are rapidly rolling out
  similar capabilities, suggesting this hybrid research/tool-use model will soon be
  standard across major providers.


  ### 4. Notable Companies/People

  *   **Anthropic (Claude):** The central company whose new feature rollout is the
  subject of the episode.

  *   **Jordan Wilson (Host):** The host of Everyday AI, who previously expressed
  skepticism about Claude''s consumer utility but is now highly impressed by this
  specific feature combination.

  *   **Google (Gemini) & OpenAI (ChatGPT):** Mentioned as key competitors who are
  either leading in certain areas or rapidly catching up to Claude''s new integration
  capabilities.


  ### 5. Future Implications

  The industry is moving toward **highly autonomous, multi-step AI agents** capable
  of complex project execution. Future AI tools will not just answer questions but
  will proactively use integrated data sources (internal documents, email, web) to
  synthesize comprehensive projects, effectively acting as high-level research assistants
  or project managers.


  ### 6. Target Audience

  This episode is highly valuable for **AI Practitioners, Knowledge Workers, Tech
  Professionals, and Business Leaders** who are actively seeking to implement practical,
  high-leverage AI workflows beyond basic prompting, especially those already subscribed
  to or considering Claude Pro.


  ---


  ### Comprehensive Summary


  The podcast episode centers on the host’s excitement over a single, newly accessible
  feature in **Anthropic’s Claude**: the integration of its **Deep Research Mode**
  with its expanding **tool integrations**, now available on the affordable **$20/month
  Claude Pro plan**. The host, who has previously been critical of Claude’s consumer
  utility compared to competitors, argues this specific combination is a game-changer
  for knowledge work.


  The core discussion revolves around a live demonstration where the host tasks Claude
  with a Herculean project: synthesizing content from hundreds of past newsletter
  documents stored in his Google Drive, cross-referencing that with external web research,
  and then generating new, complex content outlines (mashup episodes) based on the
  synthesized knowledge. This task, which would take hundreds of human hours, is executed
  using Claude''s agentic capabilities.


  Technically, the power lies in the **agentic tool use**, where Claude cycles between
  accessing private data (Drive) and public data (web browsing) to refine its understanding—a
  process the host likens to the parallel processing power of a GPU. The episode highlights
  that this capability is supported by the **Model Context Protocol (MCP)**, which
  standardizes how LLMs interact with external software.


  The business significance is the **democratization of advanced AI workflows**. Previously,
  these deep research capabilities were locked behind expensive tiers. Now, professionals
  can leverage complex data synthesis and cross-referencing for significant productivity
  gains. The host stresses that businesses must start developing their own internal,
  complex use cases now, as competitors like Google and OpenAI are quickly closing
  the gap on these integrated research features. The episode concludes by emphasizing
  that the future of AI utility lies in these reasoning, planning, and tool-using
  models that can manage multi-stage projects autonomously.'
tags:
- artificial-intelligence
- generative-ai
- ai-infrastructure
- anthropic
- openai
- microsoft
- google
- nvidia
title: 'EP 539: The 1 new Claude feature that changes knowledge work and how to use
  it'
topics:
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 99
  prominence: 1.0
  topic: artificial intelligence
- keywords:
  - generative ai
  - genai
  - chatgpt
  - gpt
  - claude
  - text generation
  - image generation
  mentions: 62
  prominence: 1.0
  topic: generative ai
- keywords:
  - gpu
  - tensor
  - training
  - inference
  - model deployment
  - vector database
  mentions: 4
  prominence: 0.4
  topic: ai infrastructure
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-10-05 12:30:47 UTC -->
