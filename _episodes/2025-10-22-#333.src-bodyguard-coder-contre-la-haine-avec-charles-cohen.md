---
companies:
- category: unknown
  confidence: medium
  context: s extraordinaires et visionnaires. Bienvenue dans If This Then Dev, le
    podcast qui veut résoudre le problème avant d
  name: If This Then Dev
  position: 117
- category: tech
  confidence: high
  context: hen Dev, le podcast qui veut résoudre le problème avant de passer au Dev.
    Chaque semaine, je recevrai un
  name: Avant
  position: 176
- category: unknown
  confidence: medium
  context: les embrouilles que vous pouvez avoir avec Kevin. Sur Internet, il n'y
    a personne, ou plutôt, il y a les platefo
  name: Sur Internet
  position: 2159
- category: unknown
  confidence: medium
  context: à ces questions, modérateur, je ne ressens pas à Chris Poul, mais il s'y
    connaît en commentaires qui dérapent
  name: Chris Poul
  position: 2772
- category: unknown
  confidence: medium
  context: mais il s'y connaît en commentaires qui dérapent, Charles Mangeon. Salut
    Bruno. Alors Charles, est-ce que je peux t
  name: Charles Mangeon
  position: 2834
- category: unknown
  confidence: medium
  context: ît en commentaires qui dérapent, Charles Mangeon. Salut Bruno. Alors Charles,
    est-ce que je peux te présenter p
  name: Salut Bruno
  position: 2851
- category: unknown
  confidence: medium
  context: aires qui dérapent, Charles Mangeon. Salut Bruno. Alors Charles, est-ce
    que je peux te présenter pour les quelque
  name: Alors Charles
  position: 2864
- category: unknown
  confidence: medium
  context: ne me connaissent pas. Mais du coup, je m'appelle Charles Cohen, j'ai 29
    ans, 30 ans dans un mois, terrible. Et j
  name: Charles Cohen
  position: 3082
- category: unknown
  confidence: medium
  context: s de techno. J'ai commencé avec Java sur le back, Java PHP, j'ai fait PostgreSQL,
    donc du SQL sur les bases
  name: Java PHP
  position: 5722
- category: unknown
  confidence: medium
  context: t donc je commence à développer une technologie d'IA Symbolique. Et je
    pense qu'on reviendra sur l'IA de manière
  name: IA Symbolique
  position: 7620
- category: tech
  confidence: high
  context: u trop gros. Et le chat, de par sa taille, ce que Facebook, ce que Meta,
    c'est énorme. Il y a 50 000 employé
  name: Facebook
  position: 9460
- category: tech
  confidence: high
  context: e chat, de par sa taille, ce que Facebook, ce que Meta, c'est énorme. Il
    y a 50 000 employés. Il est un
  name: Meta
  position: 9477
- category: unknown
  confidence: medium
  context: ématique ou pas. À l'époque, Bodyguard protégeait Bilal Hassani. Bilal
    Hassani, qui est un chanteur transsexuel e
  name: Bilal Hassani
  position: 12610
- category: tech
  confidence: high
  context: ussi pouvoir associer à chaque classification une notion de sévérité. Parce
    que pas tout le monde a la mêm
  name: Notion
  position: 15175
- category: unknown
  confidence: medium
  context: ', c''est ça, quoi. Il y a ce qu''on appelle du *One-Hot Encoding*. Quand
    on reçoit un commentaire textuel, on va s'
  name: Hot Encoding
  position: 20276
- category: unknown
  confidence: medium
  context: e perds tous mes clients. Je me retrouve avec des Ruits Vuitton, des *Vissofts*,
    etc., si je me mets à supprimer
  name: Ruits Vuitton
  position: 24968
- category: unknown
  confidence: medium
  context: rmes. Donc on a une fonctionnalité qu'on appelle *Audience Intelligence*
    qui permet en fait de fournir des rapports détai
  name: Audience Intelligence
  position: 43009
- category: unknown
  confidence: medium
  context: nction de ce qui s'est passé sur leur plateforme. Le PSG fait un défilé.
    Le Paris Saint-Germain signe un n
  name: Le PSG
  position: 43175
- category: unknown
  confidence: medium
  context: passé sur leur plateforme. Le PSG fait un défilé. Le Paris Saint-Germain
    signe un nouveau joueur. Il peut, en temp
  name: Le Paris Saint
  position: 43198
- category: unknown
  confidence: medium
  context: autour de Kylian Mbappé, ce qui se dit autour de Lionel Messi, ce qui se
    dit autour de tel acteur, autour de te
  name: Lionel Messi
  position: 43376
- category: tech
  confidence: high
  context: ences Copilot pour nos développeurs, des licences Anthropic, parce que
    Claude n'était pas disponible dans Cop
  name: Anthropic
  position: 43866
- category: unknown
  confidence: medium
  context: code React qui est généré pour générer le visuel. Avec Canva ? Avec Canva.
    Je ne savais pas, je sais que c'est
  name: Avec Canva
  position: 44589
- category: unknown
  confidence: medium
  context: t très loin, mais c'était avec Figma, par contre. Avec Figma. J'ai reçu
    les gens de Figma où, du coup, on a pa
  name: Avec Figma
  position: 44900
- category: unknown
  confidence: medium
  context: il y a tout le monde qui a des licences quasiment Gemini Pro dans la boîte.
    On a plein de solutions comme ça i
  name: Gemini Pro
  position: 45619
- category: unknown
  confidence: medium
  context: des exemples de joueurs du PSG que de sacs à main Louis Vuitton. C'est
    peut-être juste une question d'intérêt per
  name: Louis Vuitton
  position: 45957
- category: unknown
  confidence: medium
  context: parce que j'ai une expertise en fait en NLP, en *Natural Language Processing*,
    en compréhension de ce qui se passe sur... Je c
  name: Natural Language Processing
  position: 46660
- category: ai_application
  confidence: high
  context: Partenaire du podcast, aide les entreprises à se mettre en conformité (SOC
    2, ISO 27001) en utilisant l'automatisation et l'IA pour le 'trust management'.
  name: Vanta
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Entreprise fondée par Charles Mangeon, spécialisée dans la modération de
    contenu en ligne utilisant une technologie d'IA Symbolique (moteurs de règles)
    développée en Java.
  name: Bodyguard
  source: llm_enhanced
- category: other
  confidence: high
  context: Société de production du podcast 'If This Then Dev'.
  name: Cause à vos traces
  source: llm_enhanced
- category: other
  confidence: medium
  context: Société d'études citée pour une étude sur les économies réalisées par les
    clients de Vanta.
  name: IDC
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Mentionné comme un exemple de grande plateforme ('le chat') qui a du mal
    à suivre rapidement les nouvelles formes de toxicité en ligne.
  name: Facebook / Meta
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Entreprise dont le fondateur, Yann Guérin, a conseillé le locuteur sur
    le concept de One-Hot Encoding.
  name: Gladia.io
  source: llm_enhanced
- category: ai_research
  confidence: medium
  context: Institution où Yann Guérin était directeur de l'IA et qui a investi dans
    Bodyguard au début.
  name: HEC
  source: llm_enhanced
- category: ai_model
  confidence: high
  context: Mentioned as the model released via API that prompted the speaker to initiate
    a major AI integration plan at Bodyguard in November 2022.
  name: GPT-3.5
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned in conjunction with the release of GPT-3.5, triggering a crisis
    meeting at Bodyguard regarding AI integration.
  name: ChatGPT
  source: llm_enhanced
- category: ai_tool
  confidence: high
  context: Mentioned as an internal AI tool licensed for developers at Bodyguard to
    improve productivity.
  name: Copilot
  source: llm_enhanced
- category: ai_company
  confidence: high
  context: Mentioned as the provider of models used internally via Copilot, specifically
    noted for having the best code models at the time.
  name: Anthropic
  source: llm_enhanced
- category: ai_model
  confidence: medium
  context: Mentioned as a model from Anthropic that was not available via Copilot
    at the time of the discussion.
  name: Claude
  source: llm_enhanced
- category: ai_tool
  confidence: medium
  context: Mentioned as a tool used by marketing and product teams internally, likely
    an AI-assisted productivity tool.
  name: Low-Fibal
  source: llm_enhanced
- category: ai_tool
  confidence: high
  context: Mentioned as a design tool whose AI features (prompt-to-design) are being
    used by UX designers to generate visuals and React code.
  name: Canva
  source: llm_enhanced
- category: ai_tool
  confidence: high
  context: Mentioned in comparison to Canva regarding AI features; specifically noted
    for a plugin that converts Figma designs directly into React components with symbolic
    linking.
  name: Figma
  source: llm_enhanced
- category: ai_model
  confidence: high
  context: Mentioned as a model/tool for which the entire company (Bodyguard) has
    licenses to boost productivity.
  name: Gemini Pro
  source: llm_enhanced
- category: technology_concept
  confidence: high
  context: General term for Large Language Models, the core technology being discussed
    for advanced contextual understanding and structured output.
  name: LLM
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Specific version of OpenAI's model whose quality leap over GPT-3.5 signaled
    rapid progress in the field.
  name: GPT-4
  source: llm_enhanced
- category: technology_concept
  confidence: high
  context: Mentioned as the older, rule-based AI approach that LLMs can now replace
    or augment.
  name: IA Symbolique
  source: llm_enhanced
- category: technology_concept
  confidence: high
  context: General term for the older, supervised models used previously for large-scale
    classification tasks, contrasted with the capabilities of LLMs.
  name: Machine Learning
  source: llm_enhanced
date: 2025-10-22 03:00:37 +0000
duration: 65
has_transcript: false
layout: episode
llm_enhanced: true
original_url: https://audio.listennotes.com/e/p/59b86166302f46c4b2dededab56f5bb8/
processing_date: 2025-10-22 07:53:02 +0000
quotes:
- length: 67
  relevance_score: 4
  text: Il y a du *machine learning* et après, il y a eu du *deep learning*
  topics: []
- length: 54
  relevance_score: 4
  text: Donc les LLM sont du *deep learning*, je suis terrible
  topics: []
- length: 296
  relevance_score: 4
  text: Mais, je peux vous montrer que la technologie Bodyguard d'IA Symbolique, dont
    je parle là, qui est maintenant alimentée par une équipe de 8 linguistes depuis
    maintenant 6 ans, c'est une IA qui est beaucoup plus performante que la plupart
    des modèles de *machine learning* ou de certains LLM aussi
  topics: []
- length: 147
  relevance_score: 4
  text: Après, on pourra faire la comparaison avec du *machine learning* avec du LLM
    qui sont des technologies qu'on utilise, mais ça doit dépendre des cas
  topics: []
- length: 93
  relevance_score: 4
  text: C'était l'IA Symbolique, après tu as ajouté le *tuning* du *machine learning*
    et après le LLM
  topics: []
- length: 246
  relevance_score: 4
  text: Et quand on va sûrement parler du LLM, je suppose qu'ils sont en fait des
    modèles de *transformer*, donc une type technologie BERT, sous-jacente, on retrouve
    les mêmes problématiques dont je ne sais pas si on va parler, pas toutes, mais
    certaines
  topics: []
- length: 108
  relevance_score: 4
  text: Donc, au moment où je vous parle, on avait l'IA Symbolique plus du *machine
    learning*, on n'avait pas de LLM
  topics: []
- length: 148
  relevance_score: 4
  text: Je le comprends tout de suite parce que j'ai une expertise en fait en NLP,
    en *Natural Language Processing*, en compréhension de ce qui se passe sur
  topics: []
- length: 150
  relevance_score: 4
  text: C'est-à-dire que à la différence du *machine learning*, le LLM, tu peux lui
    donner le commentaire, mais tu peux lui donner aussi le sujet de l'article
  topics: []
- length: 291
  relevance_score: 3
  text: 'Le terme IA Symbolique, je l''ai appris que vraiment, à la maturité du *machine
    learning* et à l''arrivée encore récent de l''intelligence artificielle, mais
    ce terme-là, pour moi, c''était juste : bon, je veux créer une technologie qui
    va résoudre un problème précis que je connais parfaitement'
  topics: []
- length: 209
  relevance_score: 3
  text: Et ensuite, en interne, très vite, on va utiliser des licences Copilot pour
    nos développeurs, des licences Anthropic, parce que Claude n'était pas disponible
    dans Copilot à l'époque, donc pas de non, c'est bon
  topics: []
- length: 124
  relevance_score: 3
  text: Donc on utilise uniquement Copilot avec principalement les modèles d'Anthropic
    qui sont les meilleurs en code pour le moment
  topics: []
- impact_reason: Pose directement le dilemme Build vs Buy (ou Fine-tune) dans le contexte
    de l'application de l'IA pour la modération.
  relevance_score: 10
  source: llm_enhanced
  text: Faut-il tout construire maison ou simplement *fine-tuner* un LLM ?
  topic: technical/business
- impact_reason: Proposition d'une taxonomie claire des IA (Symbolique, ML, DL), plaçant
    les LLM dans la catégorie Deep Learning.
  relevance_score: 10
  source: llm_enhanced
  text: 'Pour moi, il y a trois types d''IA : il y a l''IA Symbolique, qui est en
    fait du code, de l''algorithmique, des moteurs de règles. Il y a du *machine learning*
    et après, il y a eu du *deep learning*. Donc les LLM sont du *deep learning*,
    je suis terrible. Donc pour moi, il y a eu ces trois évolutions majeures.'
  topic: technical/AI_trend
- impact_reason: 'Affirmation forte et contre-intuitive : un système d''IA Symbolique
    codé sur mesure surpasse encore les LLM pour cette tâche spécifique (modération).'
  relevance_score: 10
  source: llm_enhanced
  text: Je crée un moteur de règles en Java, qui est, pour l'histoire, encore utilisé
    maintenant sur l'analyse de milliards de contenus tous les mois, et qui est encore
    maintenant plus performant que du LLM.
  topic: technical/comparison
- impact_reason: 'Définit le besoin fondamental de l''analyse contextuelle pour distinguer
    l''intention (ex: ''connard'' utilisé comme insulte vs. comme citation).'
  relevance_score: 10
  source: llm_enhanced
  text: Il faut du contexte. Le contexte, c'est ce qui se passe avant ou après dans
    la phrase.
  topic: technical/context
- impact_reason: 'Crucial insight for developing adaptive safety systems: the required
    level of protection must scale based on the vulnerability of the target individual.'
  relevance_score: 10
  source: llm_enhanced
  text: protéger un... un youtubeur de 40 ans qui fait des vidéos un peu marrantes
    sur GTA 5... Ce n'est pas la même chose que protéger une petite fille qui présente
    les jouets qu'elle a eu à Noël, quand elle a 10 ans. L'impact n'est pas le même.
  topic: safety/strategy
- impact_reason: A strong claim asserting the superior performance of a specialized,
    human-augmented Symbolic AI system over general-purpose Machine Learning models
    (including some LLMs) for a specific task (moderation).
  relevance_score: 10
  source: llm_enhanced
  text: je peux vous montrer que la technologie Bodyguard d'IA Symbolique, dont je
    parle là, qui est maintenant alimentée par une équipe de 8 linguistes depuis maintenant
    6 ans, c'est une IA qui est beaucoup plus performante que la plupart des modèles
    de *machine learning* ou de certains LLM aussi.
  topic: technical/predictions
- impact_reason: 'Crucial strategic advice for the current tech landscape: LLMs are
    powerful but not universal; success lies in understanding limitations and combining
    technologies (hybrid approach).'
  relevance_score: 10
  source: llm_enhanced
  text: 'ne pas foncer tête baissée sur du LLM, en disant que c''est la solution à
    tout. *Spoiler alert* : ce n''est pas la solution à tout. Pour moi, c''est une
    complémentarité de technologies.'
  topic: strategy/predictions
- impact_reason: 'A significant warning for software engineering in the LLM era: traditional
    deterministic unit testing breaks down due to model stochasticity, necessitating
    probabilistic testing methods like regression tests based on validated outputs.'
  relevance_score: 10
  source: llm_enhanced
  text: j'ai de façon tout à fait naturelle, j'ai codé des tests de non-régression.
    [...] les tests unitaires dans un code, ils vont être chamboulés avec l'arrivée
    de l'IA. Parce que les hallucinations des LLM, ou le fait que parfois, un LLM
    peut répondre différemment pour le même *prompt*, fait que tes tests unitaires,
    parfois, peuvent marcher ou pas marcher.
  topic: technical/safety
- impact_reason: Directly addresses the core challenge of maintaining accuracy in
    evolving moderation systems—ensuring new changes don't break established, critical
    classifications.
  relevance_score: 10
  source: llm_enhanced
  text: je sais que ce commentaire a été un "connard", ça doit être classifié en tant
    qu'insulte. Et donc, ça, c'est mes tests de non-régression que j'ajoute pour que
    dès que je fais une modification, que ce soit sur les règles linguistiques ou
    sur l'algorithme de l'IA Symbolique, je m'assure de rien casser.
  topic: technical
- impact_reason: Draws a direct parallel between custom, rule-based tokenization/encoding
    (pre-2017) and modern LLM tokenization, showing conceptual continuity in NLP.
  relevance_score: 10
  source: llm_enhanced
  text: Est-ce que c'est assez proche, c'est assez proche de la conversion aussi en
    token dans les LLM aujourd'hui ? C'est en fait, c'est ça. C'est une conversion,
    ce n'est pas une matrice, c'est en sortie, mais c'est la même idée.
  topic: technical
- impact_reason: 'A major critique of standard supervised ML classification in moderation:
    its inability to incorporate surrounding context (e.g., post topic, user history)
    easily.'
  relevance_score: 10
  source: llm_enhanced
  text: la problématique du machine learning, c'est que ce n'est pas contextuel. C'est-à-dire
    que tu ne peux pas lui donner le contexte du commentaire. L'entrée, généralement,
    c'est un texte, à la sortie, c'est une classification ou une liste de classifications.
  topic: technical
- impact_reason: Crucial point on the slow iteration cycle of traditional ML models
    versus the rapid evolution of adversarial behavior in content moderation.
  relevance_score: 10
  source: llm_enhanced
  text: Comment je fais pour corriger la technologie, aussi rapidement ? Parce que,
    en train d'être un modèle de machine learning, ça nécessite de reclassifier ton
    dataset, donc collecter les données, les classifier, ré-entraîner ton modèle...
    Il s'est passé deux semaines, le mal est déjà fait depuis deux semaines.
  topic: technical
- impact_reason: A strong conclusion on the limitations of ML for dynamic, adversarial
    tasks like hate speech detection, contrasting it with stable tasks like spam or
    sentiment analysis.
  relevance_score: 10
  source: llm_enhanced
  text: OK. Le machine learning, ça ne va pas être adapté pour de la modération automatisée
    sur des contenus haineux. Ça va l'être sur des classifications qui ne changent
    pas.
  topic: predictions
- impact_reason: 'The core strategic takeaway: modern, high-performance moderation
    requires a hybrid approach combining Symbolic AI, ML, and human review, not a
    single silver bullet.'
  relevance_score: 10
  source: llm_enhanced
  text: 'Donc je comprends : "Bon, alors, ben déjà, c''est une complémentarité." Et
    donc c''est là où je me dis : "Ça va nécessiter une complémentarité de technologies
    qu''on doit mettre en place."'
  topic: strategy
- impact_reason: 'Provides a comprehensive, three-pillar framework for enterprise-wide
    AI adoption: Technology enhancement, Product feature integration, and Internal
    productivity boost.'
  relevance_score: 10
  source: llm_enhanced
  text: 'L''intégration de l''IA chez Bodyguard, c''est une intégration à trois niveaux
    : une intégration technologique, dans la technologie Bodyguard de modération et
    de classification. [...] l''intégration dans le produit Bodyguard [...] Et l''intégration
    de l''IA chez Bodyguard, et c''est un des sujets les plus importants, c''est l''intégration
    d''outils d''IA en interne pour améliorer la productivité de toute la boîte.'
  topic: strategy
- impact_reason: 'Detailed comparison showing LLM superiority: ability to ingest context,
    output structured data (severity, target audience), and handle multi-faceted classification,
    which traditional ML struggled with.'
  relevance_score: 10
  source: llm_enhanced
  text: À la différence du *machine learning*, le LLM, tu peux lui donner le commentaire,
    mais tu peux lui donner aussi le sujet de l'article. Tu peux lui demander en sortie
    d'avoir une liste de classifications mais également qu'il te dise vers qui le
    commentaire est destiné. Tu peux aussi lui demander une notion de sévérité, si
    c'est *low*, *medium*, *high*, d'imposer une sévérité sur les classifications
    qu'il a trouvées.
  topic: technical
- impact_reason: 'C''est le point de rupture : les LLM permettent l''interrogation
    fine et contextuelle (Question Answering) que les anciens modèles ML ne pouvaient
    pas gérer efficacement.'
  relevance_score: 10
  source: llm_enhanced
  text: c'était la possibilité qu'on ne pouvait pas faire avec du *machine learning*,
    c'était de poser des questions clés.
  topic: Technique/Avancées LLM
- impact_reason: Expose concrètement l'application de la granularité des LLM dans
    un cas d'usage sensible (modération/analyse de contenu), nécessitant des détails
    factuels très fins.
  relevance_score: 10
  source: llm_enhanced
  text: 'On utilise du LLM pour comprendre l''article et surtout avoir des réponses
    avec des questions très précises : "Est-ce que l''article parle de gens qui ont
    été tués ? Est-ce que l''article parle d''un objet ? [...] Est-ce que l''humain,
    quelle est la couleur de peau de la personne qui est sur l''article ? Sur la photo
    ?"'
  topic: Application IA/Modération
- impact_reason: 'Clarifie la limitation fondamentale des anciens systèmes ML : ils
    excellaient dans la classification de haut niveau, mais échouaient dans l''extraction
    de faits précis et nuancés.'
  relevance_score: 10
  source: llm_enhanced
  text: 'Le *machine learning* répondait : "Ça, c''est un article politique, ça, c''est
    un article géopolitique, ça, c''est un article sur la technologie." On avait des
    grandes classifications, mais on n''avait pas des réponses précises à des questions.'
  topic: Technique/Limitation ML vs LLM
- impact_reason: 'Souligne le problème fondamental de la modération centralisée par
    les plateformes : lenteur et inefficacité face à la toxicité émergente.'
  relevance_score: 9
  source: llm_enhanced
  text: Sur Internet, il n'y a personne, ou plutôt, il y a les plateformes qui régulent,
    modèrent, interdisent, mais pas toujours assez vite, ni forcément assez bien.
  topic: safety/strategy
- impact_reason: Question centrale du podcast, posant le défi d'automatiser la régulation
    du discours en ligne.
  relevance_score: 9
  source: llm_enhanced
  text: Mais alors, peut-on vraiment modérer la modération avec du code ?
  topic: safety/technical
- impact_reason: Le catalyseur émotionnel et éthique direct qui a mené à la création
    de la solution de modération.
  relevance_score: 9
  source: llm_enhanced
  text: Et là, j'ai 20 ans et un soir, je lis un article d'une jeune fille de 11 ans
    qui s'est pendue dans sa chambre à cause du cyber-harcèlement qu'elle recevait.
  topic: safety/personal
- impact_reason: Métaphore clé décrivant la course constante à l'innovation entre
    les modérateurs (chat) et les utilisateurs toxiques (souris).
  relevance_score: 9
  source: llm_enhanced
  text: La modération, c'est à la fois un jeu du chat et de la souris. Et ça c'est
    important de le retenir.
  topic: safety/strategy
- impact_reason: 'Critique structurelle des grandes plateformes : leur taille les
    rend intrinsèquement lentes à réagir aux nouvelles formes de toxicité.'
  relevance_score: 9
  source: llm_enhanced
  text: Le chat, c'est les plateformes, les réseaux sociaux. Le chat, il est un peu
    trop gros. Et le chat, de par sa taille, ce que Facebook, ce que Meta, c'est énorme.
    Il y a 50 000 employés. Il est un peu trop gros pour pouvoir suivre les nouvelles
    tendances.
  topic: safety/strategy
- impact_reason: 'Déduction stratégique : la rapidité de mise à jour des règles est
    plus cruciale que la complexité initiale du modèle.'
  relevance_score: 9
  source: llm_enhanced
  text: Je comprends dès le début que la modération, c'est un jeu du chat et de la
    souris où la technologie, il faut qu'elle puisse être mise à jour très rapidement.
  topic: strategy/technical
- impact_reason: Rejette la méthode la plus basique de filtrage, soulignant la nécessité
    d'une compréhension plus fine du langage.
  relevance_score: 9
  source: llm_enhanced
  text: La modération, ce n'est pas juste de la détection de mot-clé.
  topic: technical/safety
- impact_reason: Renforce l'idée que les tactiques de filtrage simples sont obsolètes
    face à l'évolution du langage toxique (évasion par orthographe, etc.).
  relevance_score: 9
  source: llm_enhanced
  text: Le premier truc que je comprends, c'est que les mots-clés, la détection de
    mots-clés, ça ne va pas marcher.
  topic: technical/safety
- impact_reason: 'Ajoute une dimension cruciale : l''identification de la cible (destinataire)
    est aussi importante que le contexte de la phrase.'
  relevance_score: 9
  source: llm_enhanced
  text: Il faut comprendre vers qui il est destiné, dans quel contexte les mots sont
    utilisés.
  topic: safety/ethics
- impact_reason: 'Illustre la dépendance sémantique au contenu hôte (ex: vomir sur
    un coming out vs. sur de la nourriture).'
  relevance_score: 9
  source: llm_enhanced
  text: Le même commentaire, en fonction de ce qu'il suggère, il peut avoir une signification
    totalement différente.
  topic: technical/context
- impact_reason: Exemple précis de la détection d'une attaque contextuelle basée sur
    un symbole (emoji) et le sujet de la vidéo.
  relevance_score: 9
  source: llm_enhanced
  text: 'Quelqu''un qui vient poster sous la vidéo : "Je fais mon *coming out*", un
    émoji qui vomit, ça, c''est de l''homophobie.'
  topic: safety/context
- impact_reason: Exemple choc illustrant comment une phrase neutre ('Je suis content
    pour lui') devient inappropriée ou toxique selon le contexte de l'événement mentionné
    (suicide vs. succès).
  relevance_score: 9
  source: llm_enhanced
  text: Si je suis content pour lui, on parle de quelqu'un qui s'est suicidé...
  topic: safety/context
- impact_reason: Highlights the critical limitation of keyword-based moderation systems,
    emphasizing the necessity of contextual understanding (who is the target, what
    is the context) for accurate content filtering.
  relevance_score: 9
  source: llm_enhanced
  text: il ne faut pas que des mots-clés, il faut comprendre vers qui il est destiné,
    dans quel contexte les mots sont utilisés.
  topic: safety/technical
- impact_reason: Advocates for a multi-dimensional classification approach (type +
    severity level), moving beyond binary flagging to nuanced moderation.
  relevance_score: 9
  source: llm_enhanced
  text: il faut classifier les contenus, mais il faut aussi pouvoir associer à chaque
    classification une notion de sévérité.
  topic: safety/technical
- impact_reason: Identifies the need to track author behavior (frequency, pattern)
    to distinguish isolated insults from systemic harassment, a key component of advanced
    moderation.
  relevance_score: 9
  source: llm_enhanced
  text: il faut aussi faire une technologie d'analyse sur le comportement des auteurs,
    pour justement gérer ces cas [de harcèlement moral].
  topic: safety/technical
- impact_reason: Provides a high-level technical overview of the Symbolic AI pipeline,
    emphasizing its transparency and maintainability—a major advantage over opaque
    ML models.
  relevance_score: 9
  source: llm_enhanced
  text: Il y a du *pré-processing* poussé, il y a du *One-Hot Encoding*, et ensuite,
    c'est notre algorithme avec des `if`, avec des `foreach`, avec des statistiques,
    avec tout ça. Mais c'est quelque chose qui est un algorithme qui peut être transparent,
    on peut comprendre ce qu'il se passe, on peut le mettre à jour, on peut l'améliorer,
    etc.
  topic: technical
- impact_reason: 'Details the practical implementation of robust regression testing
    for AI systems: using human-validated historical data points as immutable test
    cases to prevent algorithmic drift.'
  relevance_score: 9
  source: llm_enhanced
  text: j'ai très vite ajouté les tests de non-régression, qui sont en fait des commentaires,
    des commentaires haineux, qui sont classifiés comme ça, qui ont été validés par
    un humain. Et donc, je sais que ce commentaire a été un 'connard', ça doit être
    classifié en tant qu'insulte.
  topic: technical/safety
- impact_reason: Illustrates the extreme business risk associated with false positives
    in content moderation, emphasizing the need for rigorous testing.
  relevance_score: 9
  source: llm_enhanced
  text: si par exemple, du jour au lendemain, je dis n'importe quoi, mais le mot "bateau"
    se met à être haineux, parce qu'on a merdé sur une règle linguistique, enfin,
    moi, je perds tous mes clients.
  topic: business
- impact_reason: Detailed explanation of a crucial pre-processing technique used to
    normalize text input, making the system robust against common obfuscation tactics
    (e.g., typos, accents).
  relevance_score: 9
  source: llm_enhanced
  text: j'ai la valeur du mot en texte, avec un pré-processing qui est effectué. Le
    mot, par exemple, le mot, je vais pas en termes, le mot "épée", une épée. Une
    épée, c'est accentué, le pré-processing de Bodyguard, il va retirer les doubles
    lettres, il va retirer les accents.
  topic: technical
- impact_reason: 'Defines the primary role of pre-processing in adversarial text environments:
    managing infinite input variations caused by users trying to bypass filters.'
  relevance_score: 9
  source: llm_enhanced
  text: il y a des possibilités infinies [de façons d'écrire des insultes]. Donc comment
    on traite ça ? On traite ça avec du pré-processing, pour pouvoir gérer justement
    toutes les entrées.
  topic: technical
- impact_reason: Sets a clear, high-stakes performance benchmark (20ms latency for
    massive scale) that drives architectural decisions away from slow methods like
    complex rules or large ML models.
  relevance_score: 9
  source: llm_enhanced
  text: Bodyguard, c'est plusieurs milliards de commentaires par mois, et on doit
    répondre en 20 millisecondes, une analyse.
  topic: business
- impact_reason: Exposes the difficulty of setting hard thresholds on ML probability
    outputs, especially when the cost of error (false positive/negative) is high.
  relevance_score: 9
  source: llm_enhanced
  text: Qu'est-ce que je fais, moi, si le commentaire est à 69 % haineux, et pas 70
    % ? Où est-ce que je mets la barre de retrait ?
  topic: safety
- impact_reason: Highlights the lack of fine-grained severity control in standard
    classification models, a necessary feature for nuanced moderation.
  relevance_score: 9
  source: llm_enhanced
  text: Comment je fais pour la granularité ? La granularité de la sévérité. Comment
    je fais pour savoir si l'insulte, si elle est sévère ou pas sévère ? Ça, je ne
    l'ai pas dans ce type de formation.
  topic: safety
- impact_reason: 'Provides actionable advice: use ML where the input distribution
    is stable and less adversarial (spam/positive sentiment) rather than highly dynamic
    (hate speech).'
  relevance_score: 9
  source: llm_enhanced
  text: Donc en fait, je crée les premiers modèles de machine learning sur la détection
    de spam, la détection du positif, ou là, ça marche bien, et ce ne sont pas des
    choses qui évoluent.
  topic: business
- impact_reason: Describes a specific conflict resolution mechanism (ML vs. Symbolic
    AI) resolved by human oversight, demonstrating a robust system architecture.
  relevance_score: 9
  source: llm_enhanced
  text: 'Donc quand mon IA Symbolique dit que ce n''est pas haineux, que le machine
    learning dit que c''est haineux, j''envoie ça à une revue humaine qui va revoir
    le commentaire et me dire : "Auquel il y a deux, c''est trompé."'
  topic: technical
- impact_reason: A stark, high-stakes declaration about the existential necessity
    of integrating modern AI (LLMs) for business survival post-2022.
  relevance_score: 9
  source: llm_enhanced
  text: Bon, maintenant, l'intégration de l'IA sur Bodyguard, ça va être une question
    de vie ou de mort pour Bodyguard.
  topic: business/strategy
- impact_reason: 'Highlights the primary value proposition of LLMs in content moderation:
    scalable, one-time contextual understanding of the source material (post/video)
    to inform subsequent moderation decisions.'
  relevance_score: 9
  source: llm_enhanced
  text: On intègre dans un tout premier temps l'IA pour... Je parlais de l'importance
    de comprendre le contexte, le sujet de la vidéo. [...] On arrive à comprendre
    en fait ce qui se passe et ce qui se dit dans l'article, dans la publication.
    C'est plus ça que tu as besoin de le faire une fois, même si tu as 2 millions
    de commentaires, tu le fais une fois. C'est très scalable, ça coûte pas très cher.
  topic: technical/business
- impact_reason: Describes a highly advanced feature in design-to-code workflows (Figma),
    emphasizing bidirectional synchronization, which significantly improves development
    delivery speed.
  relevance_score: 9
  source: llm_enhanced
  text: Le truc qui m'a le plus bluffé sur la conversion Figma code, c'est qu'en fait,
    il te crée un lien symbolique entre ta maquette et les composants React qui sont
    générés. Et si tu déformes un changement sur le composant React, le changement
    se répercute sur la maquette dans Figma. C'est magnifique.
  topic: technical/strategy
- impact_reason: 'A key insight from an expert: LLMs can immediately supersede older
    Symbolic AI systems due to their superior contextual understanding.'
  relevance_score: 9
  source: llm_enhanced
  text: Je le comprends tout de suite parce que j'ai une expertise en fait en NLP,
    en *Natural Language Processing*, en compréhension de ce qui se passe sur... Je
    connais quasiment toutes les technologies qui existent à ce moment-là et je me
    rends compte que le LLM peut déjà remplacer mon IA Symbolique.
  topic: technical
- impact_reason: A powerful observation on the rapid pace of LLM advancement, using
    the GPT-3.5 vs. GPT-4 jump as a benchmark for future speed of improvement.
  relevance_score: 9
  source: llm_enhanced
  text: 'Je me souviens très bien avoir mesuré la différence de qualité entre 3.5
    et GPT-4 où je me dis : "OK, bon, le progrès va être très vite."'
  topic: predictions
- impact_reason: Reiterates the high-stakes nature of keeping up with AI evolution,
    framing it as a critical competitive differentiator or existential threat.
  relevance_score: 9
  source: llm_enhanced
  text: 'Le danger, si on n''est pas à la page, est forcément très gros. C''est pour
    ça que j''ai dit : "Soit tu meurs, soit tu crèves." Et j''ai dit : "C''est une
    question de vie ou de mort pour moi, l''intégration de l''IA."'
  topic: strategy/safety
- impact_reason: Confirms that for precise, context-heavy tasks (like summarizing
    post context), the quality and speed improvements from GPT-3.5 to GPT-4 are 'enormous'.
  relevance_score: 9
  source: llm_enhanced
  text: Est-ce que tu as perçu un progrès réel sur ce travail très précis là, entre
    GPT-3.5, qu'est-ce qu'on a aujourd'hui avec un GPT-4, où je peux utiliser aujourd'hui
    ? C'est énorme. Ok, la progression, elle est énorme. Mais surtout sur la qualité,
    la rapidité, et surtout la qualité et la rapidité.
  topic: technical/predictions
- impact_reason: Souligne l'importance existentielle et stratégique de l'IA pour l'entreprise
    ou le projet discuté, allant au-delà d'une simple amélioration technologique.
  relevance_score: 9
  source: llm_enhanced
  text: C'est une question de vie ou de mort pour moi, l'intégration de l'IA.
  topic: Business/Stratégie
- impact_reason: 'Définit une exigence clé pour l''adoption industrielle des LLM :
    la capacité à structurer la sortie (JSON) basée sur des requêtes spécifiques,
    allant au-delà du simple résumé.'
  relevance_score: 9
  source: llm_enhanced
  text: Quand tu reçois un article, c'est bien beau d'avoir un résumé de l'article,
    mais c'est aussi important de pouvoir avoir un extrait JSON à certaines questions
    clés.
  topic: Business/Adoption IA
- impact_reason: Relie la précision des LLM à l'amélioration de systèmes hybrides
    (LLM + IA Symbolique), permettant une modération beaucoup plus fine et basée sur
    des règles complexes.
  relevance_score: 9
  source: llm_enhanced
  text: C'est ça qui nous permet, c'est la réponse précise à ces questions-là, qui
    nous permet d'avoir une vraie granularité sur la modération qui est effectuée
    avec l'IA Symbolique.
  topic: Technique/Architecture Hybride
- impact_reason: Aborde l'impact humain et psychologique du travail de modération,
    un aspect souvent négligé.
  relevance_score: 8
  source: llm_enhanced
  text: Et surtout comment garder sa santé mentale quand son taf, c'est de lire les
    pires horreurs du web ?
  topic: safety/ethics
- impact_reason: Explique la motivation profonde et éthique derrière la création de
    Bodyguard, liant valeurs personnelles et mission technologique.
  relevance_score: 8
  source: llm_enhanced
  text: J'ai reçu une éducation de mes parents qui est une éducation où on m'a toujours
    appris à lutter contre l'injustice. J'ai toujours eu cette volonté de lutter contre
    l'injustice et de protéger les gens qui sont potentiellement vulnérables, dans
    la vraie vie, mais également sur Internet.
  topic: safety/strategy
- impact_reason: Décrit la phase initiale de collecte de données et d'annotation manuelle,
    essentielle pour entraîner tout modèle d'IA.
  relevance_score: 8
  source: llm_enhanced
  text: Je commence par modérer à la main, peut-être. Je *scrape* peut-être les 10
    vidéos des 10 plus gros youtubeurs du moment, je *scrape* tous les espaces commentaires.
    Donc je me retrouve en fait avec à peu près 2 millions de commentaires.
  topic: technical/data
- impact_reason: Transition de l'analyse manuelle à la tentative de formalisation
    algorithmique (IA Symbolique).
  relevance_score: 8
  source: llm_enhanced
  text: Et de là, je me dis, bon, il y a des *patterns* qui reviennent quand même.
    Donc on peut commencer à essayer à faire quelque chose. Et donc je commence à
    développer une technologie d'IA Symbolique.
  topic: technical/AI_trend
- impact_reason: Contextualise l'état de l'art du Machine Learning en 2017, justifiant
    le choix initial de l'IA Symbolique plutôt que le DL/ML moderne.
  relevance_score: 8
  source: llm_enhanced
  text: Et donc je commence, parce qu'on est en 2017. En 2017, le *machine learning*,
    c'était à peu près la mode depuis 2015, mais c'était encore au prémices. C'était
    vraiment encore au tout début.
  topic: technical/AI_trend
- impact_reason: 'Fournit un exemple concret et sensible de la raison d''être de la
    technologie : protéger des communautés ciblées.'
  relevance_score: 8
  source: llm_enhanced
  text: À l'époque, Bodyguard protégeait Bilal Hassani. Bilal Hassani, qui est un
    chanteur transsexuel et homosexuel.
  topic: safety/ethics
- impact_reason: 'Defines the gold standard for AI moderation: replicating the complex,
    nuanced decision-making process of a human moderator.'
  relevance_score: 8
  source: llm_enhanced
  text: La modération effective, c'est ce qui se passe dans ton cerveau, en tant qu'humain,
    quand tu fais de la modération ou quand tu te poses la question de si c'est un
    contenu problématique ou pas, c'est ça.
  topic: safety/strategy
- impact_reason: Demystifies Symbolic AI, suggesting it is fundamentally built upon
    complex, structured rule-based logic (if/while/for loops), contrasting with the
    black-box nature of purely statistical ML.
  relevance_score: 8
  source: llm_enhanced
  text: Qu'est-ce qui fait la différence entre une succession de `if` et cette idée
    d'IA Symbolique ? C'est à quel moment, en fait, tu fais le... En fait, c'est techniquement,
    c'est à peu près la même chose. On parle de `if`, mais c'est beaucoup de boucles
    `while` et des `for` et des `foreach`.
  topic: technical
- impact_reason: Explains the performance bottleneck of naive text searching and the
    technical motivation behind adopting encoding techniques like One-Hot Encoding
    for efficiency.
  relevance_score: 8
  source: llm_enhanced
  text: Je me rends compte très vite que plus j'ajoute de règles, bah, plus ça me
    prend du temps à répondre. Et plus ça coûte cher en CPU. Et donc, je comprends
    aussi très vite que de la recherche. Rechercher dans un texte de 300 caractères,
    s'il y a le mot 'connard', ça met beaucoup plus de temps que de rechercher un
    entier dans une liste d'entiers.
  topic: technical
- impact_reason: Emphasizes the extreme business risk associated with model drift
    or rule errors in high-stakes moderation, reinforcing the need for rigorous testing.
  relevance_score: 8
  source: llm_enhanced
  text: si, par exemple, du jour au lendemain, je dis n'importe quoi, mais le mot
    'bateau' se met à être haineux, parce qu'on a merdé sur une règle linguistique,
    enfin, moi, je perds tous mes clients.
  topic: business/safety
- impact_reason: 'Signals a key transition point in the discussion: how traditional
    testing methodologies must adapt to the era of Large Language Models (LLMs).'
  relevance_score: 8
  source: llm_enhanced
  text: D'ailleurs, c'est mes meilleurs. On en parle, ça lance le débat sur l'avenir
    de tes tests, avec l'arrivée du LLM.
  topic: predictions
- impact_reason: Provides a specific, actionable checklist of text normalization steps
    essential for robust NLP/moderation pipelines.
  relevance_score: 8
  source: llm_enhanced
  text: je remplace les émojis par des valeurs textuelles, je retire la ponctuation
    à certains endroits, je retire les mots similaires consécutifs, très, très, très,
    très, très, très, très, je le remets en minuscule.
  topic: technical
- impact_reason: Emphasizes that noise reduction (via pre-processing) is key to scalability,
    allowing human experts (linguists) to focus on semantic meaning rather than orthographic
    variations.
  relevance_score: 8
  source: llm_enhanced
  text: on enlève toute cette couche de bruit là, et ça permettait de travailler de
    façon beaucoup plus scalable sur la création de règles.
  topic: strategy
- impact_reason: Highlights the performance and cost limitations of purely rule-based
    systems, especially at high scale (billions of comments per month).
  relevance_score: 8
  source: llm_enhanced
  text: Au début, ça a aussi commencé avec les règles. Mais les règles, ça te consomme
    en CPU de dingue, ça te prend un temps fou.
  topic: business
- impact_reason: Points out the critical operational and communication overhead associated
    with maintaining complex, opaque rule sets in a team environment.
  relevance_score: 8
  source: llm_enhanced
  text: Les règles, comment tu les transmets dans une équipe de linguistes ? Tu vois,
    l'enfer du truc. Les règles, comment tu les expliques, comment tu les transmets,
    comment tu expliques une décision, comment tu les corriges ? C'était un enfer
    fou.
  topic: strategy
- impact_reason: 'Shows a practical, high-value application of ML in a hybrid system:
    triaging human review queues and performing quality checks on automated decisions.'
  relevance_score: 8
  source: llm_enhanced
  text: J'utilise du machine learning pour savoir si on doit faire une revue humaine
    sur le contenu et j'utilise du machine learning aussi pour du contrôle qualité.
  topic: business
- impact_reason: 'Details a specific, high-value product application of LLMs: generating
    real-time, detailed audience intelligence reports by summarizing aggregated data.'
  relevance_score: 8
  source: llm_enhanced
  text: On a une fonctionnalité qu'on appelle *Audience Intelligence* qui permet en
    fait de fournir des rapports détaillés et en temps réel à nos entreprises en fonction
    de ce qui s'est passé sur leur plateforme. [...] on va venir agréger tous les
    commentaires qu'on a présélectionnés, les envoyer dans un LLM et fournir un portrait
    détaillé par rapport à cette question.
  topic: business/predictions
- impact_reason: A surprising anecdote showcasing the rapid advancement of generative
    AI in design tools (Canva) moving beyond simple image generation to producing
    functional code (React).
  relevance_score: 8
  source: llm_enhanced
  text: Mon UX designer, il code avec Canva, enfin, avec un *prompt* Canva, il arrive
    à générer le visuel, et derrière en fait, c'est du code React qui est généré pour
    générer le visuel. Avec Canva ?
  topic: predictions/technical
- impact_reason: Emphasizes the flexibility and multilingual capability of LLMs, making
    them highly adaptable for diverse enterprise clients compared to static ML models.
  relevance_score: 8
  source: llm_enhanced
  text: Tu peux adapter tout ça en fonction du client. Et donc en fait, il a toute
    cette contextualité, plus fonctionne en 45 langues, même plus.
  topic: business/technical
- impact_reason: Illustre la capacité multimodale des LLM modernes (implicitement
    GPT-4V ou similaire) à traiter des données visuelles, un bond en avant par rapport
    aux modèles purement textuels ou aux anciens modèles ML spécialisés.
  relevance_score: 8
  source: llm_enhanced
  text: 'tu leur balances une photo, tu leur demandes : "C''est quoi le contenu de
    la photo ?"'
  topic: Technique/Avancées IA
- impact_reason: 'Met en évidence les deux axes majeurs d''amélioration des LLM :
    la qualité des résultats et la vitesse d''exécution.'
  relevance_score: 8
  source: llm_enhanced
  text: La progression, elle est énorme. Mais surtout sur la qualité, la rapidité,
    et surtout la qualité et la rapidité.
  topic: Technique/Performance
- impact_reason: Illustre la complexité des règles de modération basées sur le contexte
    et les symboles (émojis), nécessitant une compréhension sémantique profonde que
    seuls les LLM peuvent fournir pour l'application de règles symboliques.
  relevance_score: 8
  source: llm_enhanced
  text: on peut dire que telle règle, par exemple, les émojis qui vomissent, et les
    émojis qui vomissent, c'est de l'homophobie, si le sujet de l'article, ça parle,
    c'est un article en faveur de la communauté
  topic: Sécurité/Éthique/Modération
- impact_reason: Anecdote marquante sur l'adéquation entre l'éducation formelle et
    les aptitudes réelles, soulignant l'importance de l'auto-apprentissage dans la
    tech.
  relevance_score: 7
  source: llm_enhanced
  text: J'essaie de faire un an d'école d'ingénieurs où je termine dernier, je fais
    un an de fac où je termine dernier, deux facs informatiques où je termine dernier,
    sauf en informatique où je termine premier.
  topic: strategy/personal
- impact_reason: Insight business sur l'application de l'IA pour la conformité (Trust
    Management), montrant l'utilité de l'IA au-delà de la création de contenu.
  relevance_score: 7
  source: llm_enhanced
  text: Vanta aide les entreprises de toute taille à se mettre rapidement en conformité
    et surtout à y rester grâce à l'automatisation, à l'IA et au contrôle continu.
  topic: business/AI_application
- impact_reason: Explicitly names the core technology approach (Symbolic AI) used
    to solve complex contextual moderation problems.
  relevance_score: 7
  source: llm_enhanced
  text: Bodyguard, de l'IA Symbolique, c'est ça. C'est tout ce que je vous dis depuis
    le début.
  topic: technical
- impact_reason: Illustrates that practical problem-solving often precedes formal
    categorization in technology development; the focus was on utility, not nomenclature.
  relevance_score: 7
  source: llm_enhanced
  text: 'Je ne savais pas du tout que j''étais en train de créer une IA Symbolique.
    [...] pour moi, c''était juste : bon, je veux créer une technologie qui va résoudre
    un problème précis que je connais parfaitement.'
  topic: strategy
- impact_reason: Quantifies the scale of necessary quality assurance (200k regression
    tests) required to maintain stability and accuracy in a complex, evolving Symbolic
    AI system.
  relevance_score: 7
  source: llm_enhanced
  text: on a genre peut-être 200 000 tests de non-régression qui permettent, à chaque
    modification d'algorithme ou à chaque modification linguistique, de s'assurer
    qu'on est aux aguets et qu'il n'y a pas de contenu *ill-breaker* qui soient retirés
    par les technologies.
  topic: technical
- impact_reason: Highlights the necessity of flexibility in unit testing, especially
    for non-deterministic systems like content moderation.
  relevance_score: 7
  source: llm_enhanced
  text: il faut allouer une certaine marge de manœuvre dans ces tests unitaires.
  topic: strategy
- impact_reason: Contrasts academic training with real-world, experience-driven best
    practices in software engineering, particularly for critical systems.
  relevance_score: 7
  source: llm_enhanced
  text: Donc j'ai tout de suite naturellement vers des tests unitaires. Tests unitaires,
    quand tu as fait de formation, quand tu as pas eu d'expérience professionnelle,
    ce n'est pas un truc qui vient naturellement à l'esprit.
  topic: strategy
- impact_reason: Historical context showing the limitations of simple keyword matching
    before advanced NLP/encoding techniques became widespread.
  relevance_score: 7
  source: llm_enhanced
  text: les réseaux sociaux, il n'y a pas ce système-là. Donc si tu écrivais une insulte
    dans le mot "connard" avec une étoile ou en doublant le o, en mettant un o, ça
    n'était pas détecté par la technologie du mot-clé.
  topic: predictions
- impact_reason: 'Describes a practical strategy for optimizing computational load
    and trust levels: delegating low-risk, positive classifications to ML while reserving
    symbolic AI for complex/sensitive cases.'
  relevance_score: 7
  source: llm_enhanced
  text: En gros, je prends la meilleure décision des deux. Mais donc en gros, c'est
    un pré-filtre qui va retirer de ton... Pour ton IA Symbolique pour la légèreté
    de la charge, et le laisser que des choses entre guillemets... J'autorise le *machine
    learning* à prendre des décisions quand un contenu est positif.
  topic: strategy/technical
- impact_reason: 'Provides clear guidance on where traditional ML models are still
    suitable: stable domains where misclassification has low impact, contrasting with
    rapidly evolving topics.'
  relevance_score: 7
  source: llm_enhanced
  text: C'est une classification positive et les classifications qui n'évoluent pas
    trop. Et genre, géopolitique et politique, tu vois, il n'y a pas des nouveaux
    présidents qui arrivent toutes les semaines. Donc en gros, c'est des modèles qu'on
    entraîne tous les mois, ça va, tu vois. Et si on fait une erreur, ce n'est pas
    très grave parce qu'on ne retire pas.
  topic: business/strategy
- impact_reason: Offers specific advice on internal tooling, noting the preference
    for Anthropic models (Claude) for coding tasks, even within platforms like Copilot,
    based on perceived quality.
  relevance_score: 7
  source: llm_enhanced
  text: En interne, très vite, on va utiliser des licences Copilot pour nos développeurs,
    des licences Anthropic parce que Claude n'était pas disponible dans Copilot à
    l'époque, donc pas de non, c'est bon. Donc on utilise uniquement Copilot avec
    principalement les modèles d'Anthropic qui sont les meilleurs en code pour le
    moment.
  topic: business/strategy
- impact_reason: 'Clarifies the limitations of pre-LLM context understanding: reliance
    on supervised ML models, especially for modalities like images, which lacked deep
    contextual reasoning.'
  relevance_score: 7
  source: llm_enhanced
  text: Ma question, c'était du coup déjà comment on faisait avant pour comprendre
    le contexte sur des élèves ? C'était des modèles de *machine learning*. Ok, c'était
    des modèles de *machine learning* et des modèles linguistiques aussi en fait.
    Mais tu vois, sur une photo, c'était des modèles de *machine learning* supervisés.
  topic: technical
- impact_reason: 'Fournit un aperçu de l''état de l''art avant les LLM : utilisation
    de ML supervisé pour des tâches spécifiques (comme l''analyse d''images), contrastant
    avec la généralité des LLM actuels.'
  relevance_score: 7
  source: llm_enhanced
  text: Avant pour comprendre le contexte sur des élèves ? C'était des modèles de
    *machine learning*. Ok, c'était des modèles de *machine learning* et des modèles
    linguistiques aussi en fait. Mais tu vois, sur une photo, c'était des modèles
    de *machine learning* supervisés.
  topic: Technique/Comparaison ML vs LLM
- impact_reason: Indique que pour certaines applications critiques (comme la modération),
    la précision et la nuance priment sur la latence.
  relevance_score: 7
  source: llm_enhanced
  text: surtout la qualité. La rapidité, je m'en fiche un peu, mais surtout la qualité.
  topic: Business/Priorités Produit
- impact_reason: Révèle le parcours autodidacte et précoce de l'invité, ancrant son
    expertise technique très tôt.
  relevance_score: 6
  source: llm_enhanced
  text: J'ai commencé la programmation à 10 ans, dans ma chambre, tout seul, avec
    un livre, programmer en Java et ce n'est pas une heure à l'air, la technologie
    Bodyguard dit à symbolique, dont on parlera après.
  topic: strategy/personal
- impact_reason: 'A practical lesson in product development: acknowledging the trade-off
    between native performance and the speed/flexibility of hybrid solutions, especially
    in early stages.'
  relevance_score: 6
  source: llm_enhanced
  text: J'aurais dû faire un truc, un truc hybride, mais bon, ça, ça, c'est pas grave.
    [concernant le développement d'une application mobile native iOS/Android].
  topic: business/strategy
- impact_reason: An anecdote showing organic discovery of established computer science
    concepts through practical engineering challenges.
  relevance_score: 6
  source: llm_enhanced
  text: 'je me rends compte par la suite. Parce que pour la petite histoire, j''en
    ai parlé à Yann Guérin [...] c''est lui qui me parle de ce *One-Hot Encoding*
    et me dit : ''Bah, là, ce que tu as codé là, c''est du *One-Hot Encoding*.'''
  topic: technical/strategy
- impact_reason: Indicates the foundational technology (BERT/early Transformers) used
    for their established ML models, providing context before the LLM integration.
  relevance_score: 6
  source: llm_enhanced
  text: C'est des modèles créés *in-house* qui utilisent des technologies BERT, qui
    sont vraiment les premières technologies *transformer* qui sont arrivées.
  topic: technical
source: Unknown Source
summary: '## Podcast Summary: #333.src - Bodyguard: Coder contre la haine avec Charles
  Cohen


  This episode of *If This Then Dev* features Bruno Soulès in conversation with **Charles
  Cohen**, the 29-year-old President and Founder of **Bodyguard**, a company dedicated
  to combating online hate speech and cyberbullying. The discussion centers on the
  genesis of Bodyguard, the technical philosophy behind its moderation engine, and
  the critical distinction between different types of Artificial Intelligence in solving
  complex real-world problems like online toxicity.


  ### 1. Focus Area

  The primary focus is **Online Content Moderation and AI Strategy**. Specific topics
  include:

  *   The personal motivation behind fighting online injustice (triggered by a tragic
  case of cyberbullying).

  *   The limitations of keyword-based moderation and early Machine Learning approaches.

  *   The technical architecture of Bodyguard, heavily relying on **Symbolic AI (Rule
  Engines)** rather than solely on Deep Learning/LLMs.

  *   The necessity of contextual understanding, severity classification, and behavioral
  analysis in effective moderation.


  ### 2. Key Technical Insights

  *   **Symbolic AI Superiority for Specific Tasks:** Cohen argues that his custom-built
  Symbolic AI (rule-based engine coded in Java) remains more performant than many
  current LLMs for the specific task of hate speech detection, emphasizing its transparency
  and update speed.

  *   **Context is King (Beyond Keywords):** Effective moderation requires analyzing
  context (what precedes/follows a word), the target (who the comment is directed
  at), the subject matter of the content being commented on, and the severity/frequency
  of the language used.

  *   **Natural Implementation of ML Concepts:** Cohen discovered concepts like **One-Hot
  Encoding** organically by optimizing performance—realizing that searching for integers
  (encoded words) was faster than searching through strings, demonstrating an intuitive
  approach to data processing optimization.


  ### 3. Business/Investment Angle

  *   **Agility vs. Scale in Moderation:** Large platforms (like Meta) are too slow
  ("too big") to keep up with the rapidly evolving tactics of toxic users ("the mouse").
  Bodyguard’s strength lies in its technological agility, allowing rapid updates to
  linguistic rules.

  *   **Trust Management as Essential Growth Factor:** The episode opens with a mention
  of Vanta, highlighting that in the digital evolution, proving trust (via compliance
  and security) is essential for business growth.

  *   **The Value of Non-Regression Testing:** Cohen stressed the importance of maintaining
  robust, human-validated test sets (non-regression tests) to ensure that algorithmic
  or rule updates do not inadvertently break existing, correctly classified moderation
  scenarios—a critical need when dealing with high-stakes content.


  ### 4. Notable Companies/People

  *   **Charles Cohen (Bodyguard Founder):** Self-taught developer who founded Bodyguard
  at 21 after being motivated by a cyberbullying tragedy. He champions a critical,
  pragmatic view of AI technologies.

  *   **Yann Guérin (Founder of Gladia.io):** Mentioned as the person who later identified
  Cohen’s early optimization technique as formal **One-Hot Encoding**.

  *   **Vanta:** Mentioned as the episode sponsor, focusing on automated compliance
  and trust management for businesses.


  ### 5. Future Implications

  The conversation strongly suggests a future where **AI solutions are specialized
  and complementary**, rather than monolithic. Cohen predicts that developers must
  maintain a critical spirit, avoiding the trap of assuming LLMs are the universal
  solution. For moderation, the future requires hybrid systems that combine the speed
  and transparency of rule-based Symbolic AI with the pattern recognition capabilities
  of Machine Learning/Deep Learning, depending on the specific moderation challenge.


  ### 6. Target Audience

  This episode is highly valuable for **Software Developers, CTOs, Product Managers,
  and AI/ML Engineers** who are building or integrating content moderation systems,
  or those interested in the practical trade-offs between different AI paradigms (Symbolic
  vs. Deep Learning) in real-world applications.'
tags:
- artificial-intelligence
- generative-ai
- startup
- meta
- anthropic
title: '#333.src - Bodyguard: Coder contre la haine  avec Charles Cohen'
topics:
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 626
  prominence: 1.0
  topic: artificial intelligence
- keywords:
  - generative ai
  - genai
  - chatgpt
  - gpt
  - claude
  - text generation
  - image generation
  mentions: 13
  prominence: 1.0
  topic: generative ai
- keywords:
  - startup
  - entrepreneur
  - founder
  - venture
  mentions: 2
  prominence: 0.2
  topic: startup
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-10-22 07:53:02 UTC -->
