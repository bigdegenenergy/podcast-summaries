---
companies:
- category: unknown
  confidence: medium
  context: eally want to enable with this interleaved model. The MSIS Office tweeted,
    the Gemini app is now the most downloade
  name: The MSIS Office
  position: 757
- category: unknown
  confidence: medium
  context: Gemini app is now the most downloaded app on the App Store, but it's Nandobin
    and the main factor behind the
  name: App Store
  position: 835
- category: tech
  confidence: high
  context: iting day. I have the team that's been working on Google's exciting new
    Nandobin and MSIS model. I have Na
  name: Google
  position: 1212
- category: unknown
  confidence: medium
  context: le's exciting new Nandobin and MSIS model. I have Nana Rasingani who works
    on the product team, and I have Philip
  name: Nana Rasingani
  position: 1266
- category: unknown
  confidence: medium
  context: singani who works on the product team, and I have Philip Lip who works
    on the research side of things. I'm rea
  name: Philip Lip
  position: 1323
- category: unknown
  confidence: medium
  context: he research side, the use cases, everything else. But I want to start with
    a question that probably every
  name: But I
  position: 1573
- category: unknown
  confidence: medium
  context: e code name be? Like, let's do something fun like Nana Banana, and it's
    taken off by storm. I keep saying peopl
  name: Nana Banana
  position: 2199
- category: unknown
  confidence: medium
  context: rs who want to have proper naming like Gemini 2.5 Flash Preview XYZ, Matrix,
    Reliance, and so on. And I get that. But
  name: Flash Preview XYZ
  position: 2538
- category: unknown
  confidence: medium
  context: 5 Flash Preview XYZ, Matrix, Reliance, and so on. And I get that. But I
    think for the average consumer, j
  name: And I
  position: 2586
- category: unknown
  confidence: medium
  context: for example, where people put in a screenshot of Google Maps and say, basically,
    okay, reimagine this scene no
  name: Google Maps
  position: 5018
- category: unknown
  confidence: medium
  context: e it a young woman." Awesome. Managed to do that. So I think it's a partner
    to preserve facial details,
  name: So I
  position: 6743
- category: unknown
  confidence: medium
  context: the real business use cases of this thing? Right? Because I think it's
    one thing to say, "Okay, I'm going to
  name: Because I
  position: 7301
- category: unknown
  confidence: medium
  context: '''re a car manufacturer making a tennis ad for the US Open, for example,
    now let''s have some tennis balls th'
  name: US Open
  position: 8562
- category: unknown
  confidence: medium
  context: your compliance so your deals are never blocked. With AI changing regulations,
    Vanta knows what's needed a
  name: With AI
  position: 21050
- category: unknown
  confidence: medium
  context: l go into Figma. I'll quickly design the feature. Sometimes I just design
    it myself if the PM or the designer d
  name: Sometimes I
  position: 21968
- category: unknown
  confidence: medium
  context: tand what's left with image models at this point. Like I have a hard time
    telling—everything just looks pe
  name: Like I
  position: 23163
- category: unknown
  confidence: medium
  context: to have at some point is, for instance, I have a Google Doc where I wrote
    all of kind of technical details, a
  name: Google Doc
  position: 24446
- category: big_tech
  confidence: high
  context: Mentioned as Google's exciting new model, which the Nandobin/MSIS model
    is related to, and the Gemini app is topping app store charts.
  name: Gemini
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: The team works on Google's exciting new Nandobin and MSIS model, and the
    Gemini app is mentioned.
  name: Google
  source: llm_enhanced
- category: big_tech
  confidence: medium
  context: Mentioned as tweeting about the Gemini app being the most downloaded app.
  name: MSIS Office
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: The primary multimodal AI model being discussed, capable of handling text,
    image, and audio input/output, developed by Google.
  name: Gemini
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: The company behind Gemini and previous image models, heavily invested in
    multimodal AI.
  name: Google
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Mentioned alongside Google as seemingly leading the pack in AI development
    at this point.
  name: DeepMind
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: A company providing AI and automation for compliance monitoring, mentioned
    as a partner/sponsor.
  name: Vanta
  source: llm_enhanced
date: 2025-10-03 20:33:48 +0000
duration: 1
has_transcript: false
insights:
- actionable: false
  confidence: high
  source: llm_enhanced
  text: ''
  type: general
- actionable: false
  confidence: high
  source: llm_enhanced
  text: ''
  type: general
- actionable: false
  confidence: high
  source: llm_enhanced
  text: ''
  type: general
- actionable: false
  confidence: medium
  source: llm_enhanced
  text: ''
  type: general
- actionable: false
  confidence: high
  source: llm_enhanced
  text: ''
  type: general
- actionable: false
  confidence: high
  source: llm_enhanced
  text: ''
  type: general
- actionable: false
  confidence: high
  source: llm_enhanced
  text: ''
  type: general
- actionable: false
  confidence: high
  source: llm_enhanced
  text: ''
  type: general
- actionable: false
  confidence: high
  source: llm_enhanced
  text: ''
  type: general
- actionable: false
  confidence: medium
  source: llm_enhanced
  text: ''
  type: general
- actionable: false
  confidence: high
  source: llm_enhanced
  text: ''
  type: general
- actionable: false
  confidence: high
  source: llm_enhanced
  text: ''
  type: general
- actionable: false
  confidence: medium
  source: llm_enhanced
  text: ''
  type: general
layout: episode
llm_enhanced: true
original_url: https://www.youtube.com/watch?v=qrSaLCI9A3U
processing_date: 2025-10-03 20:33:48 +0000
quotes:
- length: 288
  relevance_score: 4
  text: It's just so core to the way we communicate, the way we learn, the way we
    share that it just felt like the right thing to do for Gemini to then be multimodal,
    for it to understand multi-modal context, but then also output itself and communicate
    back with the user in a multi-modal fashion
  topics: []
- length: 211
  relevance_score: 3
  text: Essentially, we definitely scaled up the data, specifically for character
    consistency, because you have to imagine you need now pairs of images where potentially
    it's the same person behind it or the same object
  topics: []
- length: 150
  relevance_score: 3
  text: So let's say, for instance, the math problem, you have to add extra lines
    and show that basically at a certain cross point that gives you the solution
  topics: []
- impact_reason: 'Highlights a key breakthrough in generative models: maintaining
    high fidelity and consistency of specific subjects (characters, objects) across
    varied generated scenarios, which is crucial for practical applications.'
  relevance_score: 9
  source: llm_enhanced
  text: The thing we are most proud of is our characteristic consistency. You can
    take something that is so hard to get to yourself and then kind of reimagine them
    in a whole bunch of different situations.
  topic: technical
- impact_reason: Emphasizes the shift from purely text-guided generation to models
    capable of visual reasoning based on input images, indicating progress in multimodal
    understanding.
  relevance_score: 9
  source: llm_enhanced
  text: it's not only where you believe it specifies something very specific in text,
    it's not that you can also make it actually reason about the input images.
  topic: technical
- impact_reason: A strong strategic statement indicating that despite current advancements,
    the field (and this specific technology) is still in its nascent stages, suggesting
    massive future potential.
  relevance_score: 8
  source: llm_enhanced
  text: We're at the start. We've come to the start of the racetrack. Now we're like,
    right, let's do this. Let's just go for it.
  topic: strategy
- impact_reason: A business/product insight suggesting that while catchy branding
    (like 'Nandobin') drives initial adoption, sustained success relies entirely on
    the underlying product quality and performance.
  relevance_score: 7
  source: llm_enhanced
  text: I keep saying people came for the name, but they stayed for the model, and
    it just shows what the excitement people have.
  topic: business
- impact_reason: Identifies a high-volume, practical use case for image editing models
    that solves a common user pain point, demonstrating immediate utility beyond novelty.
  relevance_score: 8
  source: llm_enhanced
  text: 'We''re very good at the hyper-local edit. Like you want to remove the people
    in the background. That''s probably been my volume-based query I''ve used the
    most: remove the people in the background.'
  topic: business
- impact_reason: Highlights the strategic advantage of unifying large language model
    (LLM) reasoning ('world knowledge') with visual capabilities within a single architecture,
    enabling more complex tasks.
  relevance_score: 9
  source: llm_enhanced
  text: you get this leverage Gemini's world knowledge and its multi-modal understanding
    in one model space, and it makes it really exciting to play with and do a whole
    bunch of use cases.
  topic: technical
- impact_reason: Provides a concrete benchmark (preserving physical laws like gravity/levers)
    that previous models failed, indicating a significant leap in the model's ability
    to understand and adhere to real-world constraints.
  relevance_score: 10
  source: llm_enhanced
  text: Nandobin was the first one where actually I just gave it the image and I said,
    'Reproduce this in a different style.' [...] I'm glad that we can preserve some
    physics within the output as well now.
  topic: technical
- impact_reason: Outlines specific, high-value commercial applications (e-commerce,
    interior design) driven by multimodal AI, pointing toward future industry disruption.
  relevance_score: 8
  source: llm_enhanced
  text: We're seeing Gemini really be your collaborator on all different surfaces,
    and we're seeing a lot of apps kind of developers building on this use case, like
    the ability to do virtual try-ons, the ability to—you're looking at a store and
    you have a product, and being able to physically place it at your home and actually
    see what it would look like in your space.
  topic: predictions
- impact_reason: Reveals that algorithmic breakthroughs, driven by focused engineering
    effort (even last-minute sprints), were the primary factor in achieving significant
    speed improvements, rather than just data or hardware.
  relevance_score: 9
  source: llm_enhanced
  text: I think in terms of speed, it was more on the algorithm side. [...] I was
    really pushing for the latency, and there was also like a last-minute weekend
    sprint to basically get this over the line that we have is the algorithmic benefit
    of being now so fast behind it.
  topic: technical
- impact_reason: 'Details the dual requirement for achieving high-fidelity consistency:
    scaling specialized paired data *and* developing targeted algorithmic improvements
    for pixel-perfect editing.'
  relevance_score: 9
  source: llm_enhanced
  text: Essentially, we definitely scaled up the data, specifically for character
    consistency, because you have to imagine you need now pairs of images where potentially
    it's the same person behind it or the same object. And also on the side of our
    algorithm development. So there are still some improvements that we found to be
    a lot better, especially in this pixel-perfect editing, which we then further
    developed.
  topic: technical
- impact_reason: Highlights the value of generalist models in uncovering unexpected,
    popular use cases driven by user creativity, which is a key strategic insight
    for AI development.
  relevance_score: 9
  source: llm_enhanced
  text: But it's—I think it's the fact that this model is so generalist, it allows
    for it to surprise us.
  topic: strategy
- impact_reason: 'Strong business/product advice: prioritize building general capabilities
    and let emergent user behavior guide product evolution, rather than strictly pre-defining
    use cases.'
  relevance_score: 10
  source: llm_enhanced
  text: So that's why it's actually very nice to always build a very general model
    and then just let the users have their go with it and see what is the most fun
    for them.
  topic: business
- impact_reason: A concise summary of successful product iteration driven by user
    feedback, even when it contradicts initial internal assumptions (e.g., the figurine
    trend).
  relevance_score: 8
  source: llm_enhanced
  text: Give the people what they want is what we realized. Exactly. Exactly. 100%.
  topic: business
- impact_reason: 'Provides the core justification for multimodal AI: mirroring fundamental
    human communication methods (visual learning) for better user experience and learning
    outcomes.'
  relevance_score: 10
  source: llm_enhanced
  text: It's just so core to the way we communicate, the way we learn, the way we
    share that it just felt like the right thing to do for Gemini to then be multimodal,
    for it to understand multi-modal context, but then also output itself and communicate
    back with the user in a multi-modal fashion.
  topic: technical
- impact_reason: 'Defines the ideal state for advanced multimodal interaction: seamless,
    context-aware output switching without explicit user command, moving beyond simple
    tool invocation.'
  relevance_score: 9
  source: llm_enhanced
  text: We don't want that a user always has to say, 'Give me an image.' Just whenever
    Gemini thinks it's easier to explain in an image than use it.
  topic: technical
- impact_reason: Poses the central question defining the value proposition of current
    cutting-edge AI models over siloed, single-modality systems.
  relevance_score: 9
  source: llm_enhanced
  text: 'So the real question is, I''d love to hear this more generally as well, but
    specifically towards image as well: why does it matter to have a multimodal model?'
  topic: technical
- impact_reason: Emphasizes the specific advantage of interleaved multimodality (like
    in solving geometric problems) over sequential, separate model calls.
  relevance_score: 8
  source: llm_enhanced
  text: And then it's just like sometimes an image says more than a thousand words.
    And that is something that we really want to enable with this interleaved model,
    which you cannot do with everything separate...
  topic: technical
- impact_reason: A concrete, high-value workflow for product development using multimodal
    input (UI screenshot) combined with advanced reasoning ('deep thinking') for rapid
    iteration.
  relevance_score: 9
  source: llm_enhanced
  text: I'll upload it into models now and I'll just get feedback from like—I'll enable
    deep thinking and I'll basically say, 'Okay, think deeply about this user. Tell
    me everything that is wrong with the UI of this page and how I should be thinking
    about making this more usable, more easy.'
  topic: business
- impact_reason: Directly addresses the future roadmap and current technical limitations
    of state-of-the-art image generation models.
  relevance_score: 8
  source: llm_enhanced
  text: I was just left to get your perspectives. I guess Philip first from your side
    on what is left from a technical perspective? Like what are still some things
    which you need to get solved?
  topic: technical
- impact_reason: Identifies a critical, remaining technical challenge (text rendering
    within images) and outlines a highly desired, complex multimodal use case (document-to-presentation
    generation).
  relevance_score: 10
  source: llm_enhanced
  text: So, from a user perspective, one thing that we know we still have to improve
    is, for instance, text rendering. And something that I would love to have at some
    point is, for instance, I have a Google Doc where I wrote all of kind of technical
    details, and I need to do a presentation. So, how about just putting it to Gemini
    and being like, 'Okay, generate a whole presentation for me with image generation,
    one per slide.'
  topic: technical
source: AI Channel UC6gqge976jxqphEaqXPjBPg
summary:
- key_takeaways:
  - The model's name, Nandobin, originated from a tired Product Manager's suggestion
    ("Nana Banana") late at night, highlighting the contrast between its fun name
    and serious technological achievement.
  - A key feature is 'characteristic consistency,' allowing users to reimagine specific
    subjects (like themselves or pets) in diverse situations while preserving facial
    and physical details.
  - Nandobin demonstrates advanced reasoning capabilities, such as understanding physics
    (like Archimedes' lever) and interpreting complex inputs like Google Maps screenshots
    to perform edits.
  - The model achieves remarkable speed (2-6 seconds per image generation), which
    the team attributes primarily to algorithmic breakthroughs and the use of a 'flash
    model' backend, making image generation seamless in user interaction.
  - Business use cases range from virtual try-ons and interior design visualization
    to end-to-end ad creation collaboration.
  - Future technical improvements are focused on better text rendering within images
    and reducing 'no-ops' (failure cases) in editing tasks.
  - The integration of image generation into a single multimodal model is crucial
    for improving user experience, especially in education, where visual explanations
    can be more effective than long text.
  overview: The podcast features Naina Raisinghani and Phillip Lippe from DeepMind
    discussing the breakthrough AI image model, "Nandobin," which has rapidly gained
    popularity for its characteristic consistency and speed. The model excels at maintaining
    subject identity across various scenarios while integrating Gemini's world knowledge
    for reasoning-based image editing, signaling a major step forward in multimodal
    AI capabilities.
  themes:
  - Nandobin Model Capabilities and Performance (Consistency, Speed, Reasoning)
  - The Importance of Multimodality in AI
  - User Experience and Viral Adoption
  - Business and Consumer Use Cases
  - Future Research Directions and Technical Challenges
tags:
- artificial-intelligence
- generative-ai
- startup
- google
title: 'Nano Banana Breakthrough: The Future of AI Images - Naina Raisinghani & Phillip
  Lippe, DeepMind'
topics:
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 39
  prominence: 1.0
  topic: artificial intelligence
- keywords:
  - generative ai
  - genai
  - chatgpt
  - gpt
  - claude
  - text generation
  - image generation
  mentions: 8
  prominence: 0.8
  topic: generative ai
- keywords:
  - startup
  - entrepreneur
  - founder
  - venture
  mentions: 3
  prominence: 0.3
  topic: startup
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-10-03 20:33:48 UTC -->
