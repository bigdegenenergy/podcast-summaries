---
companies:
- category: unknown
  confidence: medium
  context: ome to our event. This event is brought to you by DataDocs Club, which
    is a community of people who love data. We
  name: DataDocs Club
  position: 64
- category: unknown
  confidence: medium
  context: erly part of Tesla's out-of-the-box AI team and a Carnegie Mellon University
    alumna. Aishwarya has worked across some of the t
  name: Carnegie Mellon University
  position: 1335
- category: unknown
  confidence: medium
  context: 'AI problems: financial recommendation systems at Morgan Stanley, multimodal
    research at CMU, perception and video'
  name: Morgan Stanley
  position: 1468
- category: unknown
  confidence: medium
  context: REM, a pain project in Africa, and the LaChief 3L World Impact at scale.
    Welcome to this event. Thank you for ha
  name: World Impact
  position: 1719
- category: unknown
  confidence: medium
  context: ntioned, at Morgan Stanley, it was a lot of data. So I was a big data engineer
    at Morgan Stanley, and I
  name: So I
  position: 2375
- category: unknown
  confidence: medium
  context: 'ly did that: handle all the huge amounts of data. And I was there when
    Morgan Stanley was doing this acqu'
  name: And I
  position: 2486
- category: unknown
  confidence: medium
  context: avigational apps for blind people, so it's called AI Guide Dog. So it takes
    in the world and navigates people wi
  name: AI Guide Dog
  position: 4076
- category: unknown
  confidence: medium
  context: eah. Do you know if this app is accessible in the App Store? Not yet. So
    the next community, like the new bat
  name: App Store
  position: 7563
- category: tech
  confidence: high
  context: AR and glasses, you probably heard, like I think Meta has some other companies
    too that have them. So y
  name: Meta
  position: 8959
- category: unknown
  confidence: medium
  context: ll. They rely solely on the cameras here. Mm-hmm. So Tesla, I took a few
    times a taxi, which turned out to b
  name: So Tesla
  position: 10902
- category: unknown
  confidence: medium
  context: was more entertaining than usually. I don't know. The UI, right? Because
    I look at the screen. So this thi
  name: The UI
  position: 11336
- category: unknown
  confidence: medium
  context: aining than usually. I don't know. The UI, right? Because I look at the
    screen. So this thing works with the
  name: Because I
  position: 11351
- category: unknown
  confidence: medium
  context: me cars already drive without drivers. I guess in San Francisco too, right?
    Yes. As I've also had Waymo, which ha
  name: San Francisco
  position: 15299
- category: unknown
  confidence: medium
  context: rivers. I guess in San Francisco too, right? Yes. As I've also had Waymo,
    which has like no driver at al
  name: As I
  position: 15330
- category: unknown
  confidence: medium
  context: a sudden there is an event like, I don't know, a Pride Day or whatever
    with a lot of people, like what the c
  name: Pride Day
  position: 16978
- category: unknown
  confidence: medium
  context: ic. Yeah, I think all of these cases are covered. Like Waymo has been in
    business since like, I think 15 years
  name: Like Waymo
  position: 17272
- category: unknown
  confidence: medium
  context: So, there was this nonprofit organization called Zap Malaria. They were
    trying to lead efforts for fumigation
  name: Zap Malaria
  position: 20354
- category: tech
  confidence: high
  context: to use topographic information. So, we have this Google data that gives
    you information about the geograp
  name: Google
  position: 21745
- category: unknown
  confidence: medium
  context: on any type of projects right now? Not right now. What I'm doing right
    now is the AI Guide Dog thing that
  name: What I
  position: 28507
- category: unknown
  confidence: medium
  context: ies. I think I had similar experiences in Europe. In Europe, definitely.
    Yeah. I know what the states. Yeah,
  name: In Europe
  position: 29050
- category: unknown
  confidence: medium
  context: at you do at work? Actually, in CMU, I was in the Language Technologies
    Institute. So I actually studied NLP and then tra
  name: Language Technologies
  position: 30829
- category: unknown
  confidence: medium
  context: at you do at work? Actually, in CMU, I was in the Language Technologies
    Institute. So I actually studied NLP and then transitioned
  name: Language Technologies Institute
  position: 30829
- category: unknown
  confidence: medium
  context: and that was really helpful when jumping to LLMs. But I feel like, with
    LLMs, there's a lot of more creat
  name: But I
  position: 34555
- category: ai_application
  confidence: high
  context: The current employer of the guest, working on gesture and pedestrian semantics
    for self-driving technology.
  name: Weimo
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: The former employer of the guest, focusing on perception and video understanding
    for their self-driving systems (which rely solely on cameras).
  name: Tesla
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Where the guest worked on financial recommendation systems and handling
    large datasets, leading to an interest in ML.
  name: Morgan Stanley
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: The institution where the guest pursued a Master's degree in data science
    and machine learning, involving computer vision projects.
  name: Carnegie Mellon University
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: Abbreviation for Carnegie Mellon University, mentioned in relation to multimodal
    research and the AI Guide Dog project.
  name: CMU
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: An AI for social good project in Africa that the guest contributed to.
  name: ML4REM
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: An AI for social good initiative the guest contributed to.
  name: LaChief 3L World Impact at scale
  source: llm_enhanced
- category: ai_application
  confidence: low
  context: Mentioned in the context of a data acquisition by Morgan Stanley.
  name: E-Trade
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: The current employer of the alumnus from CMU who started the AI Guide Dog
    project.
  name: Pinterest
  source: llm_enhanced
- category: big_tech
  confidence: medium
  context: Mentioned in relation to developing AR glasses with integrated cameras
    for broader vision applications.
  name: Meta
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: A ride-hailing service mentioned as a partner through which Waymo vehicles
    can sometimes be hailed.
  name: Uber
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: A ride-hailing service mentioned as a potential partner through which Waymo
    vehicles can sometimes be hailed.
  name: Lyft
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: The company where the interviewee currently works, focusing on fully autonomous
    (self-driving) ride-hailing services, utilizing in-house AI models, LiDAR, and
    camera data for real-time decision-making.
  name: Waymo
  source: llm_enhanced
- category: ai_organization
  confidence: high
  context: An organization that hosts 'AI for good' projects where volunteer ML engineers
    work on problems for non-profits.
  name: Oundina
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: A non-profit organization that partnered with Oundina to use ML models
    (leveraging satellite and topographic data) to efficiently target areas for fumigation
    to prevent Malaria.
  name: Zap Malaria
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: Mentioned in reference to a major software bug (Blue Screen of Death) that
    affected airports, highlighting the risks of deploying software, similar to safety-critical
    AI systems.
  name: CrowdStrike
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: The university where the interviewee studied at the Language Technologies
    Institute, focusing on NLP before transitioning to Computer Vision.
  name: CMU (Carnegie Mellon University)
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: The specific institute within CMU where the interviewee studied NLP.
  name: Language Technologies Institute (at CMU)
  source: llm_enhanced
- category: ai_model_framework
  confidence: medium
  context: Mentioned as an example of a known object detection model, suggesting the
    type of technology used in real-time vision systems like Waymo's.
  name: YOLO
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Mentioned as the source of topographic data used in the Zap Malaria project.
  name: Google
  source: llm_enhanced
- category: organization_other
  confidence: high
  context: Mentioned in relation to the CrowdStrike bug, referring to the operating
    system that experienced the widespread failure.
  name: Windows
  source: llm_enhanced
- category: ai_model_framework
  confidence: high
  context: Mentioned as the major LLM release that coincided with the interviewee's
    graduation, triggering the current AI/LLM boom.
  name: ChatGPT
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: The speaker's department at CMU where they studied NLP.
  name: Language Technologies Institute
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: Mentioned as a company that works on self-driving cars and could potentially
    use the German testing environment described.
  name: BMW
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: Mentioned as a company that works on self-driving cars and could potentially
    use the German testing environment described.
  name: Audi
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: Mentioned as a source where the speaker finds modern papers on NLP or computer
    vision.
  name: arXiv
  source: llm_enhanced
- category: other
  confidence: low
  context: A person asking a question about the state of AI in self-driving.
  name: Lecker
  source: llm_enhanced
date: 2025-10-10 17:30:00 +0000
duration: 59
has_transcript: false
layout: episode
llm_enhanced: true
original_url: https://audio.listennotes.com/e/p/02bb9448aa84459388aa4df797e8afee/
processing_date: 2025-10-11 02:29:26 +0000
quotes:
- length: 125
  relevance_score: 4
  text: So since you were working in computer vision, but all these new things, they
    are mostly related to NLP and text, NLP and text
  topics: []
- length: 93
  relevance_score: 4
  text: But many times it's also a hybrid, like multimodal large language models are
    very popular now
  topics: []
- length: 86
  relevance_score: 4
  text: I wonder, in your case, when you studied NLP, you already covered deep learning,
    right
  topics: []
- length: 172
  relevance_score: 4
  text: So, for you, when these LLMs came up, like, when they started to be and ChatGPT,
    like, people started using it, for you, because you studied deep learning techniques,
    right
  topics: []
- length: 128
  relevance_score: 4
  text: So, in Masters, there was a lot of focus on deep learning, transformer-based
    systems, because that was already big at that point
  topics: []
- length: 101
  relevance_score: 4
  text: So, for sure, like, I did do a lot of deep learning, and that was really helpful
    when jumping to LLMs
  topics: []
- length: 138
  relevance_score: 4
  text: But I feel like, with LLMs, there's a lot of more creative or ingenuity in
    how the pre-training, how they made it work, or the other stuff
  topics: []
- length: 159
  relevance_score: 4
  text: Of course, like, if I had not learned about deep learning, if I had not learned
    about the representation learning or embeddings, it would have been much harder
  topics: []
- length: 177
  relevance_score: 4
  text: For me, I think it would be, like, two weeks if I needed to get into any modern
    papers, like this, I don't know, if I go to arXiv and take any paper about NLP
    or computer vision
  topics: []
- length: 198
  relevance_score: 4
  text: Because for me, before this whole LLM space appeared, so for me, AI was, so
    there was machine learning, which was kind of part of AI, but for me, machine
    learning was machine learning, never like AI
  topics: []
- length: 74
  relevance_score: 3
  text: So, I guess you have to be super careful when you work on things like that
  topics: []
- length: 118
  relevance_score: 3
  text: Like you have to be, you just have to go across the street, then they will
    stop, otherwise they will just keep driving
  topics: []
- impact_reason: 'Clearly delineates the two major architectural philosophies in autonomous
    driving: sensor fusion (including LiDAR) versus vision-only approaches.'
  relevance_score: 10
  source: llm_enhanced
  text: Some companies they do use, like, most of the, like, fully self-driving, where
    there's like, absolutely no driver, use it [LiDAR]. Whereas if you see some of
    the Tesla systems, they do not use it at all. They rely solely on the cameras.
  topic: technical/self-driving architecture
- impact_reason: Describes the technical necessity of multi-camera setups (360-degree
    coverage) to compensate for the lack of LiDAR in vision-only systems, requiring
    sophisticated sensor fusion modeling.
  relevance_score: 10
  source: llm_enhanced
  text: But it's not just one camera. There's like, you know, cameras all around the
    car. So, you get a view from all around, like a 360 view of the system. And you
    kind of run your models on top of it that can make use of these different views
    of the world and see basically all around the car.
  topic: technical/perception systems
- impact_reason: 'Crucial insight into the deployment pipeline: training models are
    distinct from optimized, production models that run inference multiple times per
    second on edge hardware.'
  relevance_score: 10
  source: llm_enhanced
  text: So, these are internal models that, you know, they are optimized to run on
    the car and they're optimized to run really fast. So, it's probably not the same
    neural network that was trained. It was like, you know, we use various techniques
    to make it much faster and run much faster on the car to like, it detects in very
    quick amounts of time and detects like multiple times a second about what's happening
    with the world.
  topic: technical
- impact_reason: Explicitly names 'quantization' as a key technique for model optimization
    and deployment on resource-constrained edge devices (like cars).
  relevance_score: 10
  source: llm_enhanced
  text: How is this process called when you take a big model and make it smaller and
    faster? I guess there's a bunch of ways to do it, like, you know, publicly available
    ways, like something like, you know, you quantize the model. Yeah, exactly. This
    is what the work I was looking for, quantization.
  topic: technical
- impact_reason: Directly addresses the extreme stakes of safety-critical AI deployment,
    where failure results in physical harm and massive liability.
  relevance_score: 10
  source: llm_enhanced
  text: Which makes me wonder now, how does it work with self-driving cars? Because
    it's also not, I think you can easily roll out, right? So, first of all, there
    is this component that like you cannot really afford having bugs there, right?
    Because like if there is a bug and then a car misbehaves and I don't know, hits
    a traffic light. And then like, it's good if nobody gets injured, but what if
    somebody gets injured? Then it's super bad.
  topic: safety
- impact_reason: Confirms that even in cutting-edge AV development, deployment cycles
    are heavily gated by rigorous, multi-month safety validation processes, reflecting
    the high bar for production release.
  relevance_score: 10
  source: llm_enhanced
  text: Yeah, I think like there is again, a lot, I would say multi-month process
    of, you know, deploying any, I guess, new release or software. Because like you
    mentioned, it's a very sensitive and safety-critical domain. So, we want to be
    absolutely sure that it doesn't like negatively impact and doesn't have any bad
    behavior out in the open or out in the wild in
  topic: safety
- impact_reason: Details the rigorous, multi-stage deployment pipeline for safety-critical
    AI (self-driving), involving simulation, log replay, and extensive real-world
    testing by human drivers over months.
  relevance_score: 10
  source: llm_enhanced
  text: So, we want to be absolutely sure that it doesn't like negatively impact and
    doesn't have any bad behavior out in the open or out in the wild in the world.
    So, yes, I think there are different components. You know, every time you push
    a change, you do these whole bunch of evaluations, you try to re-run from existing
    logs, you run a lot of different evaluations. And then you combine your changes
    with all other changes. And then again, like for many months, you have drivers
    driving in multiple areas, testing out the software.
  topic: technical/safety
- impact_reason: 'Crucial insight for cross-domain AI professionals: fundamental deep
    learning knowledge (like CV expertise) is transferable and highly valued in emerging
    LLM/multimodal roles.'
  relevance_score: 10
  source: llm_enhanced
  text: although you are from a CV background, it's the same underlying fundamentals.
    So, you know, you still are eligible to interview for many of the LLM roles. And
    I did interview with a bunch of places where it was only NLP focused, not much
    CV. But many times it's also a hybrid, like multimodal large language models are
    very popular now.
  topic: business/AI technology trends
- impact_reason: 'Illustrates the dramatic paradigm shift in NLP: moving from feature
    engineering, labeled corpora, and classical ML models (logistic regression, POS
    tagging) to end-to-end LLM solutions.'
  relevance_score: 10
  source: llm_enhanced
  text: My master's was in 2013-14. It wasn't focusing on even not on machine learning,
    but I was taking a lot of extra courses. In particular, I was quite interested
    in NLP, but NLP was quite different. So, we were doing like logistic regression,
    this kind of stuff, like, to, I don't know, to identify. Yeah, so, like, if you
    want to identify part of speech, and then there was, I don't even remember how
    these models were called, but today, you just throw everything in the LLM, and
    it tells you, here's a noun, or these names, there are named entities.
  topic: AI technology trends/technical
- impact_reason: 'Provides a concise, fundamental breakdown of LLM architecture: Transformers
    -> Attention -> Representation Learning (Embeddings). This demystifies the core
    mechanism.'
  relevance_score: 10
  source: llm_enhanced
  text: But now, like, if you think of it, it's all based on the same fundamentals.
    Like, you know, your LLMs, they're based on transformers, which is based on, like,
    the attention mechanism, and that boils down to your representation learning,
    where you have, like, embeddings, and the embeddings have similarity, and like,
    the whole core of LLMs could be, like, you know, said, it's like a representation
    learning kind of thing, which is, like, where the basics began, which is where
    the fundamentals began.
  topic: technical
- impact_reason: 'Describes a specific application of RL in self-driving simulation:
    creating realistic testbeds where agents learn through massive penalty/reward
    structures (e.g., avoiding pedestrian collisions).'
  relevance_score: 10
  source: llm_enhanced
  text: they have the environment with streets and whatnot, so they look very realistic.
    And I don't know, it was in Germany, so I guess like BMWs and Audis and whatnot,
    like companies who also work on self-driving here in Germany, they could use this
    environment to test their cars. And the idea there was that they have this reinforcement
    learning framework where they can, the car can just go wild and learn from like,
    okay, like if I hit a pedestrian, then there is a huge penalty, and then it learns
    not to do this.
  topic: technical/safety
- impact_reason: Provides a clear, high-level explanation of how RL, using penalty/reward
    structures, is theoretically applied to critical safety scenarios like avoiding
    pedestrians.
  relevance_score: 10
  source: llm_enhanced
  text: And the idea there was that they have this reinforcement learning framework
    where they can, the car can just go wild and learn from like, okay, like if I
    hit a pedestrian, then there is a huge penalty, and then it learns not to do this.
  topic: technical
- impact_reason: Defines the role of RL as the 'behavior modification' layer, contrasting
    it with the 'perception' layer handled by CV.
  relevance_score: 10
  source: llm_enhanced
  text: And then I believe like reinforcement learning comes into picture when you're
    trying to modify the behavior of the agent or trying to teach it how to behave
    in the world it is in.
  topic: technical
- impact_reason: Raises a crucial safety and deployment concern regarding the direct
    application of raw RL training methods in real-world, safety-critical systems.
  relevance_score: 10
  source: llm_enhanced
  text: I imagine also it's not you will not let a car go wild and learn the way to
    interact with pedestrians right outside.
  topic: safety
- impact_reason: Confirms that even advanced AI systems require explicit, hard-coded
    constraints based on physical laws and regulations.
  relevance_score: 10
  source: llm_enhanced
  text: I think like all environments, like even in reinforcement learning or other
    ways to teach the car, there would be some constraints that you impose upon it,
    the rules of the world.
  topic: safety
- impact_reason: Detailed explanation of a practical, real-time computer vision application
    for accessibility (AI Guide Dog), demonstrating multimodal output (vision to audio
    instruction).
  relevance_score: 9
  source: llm_enhanced
  text: So this app is basically their eyes. So you just hang it around your neck,
    and you walk with it, and it gets a worldview of what is in front of you, and
    then via live audio instructions, it tells you, you know, keep walking straight,
    and if you enter the destination based on that, you know, take left or right,
    or stop at a traffic signal, or there's like, you know, pedestrian crossing, so
    it gives you instructions via audio.
  topic: AI for social good/technical application
- impact_reason: Offers crucial advice on tackling large, complex, long-term AI projects
    (like the social good app) through iterative development and phased contributions.
  relevance_score: 9
  source: llm_enhanced
  text: You pick up small pieces. Like the first one started with like the data efforts,
    the second one started building like baseline models, the third one tried improving
    it with evaluations and stuff. So you do it iteratively, so it's a good idea,
    yeah.
  topic: strategy/product building
- impact_reason: 'Emphasizes a key strategic constraint in developing widely accessible
    AI solutions: leveraging ubiquitous, cost-effective hardware (smartphones) over
    specialized sensors.'
  relevance_score: 9
  source: llm_enhanced
  text: So, mobile phone everyone has it; like, it is, we're trying to fit it on what
    everyone has.
  topic: business/strategy/accessibility
- impact_reason: 'Explains the business and scalability rationale behind the vision-only
    approach: cost reduction and mass market adoption.'
  relevance_score: 9
  source: llm_enhanced
  text: Yeah, so I think that's like the USP of Tesla systems, that, you know, because
    LiDAR is expensive, or at least the good quality ones, and they want to be like,
    really scalable, they rely on just cameras.
  topic: business/strategy/self-driving
- impact_reason: A powerful statement on the potential safety advantage of advanced
    ADAS/self-driving systems over human perception.
  relevance_score: 9
  source: llm_enhanced
  text: So, basically, the car has a much better holistic view of the world than a
    person driving the car.
  topic: predictions/safety impact
- impact_reason: Highlights the multi-sensor fusion approach (360 view) essential
    for robust autonomous driving systems, contrasting it with limited human perception.
  relevance_score: 9
  source: llm_enhanced
  text: So, you get a view from all around, like a 360 view of the system. And you
    kind of run your models on top of it that can make use of these different views
    of the world and see basically all around the car.
  topic: technical
- impact_reason: Confirms the real-world deployment of fully driverless (Level 4/5)
    services like Waymo in specific geographies (SF), contrasting with ADAS deployments
    elsewhere.
  relevance_score: 9
  source: llm_enhanced
  text: And see, I see. Makes sense. Because I am originally from Russia, and I know
    in Russia, in Moscow, some cars already drive without drivers. I guess in San
    Francisco too, right? Yes. As I've also had Waymo, which has like no driver at
    all.
  topic: predictions
- impact_reason: Emphasizes the paramount requirement for low-latency, real-time decision-making
    in safety-critical AI applications like autonomous driving.
  relevance_score: 9
  source: llm_enhanced
  text: So, my job is to make Waymo better at understanding. How much can you talk
    about this project? Because I wonder how does it actually work, like what kind
    of tech do you use? It must be something super fast, right? Yeah, I know you cannot
    go into details, but I guess it should be something super fast because like you
    need to make this decision in real life, in real time, right?
  topic: technical
- impact_reason: Confirms that quantization is standard, but leading companies use
    proprietary techniques beyond public knowledge to achieve necessary speed/size
    trade-offs.
  relevance_score: 9
  source: llm_enhanced
  text: So, you make it like, you make it smaller, you make it faster with quantization.
    So, many of similar techniques, but there are a whole bunch of other stuff that
    we also do internally.
  topic: technical
- impact_reason: Demonstrates leveraging non-traditional data sources (topographic/geographical
    data) alongside satellite imagery for environmental prediction tasks.
  relevance_score: 9
  source: llm_enhanced
  text: What my model did was to use topographic information. So, we have this Google
    data that gives you information about the geography of a particular region, and
    then you try to basically train a model to identify what could be like low-lying
    areas where there's a high possibility of water stagnating and detect those areas...
  topic: technical
- impact_reason: Illustrates the extreme friction and long feedback loops (monthly
    deployment cycles, mandatory audits) common in legacy enterprise/finance environments,
    contrasting sharply with fast-moving tech.
  relevance_score: 9
  source: llm_enhanced
  text: And we deploy it even once per month. And if we didn't have a chance to prepare
    some things for the deployment, because there is a process like you need to do
    some sort of audit... if you missed this deadline, then you wait for one month
    for the next cycle, right?
  topic: strategy
- impact_reason: Emphasizes the extreme safety criticality of self-driving technology,
    setting a high bar for deployment that contrasts with typical software releases.
  relevance_score: 9
  source: llm_enhanced
  text: first of all, there is this component that like you cannot really afford having
    bugs there, right? Because like if there is a bug and then a car misbehaves and
    I don't know, hits a traffic light. And then like, it's good if nobody gets injured,
    but what if somebody gets injured? Then it's super bad.
  topic: safety/predictions
- impact_reason: Provides a clear comparison of risk tolerance between financial software
    (recoverable monetary loss) and autonomous systems (loss of life), illustrating
    the ethical weight on AI engineers in certain sectors.
  relevance_score: 9
  source: llm_enhanced
  text: in engineering, there are a lot more than in a financial company because in
    like in Morgan Stanley, I've seen there's been losses, there's been millions of
    dollars of losses, but that you can recover. But this is like someone's life or
    something changed. It's much more important.
  topic: safety/ethics
- impact_reason: Reiterates that LLM advancements are built upon established deep
    learning principles, encouraging practitioners to look beyond the hype and apply
    core concepts universally.
  relevance_score: 9
  source: llm_enhanced
  text: many of these techniques are general deep learning techniques rather than
    just that are applicable to LLMs. So, you can use some of these techniques even
    for your models that work with CV data. So, yeah, at the end of the day, it's
    all deep learning.
  topic: technical/AI technology trends
- impact_reason: Directly contrasts the time required to understand a technical paper
    with and without foundational knowledge (2 weeks vs. 1 hour), emphasizing the
    ROI of deep learning education.
  relevance_score: 9
  source: llm_enhanced
  text: No, no, it's, like, probably an hour at max. It's much more efficient now.
  topic: strategy
- impact_reason: Points to the critical role of high-fidelity simulation environments
    (digital twins/testbeds) in developing and validating autonomous systems.
  relevance_score: 9
  source: llm_enhanced
  text: there were companies I interviewed with, one of them who were creating these
    environments for self-driving cars to be like a testbed or whatever, like for
    testing.
  topic: business
- impact_reason: 'Clearly delineates the two major components of autonomous systems:
    Perception (Computer Vision) vs. Action/Behavior (RL).'
  relevance_score: 9
  source: llm_enhanced
  text: my career, like whatever career has been in computer vision or robotics, so
    to speak, it has mostly been on the computer vision side, so perception, I try
    to understand the world.
  topic: technical
- impact_reason: 'Frames the core debate in complex systems like self-driving: pure
    learned intelligence vs. hybrid rule-based systems.'
  relevance_score: 9
  source: llm_enhanced
  text: What's the question is, is this full AI or a mix of rules and AI?
  topic: strategy
- impact_reason: Provides a concrete example of necessary constraints that must override
    learned behavior for safety.
  relevance_score: 9
  source: llm_enhanced
  text: You shouldn't go against the traffic, you need to put these constraints.
  topic: safety
- impact_reason: Strong statement against the feasibility of purely autonomous, unconstrained
    learning in regulated industries.
  relevance_score: 9
  source: llm_enhanced
  text: So, it's like I don't think it's full to do whatever learn, learn however
    you want to try. Definitely constrained by a lot of rules...
  topic: strategy
- impact_reason: Emphasizes the need for AI systems to adapt to diverse, culturally
    specific human behavioral patterns, not just static rules.
  relevance_score: 9
  source: llm_enhanced
  text: Sometimes the drivers are very aggressive, sometimes it's like more rule-following.
    Right, right. So, it needs to be adaptable that way and can change specifically.
  topic: predictions
- impact_reason: Pinpoints a critical realization moment (2018) regarding the untapped
    value in large datasets, just before the major AI boom, showing an early pivot
    towards automation.
  relevance_score: 8
  source: llm_enhanced
  text: From there, I realized that there's so much of data that it has so much of
    value that we don't need to do all the things that we do manually. And that was
    back, I guess, in 2018, and the whole AI bubble hadn't formed yet, but it was
    getting there; people were realizing how important it was.
  topic: strategy/AI adoption timeline
- impact_reason: Shows the progression from standard ML (recommendation engines) to
    more complex architectures (GNNs) and the realization of the field's depth, leading
    to further education.
  relevance_score: 8
  source: llm_enhanced
  text: We tried out graph neural networks, which was some of the more complicated
    topics at that point, and that's when I realized that, oh, there's so much to
    be learned here, and this field is so vast.
  topic: technical/model architecture
- impact_reason: Highlights the necessary rigor and caution required when deploying
    AI in sensitive, safety-critical domains (like navigation for the visually impaired).
  relevance_score: 8
  source: llm_enhanced
  text: We have the model, but it's still in beta phase. We are doing a lot of testing
    because it's kind of like a sensitive use case, and yeah, yeah, you can imagine.
  topic: safety/deployment
- impact_reason: 'Reiterates the primary societal goal of self-driving technology:
    achieving a safety level superior to human drivers.'
  relevance_score: 8
  source: llm_enhanced
  text: So, yeah, I think that's the goal which self-driving is to make driving safer
    once it accomplishes that level of, you know, ADAS, that level.
  topic: predictions/safety
- impact_reason: Points out the critical role of regulatory environments and localization
    (e.g., handling unique European road signs) as barriers to global deployment.
  relevance_score: 8
  source: llm_enhanced
  text: I guess that's why they don't use self-driving. I think Tesla is trying to
    get into the European markets though with the autopilot. Like at least when I
    was trying to like when I was there, I was working on some European road signs,
    like speed limit signs.
  topic: safety
- impact_reason: Reveals the proprietary nature of cutting-edge AV models, which rely
    on complex sensor fusion (cameras + LiDAR) and are kept internal for competitive
    advantage.
  relevance_score: 8
  source: llm_enhanced
  text: Yeah, there are like a bunch of in-house models that use like cameras, LiDAR
    data, and like all the sensor information that we have, we get some of the car.
    And it's like Waymo does not publish its models what it uses.
  topic: technical
- impact_reason: 'A clear use case for ML in public health: optimizing resource allocation
    (fumigation) by predicting high-risk areas, maximizing efficiency.'
  relevance_score: 8
  source: llm_enhanced
  text: So, the first iteration was to just go in places and fumigate places where
    there could be a high possibility of Malaria mosquitoes... they only want to target
    places where there's a high probability of mosquitoes. So, they wanted to use
    machine learning models or AI to do that.
  topic: business
- impact_reason: 'A common pain point for ML practitioners: institutional inertia
    and slow adoption rates for cutting-edge technology within highly regulated sectors
    like finance.'
  relevance_score: 8
  source: llm_enhanced
  text: I was interested in learning more because in financial institutions, generally,
    like, you know, these newer technologies, like ML and all, it's not easily adoptable.
    So, it's really hard to get started on a project.
  topic: business
- impact_reason: Highlights the tension between necessary rigorous process (especially
    in safety-critical domains) and the desire for rapid innovation, a common pain
    point in mature tech organizations.
  relevance_score: 8
  source: llm_enhanced
  text: And it's after a point, it gets repetitive. And it's like, even for like putting
    the smallest thing in production, you need to go through this. At some point,
    it gets to you. And you're like, I want to like do innovation. I want to like
    make an impact. I don't want to get caught in process and stuff.
  topic: strategy/business
- impact_reason: Highlights the complexity introduced when AI software interacts directly
    with low-level hardware (e.g., actuation in robotics/automotive), requiring deeper
    systems knowledge than typical cloud software.
  relevance_score: 8
  source: llm_enhanced
  text: But once you need to use something low-level, something native, and you need
    to be closer to hardware, then things can get complicated, right? And in case
    of self-driving, you're very, very closely connected with hardware because you
    actually need to, I don't know, steer the wheel or hit the brakes or whatever.
  topic: technical/strategy
- impact_reason: Provides anecdotal evidence of industry fluidity and the portability
    of core deep learning skills across different high-profile AI companies (Tesla,
    Waymo).
  relevance_score: 8
  source: llm_enhanced
  text: Even when I was switching my roles from Tesla to Waymo, I did a lot of different
    interviews, and the way it works in the industry is like, although you are from
    a CV background, it's the same underlying fundamentals.
  topic: business/strategy
- impact_reason: Quantifies the steep learning curve for complex ML topics (like GNNs)
    without a foundational deep learning background (2 weeks for an 8-page paper).
  relevance_score: 8
  source: llm_enhanced
  text: I remember, like, I mentioned in Morgan Stanley, we were doing these basic
    things with the recommendation systems and, like, graph neural networks. It took
    me, like, almost two weeks to go through one paper, and it was just, like, eight
    pages, and at that time, I did not have any background about deep learning.
  topic: technical/strategy
- impact_reason: Points out the specific relevance of Reinforcement Learning (RL)
    in autonomous systems, even if the speaker's direct experience was limited.
  relevance_score: 8
  source: llm_enhanced
  text: Interesting that you mentioned you didn't have prior experience with reinforcement
    learning, because I thought reinforcement learning is something that's used quite
    often for driving too.
  topic: technical/safety
- impact_reason: Identifies Reinforcement Learning (RL) as a key, though perhaps less
    visible post-LLM, area in autonomous driving.
  relevance_score: 8
  source: llm_enhanced
  text: I thought reinforcement learning is something that's something that's used
    quite often for driving too.
  topic: technical
- impact_reason: Reaffirms the ongoing relevance of RL in the field of robotics, separate
    from the current focus on LLMs.
  relevance_score: 8
  source: llm_enhanced
  text: I think reinforcement learning is still a big part of robotics.
  topic: technical
- impact_reason: Equates 'full AI' in this context with the idealized, unconstrained
    learning capability of RL.
  relevance_score: 8
  source: llm_enhanced
  text: I am assuming Lecker is referring to self-driving because I guess like full
    AI would be this reinforcement learning, right, when the car just learns to drive
    by itself.
  topic: technical
- impact_reason: Highlights the massive regulatory and operational complexity (localization)
    that AI systems must handle beyond core technical training.
  relevance_score: 8
  source: llm_enhanced
  text: '...as you try to expand into different countries or different continents,
    there are a whole bunch of new rules that go about over there.'
  topic: business
- impact_reason: Highlights the massive data challenges in finance during major acquisitions,
    setting the stage for the realization that manual processing is insufficient.
  relevance_score: 7
  source: llm_enhanced
  text: I was there when Morgan Stanley was doing this acquisition of E-Trade, so
    we had a lot more data coming in. So my role there was handling all this data,
    how do we connect the different dots, how do we analyze them together?
  topic: business/data engineering
- impact_reason: Provides insight into industry-specific AI adoption lag, contrasting
    finance with other sectors that adopted ML earlier.
  relevance_score: 7
  source: llm_enhanced
  text: Finance was one of the last fields to take on the machine learning aspect,
    the AI aspect.
  topic: business/industry trends
- impact_reason: Identifies AR glasses as a future platform for vision-based AI, noting
    their advantage in wider field-of-view compared to current mobile phone sensors.
  relevance_score: 7
  source: llm_enhanced
  text: And also with this AR and glasses, you probably heard, like I think Meta has
    some other companies too that have them. So you put them in your eyes, and they
    have cameras, right? And the cameras, they have a broader vision than mobile phones,
    yeah.
  topic: technology trends/hardware
- impact_reason: A personal anecdote illustrating the current capability and psychological
    effect of high-level ADAS systems, showing significant driver assistance even
    if full autonomy isn't achieved.
  relevance_score: 7
  source: llm_enhanced
  text: And then that car tricks you, like, I remember two years ago I took a trip
    to like Vegas. It was like a 13-hour drive one way and then 13 hours back. And
    I was the only person driving, and like that car aided me all the way. Like it
    drove 95% of the time, and I was like, it's there.
  topic: practical experience/ADAS
- impact_reason: Identifies highway driving (low complexity, high monotony) as the
    current sweet spot where AI assistance provides maximum immediate value.
  relevance_score: 7
  source: llm_enhanced
  text: But for some simple cases, like you said, when you need to go to Vegas, I
    don't know what kind of road is there. But maybe it's like most of the time is
    just straight, right? Yeah, I think like it's a highway. So, it's not like, you
    know, there's a lot of traffic lights and stuff. You just go straight and you
    go along the road.
  topic: strategy
- impact_reason: Describes a successful model for leveraging skilled volunteer ML
    engineers for social good projects (AI for Good movement).
  relevance_score: 7
  source: llm_enhanced
  text: I joined an organization called Oundina, and basically, they work, they have
    like AI for good projects where you have like a nonprofit company that comes in
    with their problem, and you have these volunteer ML engineers... who work together
    on this problem.
  topic: strategy
- impact_reason: Highlights the crucial business constraint (cost sensitivity) that
    drives the need for AI-driven efficiency in non-profit/social impact work.
  relevance_score: 7
  source: llm_enhanced
  text: And, you know, for these kind of nonprofits, cost is a very big, I guess,
    consideration.
  topic: business
- impact_reason: Captures the core tension between the desire for rapid innovation/impact
    and the necessity of bureaucratic process/governance in large organizations.
  relevance_score: 7
  source: llm_enhanced
  text: I want to like do innovation. I want to like make an impact. I don't want
    to get caught in process and stuff.
  topic: strategy
- impact_reason: A cautionary tale about the dangers of incomplete testing, even in
    non-safety-critical enterprise software (CrowdStrike/Windows BSOD), reinforcing
    the need for comprehensive test coverage.
  relevance_score: 7
  source: llm_enhanced
  text: And so the story there was that they wrote something out and then it broke,
    right? Yes, I think the testing, they missed some test cases and something very
    unexpected happened over there.
  topic: safety/strategy
- impact_reason: Identifies the recent industry shift where NLP/LLMs have dominated
    the AI landscape, contrasting with the speaker's prior specialization in Computer
    Vision (CV).
  relevance_score: 7
  source: llm_enhanced
  text: With all these new things coming out of AI, LLMs and whatnot. So since you
    were working in computer vision, but all these new things, they are mostly related
    to NLP and text, NLP and text.
  topic: AI technology trends
- impact_reason: Acknowledges the practical utility of LLMs like ChatGPT as immediate,
    personalized tutors for understanding complex technical literature.
  relevance_score: 7
  source: llm_enhanced
  text: Good that we have ChatGPT, so I can ask it to explain things. That was good,
    not like, it was not there back when we were in school and doing assignments.
  topic: AI technology trends/business
- impact_reason: Highlights the immediate utility and reliance on LLMs like ChatGPT
    for knowledge acquisition, even in technical discussions.
  relevance_score: 7
  source: llm_enhanced
  text: Yeah, well, good that we have ChatGPT, so I can ask it to explain things.
  topic: strategy
- impact_reason: A classic startup anecdote illustrating the resource-intensive nature
    (GPUs) of early-stage deep learning/AI ventures.
  relevance_score: 7
  source: llm_enhanced
  text: It was funny; it was like a company with four people in the basement and a
    lot of GPUs.
  topic: business
- impact_reason: Uses specific international examples to illustrate the variability
    in real-world data distributions that AI must generalize across.
  relevance_score: 7
  source: llm_enhanced
  text: So in Italy and in Germany it's so so different, like the way people drive.
  topic: strategy
- impact_reason: Offers a strategic insight into leveraging mentorship for rapid,
    low-cost idea validation by offloading the implementation burden to invested mentees.
  relevance_score: 6
  source: llm_enhanced
  text: What I like about mentoring is you can test the ideas without actually spending
    a lot of time implementing them, but you know the outcome. You learn the outcome
    from the person you mentor.
  topic: business/strategy
- impact_reason: Reflects a common historical perception gap where ML was seen as
    distinct from the broader concept of AI before the current LLM wave.
  relevance_score: 6
  source: llm_enhanced
  text: for me, AI was, so there was machine learning, which was kind of part of AI,
    but for me, machine learning was machine learning, never like AI.
  topic: strategy
- impact_reason: Highlights the perceived difficulty and complexity of RL as a barrier
    to entry for some practitioners.
  relevance_score: 6
  source: llm_enhanced
  text: I've like, I skipped all reinforcement learning courses in college because
    I just found it too hard.
  topic: strategy
source: Unknown Source
summary: '## Comprehensive Summary: Lessons from Applied AI: Tesla, Waymo, and Beyond
  - Aishwarya Jadhav


  This 59-minute podcast episode features an in-depth conversation with **Aishwarya
  Jadhav**, an ML Engineer currently at **Waymo**, with prior significant experience
  at **Tesla** (out-of-the-box AI team) and **Morgan Stanley**. The discussion traces
  her career trajectory from handling massive datasets in finance to tackling cutting-edge
  challenges in computer vision for autonomous driving and AI for social good.


  ### Main Narrative Arc and Key Discussion Points


  The conversation follows a chronological path through Aishwarya’s diverse career:


  1.  **Finance to AI (Morgan Stanley):** Starting as a Big Data Engineer, she managed
  data integration during the E-Trade acquisition, realizing the untapped value in
  automation. This led her to explore recommendation systems and advanced topics like
  Graph Neural Networks, prompting her move to academia.

  2.  **Academia and Social Good (CMU):** At CMU, her focus shifted to Computer Vision,
  culminating in the "AI Guide Dog" project—a navigation app for the visually impaired
  using audio instructions derived from real-time scene understanding. This project
  is highlighted as an iterative, volunteer-driven effort for social impact.

  3.  **Autonomous Vehicles (Tesla & Waymo):** Her CV expertise naturally transitioned
  her into the self-driving domain. The discussion contrasts the approaches of Tesla
  (camera-only, vision-centric) and Waymo (multi-sensor fusion, including LiDAR).

  4.  **Current Work at Waymo:** Aishwarya details her current role focusing on **gesture
  and pedestrian semantics**, specifically enabling the autonomous vehicle to interpret
  human signals from traffic controllers (police officers, construction workers) to
  modify driving behavior safely, even in unpredictable scenarios like broken traffic
  lights or large crowds.

  5.  **Deployment Challenges:** The conversation touches upon the extreme rigor required
  for deploying safety-critical AI, contrasting the slow, audited processes in finance
  with the real-time, zero-tolerance-for-error environment of autonomous driving.


  ---


  ### Key Insights & Technical Details


  *   **Autonomous Vehicle Sensor Stacks:** A clear distinction was drawn between
  **Tesla''s vision-only approach** (relying on multiple cameras for a 360-degree
  view) and the **multi-sensor fusion approach** used by many others, including Waymo,
  which incorporates LiDAR (Light Detection and Ranging) for robust environmental
  mapping.

  *   **Model Optimization for Edge Deployment:** For real-time tasks like gesture
  recognition, models must be heavily optimized to run quickly on in-car hardware.
  Techniques mentioned include **quantization** and other internal methods to drastically
  reduce model size and latency while maintaining necessary accuracy.

  *   **AI for Social Good Methodology:** The "AI Guide Dog" project exemplifies successful
  iterative development in a volunteer setting, where successive cohorts tackle specific,
  manageable components (data collection, baseline modeling, evaluation improvement)
  rather than attempting a full solution at once.


  ### Business/Investment Angle


  *   **Autonomous Driving Market Segmentation:** The industry is split between camera-only
  systems (like Tesla, aiming for scalability and lower hardware cost) and sensor-rich
  systems (like Waymo, prioritizing maximum redundancy and safety for fully driverless
  operations).

  *   **Regulatory Hurdles in Global Markets:** The adoption of advanced ADAS/Autonomy
  is heavily influenced by regional regulations, as noted by the challenges Tesla
  faces implementing full autopilot features in complex European environments compared
  to the US.

  *   **Value of Specialized Perception:** Work on interpreting human intent (like
  police gestures) represents a critical, high-value niche in Level 4/5 autonomy,
  as it addresses complex, unstructured edge cases that standard traffic rules cannot
  cover.


  ### Notable Companies/People


  *   **Aishwarya Jadhav:** ML Engineer at Waymo, formerly Tesla and Morgan Stanley.

  *   **Tesla:** Highlighted for its camera-only approach to self-driving and its
  Autopilot visualization UI.

  *   **Waymo:** Discussed as a leader in fully driverless ride-hailing (available
  via their app or integrated with Uber/Lyft in certain cities).

  *   **Morgan Stanley:** Represented the initial phase of her career, emphasizing
  the difficulty of adopting new ML technologies in highly regulated financial institutions.

  *   **Zap Malaria (via Oundina):** The nonprofit partner for the Malaria mapping
  project, demonstrating the application of ML to resource allocation in humanitarian
  efforts.


  ### Future Implications


  The conversation points toward an industry where AI systems must handle increasingly
  nuanced, real-world human interactions (gestures, unexpected events). While current
  deployment is geographically limited (e.g., San Francisco, Moscow), the underlying
  technology is rapidly maturing, driven by the need for extreme real-time performance
  achieved through advanced model compression techniques. The social good projects
  suggest a growing trend of skilled engineers dedicating time to solving critical,
  non-commercial problems using applied ML.


  ### Target Audience


  This episode is highly valuable for **AI/ML Engineers**, **Computer Vision Specialists**,
  **Product Managers in Autonomous Systems**, and **Tech Professionals** interested
  in the practical application, deployment challenges, and career paths within cutting-edge
  AI fields.'
tags:
- artificial-intelligence
- generative-ai
- investment
- ai-infrastructure
- meta
- google
title: 'Lessons from Applied AI: Tesla, Waymo, and Beyond - Aishwarya Jadhav'
topics:
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 107
  prominence: 1.0
  topic: artificial intelligence
- keywords:
  - generative ai
  - genai
  - chatgpt
  - gpt
  - claude
  - text generation
  - image generation
  mentions: 10
  prominence: 1.0
  topic: generative ai
- keywords:
  - investment
  - funding
  - valuation
  - ipo
  - acquisition
  mentions: 6
  prominence: 0.6
  topic: investment
- keywords:
  - gpu
  - tensor
  - training
  - inference
  - model deployment
  - vector database
  mentions: 3
  prominence: 0.3
  topic: ai infrastructure
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-10-11 02:29:26 UTC -->
