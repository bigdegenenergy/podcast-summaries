---
companies:
- category: unknown
  confidence: medium
  context: You are listening to 20VC with me Harry Stebbings. Now what on earth is
    going on in the foundationa
  name: Harry Stebbings
  position: 34
- category: unknown
  confidence: medium
  context: it. So joining me in the hot seat today, we have Rich Sutton, founder and
    CEO of U.com. Before founding U, Ric
  name: Rich Sutton
  position: 372
- category: tech
  confidence: high
  context: acked by top-tier investors and corporations like Google and Kleiner Perkins,
    the company is among Forbes'
  name: Google
  position: 1359
- category: unknown
  confidence: medium
  context: p-tier investors and corporations like Google and Kleiner Perkins, the
    company is among Forbes' list of the top 100
  name: Kleiner Perkins
  position: 1370
- category: unknown
  confidence: medium
  context: of the top 100 startup employers for 2024, CTO's Best Software Awards for
    higher satisfaction products, and a recipient
  name: Best Software Awards
  position: 1470
- category: unknown
  confidence: medium
  context: atisfaction products, and a recipient of the 2024 Cybersecurity Excellence
    Awards, something I definitely never got in school mysel
  name: Cybersecurity Excellence Awards
  position: 1553
- category: tech
  confidence: high
  context: hat half of the 27 companies started last year by OpenAI alumni are still
    in stealth? I discovered this on
  name: Openai
  position: 1810
- category: tech
  confidence: high
  context: ', as well as go-to-market teams from the likes of Notion, Brex and Google
    to find the best start-ups and f'
  name: Notion
  position: 2021
- category: unknown
  confidence: medium
  context: 'od out so much I personally became a shareholder: Mode Mobile. Mode Mobile
    created the Earn Phone, a smartphone'
  name: Mode Mobile
  position: 3073
- category: unknown
  confidence: medium
  context: 'shareholder: Mode Mobile. Mode Mobile created the Earn Phone, a smartphone
    that pays you for daily activities.'
  name: Earn Phone
  position: 3110
- category: unknown
  confidence: medium
  context: 'tte as 2023''s fastest-growing software company in North America. And
    here''s what I''m excited about: Mode''s equity'
  name: North America
  position: 3438
- category: unknown
  confidence: medium
  context: ted papers still in the world. And then we met at Prompt Engineering, which
    was majorly rejected publicly on Open Revi
  name: Prompt Engineering
  position: 4980
- category: unknown
  confidence: medium
  context: gineering, which was majorly rejected publicly on Open Review. An idea
    that made no sense to the reviewers. And
  name: Open Review
  position: 5039
- category: unknown
  confidence: medium
  context: and whoever don't get a cut of Uber working now. So I think that's kind
    of the mental model I built for
  name: So I
  position: 9260
- category: unknown
  confidence: medium
  context: that's kind of the mental model I built for LLMs. Can I interject there
    and say the core of a telco busin
  name: Can I
  position: 9321
- category: unknown
  confidence: medium
  context: with open source, it's even more. I said this to Kevin Scott at Microsoft
    and he said, what's the moat with se
  name: Kevin Scott
  position: 9808
- category: tech
  confidence: high
  context: ce, it's even more. I said this to Kevin Scott at Microsoft and he said,
    what's the moat with search? Go from
  name: Microsoft
  position: 9823
- category: unknown
  confidence: medium
  context: t's very different. You have a lot more pressure. And Anthropic has a lot
    more pressure to keep building the best
  name: And Anthropic
  position: 10486
- category: tech
  confidence: high
  context: very different. You have a lot more pressure. And Anthropic has a lot more
    pressure to keep building the best
  name: Anthropic
  position: 10490
- category: unknown
  confidence: medium
  context: rk 10 to 100x worse. Wow. Search ads. Search ads. You Google at some point
    found that no matter how bad they m
  name: You Google
  position: 12498
- category: tech
  confidence: high
  context: the default gets used. And that's why Google pays Apple $20 billion a year
    to be that default. And so it'
  name: Apple
  position: 12807
- category: unknown
  confidence: medium
  context: ong. What happens from this point on? We add like Guillermo Rauch's from
    Waze tweet the other day that actually the
  name: Guillermo Rauch
  position: 13543
- category: unknown
  confidence: medium
  context: app like Windy, then they go to specific app like Uber Eats to get food
    delivery or DoorDash or whatever to g
  name: Uber Eats
  position: 14358
- category: tech
  confidence: high
  context: they don't care about it, they search directly on Amazon. Young people
    now look directly on TikTok because
  name: Amazon
  position: 14554
- category: unknown
  confidence: medium
  context: sitting and paying for 90% licenses. Why is that? With AI, every person
    will become a manager, but most peo
  name: With AI
  position: 16518
- category: unknown
  confidence: medium
  context: s weekend and then one, two, three and it's done. And I was like, that
    was definitely BS. Like there's no
  name: And I
  position: 18060
- category: unknown
  confidence: medium
  context: tra for a direct flight versus a one-stop flight. The AI needs to know
    all these subtle details about you
  name: The AI
  position: 18858
- category: unknown
  confidence: medium
  context: ny regulators. So I totally agree with you there. But I do think Google
    are actually best positioned. Whe
  name: But I
  position: 20931
- category: unknown
  confidence: medium
  context: pend millions of dollars every week on marketing. And DeepSeek comes in
    and they did that. I mean, obviously one
  name: And DeepSeek
  position: 21647
- category: unknown
  confidence: medium
  context: hey stated how much money it cost? Of course not. Like I think they had,
    and that was part of their market
  name: Like I
  position: 23019
- category: unknown
  confidence: medium
  context: ow. We've had this paper in 2018, I think, called The AI Economist. And
    the field of economics hasn't had their Chat
  name: The AI Economist
  position: 28031
- category: unknown
  confidence: medium
  context: the bull case to be excited about humanoids then? Because I just listened
    to you there and I'm like it's a co
  name: Because I
  position: 31989
- category: unknown
  confidence: medium
  context: the custom robot form factor doesn't make sense. Then I think humanoids
    can be helpful and if they're qui
  name: Then I
  position: 32696
- category: tech
  confidence: high
  context: earch and more and more development. I think like Facebook Meta had open-sourced
    like some new fingertips al
  name: Facebook
  position: 34307
- category: unknown
  confidence: medium
  context: earch and more and more development. I think like Facebook Meta had open-sourced
    like some new fingertips also th
  name: Facebook Meta
  position: 34307
- category: tech
  confidence: high
  context: more and more development. I think like Facebook Meta had open-sourced
    like some new fingertips also th
  name: Meta
  position: 34316
- category: unknown
  confidence: medium
  context: s where people just say, look, I used to journal. Now I write into this
    thing and sometimes it asks me qu
  name: Now I
  position: 41629
- category: unknown
  confidence: medium
  context: I would have loved to invest. But yeah, so an in Codium I fortunately was
    able to invest in. Is he Berlin?
  name: Codium I
  position: 47475
- category: unknown
  confidence: medium
  context: Moore's Law in terms of our speed of progression. Is Moore's Law ever escapable?
    Of course. And like, you kn
  name: Is Moore
  position: 54123
- category: tech
  confidence: high
  context: u know, I think parallelism has helped a ton like Nvidia shows us that
    yeah, we might not double the numbe
  name: Nvidia
  position: 54227
- category: unknown
  confidence: medium
  context: reasonable amount of money and needs to solve the Millennium Math Problem
    and it needs to like translate a book perfectly s
  name: Millennium Math Problem
  position: 58066
- category: tech
  confidence: high
  context: ds those goals. OpenAI at 300, Anthropic at 60 or Groq at 50, which would
    you most invest in? Can I choo
  name: Groq
  position: 58771
- category: ai_application
  confidence: high
  context: The current company founded by Rich Sutton, focusing on providing answers
    and agents for enterprise workflows using LLMs.
  name: U.com
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Rich Sutton was previously Chief Scientist and EVP here after they acquired
    MetaMind. They are a major enterprise software company that utilizes AI.
  name: Salesforce
  source: llm_enhanced
- category: ai_startup
  confidence: high
  context: An AI startup founded by Rich Sutton (CEO/CTO) that was acquired by Salesforce.
  name: MetaMind
  source: llm_enhanced
- category: ai_company
  confidence: high
  context: Mentioned as the creator of ChatGPT and a provider of foundational models/APIs.
    Also referenced via its alumni starting new companies.
  name: OpenAI
  source: llm_enhanced
- category: ai_company
  confidence: high
  context: A competitor to OpenAI, focusing on building foundational models (Claude)
    and facing pressure to maintain model quality.
  name: Anthropic
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Mentioned regarding its search dominance, its payment to Apple for default
    status, and its AI division (implied by Gemini/Google AI context).
  name: Google
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Mentioned via Kevin Scott (CTO), indicating their significant role in the
    AI landscape.
  name: Microsoft
  source: llm_enhanced
- category: ai_research
  confidence: medium
  context: Rich Sutton received his PhD here, implying the presence of a significant
    AI research institution (Stanford AI Lab is implied).
  name: Stanford
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: A company simplifying security/compliance using AI and automation, backed
    by Google and Kleiner Perkins.
  name: SecureFrame
  source: llm_enhanced
- category: financial_entity
  confidence: high
  context: A top-tier investor backing SecureFrame.
  name: Kleiner Perkins
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: A complete start-up database used by VCs (like Insight, Menlo) and GTM
    teams to track startups, including those founded by OpenAI alumni.
  name: Harmonic
  source: llm_enhanced
- category: financial_entity
  confidence: high
  context: A leading VC firm that uses the Harmonic database.
  name: Insight
  source: llm_enhanced
- category: financial_entity
  confidence: high
  context: A leading VC firm that uses the Harmonic database.
  name: Menlo
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: A company whose GTM teams use the Harmonic database.
  name: Notion
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: A company whose GTM teams use the Harmonic database.
  name: Brex
  source: llm_enhanced
- category: technology_company
  confidence: medium
  context: A company creating the 'Earn Phone,' recognized as a fast-growing software
    company, indicating use of software/tech innovation.
  name: Mode Mobile
  source: llm_enhanced
- category: organization
  confidence: low
  context: Recognized Mode Mobile as the fastest-growing software company.
  name: Deloitte
  source: llm_enhanced
- category: technology_company
  confidence: medium
  context: Mentioned via its CEO, Guillermo Rauch, in the context of migration trends
    away from Google.
  name: Waze
  source: llm_enhanced
- category: individual_leader
  confidence: high
  context: CEO of Waze, mentioned regarding conversion trends.
  name: Guillermo Rauch
  source: llm_enhanced
- category: big_tech
  confidence: medium
  context: Mentioned as a platform where users search directly for small purchases,
    indicating its role in the unbundling wave.
  name: Amazon
  source: llm_enhanced
- category: technology_company
  confidence: medium
  context: Mentioned as a platform young people use for search/discovery.
  name: TikTok
  source: llm_enhanced
- category: technology_company
  confidence: medium
  context: Mentioned as a specialized app consumers use for restaurant reviews, part
    of the unbundling trend.
  name: Yelp
  source: llm_enhanced
- category: technology_company
  confidence: medium
  context: Mentioned as a specific weather app consumers use, part of the unbundling
    trend.
  name: Windy
  source: llm_enhanced
- category: technology_company
  confidence: medium
  context: Mentioned as a specialized app for food delivery, part of the unbundling
    trend.
  name: Uber Eats
  source: llm_enhanced
- category: technology_company
  confidence: medium
  context: Mentioned as a food delivery service, part of the unbundling trend.
  name: DoorDash
  source: llm_enhanced
- category: big_tech
  confidence: medium
  context: Mentioned as a company theoretically well-positioned for AI due to consumer
    touchpoints, but currently perceived as not doing much in the space.
  name: Apple
  source: llm_enhanced
- category: ai_company
  confidence: high
  context: An open-source model from China that rapidly overtook many competitors,
    challenging the narrative that only massive VC funding guarantees success.
  name: DeepSeek
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Used as a benchmark for market disruption ('ChatGPT moment') for various
    fields like medicine and economics. Implies OpenAI's product.
  name: ChatGPT
  source: llm_enhanced
- category: ai_model
  confidence: medium
  context: A new LLM model launched on a weekend, suggesting rapid iteration and competition
    in the space.
  name: LLM4 model
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: A paper/model developed by the speaker (at Salesforce) using two-level
    reinforcement learning to simulate optimal taxation schemes.
  name: The AI Economist
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: Mentioned as an organization in London that excels at 'science marketing'
    for their research findings.
  name: DeepMind
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Mentioned for open-sourcing new fingertips with pressure sensors for robotics.
  name: Facebook Meta
  source: llm_enhanced
- category: ai_startup
  confidence: high
  context: The speaker mentions having been an investor in Replika many years ago,
    which is an AI companion/friend application.
  name: Replika
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned in the context of a continuous battle with Cursor, suggesting
    it is a competing AI/developer tool.
  name: Windsurf
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as a competitor to Windsurf, likely an AI-powered coding assistant
    or IDE.
  name: Cursor
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: An AI company the speaker was able to invest in; likely an AI coding tool
    competitor.
  name: Codium
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: Mentioned in the context of hardware acceleration and parallelism helping
    to escape Moore's Law, indicating their role in AI infrastructure.
  name: Nvidia
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: Mentioned as a company in the context of investment valuation ($50B figure
    implied), indicating it is an AI infrastructure or model company.
  name: Groq
  source: llm_enhanced
- category: technology_analogy
  confidence: medium
  context: Mentioned as a historical photo-sharing app, used as an analogy for how
    the consumer AI market might consolidate.
  name: Flickr
  source: llm_enhanced
- category: technology_analogy
  confidence: medium
  context: Mentioned as a historical photo-sharing app that succeeded, used as an
    analogy for successful consumer AI branding/distribution.
  name: Instagram
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: Mentioned as the person who made a bet with the speaker about AGI timelines,
    indicating involvement in high-level AI research/development.
  name: OpenAI co-founder
  source: llm_enhanced
- category: technology_analogy
  confidence: medium
  context: Mentioned as an example of successful open-source software, used to contrast
    against closed-source LLMs.
  name: Linux
  source: llm_enhanced
date: 2025-04-18 14:40:00 +0000
duration: 64
has_transcript: false
insights:
- actionable: true
  confidence: medium
  extracted: think about it
  text: we should think about it.
  type: recommendation
- actionable: true
  confidence: medium
  extracted: like spread consciousness into the universe
  text: we should like spread consciousness into the universe.
  type: recommendation
layout: episode
llm_enhanced: true
original_url: https://traffic.libsyn.com/secure/thetwentyminutevc/20VC-_Richard_Socher__You.com.mp3?dest-id=240976
processing_date: 2025-10-06 12:19:34 +0000
quotes:
- length: 195
  relevance_score: 6
  text: He's also widely recognized as having brought neural networks into the field
    of natural language processing, inventing the most widely used word vectors, contextual
    vectors and prompt engineering
  topics: []
- length: 255
  relevance_score: 6
  text: I discovered this on Harmonic, the complete start-up database used by Excel,
    Insight, Menlo and hundreds of other leading VCs, as well as go-to-market teams
    from the likes of Notion, Brex and Google to find the best start-ups and founders,
    even in stealth
  topics:
  - market
  - vc
- length: 99
  relevance_score: 6
  text: Learn how VCs and GTM teams find the best start-ups six months ahead of the
    competition on harmonic
  topics:
  - competition
  - vc
  - gtm
- length: 140
  relevance_score: 6
  text: Right now the markets are really down, public bio valuations are much lower
    for early-stage startups, even if they already make good revenue
  topics:
  - revenue
  - market
  - valuation
- length: 61
  relevance_score: 6
  text: Like is cash a moat for LLMs and for companies in this market
  topics:
  - market
  - moat
- length: 109
  relevance_score: 5
  text: Maybe just because ChatGPT owns the consumer market that hard, you have to
    find a different part of the niche
  topics:
  - market
- length: 104
  relevance_score: 5
  text: And you have to do brand and marketing, like something that DeepMind in London
    here does incredibly well
  topics:
  - market
- length: 88
  relevance_score: 5
  text: What do you think is the biggest misconception that people have today around
    AI and LLMs
  topics: []
- length: 93
  relevance_score: 4
  text: I'm credited for having brought neural networks into the field of natural
    language processing
  topics: []
- length: 216
  relevance_score: 4
  text: I feel like we have still not maxed out our abilities on the marketing side
    and branding side of things but at least sales works well enough now that we're
    really increasing revenue and that's ultimately what matters
  topics:
  - revenue
  - market
- length: 171
  relevance_score: 4
  text: When you think about one of the most important things being touchpoints to
    end consumers, I don't think anyone other than them and Microsoft are actually
    better positioned
  topics: []
- length: 102
  relevance_score: 4
  text: You could almost hear billions of dollars of VC investment evaporate into
    the ether when that happened
  topics:
  - investment
  - vc
- length: 171
  relevance_score: 4
  text: And so it's useful to understand that you also have seen that even LLMs benefit
    in their general reasoning skills when they know and have seen programming as
    training data
  topics: []
- length: 179
  relevance_score: 4
  text: And then they saw our prompt engineering paper which they cited and that NLP
    route was a more legit step towards AGI than the previous things but long story
    short, we did this bet
  topics: []
- length: 121
  relevance_score: 3
  text: 'And here''s what I''m excited about: Mode''s equity offerings have raised
    over $30 million from 20,000 plus retail investors'
  topics: []
- length: 99
  relevance_score: 3
  text: And on a lot of those questions, you don't really have the opportunity to
    be 10x better than Google
  topics:
  - opportunity
- length: 85
  relevance_score: 3
  text: But on value, you have to also differentiate between value creation and value
    capture
  topics: []
- length: 80
  relevance_score: 3
  text: I said this to Kevin Scott at Microsoft and he said, what's the moat with
    search
  topics:
  - moat
- length: 150
  relevance_score: 3
  text: And Anthropic has a lot more pressure to keep building the best models because
    Claude is so much smaller in terms of market share for the consumer app
  topics:
  - market
- length: 57
  relevance_score: 3
  text: And so LLMs, it is part of that unbundling wave of Google
  topics: []
- length: 102
  relevance_score: 3
  text: So whenever you say you're the best, you're the best in that moment and you
    have to keep working on it
  topics: []
- length: 159
  relevance_score: 3
  text: Now when you become a manager, you have to learn to distill all your knowledge
    in a very succinct and unambiguous way to another entity, in this case, an agent
  topics: []
- length: 132
  relevance_score: 3
  text: So you have to keep doing something and they built internet balloons and self-driving
    cars and just infrastructure, fiber, and trust
  topics: []
- length: 138
  relevance_score: 3
  text: The problem is when robotics, like the cost, right, you only want to build
    specific types of robots when there's a highly scalable process
  topics: []
- length: 87
  relevance_score: 3
  text: The problem is that that is in like these cluttered environments that are
    all different
  topics: []
- length: 157
  relevance_score: 3
  text: Do you think that we will find the solution to some of the biggest medical
    problems in the next 10 years through some of the discussion that we found already
  topics: []
- length: 91
  relevance_score: 3
  text: And I think you have to, one, acknowledge that everything falls in some normal
    distribution
  topics: []
- length: 202
  relevance_score: 3
  text: If, in fact, I think one of the biggest civilizationary unlocks would be to
    all agree that entropy or darkness in the universe is the enemy and that we should
    like spread consciousness into the universe
  topics: []
- length: 120
  relevance_score: 3
  text: But assuming back in, I think the problem is that while most people complain
    about their jobs, it does give them meaning
  topics: []
- length: 121
  relevance_score: 3
  text: I think the biggest problem and biggest worry I have is that the entry-level
    jobs right now are more and more automatable
  topics: []
- impact_reason: Directly credits the speaker's work leading to foundational models
    like BERT, tracing the lineage of modern NLP architectures.
  relevance_score: 10
  source: llm_enhanced
  text: pushed contextual vectors so you can pre-train not just a single word vector,
    but a whole sentence embedding. And that then became ELMo, which became BERT,
    which is one of the most cited papers still in the world.
  topic: technical
- impact_reason: 'A key strategic pivot/realization: LLMs are best suited for complex
    enterprise workflows rather than simple, low-latency consumer queries where Google
    dominates.'
  relevance_score: 10
  source: llm_enhanced
  text: we realized eventually, the killer app for large language models and complex
    answers is enterprise.
  topic: business/strategy
- impact_reason: 'A critical business distinction: LLMs create massive societal value
    but may not capture that value for the infrastructure providers.'
  relevance_score: 10
  source: llm_enhanced
  text: If they are being commoditized, is there value in them? It's very interesting.
    But on value, you have to also differentiate between value creation and value
    capture.
  topic: business
- impact_reason: 'A powerful analogy comparing foundational model providers (API layer)
    to utility companies: high CapEx, high value creation, low margin capture/moat.'
  relevance_score: 10
  source: llm_enhanced
  text: LLM companies, especially just the pure thin infrastructure layer of LLMs,
    are going to look, I think, more and more like telcos.
  topic: business/strategy
- impact_reason: 'Crucial distinction: OpenAI''s business model (consumer app) insulates
    them from the commoditization pressures faced by pure API providers.'
  relevance_score: 10
  source: llm_enhanced
  text: OpenAI is a consumer app company. They make their revenue, the vast majority
    of their revenue from a consumer app called ChatGPT. If you're now just in that
    API infrastructure layer, it's very different.
  topic: business
- impact_reason: A striking, quantitative claim about the failure of the traditional
    search advertising model in the context of generative AI interfaces.
  relevance_score: 10
  source: llm_enhanced
  text: Ads in AI are really hard. We actually evaluated that. They work about 10
    to 100x worse than search ads.
  topic: business
- impact_reason: Provides real-world evidence of enterprise AI adoption challenges,
    specifically citing failures with major platforms, which serves as a cautionary
    tale for large-scale deployments.
  relevance_score: 10
  source: llm_enhanced
  text: We have seen actually some of our largest enterprise customers now had failed
    OpenAI projects or had failed Salesforce projects. I'll tell you that or built
    their own with some APIs.
  topic: business
- impact_reason: 'Pinpoints the primary failure mode in enterprise AI adoption: low
    utilization despite high licensing costs, emphasizing the gap between procurement
    and actual usage.'
  relevance_score: 10
  source: llm_enhanced
  text: They fail usually for two reasons. One is adoption. They had to pay a thousand
    seat licenses for OpenAI and then six months later they realize only 6% are actually
    using them every week.
  topic: business
- impact_reason: 'Offers a profound sociological and workflow prediction: AI agents
    force workers into a ''managerial'' role, requiring new skills in clear instruction
    and knowledge distillation.'
  relevance_score: 10
  source: llm_enhanced
  text: With AI, every person will become a manager, but most people are not used
    to managing other people or processes. They're used to being individual contributors...
    Now when you become a manager, you have to learn to distill all your knowledge
    in a very succinct and unambiguous way to another entity, in this case, an agent.
  topic: predictions
- impact_reason: Diagnoses Google's slow AI integration as a classic Innovator's Dilemma,
    where existing, highly profitable business models conflict with disruptive, potentially
    superior user experiences.
  relevance_score: 10
  source: llm_enhanced
  text: I think it's never been a question of technical strength for Google. It's
    just a question of classic innovator's dilemma. You make money by showing ads
    and lists of blue links. So it's hard to give people just a straightforward, useful
    answer.
  topic: strategy
- impact_reason: 'A major industry shockwave: The rapid success of DeepSeek demonstrated
    that open-source models could immediately challenge closed-source leaders, shattering
    the narrative that only massive VC-backed entities could compete.'
  relevance_score: 10
  source: llm_enhanced
  text: DeepSeek overtook almost every other thing other than ChatGPT within weeks
    with almost no proper marketing... one, the fact that it was the first open-source
    model that wasn't just almost up to par, but in some cases it was actually above
    the closed-source models was just a shock.
  topic: technical
- impact_reason: 'A highly controversial investment thesis: predicting that pure LLM
    infrastructure plays will fail to yield returns for VCs, favoring companies that
    own the application layer or specific verticals.'
  relevance_score: 10
  source: llm_enhanced
  text: I don't think any venture investors are going to make money from LLMs. Yeah,
    again, if you're just in that narrow niche of infrastructure rather than you own
    the end user in some capacity, you own some vertical.
  topic: business
- impact_reason: Reframes the current AI excitement not as a speculative bubble, but
    as a fundamental shift akin to the industrial revolutions driven by falling marginal
    costs of a core utility (intelligence).
  relevance_score: 10
  source: llm_enhanced
  text: I don't think we're in an AI bubble period. I think intelligence, the fact
    that the marginal cost of intelligence goes down is the same as like the marginal
    cost of electricity or coal or something going down.
  topic: strategy
- impact_reason: Introduces Jevons' Paradox as the key framework for understanding
    the long-term economic impact of cheaper intelligence—increased consumption rather
    than reduced need.
  relevance_score: 10
  source: llm_enhanced
  text: But we will just use it more and more. Like a couple of years ago, I tweeted
    and read about this thing called Jevons' Paradox.
  topic: strategy
- impact_reason: Highlights research and medicine as the two sectors where AI's impact
    will be most universally welcomed based on outcome improvement (cheaper, faster,
    better results) rather than job displacement.
  relevance_score: 10
  source: llm_enhanced
  text: Two areas where I think almost every person also agrees on the planet that
    it's not about the jobs, but about the outcomes. And that's research and medicine.
  topic: predictions
- impact_reason: 'Explains the core challenge in robotics: achieving the generality
    of LLMs (represented by the humanoid form factor) is currently technologically
    infeasible compared to text generation.'
  relevance_score: 10
  source: llm_enhanced
  text: The tricky bit in robotics is that the part of why ChatGPT had this amazing
    moment is that it's so general. And you can just ask it anything. So the equivalent
    to the generality of a ChatGPT is a humanoid. But the humanoids don't work really
    well yet.
  topic: technical
- impact_reason: Contrasts the adoption bottleneck in software AI (human acceptance/inertia)
    with the bottleneck in robotics (fundamental technological limitations).
  relevance_score: 10
  source: llm_enhanced
  text: It's almost like the opposite of our lens where like the technology is ready
    and it's actually human adoption that's the thing that's stopping it versus like
    robotics, which is like actually the adoption I think would be there to have a
    cleaner in every household. But actually it's the technology that's blocking it.
  topic: strategy
- impact_reason: Diagnoses a fundamental limitation in traditional science—the inability
    to model emergent properties in complex systems—which AI is uniquely positioned
    to solve.
  relevance_score: 10
  source: llm_enhanced
  text: Science I think has been stuck in understanding the micro really, really well,
    but has not yet found a tool to understand complex systems really well.
  topic: predictions
- impact_reason: Draws a direct parallel between the complexity of the human brain
    and the scaling laws of neural networks, suggesting AI is the necessary tool for
    understanding complex biological systems.
  relevance_score: 10
  source: llm_enhanced
  text: AI is the perfect tool to tackle that kind of complexity because we can now
    have similar things. We understand how one neuron works but when you have enough
    of them, you scale it up enough. All of a sudden you can have a conversation and
    people think it's a human being on the other side.
  topic: technical
- impact_reason: Argues against UBI not on economic grounds, but on psychological/societal
    grounds, suggesting that work provides essential meaning that UBI might strip
    away, worsening an existing 'meaning crisis.'
  relevance_score: 10
  source: llm_enhanced
  text: But assuming back in, I think the problem is that while most people complain
    about their jobs, it does give them meaning. It does give them meaning to be a
    valuable part of society and to have earned something that they can then give
    to their family, to their kids and so on. And so I think UBI will take that meaning
    away and we're already in a meaning crisis with the technology and society that
    we have set up for ourselves in many places and I think that was just exacerbated.
  topic: safety/social impact
- impact_reason: Defends the enduring value of computer science education even as
    coding tasks are automated. The value lies in the underlying cognitive framework,
    not just the syntax.
  relevance_score: 10
  source: llm_enhanced
  text: Knowing how to program is incredibly important. Why do you say that with the
    commoditization of a lot of low-level programming? For the same reason why we're
    speaking English... But programming isn't just about programming itself... it's
    also about a different way of thinking. And it's a different way of understanding
    the world that you're in.
  topic: strategy/education
- impact_reason: 'Identifies the critical bottleneck for future talent pipelines:
    the automation of entry-level roles removes the traditional training ground for
    senior staff.'
  relevance_score: 10
  source: llm_enhanced
  text: I think the biggest problem and biggest worry I have is that the entry-level
    jobs right now are more and more automatable. And so you hopefully have companies
    that have a long enough time horizon, such that they're willing to train people
    even though any AI could do the job...
  topic: business/strategy
- impact_reason: Crucially highlights the dependency of LLM accuracy on the quality
    and timeliness of the underlying retrieval/search infrastructure (RAG context),
    calling it the 'often forgotten infrastructure layer.'
  relevance_score: 10
  source: llm_enhanced
  text: LLMs are garbage in, garbage out to a large degree. So if you have a search
    model or an index, and you ask, like, what's new with Trump? And that search index
    brings back pages from like six years ago, the LLM will tell you wrong and outdated
    things about that query. So the search is kind of the often forgotten infrastructure
    layer for LLMs.
  topic: technical
- impact_reason: 'Identifies quantum computing''s most profound potential impact:
    enabling accurate simulation of complex physical/biological systems, which then
    becomes the ultimate training ground for AI.'
  relevance_score: 10
  source: llm_enhanced
  text: What I'm really excited about is getting quantum computers to a scale where
    we can simulate a cell... to from real first principles like really deeply model
    physics and chemistry that is complex and eventually biology. Like that will be
    such a massive unlock because in AI anything you can simulate AI can solve every
    problem in that domain.
  topic: predictions
- impact_reason: Highlights the historical resistance to foundational AI concepts
    (neural networks in NLP) that are now standard, offering a lesson in perseverance
    against conventional wisdom.
  relevance_score: 9
  source: llm_enhanced
  text: I'm credited for having brought neural networks into the field of natural
    language processing. It was a very controversial idea at the time. It's a very
    obvious in retrospect. It's this sort of story of my life.
  topic: technical/strategy
- impact_reason: Illustrates the difficulty in recognizing paradigm shifts (like prompt
    engineering) early on, even among experts, emphasizing the counter-intuitive nature
    of AI breakthroughs.
  relevance_score: 9
  source: llm_enhanced
  text: we met at Prompt Engineering, which was majorly rejected publicly on Open
    Review. An idea that made no sense to the reviewers. And now, in retrospect, it's
    so obvious.
  topic: technical/strategy
- impact_reason: Articulates the core value proposition of generative AI over traditional
    search—moving from links to direct answers.
  relevance_score: 9
  source: llm_enhanced
  text: U.com basically came from this idea that we have a single model now, a single
    neural net that can answer all the different kinds of questions. So, clearly,
    people on the internet should get better answers than lists of blue links that
    we get from Google.
  topic: business/predictions
- impact_reason: 'Provides a strategic framework for viewing the AI landscape: a fundamental,
    rising trend (AGI) overlaid with volatile, temporary hype cycles (bubbles).'
  relevance_score: 9
  source: llm_enhanced
  text: AGI is kind of this tide that's rising, but on top of that tide, you have
    a lot of little high bubbles that come up and down.
  topic: strategy
- impact_reason: Elaborates on the telco analogy, explaining why infrastructure providers
    often fail to capture the value of the applications built on top of them.
  relevance_score: 9
  source: llm_enhanced
  text: It creates a lot of value in the world. You can't build an Uber app if people
    don't have internet everywhere. But you don't necessarily capture that value,
    just like Vodafone and T-Mobile and whoever don't get a cut of Uber working now.
  topic: business
- impact_reason: Identifies software's inherent lack of moat, exacerbated by open
    source, making the infrastructure layer even more vulnerable to commoditization
    than traditional telcos.
  relevance_score: 9
  source: llm_enhanced
  text: It's even worse because the one-prevailing player breaks it. It's a software,
    so you don't have, you have even less of a moat, and with open source, it's even
    more.
  topic: business/strategy
- impact_reason: Challenges the traditional software network effect in AI, suggesting
    that immediate user experience (UX) validation trumps claims of superior underlying
    models without a direct feedback loop.
  relevance_score: 9
  source: llm_enhanced
  text: I think in AI, if you say I have the best model, but people can play around
    with it very quickly, people call BS on you. So there's not a data network effect.
  topic: business/strategy
- impact_reason: Posits that the market is naturally segmenting into specialized vertical
    plays (like enterprise focus) because horizontal, general-purpose products are
    too hard to monetize against incumbents.
  relevance_score: 9
  source: llm_enhanced
  text: Do you think we're seeing the specialization of these different providers?
    Like you said there, you have Anthropic very much focusing on engineering... U.com
    really focusing on enterprise... Are we seeing this realization that there's no
    inherent value in horizontal products? We need to be specialized?
  topic: strategy
- impact_reason: Positions LLMs as a key driver in the 'unbundling' of traditional
    search monopolies by addressing complex queries that standard search struggles
    with.
  relevance_score: 9
  source: llm_enhanced
  text: LLMs, it is part of that unbundling wave of Google. LLMs will capture whenever
    you have a more complex question.
  topic: predictions
- impact_reason: 'A key limitation insight: Natural language alone is insufficient;
    effective AI interfaces must incorporate multimodal outputs (maps, tables) tailored
    to the specific task.'
  relevance_score: 9
  source: llm_enhanced
  text: There's so many little nuances and you realize like as much as I love natural
    language, natural language is not the single best interface for a lot of different
    types of answers. Sometimes you want to see a map. Like sometimes you want to
    see a table.
  topic: technical/limitations
- impact_reason: Identifies the current 'valley of disillusionment' specifically for
    action agents, attributing it to a lack of deep, personalized user context necessary
    for reliable action-taking.
  relevance_score: 9
  source: llm_enhanced
  text: There's this valley of disillusionment that we're in right now because the
    agents just don't know enough yet about the user.
  topic: predictions
- impact_reason: Quantifies the immediate financial and psychological impact of the
    open-source breakthrough on the established venture capital narrative surrounding
    LLM infrastructure.
  relevance_score: 9
  source: llm_enhanced
  text: You could almost hear billions of dollars of VC investment evaporate into
    the ether when that happened. Everyone said that should have been impossible.
  topic: business
- impact_reason: Provides a more realistic, lower estimate for the cost of training
    state-of-the-art models compared to previous industry hype, suggesting training
    costs might be more accessible than previously feared.
  relevance_score: 9
  source: llm_enhanced
  text: It's also clear that it probably cost them $100, $200 million. But it's still
    incredibly cheaper than billions of dollars that we were told it would take to
    train these kinds of models.
  topic: technical
- impact_reason: 'Provides direct, actionable investment advice: focus on early-stage
    teams combining deep tech with specific vertical market knowledge, rather than
    generalized infrastructure.'
  relevance_score: 9
  source: llm_enhanced
  text: If you're in investing full-time, why would you be spending the most time?
    Early-stage, strong technical teams that also have some market insights into a
    specific vertical, into a specific app.
  topic: business
- impact_reason: 'Describes a practical, high-value enterprise use case: teaching
    employees to create personalized, repeatable automation agents based on existing
    workflows.'
  relevance_score: 9
  source: llm_enhanced
  text: We're helping people essentially train up their own agents. So whatever process
    they have in their company takes them enough hours, they have they repeat every
    couple of weeks or every couple of days. We teach them on how to actually tell
    that to an AI and then they just have their own agent and they'll just automate
    that for them.
  topic: technical/business
- impact_reason: Identifies personalization as the key bottleneck preventing deeper
    user lock-in and driving rapid model switching in the current landscape.
  relevance_score: 9
  source: llm_enhanced
  text: What is the thing that's holding back the progression today of LLMs and specifically
    how we use them? I think one is that personalization and that's why it's so easy
    for people to switch around LLMs too.
  topic: technical/limitations
- impact_reason: Defines the ideal investment profile for early-stage AI companies,
    emphasizing the need to combine technical strength with domain expertise.
  relevance_score: 9
  source: llm_enhanced
  text: Early-stage, strong technical teams that also have some market insights into
    a specific vertical, into a specific app.
  topic: strategy
- impact_reason: Provides the classic, detailed analogy for Jevons' Paradox, explaining
    why efficiency gains in AI (cheaper intelligence) will lead to massive overall
    demand growth.
  relevance_score: 9
  source: llm_enhanced
  text: So in the first industrial revolution like 1860s or so, Jevons was an economist
    and he looked into the price of coal. And a lot of the smartest engineers and
    minds at the time made more and more efficient coal like steam engines. And so
    he eventually thought, well, if steam engines get more and more efficient, then
    we'll need less and less coal. But what actually happened is you just used steam
    engines in more and more places. And so the price of coal actually went up instead.
  topic: strategy
- impact_reason: Suggests that the massive, transformative impact seen in language
    models (ChatGPT moment) is yet to fully materialize in medicine and research.
  relevance_score: 9
  source: llm_enhanced
  text: And so I think those are two beautiful areas that still were, they haven't
    had their ChatGPT moment.
  topic: predictions
- impact_reason: Describes a specific, advanced application of RL in economics, demonstrating
    AI's potential to model and optimize complex societal systems like taxation.
  relevance_score: 9
  source: llm_enhanced
  text: And then we actually built this two-level reinforcement learning model where
    you had an AI economist and you had a bunch of intelligent agents that were just
    maximizing their own utilities. And they're adapting to different taxation schemes
    and tariffs and subsidies and so on.
  topic: technical
- impact_reason: Identifies robotics as lagging behind language models in achieving
    a general-purpose, transformative breakthrough based on foundation models.
  relevance_score: 9
  source: llm_enhanced
  text: I worry about is the excitement around robotics. I find that robotics have
    not had their ChatGPT moment on the foundation model side.
  topic: technical
- impact_reason: Argues against the necessity of humanoid robots for optimized, scalable
    industrial tasks, suggesting specialized hardware is superior.
  relevance_score: 9
  source: llm_enhanced
  text: For almost every process that is highly repeatable, there's a better, more
    quickly evolved, new hardware form than five fingers on two arms.
  topic: predictions
- impact_reason: Highlights unstructured, non-standardized environments as the primary
    technical hurdle for general-purpose robotics.
  relevance_score: 9
  source: llm_enhanced
  text: The problem is that that is in like these cluttered environments that are
    all different. There's no standardization. That's really, really hard for AI.
  topic: technical
- impact_reason: Illustrates the 'long tail' problem common in AI deployment, where
    achieving high performance on niche, rare cases requires disproportionate resources
    compared to mastering the common cases.
  relevance_score: 9
  source: llm_enhanced
  text: It's very easy to build one radiology classifier for one thing and make that
    better than a human. But then there's this very long tail of things and so you
    need a lot of money and a lot of resources and a lot of data to see the long tail
    of all things in radiology before you could actually automate a radiology process
    fully from end to end.
  topic: technical
- impact_reason: Points directly to the mystery of emergent properties in complex
    systems (like the brain or LLMs), which AI research is now confronting directly.
  relevance_score: 9
  source: llm_enhanced
  text: But then when you put a bunch of them together and suddenly you have intelligence,
    like no one understands these thresholds, these complex systems emerging and having
    these emergent properties.
  topic: technical
- impact_reason: 'Provides a balanced view on job displacement: acknowledging severe
    short-term social disruption while maintaining long-term optimism, emphasizing
    the need for robust social safety nets.'
  relevance_score: 9
  source: llm_enhanced
  text: Job changes are brutal in the moment. There will add a lot of pressure on
    social systems. I think long term, I'm an optimist but short term, you've got
    to have good social systems and help people with a path in this new AI future
    as their jobs change and fall away.
  topic: safety
- impact_reason: Highlights AI's core strength—tackling complex, interconnected systems—using
    the microbiome as an analogy, suggesting broad applicability beyond traditional
    tech.
  relevance_score: 9
  source: llm_enhanced
  text: And so I think there's so much complexity and AI is the perfect tool to tackle
    that kind of complexity because we can now have similar things.
  topic: strategy
- impact_reason: 'Offers a clear policy recommendation: governments should facilitate
    adaptation using AI proceeds rather than attempting to block the technology.'
  relevance_score: 9
  source: llm_enhanced
  text: And so that is a negative downside that I think it's onto governments to help
    their people not to block the technology and enforce not using it but actually
    use it and use the proceeds and help people to learn new kinds of skills.
  topic: strategy/safety
- impact_reason: A critical counterpoint to 'instant adoption' narratives, emphasizing
    that human process change and initial exposure are significant friction points
    slowing the perceived speed of AI integration.
  relevance_score: 9
  source: llm_enhanced
  text: It takes people to change their process. It takes them some time. I don't
    think it'll happen as quickly as people think. There's still I think 60% of all
    adults in the US have never talked to an AI model like at all.
  topic: technical/strategy
- impact_reason: Predicts the abstraction of model selection in consumer AI interfaces,
    moving toward automated orchestration where the system selects the optimal model,
    mirroring the 'Babel fish' concept.
  relevance_score: 9
  source: llm_enhanced
  text: You'll just get given the best model for that specific prompt and request.
    Yeah, yeah. So it's actually something that we have shipped internally and I think
    it'll come out in a week or two on U.com like to just automate that orchestration
    completely away and only the power users who really want to can double click into
    the interface and then choose which model to use.
  topic: technical/business
- impact_reason: 'Actionable advice for students: interdisciplinary knowledge combining
    domain expertise with CS is the necessary future-proofing skill.'
  relevance_score: 9
  source: llm_enhanced
  text: Even if you want to study law, medicine, chemistry, or whatever, you should
    combine it with computer science. Because all of these fields are going to change
    over the next couple of decades.
  topic: strategy/education
- impact_reason: 'A fundamental management principle applied to the AI era: hands-on
    experience is crucial for effectively managing automated agents or human workers
    performing complex tasks.'
  relevance_score: 9
  source: llm_enhanced
  text: Turns out if you've never done something, it's much harder to manage someone
    to do it for you.
  topic: business/strategy
- impact_reason: 'Describes the necessary mindset shift for the future workforce:
    constant questioning of manual repetition and demanding automation, a shift not
    currently taught in education.'
  relevance_score: 9
  source: llm_enhanced
  text: What that means is like in the future, every time you do a job like a dozen,
    two dozen times, you're going to be like, wait, why hasn't the AI now taken that
    over from me? Why do I still have to do this repeatable boring thing? I personally
    hate repeatable boring things, so I'm all for it. But that is a mindset shift
    that schools don't teach yet.
  topic: strategy/education
- impact_reason: Identifies proprietary/internal data as the primary moat and source
    of high switching costs for enterprise AI solutions, contrasting with the low
    switching costs in the consumer space.
  relevance_score: 9
  source: llm_enhanced
  text: Now, where there is a lot of switching costs is if you have company internal
    data or you have unique data assets.
  topic: business
- impact_reason: A direct warning about data security risks associated with early,
    unmanaged adoption of public LLMs using sensitive corporate data.
  relevance_score: 9
  source: llm_enhanced
  text: Do you think we are seeing the biggest corporate misbehavior from this generation,
    taking ChatGPT and putting company data in it? They shouldn't. They should stop
    doing that if they have done it in the past.
  topic: safety/business
- impact_reason: 'Provides a clear, actionable requirement for securing enterprise
    LLM contracts: strict data privacy and non-training guarantees.'
  relevance_score: 9
  source: llm_enhanced
  text: And that's why we have zero data retention. We have agreements that we don't
    train any model on company internal data. That's how you get into enterprise.
  topic: business
- impact_reason: Strategic insight into the fundamental conflict between building
    scalable, secure, and compliant enterprise solutions versus fast-moving, personalized
    consumer products.
  relevance_score: 9
  source: llm_enhanced
  text: And that's where you really can't be like a great consumer company and a great
    enterprise like company. At the same time, it's very, very hard.
  topic: strategy
- impact_reason: A strong market warning about overvaluation in the AI startup space,
    emphasizing that lack of defensible moats (high switching costs) will lead to
    failure, even with high funding.
  relevance_score: 9
  source: llm_enhanced
  text: We're going to see a correction when companies are trading 180x their ARR
    and they don't have a real moat and like there's just switching costs as close
    to zero to go to DeepSeek or something else.
  topic: business
- impact_reason: 'A classic technology cycle observation: core technology becomes
    commoditized, shifting the competitive advantage back to fundamental business
    execution (Go-to-Market).'
  relevance_score: 9
  source: llm_enhanced
  text: It just goes back to is your branding good, your marketing, your sales, your
    distribution. And then of course, a lot of the technology things, but those get
    commoditized more and more.
  topic: strategy
- impact_reason: 'Offers a nuanced view on platform risk: foundational capabilities
    will be commoditized, but specialized companies can survive by mastering the ''last
    little bit'' of quality, integration, or niche performance.'
  relevance_score: 9
  source: llm_enhanced
  text: To what extent will we see OpenAI kill a generation of companies of this material?
    I actually don't think they're all going to just die overnight. Like think about
    speech recognition. It's very commodity. There's tons of open-source speech recognition,
    like algorithms you can download and so on. There's still several companies that
    make millions and like tens or even hundreds of millions of revenue, doing speech
    recognition just perfectly. That last little bit.
  topic: predictions
- impact_reason: Highlights the significant competitive threat posed by open-source
    models to highly valued, closed-source foundation model companies.
  relevance_score: 9
  source: llm_enhanced
  text: OpenAI at 300, Anthropic at 60 or Groq at 50, which would you most invest
    in? Can I choose none? I mean, open source puts a lot of pressure on it.
  topic: business
- impact_reason: Clearly outlines the catastrophic security risk posed by future quantum
    computers (breaking current encryption standards).
  relevance_score: 9
  source: llm_enhanced
  text: I mean, there's the obvious one that we don't want to see, which is like all
    the passwords need to be re-encrypted and changed and all the data that it has
    been leaked but is encrypted might get decrypted and hence like people know what's
    in some things of the past that they had hacked but couldn't really decipher yet
    or decrypt.
  topic: safety
- impact_reason: Suggests the current bottleneck is not model capability but enterprise
    adoption and integration, implying immediate utility exists.
  relevance_score: 8
  source: llm_enhanced
  text: LLMs are already good enough. They just need to be brought into companies
    to be actually made useful.
  topic: business/predictions
- impact_reason: Offers a structured way to evaluate AI progress by dimension, suggesting
    that some areas (like basic CV) are nearing their theoretical limits, contrasting
    with others.
  relevance_score: 8
  source: llm_enhanced
  text: I essentially group intelligence into 10 different dimensions... in this dimension,
    there is like a fairly low upper bound, and we're fairly close to it. For example,
    object detection in computer vision. It's actually kind of solved.
  topic: technical/strategy
- impact_reason: Provides a philosophical perspective on the near-infinite upper bounds
    of 'knowledge' for AI, tempering expectations about achieving true AGI soon.
  relevance_score: 8
  source: llm_enhanced
  text: in the other bounds, like knowledge, well, if you include the molecular composition
    of every planet in the universe as part of knowledge, we are astronomically...
    away from ever having an AI reach that upper bound.
  topic: safety/predictions
- impact_reason: Highlights the immense power of default settings and platform lock-in,
    explaining why Google pays billions to Apple.
  relevance_score: 8
  source: llm_enhanced
  text: The scary and sad statistic is like 80% of all iPhone users never change a
    single setting of any kind. Whatever is the default gets used.
  topic: strategy
- impact_reason: Analyzes how even a monopoly like Google, by optimizing for ad revenue
    over user experience, eventually degrades the product, suggesting a potential
    opening for LLMs, despite the strong default lock-in.
  relevance_score: 8
  source: llm_enhanced
  text: And so after doing that for 10 years as an untouchable monopoly, the experience
    suffered, right? And so there is like some potential here, but the default is
    still very, very strong.
  topic: strategy
- impact_reason: Expresses skepticism regarding overly simplistic 'action agent' demos,
    highlighting the gap between marketing hype and the complexity of real-world task
    execution.
  relevance_score: 8
  source: llm_enhanced
  text: I remember this demo where a startup founder was like, had his little device
    and he's like, I want to have a trip to London with my four kids and on this weekend
    and then one, two, three and it's done. And I was like, that was definitely BS.
  topic: safety/limitations
- impact_reason: Clarifies the true cost structure of LLM development, emphasizing
    that the final training run is only a fraction of the total expense, which includes
    extensive hyperparameter tuning and ablation studies.
  relevance_score: 8
  source: llm_enhanced
  text: On the path towards the best model, you usually train hundreds if not thousands
    of smaller models with increasing sizes. So all of these will have cost several
    millions of dollars to or maybe hundreds of thousands and they're smaller.
  topic: technical
- impact_reason: Identifies biology/biotech as a prime vertical for AI investment
    and application due to current market conditions and fundamental data availability.
  relevance_score: 8
  source: llm_enhanced
  text: One of the big verticals that I love so much and think from first principles
    is the right time to buy right now is in biology too. And so biotech is essentially
    a perfect storm.
  topic: business
- impact_reason: Justifies the pivot to enterprise by noting consumer limitations
    (simplicity or unwillingness to pay), suggesting a market trend.
  relevance_score: 8
  source: llm_enhanced
  text: We're also focusing more on enterprise. My hunch is other people will follow
    us into that, because that is just normal consumers again. Either they have a
    majority very simple questions or they don't want to pay.
  topic: business
- impact_reason: Despite their innovator's dilemma, Google and Microsoft are named
    as the best-positioned entities due to their massive existing consumer touchpoints.
  relevance_score: 8
  source: llm_enhanced
  text: I do think Google are actually best positioned. When you think about one of
    the most important things being touchpoints to end consumers, I don't think anyone
    other than them and Microsoft are actually better positioned.
  topic: predictions
- impact_reason: Direct investment strategy advice based on the speaker's belief about
    where value creation lies in the AI stack.
  relevance_score: 8
  source: llm_enhanced
  text: I have personally stayed away from investing in any pure LLM infrastructure
    companies.
  topic: business
- impact_reason: Illustrates the practical, policy-making power of AI models in economics,
    moving beyond simulation to optimization based on defined societal goals.
  relevance_score: 8
  source: llm_enhanced
  text: And you basically could now ask this model, the system, what's the most efficient
    taxation and subsidization scheme for maximizing this objective that I'm giving
    you?
  topic: predictions
- impact_reason: 'Pinpoints the niche where humanoids *will* succeed: unstructured,
    low-speed, high-variety domestic environments where specialized robots are impractical.'
  relevance_score: 8
  source: llm_enhanced
  text: The bull case, I think the bull case is at home. Like when it actually the
    speed doesn't matter but there's just a whole host of many different tasks.
  topic: predictions
- impact_reason: Frames the current backlash from creative professionals as an economic
    defense mechanism rather than purely an artistic one, contrasting economic loss
    with potential artistic abundance.
  relevance_score: 8
  source: llm_enhanced
  text: The modern-day Luddites are like illustrators, right? Because it used to be
    that you can charge $500 for an illustration. And if you cared about just seeing
    illustrations as art and you want to see as much art as possible in the world,
    you're excited about having AI now create Ghibli and all other kinds of beautiful
    illustrations.
  topic: safety
- impact_reason: Challenges the historical parallel argument by noting the slow, multi-decade
    adoption curve of previous revolutions, setting up a contrast for the speed of
    AI adoption.
  relevance_score: 8
  source: llm_enhanced
  text: Everyone always says, well, you know, we've always had this before you've
    got the agricultural revolution, you've got like PCs entering workforce in the
    90s. That took actually multi-decades. It took long, long time periods to actually
    move physical machinery into large farms and in still a lot of cases, there isn't
    in some parts of the world. Same with PCs, it took a decade actually for PCs to
    fully be, this is a software update.
  topic: predictions
- impact_reason: Assesses the current state of consumer LLMs, noting that lack of
    deep personalization is a key differentiator and area for future improvement,
    explaining low switching costs.
  relevance_score: 8
  source: llm_enhanced
  text: The same is true for LLMs in the consumer world, right? They're not. None
    of them are that amazing yet. None of them do enough personalization yet.
  topic: technical
- impact_reason: Provides a blunt assessment of the competitive landscape, suggesting
    that low retention for alternative models proves that switching costs are currently
    low, reinforcing the need for moats.
  relevance_score: 8
  source: llm_enhanced
  text: Like you see some retention numbers on DeepSeek. I have not. They're pretty
    shit. I'm not surprised. No one's staying with DeepSeek.
  topic: business
- impact_reason: Addresses the societal perception problem in AI—the swing between
    extreme utopianism and dystopian fear—and advocates for a more nuanced, gradual
    view of impact.
  relevance_score: 8
  source: llm_enhanced
  text: I think the biggest misconception is that we have sort of this bimodal like
    black and white when things are often in some gray in between. Like some people
    think it's going to take off over all the jobs and then because it's so brilliant
    like overnight, like everything we've gone and then like the next night it'll
    kill us all, right?
  topic: safety
- impact_reason: Technical commentary on the evolution of compute scaling, suggesting
    that parallelism (like GPUs) is the current mechanism overriding traditional transistor-density-based
    Moore's Law progression.
  relevance_score: 8
  source: llm_enhanced
  text: With this advancement, we have escaped Moore's Law in terms of our speed of
    progression. Is Moore's Law ever escapable? Of course. And like, you know, I think
    parallelism has helped a ton like Nvidia shows us that yeah, we might not double
    the number of transistors or whatever every 18 months, but like we may have more
    parallel ones.
  topic: technical
- impact_reason: A powerful personal anecdote illustrating the value of setting audacious
    goals and maintaining 'constructive optimism,' even when personal predictions
    are proven wrong by rapid technological advancement.
  relevance_score: 8
  source: llm_enhanced
  text: I will probably still win my $1,000 bet but he became a billionaire in the
    process of proving me wrong. And so that kind of shows you you have to just have
    the constructive optimism that was probably something that a belief I changed.
  topic: strategy
- impact_reason: 'Actionable advice for innovators: set massive goals, but break them
    down into practical, achievable steps.'
  relevance_score: 8
  source: llm_enhanced
  text: It's just like even if you don't think it can be quite possible you should
    try to make the most audacious goals and set the most audacious goals for yourself
    and then basically work on pragmatic milestones towards those goals.
  topic: strategy
- impact_reason: 'Lists the core pillars of enterprise AI adoption: security, trust,
    accuracy, and the crucial ability for the model to admit uncertainty (''I don''t
    know'').'
  relevance_score: 8
  source: llm_enhanced
  text: And we're focused on that enterprise and make sure that the security is there,
    the trust is there, the accuracy of the answers there, the ability to say, I don't
    know, is there.
  topic: business
- impact_reason: Emphasizes that accuracy in AI is a continuous, non-static competitive
    advantage, not a one-time achievement.
  relevance_score: 7
  source: llm_enhanced
  text: We pride ourselves to be the most accurate and that is a never-ending game.
    So whenever you say you're the best, you're the best in that moment and you have
    to keep working on it.
  topic: strategy
- impact_reason: Discusses the tension between platform owners wanting end-user control
    versus the reality that users often prefer specialized tools that simply make
    tasks easier, regardless of who owns the interface.
  relevance_score: 7
  source: llm_enhanced
  text: I think a lot of companies right now would love to immediately own the end
    user and then do all of that below. But my hunch is we've gone through this at
    U.com too when we're still doing more consumer and we're looking into like basically
    you wanted to make it easier for users to get things done, right?
  topic: strategy
- impact_reason: Explains why large incumbents like Google struggle to make non-core
    acquisitions—regulatory hurdles make it easier to build internally or focus on
    core areas.
  relevance_score: 7
  source: llm_enhanced
  text: I think they have so much money. It's also very difficult to acquire because
    you have the regulatory provisions, which mean it's super, super hard to get anything
    through that's non-core...
  topic: strategy
- impact_reason: A cynical but realistic take on scientific progress, noting that
    even groundbreaking work (like the AI Economist paper) requires effective 'science
    marketing' to gain traction, similar to commercial branding.
  relevance_score: 7
  source: llm_enhanced
  text: Science is also a human system. And you have to do brand and marketing, like
    something that DeepMind in London here does incredibly well. Their science marketing
    is probably the best in the world.
  topic: strategy
- impact_reason: 'A high-level, philosophical goal for AI development, framing the
    mission as an existential one: spreading intelligence against universal decay.'
  relevance_score: 7
  source: llm_enhanced
  text: I think one of the biggest civilizationary unlocks would be to all agree that
    entropy or darkness in the universe is the enemy and that we should like spread
    consciousness into the universe.
  topic: strategy
- impact_reason: Strategic prediction about the long-term market structure for successful
    consumer AI applications, contrasting sharply with the enterprise landscape.
  relevance_score: 7
  source: llm_enhanced
  text: Now that's consumer. In consumer, we usually end up in monopoly or duopoly
    situations.
  topic: predictions
- impact_reason: A current assessment of the state of consumer LLMs, identifying personalization
    as the key missing feature preventing mass adoption.
  relevance_score: 7
  source: llm_enhanced
  text: None of them are that amazing yet. None of them do enough personalization
    yet.
  topic: technical
- impact_reason: 'A reality check on capital efficiency: massive funding alone is
    not a sustainable moat if the underlying product lacks differentiation or switching
    costs.'
  relevance_score: 7
  source: llm_enhanced
  text: It can be [cash a weapon], but we have seen some companies now that had raised
    hundreds of millions of dollars and still died.
  topic: business
- impact_reason: Provides a realistic timeline and assessment of quantum computing's
    maturity, acknowledging its potential while noting current uncertainty.
  relevance_score: 7
  source: llm_enhanced
  text: There's still the black horse of quantum, which may, you know, a lot of announcements,
    unclear if they're like how real they all are, but like that will also be a major
    shift when it finally does happen, but it might still take 5, 10, 15 years.
  topic: predictions
- impact_reason: Identifies the misconception that AI is just another temporary tech
    bubble, contrasting it with the speaker's belief in its fundamental, lasting impact.
  relevance_score: 7
  source: llm_enhanced
  text: Then there's the misconception to still like, and I see this in Germany still,
    there's still people like, ah, you know, two years ago was crypto, this year's
    AI, like maybe it'll just go away. Like that's also a huge misconception that
    still exists in the world.
  topic: strategy
source: Unknown Source
summary: '## 20VC Podcast Summary: Foundation Models, Economics, and the AI Race with
  Rich Socher (You.com)


  This 63-minute episode of 20VC features Harry Stebbings in conversation with **Rich
  Socher**, Founder and CEO of You.com, a pioneer in NLP who previously brought neural
  networks to the field and invented key concepts like word vectors and prompt engineering.
  The discussion centers on the current, confusing state of Foundational Models (LLMs),
  the resulting economic shifts, and the competitive landscape between the US and
  China.


  ### 1. Focus Area

  The primary focus is the **Foundational Model Layer (LLMs)**, covering their rapid
  commoditization, the shift from horizontal consumer applications to specialized
  enterprise solutions, the viability of advertising models in AI, and the competitive
  dynamics (US vs. China) in AI development. Secondary themes include the future of
  work, the nature of intelligence, and the challenges of building actionable AI agents.


  ### 2. Key Technical Insights

  *   **Evolution of NLP:** Socher traces his contributions from early word vectors
  to contextual vectors (leading to ELMo/BERT) and the initially rejected concept
  of Prompt Engineering, highlighting how foundational research often faces initial
  rejection before becoming obvious.

  *   **Intelligence Upper Bounds:** The discussion introduces a framework for categorizing
  intelligence into dimensions (e.g., object detection vs. knowledge), suggesting
  that while some areas are nearing their upper bound (solved), others, like comprehensive
  knowledge, remain astronomically far from AGI.

  *   **Open Source Shock:** The rapid emergence of high-quality, open-source models
  (like DeepSeek from China) demonstrated that achieving state-of-the-art performance
  might not require the multi-billion dollar budgets previously assumed, challenging
  the VC narrative around necessary capital expenditure.


  ### 3. Business/Investment Angle

  *   **Commoditization of Infrastructure:** Pure LLM infrastructure providers are
  likely to become commoditized, resembling **telcos**: high CapEx, high value creation
  for the world, but low value capture for the provider, as moats are weak (especially
  with open source).

  *   **Value Capture in Enterprise:** The real value capture is shifting away from
  horizontal consumer apps (where ChatGPT dominates) toward **enterprise solutions**
  that solve specific, complex internal workflows, as consumers often don''t need
  or won''t pay for complex AI interactions.

  *   **Advertising Failure in AI:** Socher asserts that **ads in AI search/query
  interfaces perform 10x to 100x worse than traditional search ads**, making the traditional
  Google revenue model difficult to replicate directly in generative AI interfaces.


  ### 4. Notable Companies/People

  *   **Rich Socher (You.com):** The expert guest, detailing his background and You.com''s
  pivot to enterprise solutions.

  *   **OpenAI/ChatGPT:** Acknowledged as the dominant consumer application, making
  it difficult for other horizontal LLM apps to gain traction.

  *   **Anthropic:** Mentioned as maintaining a consumer product (Claude) likely to
  prove model quality and engineering prowess.

  *   **Google/Gemini:** Discussed as facing the classic **Innovator''s Dilemma**—their
  core business model (ads on blue links) conflicts with providing the best, direct
  answers.

  *   **DeepSeek:** Highlighted as the open-source model that shocked the industry
  by matching or exceeding closed-source performance quickly.


  ### 5. Future Implications

  *   **Agent Valley of Disillusionment:** There is a current "valley of disillusionment"
  regarding **action agents** (AI that takes irreversible actions like booking flights)
  because they lack the deep, subtle, personalized knowledge about the user required
  for complex tasks.

  *   **Unbundling Wave:** The industry is currently in a large wave of **unbundling**,
  where users move away from monolithic search (Google) to specialized apps (Windy
  for weather, TikTok for discovery, Amazon for small purchases). LLMs will capture
  the complex query segment of this unbundling.

  *   **Enterprise Adoption Hurdles:** Large enterprises struggle with adoption (paying
  for licenses that go unused) because employees, used to being individual contributors,
  are not yet skilled at distilling knowledge into succinct, unambiguous prompts for
  agents.


  ### 6. Target Audience

  This episode is highly valuable for **Venture Capitalists, AI/ML Engineers, Enterprise
  Software Strategists, and Technology Executives** who need a nuanced, expert perspective
  on the current market dynamics, investment viability, and technical trajectory of
  foundational models beyond the hype cycle.'
tags:
- artificial-intelligence
- generative-ai
- startup
- ai-infrastructure
- investment
- google
- openai
- microsoft
title: '20VC: Foundation Models: Who Wins & Who Loses | How Economies and Labour Markets
  Need to Change in a World of AI | China vs the US in an AI Race: What You Need to
  Know | Rich Socher, Founder @ You.com'
topics:
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 158
  prominence: 1.0
  topic: artificial intelligence
- keywords:
  - generative ai
  - genai
  - chatgpt
  - gpt
  - claude
  - text generation
  - image generation
  mentions: 32
  prominence: 1.0
  topic: generative ai
- keywords:
  - startup
  - entrepreneur
  - founder
  - venture
  mentions: 16
  prominence: 1.0
  topic: startup
- keywords:
  - gpu
  - tensor
  - training
  - inference
  - model deployment
  - vector database
  mentions: 5
  prominence: 0.5
  topic: ai infrastructure
- keywords:
  - investment
  - funding
  - valuation
  - ipo
  - acquisition
  mentions: 4
  prominence: 0.4
  topic: investment
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-10-06 12:19:34 UTC -->
