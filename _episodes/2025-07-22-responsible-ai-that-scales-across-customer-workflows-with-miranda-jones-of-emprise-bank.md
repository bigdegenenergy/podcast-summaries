---
companies:
- category: unknown
  confidence: medium
  context: Welcome everyone to the AI and Business Podcast. I'm Matthew Damello, editorial
    director here at
  name: Business Podcast
  position: 31
- category: unknown
  confidence: medium
  context: come everyone to the AI and Business Podcast. I'm Matthew Damello, editorial
    director here at Emerge AI Research. T
  name: Matthew Damello
  position: 53
- category: unknown
  confidence: medium
  context: . I'm Matthew Damello, editorial director here at Emerge AI Research. Today's
    guest is Miranda Jones, SVP of Data and
  name: Emerge AI Research
  position: 97
- category: unknown
  confidence: medium
  context: ctor here at Emerge AI Research. Today's guest is Miranda Jones, SVP of
    Data and AI Strategy Leader at Emprize Ba
  name: Miranda Jones
  position: 134
- category: unknown
  confidence: medium
  context: . Today's guest is Miranda Jones, SVP of Data and AI Strategy Leader at
    Emprize Bank. Miranda returns to the program t
  name: AI Strategy Leader
  position: 165
- category: unknown
  confidence: medium
  context: anda Jones, SVP of Data and AI Strategy Leader at Emprize Bank. Miranda
    returns to the program to discuss how re
  name: Emprize Bank
  position: 187
- category: tech
  confidence: high
  context: discuss how regulated industries like banking can scale AI responsibly
    without compromising customer trust,
  name: Scale Ai
  position: 285
- category: unknown
  confidence: medium
  context: ecutive thought leaders, everyone from the CIO of Goldman Sachs to the
    head of AI at Raytheon, and AI pioneers li
  name: Goldman Sachs
  position: 1118
- category: unknown
  confidence: medium
  context: the head of AI at Raytheon, and AI pioneers like Yasha Webendio. With nearly
    a million annual listeners, AI and B
  name: Yasha Webendio
  position: 1184
- category: unknown
  confidence: medium
  context: eve you can help other leaders move the needle on AI ROI, visit emerj.com
    and fill out our Thought Leader
  name: AI ROI
  position: 1653
- category: unknown
  confidence: medium
  context: eedle on AI ROI, visit emerj.com and fill out our Thought Leader submission
    form. That's emerj.com and click on be
  name: Thought Leader
  position: 1694
- category: unknown
  confidence: medium
  context: 'ge from the sponsors for today''s show.


    Hi folks, Paige Bailey here from the Google DeepMind DevRel team. For ou'
  name: Paige Bailey
  position: 2055
- category: tech
  confidence: high
  context: 'day''s show.


    Hi folks, Paige Bailey here from the Google DeepMind DevRel team. For our developers
    out ther'
  name: Google
  position: 2082
- category: unknown
  confidence: medium
  context: 'day''s show.


    Hi folks, Paige Bailey here from the Google DeepMind DevRel team. For our developers
    out there, we know there'
  name: Google DeepMind DevRel
  position: 2082
- category: unknown
  confidence: medium
  context: 'u. It''s great to be here. Thank you.


    Absolutely. Responsible AI, I think, has gone from a marketing talking point'
  name: Responsible AI
  position: 2721
- category: unknown
  confidence: medium
  context: t, we're not using that language so much anymore. But I think that's a
    big function of the bigger the mod
  name: But I
  position: 10151
- category: unknown
  confidence: medium
  context: speak English, but I think it's clear there's not British English is a
    little bit different than American English.
  name: British English
  position: 11604
- category: unknown
  confidence: medium
  context: ot British English is a little bit different than American English. That's
    a good example. So it's helpful for the m
  name: American English
  position: 11651
- category: unknown
  confidence: medium
  context: another industry means something very different. And I think a good example
    of why I believe domain spec
  name: And I
  position: 11902
- category: tech
  confidence: high
  context: cific could be much better if you think about the Apple iPhone. They have
    an app store because specific a
  name: Apple
  position: 12006
- category: tech
  confidence: high
  context: from time to time. We had a very smart woman from Intel come on the show
    and talk about how they're using
  name: Intel
  position: 12614
- category: unknown
  confidence: medium
  context: nsparency, with our employees and our regulators. So I don't think we are
    in a disadvantage if we move a
  name: So I
  position: 15298
- category: unknown
  confidence: medium
  context: this happened. We've seen this movie before with Generative AI gone or
    kind of like the impulses of, hey, just t
  name: Generative AI
  position: 16005
- category: tech
  confidence: high
  context: uld be smarter in jumping and going and getting a Facebook page where we
    know we saw this whole gold rush ar
  name: Facebook
  position: 17090
- category: unknown
  confidence: medium
  context: 'our time to make sure we are getting this right.


    So Miranda, once again, thank you so much for being with us'
  name: So Miranda
  position: 17506
- category: unknown
  confidence: medium
  context: the head of AI at Raytheon, and AI pioneers like Joshua Bengeo. With nearly
    a million annual listeners, AI and B
  name: Joshua Bengeo
  position: 18889
- category: ai_research
  confidence: high
  context: The organization hosting the 'AI and Business Podcast' and featuring executive
    thought leaders on AI adoption.
  name: Emerge AI Research
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: The organization where the guest, Miranda Jones, serves as SVP of Data
    and AI Strategy Leader. Represents a regulated industry adopting AI.
  name: Emprize Bank
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: Mentioned as an organization whose CIO has been featured on the podcast,
    indicating involvement in enterprise AI.
  name: Goldman Sachs
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: Mentioned as an organization whose head of AI has been featured on the
    podcast, indicating involvement in enterprise AI.
  name: Raytheon
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Mentioned via the DevRel team speaker (Paige Bailey) promoting Gemini 2.5
    Flash.
  name: Google DeepMind
  source: llm_enhanced
- category: ai_model
  confidence: high
  context: A specific model developed by Google DeepMind, discussed for its balance
    of intelligence, speed, and cost.
  name: Gemini 2.5 Flash
  source: llm_enhanced
- category: ai_model
  confidence: high
  context: Frequently mentioned as a key generative AI tool employees experiment with,
    highlighting its impact on user understanding and the concept of hallucination.
  name: ChatGPT
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as the organization where a previous guest discussed using an
    AI system to detect deepfake videos.
  name: Intel
  source: llm_enhanced
- category: analogy
  confidence: medium
  context: Used as an analogy (via the App Store) to explain the benefit of domain-specific,
    targeted AI applications over generalized ones.
  name: Apple iPhone
  source: llm_enhanced
- category: ai_media_research
  confidence: high
  context: The podcast itself, which focuses on enterprise AI adoption and strategy.
  name: AI and Business Podcast
  source: llm_enhanced
date: 2025-07-22 06:00:00 +0000
duration: 23
has_transcript: false
insights:
- actionable: true
  confidence: medium
  extracted: not wait until they're perfect because development takes time
  text: we should not wait until they're perfect because development takes time.
  type: recommendation
- actionable: true
  confidence: medium
  extracted: look at it from a perspective of what is the problem and what are we
    trying to accomplish, and then is AI the right tool for that versus finding ways
    to use agents? So there's different ways to think about that
  text: we should look at it from a perspective of what is the problem and what are
    we trying to accomplish, and then is AI the right tool for that versus finding
    ways to use agents? So there's different ways to think about that.
  type: recommendation
- actionable: true
  confidence: medium
  extracted: be smarter in jumping and going and getting a Facebook page where we
    know we saw this whole gold rush around
  text: we should be smarter in jumping and going and getting a Facebook page where
    we know we saw this whole gold rush around .
  type: recommendation
layout: episode
llm_enhanced: true
original_url: https://traffic.libsyn.com/secure/techemergence/Business_-_7.22.25_-_Miranda_Jones.mp3?dest-id=151434
processing_date: 2025-10-05 00:33:43 +0000
quotes:
- length: 226
  relevance_score: 6
  text: Responsible AI, I think, has gone from a marketing talking point, kind of
    at the beginning of the generative AI explosion that we saw a little under three
    years ago, to a very, very robust and serious data science conversation
  topics:
  - market
- length: 201
  relevance_score: 4
  text: I think especially something I had kind of mentioned in the last program where
    we had you was that I think regulated industries at this point of AI adoption
    for generative, we're seeing GenAI come down
  topics: []
- length: 127
  relevance_score: 4
  text: Financial institutions can leverage their cautious pace to focus on alignment
    with trust, transparency, and measurable outcomes
  topics: []
- length: 140
  relevance_score: 4
  text: Are you driving AI transformation at your organization, or maybe you're guiding
    critical decisions on AI investment, strategy, or deployment
  topics:
  - investment
- impact_reason: Provides a strong argument for immediate, safe experimentation to
    accelerate organizational learning and adoption, rather than waiting for perfection.
  relevance_score: 10
  source: llm_enhanced
  text: The most critical thing we can do right now is to enable employees to go use
    new generative AI tools. Maybe in five or 10 years, they will be much better than
    they are today, but we should not wait until they're perfect because development
    takes time.
  topic: business/strategy
- impact_reason: Emphasizes the necessity of hands-on, low-risk experimentation for
    practical user education on prompting and tool interaction, acknowledging the
    gap between user expectation (search engine) and model function.
  relevance_score: 10
  source: llm_enhanced
  text: making a space for that is helpful for them to learn what are good ways to
    prompt these tools. Some of them may not even know what to put in a prompt box.
    They might try to use it like a search engine because that's what they're used
    to, and it's critical because those are individual work tools. They can't, they
    can't be trained in another way in my opinion. They need people on opportunities
    to use them in a low-risk way so then they understand how well those tools work...
  topic: business/strategy/technical
- impact_reason: A concise, powerful explanation of the core mechanism of LLMs, directly
    addressing the root cause of hallucinations.
  relevance_score: 10
  source: llm_enhanced
  text: Fundamentally, these models are trained to write words that sound like humans,
    not learn facts.
  topic: technical
- impact_reason: Uses the highly relatable 'App Store' analogy to explain the superiority
    of specialized, domain-specific models over monolithic ones.
  relevance_score: 10
  source: llm_enhanced
  text: I think a good example of why I believe domain specific could be much better
    if you think about the Apple iPhone. They have an app store because specific apps
    designed for a specific purpose are going to perform one app design for many.
    It's the same on set.
  topic: strategy
- impact_reason: Crucial practical advice for deploying GenAI, especially agents,
    emphasizing the necessity of human oversight due to hallucination risks.
  relevance_score: 10
  source: llm_enhanced
  text: we know that generative AI can and will hallucinate. So as we roll out agents
    or other applications, I think the right thing to do is to start, always start
    with a human in the loop...
  topic: safety
- impact_reason: 'A core strategic principle: problem-first, tool-agnostic decision-making,
    rather than forcing AI/agent solutions onto every problem.'
  relevance_score: 10
  source: llm_enhanced
  text: We shouldn't ignore the change in new ways of doing things, but we should
    look at it from a perspective of what is the problem and what are we trying to
    accomplish, and then is AI the right tool for that versus finding ways to use
    agents?
  topic: strategy
- impact_reason: 'A critical distinction: the danger of agent hallucinations isn''t
    just incorrect text, but incorrect *actions* taken autonomously by the AI.'
  relevance_score: 10
  source: llm_enhanced
  text: '...the hallucination wouldn''t be an answer, the hallucination could be a
    series of actions, which is really what we stand at risk here with a lot of agent
    tech AI coming in.'
  topic: safety
- impact_reason: 'Actionable advice for enterprise AI adoption: prioritize safe sandboxes
    for employee upskilling and risk recognition.'
  relevance_score: 10
  source: llm_enhanced
  text: First, safe experimentation matters. Employees need hands-on, low-risk environments
    to learn prompt engineering and recognize model limitations like hallucinations.
  topic: business
- impact_reason: Strong endorsement for fine-tuning or smaller, specialized models
    over general-purpose foundation models for high-stakes, regulated tasks.
  relevance_score: 10
  source: llm_enhanced
  text: Second, domain-specific AI delivers more value. Smaller bespoke models are
    better suited to customer service, compliance, and communication patterns in banking.
  topic: technical/business
- impact_reason: Highlights the maturation of Responsible AI from a superficial concept
    to a core technical and strategic discussion in data science.
  relevance_score: 9
  source: llm_enhanced
  text: Responsible AI, I think, has gone from a marketing talking point, kind of
    at the beginning of the generative AI explosion that we saw a little under three
    years ago, to a very, very robust and serious data science conversation.
  topic: safety/strategy
- impact_reason: 'Points out a crucial blind spot: generative AI''s utility in unstructured
    data might distract users from the enduring importance of structured/transactional
    data integrity.'
  relevance_score: 9
  source: llm_enhanced
  text: We've sometimes called hallucinations since the ChatGPT explosion. I think
    there still is a bit of a gap in people's understanding about transactional data,
    like structured data, that generative AI doesn't really help them learn the importance
    of that being correct.
  topic: safety/technical
- impact_reason: Directly links model size to increased risk, supporting the shift
    away from monolithic foundational models for specific enterprise tasks.
  relevance_score: 9
  source: llm_enhanced
  text: I think that's a big function of the bigger the model, actually, the more
    risk that that really involves.
  topic: safety/strategy
- impact_reason: Strong argument against the 'one-size-fits-all' approach in enterprise
    AI, advocating for specialization.
  relevance_score: 9
  source: llm_enhanced
  text: Also, that this vision of one size fits all doesn't really make sense, not
    just across industries, but even you can't have a model that knows how every single
    bank operates or every single organization operates.
  topic: strategy
- impact_reason: 'Justifies the move toward domain-specific models: the general language
    capability exists; the value is in specialized vocabulary and context.'
  relevance_score: 9
  source: llm_enhanced
  text: Certainly, there are already algorithms that know how to speak English, so
    we shouldn't be trying to recreate that. So what's really critical in certain
    use cases is the words matter, and so domain matters.
  topic: technical/strategy
- impact_reason: Provides concrete examples (customer segments, local dialect) illustrating
    why generalization fails in high-stakes, customer-facing domains like banking.
  relevance_score: 9
  source: llm_enhanced
  text: If a model is too generalized, it will not know the intricacies in this particular
    customer segment. Or perhaps there's even local dialect.
  topic: technical/business
- impact_reason: Links safe experimentation directly to identifying model weaknesses
    like bias and hallucinations.
  relevance_score: 9
  source: llm_enhanced
  text: They need people on opportunities to use them in a low-risk way so then they
    understand how well those tools work and then what potential bias those tools
    may have or know the term hallucination is used a lot to describe invalid outputs.
  topic: safety/business
- impact_reason: Documents the historical shift in enterprise AI focus from large
    foundational models toward smaller, customized (bespoke) solutions.
  relevance_score: 9
  source: llm_enhanced
  text: I think one of the facets of the conversation that's changed a lot... we talked
    a lot about foundational and bespoke models. And even then, I think a lot of the
    data science folks at the table were really trying to point in the direction of
    what then were called bespoke models and say, that's really where you want to
    be.
  topic: technical/strategy
- impact_reason: 'A specific prediction about future AI architecture: a tiered system
    where smaller, specialized models interface with customers, supported by distant
    foundational models.'
  relevance_score: 9
  source: llm_enhanced
  text: You're going to see maybe a couple years from now, this kind of web of smaller
    models, and maybe your bigger models will stay a little bit farther away from
    the customer. We'll call those foundations.
  topic: predictions/technical
- impact_reason: 'A highly memorable, concise summary of Gemini 2.5 Flash''s value
    proposition: balancing reasoning power with latency and cost constraints.'
  relevance_score: 9
  source: llm_enhanced
  text: It's basically brains on a budget.
  topic: technical
- impact_reason: This draws a direct analogy between the specialized nature of mobile
    apps (App Store model) and the potential need for targeted AI solutions over monolithic
    foundation models for specific tasks.
  relevance_score: 9
  source: llm_enhanced
  text: specific apps designed for a specific purpose are going to perform one app
    design for many.
  topic: strategy
- impact_reason: 'Identifies a key trend: regulated industries (Finance, Healthcare)
    adopting a measured, slower pace relative to the speed of technological advancement.'
  relevance_score: 9
  source: llm_enhanced
  text: I think regulated industries at this point of AI adoption for generative,
    we're seeing GenAI come down. The regulated industries are feeling a lot more
    secure within themselves that they're just going to go at a certain pace adjacent
    to the technology.
  topic: business
- impact_reason: Acknowledges the current hype cycle's similarity to past tech bubbles
    (like .com), suggesting collective memory might lead to better initial deployment
    decisions.
  relevance_score: 9
  source: llm_enhanced
  text: our memory is now really good for the first round that this happened. We've
    seen this movie before with Generative AI gone or kind of like the impulses of,
    hey, just throw it everywhere, that kind of gold rush mentality...
  topic: business
- impact_reason: Reiterates the strategic advantage of regulated industries moving
    deliberately, focusing on core ethical and compliance pillars.
  relevance_score: 9
  source: llm_enhanced
  text: Finally, slow and steady wins in regulated industries. Financial institutions
    can leverage their cautious pace to focus on alignment with trust, transparency,
    and measurable outcomes.
  topic: strategy
- impact_reason: 'Identifies a key strength of GenAI: improving user awareness regarding
    the structure and language within unstructured data sources.'
  relevance_score: 8
  source: llm_enhanced
  text: What I do think it helps them with is leveraging unstructured data, like data
    in a Word document or a PDF, and having a better understanding of how critical
    the words that are used in a document or how the document might be structured.
  topic: business/technical
- impact_reason: Describes the modern, nuanced reality of AI deployment strategy,
    moving beyond the simple 'build vs. buy' dichotomy to focus on integration ratios.
  relevance_score: 8
  source: llm_enhanced
  text: Some build and some buy. It's not binary anymore where folks are just building
    versus just buying. Hardly the case anymore. It's always kind of like, what ratio
    do you have of that?
  topic: business
- impact_reason: A pragmatic view on leveraging existing general capabilities (like
    language understanding) rather than rebuilding them, focusing resources on domain
    specialization.
  relevance_score: 8
  source: llm_enhanced
  text: We shouldn't be trying to recreate that [English language understanding].
    That's already been done.
  topic: strategy
- impact_reason: 'Defines the practical role of foundation models in enterprise AI:
    as components or starting points, not end-to-end solutions.'
  relevance_score: 8
  source: llm_enhanced
  text: If you really wanted to solve a specific problem, you may use elements of
    that foundation models, but probably needs to be more targeted to what you're
    actually trying to solve.
  topic: technical/strategy
- impact_reason: Illustrates the classic organizational conflict between technical
    risk management (data science) and business pressure for speed.
  relevance_score: 8
  source: llm_enhanced
  text: If we do things the fast way, I don't know if I can control the results, and
    somebody may be in business leadership who doesn't really know any better says,
    yeah, we need this done faster, not slower.
  topic: safety/business
- impact_reason: Identifies the core engineering challenge in modern LLM deployment
    and positions a specific product as addressing it.
  relevance_score: 8
  source: llm_enhanced
  text: Gemini 2.5 Flash aims right at that challenge [trade-off between model intelligence,
    speed, and cost].
  topic: technical
- impact_reason: A stark warning about the accelerating pace of technological change,
    contrasting it with organizational inertia.
  relevance_score: 8
  source: llm_enhanced
  text: Technology is going to go at the speed of lightning, more is law, it's going
    to get faster and faster, it's going to accelerate.
  topic: predictions
- impact_reason: Suggests process redesign as an alternative to simply injecting AI
    into existing workflows, promoting thoughtful integration.
  relevance_score: 8
  source: llm_enhanced
  text: '...or do you design the process differently so you can scale in a different
    way while still letting the technology?'
  topic: strategy
- impact_reason: Posits that the short time gap since the last major tech cycle (GenAI
    vs. .com/Social Media) gives leaders a better chance to avoid past scaling mistakes.
  relevance_score: 8
  source: llm_enhanced
  text: Because it's, you know, we saw generative AI just three years ago. Everybody's
    memory I think is a lot sharper, and I think that's a huge, huge opportunity to
    get things right.
  topic: strategy
- impact_reason: A concise strategic imperative for continuous, iterative development
    in AI.
  relevance_score: 7
  source: llm_enhanced
  text: We shouldn't wait until they're perfect because development takes time.
  topic: strategy
- impact_reason: Notes the societal shift in AI literacy driven by widespread consumer
    access, impacting future professional readiness.
  relevance_score: 7
  source: llm_enhanced
  text: And as I was saying before, so much of this conversation has changed as a
    function of this technology being in the hands of individuals, being in the hands
    of high schoolers trying their best to write book reports...
  topic: predictions/strategy
- impact_reason: A philosophical insight connecting AI development directly to deeper
    understanding of human cognition and behavior.
  relevance_score: 7
  source: llm_enhanced
  text: The more we learn about these systems, the more we learn about human intelligence
    and what that's shaped like, and human behavior, the more we get a deeper understanding
    of what makes us human.
  topic: safety/strategy
- impact_reason: Uses a simple linguistic distinction to underscore the complexity
    of domain/contextual nuance that generalized models often miss.
  relevance_score: 7
  source: llm_enhanced
  text: We all speak English, but I think it's clear there's not British English is
    a little bit different than American English. That's a good example.
  topic: technical
- impact_reason: Frames the slower pace of regulated industries not as a disadvantage,
    but as a potential advantage in the context of responsible AI scaling.
  relevance_score: 7
  source: llm_enhanced
  text: what advantages do they have in the responsible scaling AI conversation?
  topic: safety/strategy
source: Unknown Source
summary: '## Podcast Episode Summary: Responsible AI That Scales Across Customer Workflows
  - with Miranda Jones of Emprise Bank


  This episode focuses on the critical challenge faced by regulated industries, particularly
  banking, in **scaling responsible Artificial Intelligence (AI)** while maintaining
  customer trust, data integrity, and regulatory compliance. Miranda Jones emphasizes
  a pragmatic approach to adopting generative AI, moving beyond initial hype toward
  robust, domain-specific implementation.


  ### 1. Focus Area

  The discussion centers on **Responsible AI scaling in regulated environments**,
  specifically addressing the transition from generalized foundational models to bespoke,
  domain-specific AI solutions. Key themes include enabling safe employee experimentation
  with generative tools, understanding model limitations (like hallucinations), and
  the strategic shift toward tailored AI applications over one-size-fits-all models.


  ### 2. Key Technical Insights

  *   **Generative Models as Word Guessers, Not Fact Disseminators:** A core technical
  understanding emphasized is that LLMs are fundamentally trained to generate human-sounding
  text, not to discern or verify facts, necessitating critical challenge of outputs
  by subject matter experts.

  *   **Value of Domain Specificity:** Generalized models lack the necessary nuance
  for specific industries or even regional dialects (e.g., British vs. American English
  in financial contexts). Bespoke, domain-specific models, akin to specialized apps
  in an app store, are crucial for solving targeted problems effectively.

  *   **Unstructured Data Insight:** Generative AI helps employees better understand
  the importance of structured data by revealing how poorly structured unstructured
  data (like verbose documents) hinders effective prompting and information extraction.


  ### 3. Business/Investment Angle

  *   **Safe Experimentation as a Prerequisite for Adoption:** Organizations must
  create protected, low-risk environments where employees can safely experiment with
  generative tools to build practical understanding of prompting, limitations, and
  appropriate data usage.

  *   **The Shift from Foundational to Bespoke:** The industry conversation has moved
  away from relying solely on massive foundational models toward prioritizing smaller,
  targeted models closer to the customer workflow, acknowledging that one-size-fits-all
  solutions fail in complex banking operations.

  *   **Pace of Adoption in Regulated Industries:** Financial services can leverage
  their naturally cautious pace to focus on alignment, transparency, and measurable
  outcomes, contrasting with the "gold rush" mentality seen in less regulated sectors.


  ### 4. Notable Companies/People

  *   **Miranda Jones (SVP, Data and AI Strategy Leader, Emprise Bank):** The primary
  expert providing insights on responsible scaling within the banking sector.

  *   **Emerge AI Research/AI and Business Podcast:** The platform hosting the discussion,
  featuring other leaders like the CIO of Goldman Sachs and the head of AI at Raytheon.

  *   **Google DeepMind (Sponsor Mention):** Mentioned Gemini 2.5 Flash as a model
  balancing intelligence, speed, and cost through features like "thinking budgets."


  ### 5. Future Implications

  The industry is moving toward a **web of smaller, targeted models** integrated into
  specific workflows rather than monolithic systems. Furthermore, the sharp memory
  of recent AI hype cycles (unlike previous cycles like the dot-com boom) provides
  a unique opportunity for regulated industries to adopt AI thoughtfully, prioritizing
  **human-in-the-loop** processes, especially when deploying AI agents that could
  execute actions based on potentially flawed outputs.


  ### 6. Target Audience

  This episode is most valuable for **Enterprise AI Leaders, Data Science Executives,
  Compliance Officers, and CIOs** within highly regulated industries (Financial Services,
  Healthcare, Life Sciences) who are responsible for guiding AI investment, strategy,
  and responsible deployment at scale.'
tags:
- artificial-intelligence
- generative-ai
- investment
- google
- apple
title: Responsible AI That Scales Across Customer Workflows - with Miranda Jones of
  Emprise Bank
topics:
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 72
  prominence: 1.0
  topic: artificial intelligence
- keywords:
  - generative ai
  - genai
  - chatgpt
  - gpt
  - claude
  - text generation
  - image generation
  mentions: 19
  prominence: 1.0
  topic: generative ai
- keywords:
  - investment
  - funding
  - valuation
  - ipo
  - acquisition
  mentions: 2
  prominence: 0.2
  topic: investment
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-10-05 00:33:43 UTC -->
