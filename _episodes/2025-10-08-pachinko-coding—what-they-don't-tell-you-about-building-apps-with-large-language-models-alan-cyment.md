---
companies:
- category: unknown
  confidence: medium
  context: and yes, you get direct access to me, Vasco, your Scrum Master Toolbox
    podcast. No, this is not a drill, it's the Scrum
  name: Scrum Master Toolbox
  position: 477
- category: unknown
  confidence: medium
  context: week of coding with AI, and joining us today from Buenos Aires is Alan
    Simont. Hey Alan, welcome to the show. He
  name: Buenos Aires
  position: 923
- category: unknown
  confidence: medium
  context: ith AI, and joining us today from Buenos Aires is Alan Simont. Hey Alan,
    welcome to the show. Hey Vasco, thanks
  name: Alan Simont
  position: 939
- category: unknown
  confidence: medium
  context: oining us today from Buenos Aires is Alan Simont. Hey Alan, welcome to
    the show. Hey Vasco, thanks for invit
  name: Hey Alan
  position: 952
- category: unknown
  confidence: medium
  context: es is Alan Simont. Hey Alan, welcome to the show. Hey Vasco, thanks for
    inviting me. Absolutely. For you to k
  name: Hey Vasco
  position: 983
- category: unknown
  confidence: medium
  context: rtified Scrum trainer with deep experience across Latin America and Europe,
    and he blends agile coaching with the
  name: Latin America
  position: 1293
- category: unknown
  confidence: medium
  context: g rational thinking, but it's just your feelings. When I first, I mean,
    before even the coinage of vibe co
  name: When I
  position: 2384
- category: unknown
  confidence: medium
  context: e a gourmet meal made for you after a given time. So I said, with some
    fear, because I was a developer f
  name: So I
  position: 3057
- category: unknown
  confidence: medium
  context: nd this was before agent coding, before Cursor or Cloud Code exploded.
    So I found myself asking things to the
  name: Cloud Code
  position: 3957
- category: unknown
  confidence: medium
  context: opying and pasting into my IDE, which I think was VS Code, trying to run
    it, and seeing either a compile er
  name: VS Code
  position: 4119
- category: unknown
  confidence: medium
  context: capturing the console output and putting it back. And I, first of all,
    I felt like a servant. You were se
  name: And I
  position: 4319
- category: tech
  confidence: high
  context: ay, when I started using the agentic ones, mostly Adept and Cloud Code.
    Those are the two ones that I mos
  name: Adept
  position: 6118
- category: unknown
  confidence: medium
  context: s, yes. And this happened when I was using Adept. And Adept tells you after
    every round because it's a bit au
  name: And Adept
  position: 7454
- category: unknown
  confidence: medium
  context: p. It was like every round was a couple of cents. Sometimes I said, "Okay,
    now I'm going to really use my money
  name: Sometimes I
  position: 7927
- category: unknown
  confidence: medium
  context: en it did work, I really felt that something that Martin Fowler recently
    quoted from someone saying that perhaps
  name: Martin Fowler
  position: 11926
- category: unknown
  confidence: medium
  context: ust wrong because that's what extrapolations are. Then I think, at least,
    I begin to come down. Okay, but
  name: Then I
  position: 16284
- category: tech
  confidence: high
  context: use they were synced automatically with my former Facebook accounts, I
    got—I have in my calendar, I have the
  name: Facebook
  position: 16961
- category: unknown
  confidence: medium
  context: ut very simple thing. I tried to do it once using React Native. I couldn't
    even—I mean, it took me half a day to
  name: React Native
  position: 18387
- category: unknown
  confidence: medium
  context: hat I start to buy into the abstraction metaphor. Because I know I have
    an understanding, and I've made some
  name: Because I
  position: 19202
- category: unknown
  confidence: medium
  context: simple thing. "You might be overcomplicating it." Like I wrote some—the
    prompt was something like, "Take t
  name: Like I
  position: 22229
- category: unknown
  confidence: medium
  context: aying, "I want this done, make it simple," right? Like YAGNI. Yes, and
    ask for very small things. And oh, by t
  name: Like YAGNI
  position: 23642
- category: unknown
  confidence: medium
  context: for enterprise-grade software, like bigger stuff. If I'm talking about
    a more birthday reminder applicat
  name: If I
  position: 23841
- category: unknown
  confidence: medium
  context: s, for processing a lot of my clients use JIRA or Azure DevOps, even though
    I don't like those tools. There's so
  name: Azure DevOps
  position: 24071
- category: unknown
  confidence: medium
  context: for instance, I was—I was thinking whether to use Monte Carlo simulations
    or not for a team. So, I said, "Okay,
  name: Monte Carlo
  position: 24572
- category: media
  confidence: high
  context: The host's podcast, promoting its membership.
  name: Scrum Master Toolbox podcast
  source: llm_enhanced
- category: media
  confidence: high
  context: The website URL for the podcast membership.
  name: ScrumMasterToolbox.org
  source: llm_enhanced
- category: tech
  confidence: high
  context: Mentioned as the original LLM tool used for code creation, specifically
    the first known version.
  name: ChatGPT
  source: llm_enhanced
- category: tech
  confidence: medium
  context: Used as an analogy for AI coding—a machine that cooks gourmet meals without
    the user knowing how to cook.
  name: Thermomix
  source: llm_enhanced
- category: tech
  confidence: high
  context: The Integrated Development Environment (IDE) the guest used to copy/paste
    code snippets from ChatGPT.
  name: VS Code
  source: llm_enhanced
- category: tech
  confidence: high
  context: Mentioned as an agentic coding tool that the guest chose not to try due
    to its business model.
  name: Cursor
  source: llm_enhanced
- category: tech
  confidence: high
  context: An agentic coding tool the guest has been using frequently, benefiting
    from subsidized tokens due to VC money.
  name: Cloud Code
  source: llm_enhanced
- category: tech
  confidence: high
  context: An agentic coding tool the guest used for a longer time, noting it was
    open source (which they preferred) but required paying for tokens.
  name: Adept
  source: llm_enhanced
- category: tech
  confidence: high
  context: Mentioned as one of the more expensive LLMs the guest tried, alongside
    Claude.
  name: Gemini
  source: llm_enhanced
- category: tech
  confidence: high
  context: Mentioned as one of the more expensive LLMs the guest tried, alongside
    Gemini.
  name: Claude
  source: llm_enhanced
- category: tech
  confidence: high
  context: The model the guest was using when running expensive rounds of coding attempts
    with Adept.
  name: GPT-4
  source: llm_enhanced
- category: tech
  confidence: high
  context: Mentioned as a platform where human developers can be hired for less than
    the cost of excessive AI token usage.
  name: Upwork
  source: llm_enhanced
- category: tech
  confidence: high
  context: Mentioned as a platform where human developers can be hired for less than
    the cost of excessive AI token usage.
  name: Fiverr
  source: llm_enhanced
- category: toys/manufacturing
  confidence: medium
  context: Mentioned in the context of the guest's child's toys, which are sometimes
    called 'mecha'. (Lego is the company)
  name: Legos
  source: llm_enhanced
- category: tech
  confidence: high
  context: Mentioned as a device that has built-in birthday reminders.
  name: iPhone
  source: llm_enhanced
- category: tech/social media
  confidence: high
  context: Mentioned regarding the automatic syncing of birthday reminders from old
    accounts.
  name: Facebook
  source: llm_enhanced
- category: tech
  confidence: high
  context: Mentioned as an operating system that has built-in birthday reminders.
  name: Android
  source: llm_enhanced
- category: tech
  confidence: high
  context: A framework the speaker tried to use to build the birthday reminder app
    but struggled to find libraries for contact access.
  name: React Native
  source: llm_enhanced
- category: tech
  confidence: high
  context: The programming language the speaker was learning/using for iOS development
    with the help of the LLM.
  name: Swift
  source: llm_enhanced
- category: tech
  confidence: high
  context: The platform architecture the speaker was developing for when using Swift.
  name: iOS
  source: llm_enhanced
- category: tech
  confidence: high
  context: A project management tool used by the speaker's clients, from which data
    was processed using Python and the LLM.
  name: JIRA
  source: llm_enhanced
- category: tech
  confidence: high
  context: A project management tool used by the speaker's clients, mentioned alongside
    JIRA.
  name: Azure DevOps
  source: llm_enhanced
- category: tech
  confidence: high
  context: A cross-platform development framework the speaker tried for an e-learning
    MVP, which proved brittle.
  name: Flutter
  source: llm_enhanced
- category: tech
  confidence: high
  context: A web technology/framework the speaker used successfully for the e-learning
    MVP, resulting in a more stable application.
  name: Svelte
  source: llm_enhanced
date: 2025-10-08 10:05:00 +0000
duration: 46
has_transcript: false
layout: episode
llm_enhanced: true
original_url: https://audio.listennotes.com/e/p/d8e131d42164484ba7d78de221e20fef/
processing_date: 2025-10-08 14:03:31 +0000
quotes:
- length: 178
  relevance_score: 4
  text: I mean, the problem is that because they were synced automatically with my
    former Facebook accounts, I got—I have in my calendar, I have the birthdays of
    people I don't even know
  topics: []
- length: 26
  relevance_score: 3
  text: But you have to control it
  topics: []
- length: 57
  relevance_score: 3
  text: I mean, yeah, I mean, you have to learn before doing that
  topics: []
- impact_reason: Identifies the rapid iteration loop of AI debugging as an 'addiction
    cycle' rather than a structured improvement process (PDCA), a key insight into
    developer workflow disruption.
  relevance_score: 10
  source: llm_enhanced
  text: The cycles became faster. And the cycles, I realized internally, that they
    were, or it was like a PDCA cycle, but more of an addiction cycle.
  topic: Business/Productivity
- impact_reason: Introduces the 'pachinko coding' metaphor, which vividly describes
    the addictive, low-yield, high-engagement loop of constantly trying to get the
    AI to succeed.
  relevance_score: 10
  source: llm_enhanced
  text: I instantly, what came to my mind at that moment, were the pachinko machines.
  topic: Technology/AI Coding
- impact_reason: Posits AI-assisted coding as a fundamental shift in how software
    is conceived, comparable to the introduction of assembly or object-oriented programming.
  relevance_score: 10
  source: llm_enhanced
  text: Perhaps this could be a new level of abstraction.
  topic: Technology/Future Trends
- impact_reason: This defines the historical progression of computing abstraction
    (punch cards -> bits -> assembly -> languages -> OOP) and sets the stage for AI
    as the next major abstraction layer.
  relevance_score: 10
  source: llm_enhanced
  text: Each one of those was a new level of abstraction that allowed us to forget
    about thinking so much at that low level and allowed us to think about bigger
    things because we had abstractions that summarized bigger concepts.
  topic: Technology/Abstraction
- impact_reason: 'A powerful metaphor for agentic AI coding: it amplifies the user''s
    capability but requires skill (piloting) to direct effectively.'
  relevance_score: 10
  source: llm_enhanced
  text: I call it mecha coding, mecha or exoskeleton. It's those robots where you
    need a person or a Lego—I mean, like a thinking being—to be in control, but you
    are like inside the robot, and the robot gives you powers like strength or weapons
    or speed that you wouldn't have on your own. But you need to be proficient in
    the use—I mean, in piloting a fighter aircraft, right?
  topic: Technology/AI Coding
- impact_reason: Actionable advice on prompt engineering for architectural decision-making,
    positioning the LLM as a consultant rather than just a coder.
  relevance_score: 10
  source: llm_enhanced
  text: I need to explicitly tell the LLM, 'Give me the options. Don't code,' and
    'Explain me the pros and cons of each of the options.'
  topic: Technology/AI Prompting
- impact_reason: 'A key distinction for tech leaders: LLMs primarily attack *accidental
    complexity* (tooling, syntax overhead), leaving the *inherent complexity* (the
    core business logic) for the human.'
  relevance_score: 10
  source: llm_enhanced
  text: I love the difference between inherent and accidental complexity. But the
    inherent complexity is what the real complexity of making an application... And
    then you have all the accidental complexities, which are like the details of the
    unnecessary complexity that are brought about by the UX of software development
    languages.
  topic: Technology/Strategy
- impact_reason: 'The core conclusion: effective AI coding leverages abstraction by
    focusing on high-level goals (YAGNI) rather than low-level implementation details.'
  relevance_score: 10
  source: llm_enhanced
  text: For coding well with LLM, it actually pays off to take that level of abstraction,
    right? So that you're not worrying about renaming methods like you said or detailed
    refactoring solutions, but you're just saying, 'I want this done, make it simple,'
    right? Like YAGNI.
  topic: Technology/AI Coding Strategy
- impact_reason: This is a powerful metaphor suggesting that AI coding assistants
    should be treated as an integrated Continuous Integration (CI) system that must
    maintain code health constantly, preventing error accumulation ('bleeding').
  relevance_score: 10
  source: llm_enhanced
  text: So, reminding the agent that he or she, it's its own CI, and that it should
    never let any kind of error appear because it starts bleeding, right?
  topic: Technology/Development Practices
- impact_reason: 'This is a key hypothesis explaining variability in AI coding performance:
    the training data depth for specific, perhaps niche or rapidly evolving, tech
    stacks might be insufficient.'
  relevance_score: 10
  source: llm_enhanced
  text: What I think is that maybe the LLM just has less information, is less proficient
    in certain tech stacks than another.
  topic: Technology/AI Limitations
- impact_reason: Provides a clear, critical definition of 'vibe coding,' framing it
    as a passive consumption of AI output, which is a key concept in the discussion.
  relevance_score: 9
  source: llm_enhanced
  text: My understanding is that the original definition of vibe coding is that even
    if you know how to code, you use an LLM and AI tool to create code for you, and
    you don't really get to think about the code or even to read about it. It's like
    you're just a mere user, so you don't have to think.
  topic: Technology/AI Coding
- impact_reason: A powerful, relatable metaphor (Thermomix) used to describe the initial,
    naive expectation of AI generating perfect, ready-to-use code without developer
    intervention.
  relevance_score: 9
  source: llm_enhanced
  text: Thermomix coding is here.
  topic: Technology/AI Coding
- impact_reason: Captures the psychological reversal of roles when interacting with
    early, unreliable AI coding tools, highlighting a crucial user experience issue.
  relevance_score: 9
  source: llm_enhanced
  text: I felt like a servant. You were serving the machine instead of serving you,
    right?
  topic: Technology/AI Coding
- impact_reason: A strong analogy illustrating the danger of AI generating unreadable,
    complex code that requires more effort to fix than writing from scratch—the 'all
    the suster' outcome.
  relevance_score: 9
  source: llm_enhanced
  text: And then when I decided to finally check on the code, the code was horribly
    complicated, complex. It was, you know, where I failed at the moment is that if
    I asked my Roomba to paint my room, I'm saying, when I entered the room, it was
    all the suster. I didn't know what—I mean, the only thing I could do was paint
    it white myself again because it was all the suster.
  topic: Technology/Code Quality
- impact_reason: 'Offers a crucial benchmark: comparing the cost of ''pachinko coding''
    against the proven cost of hiring competent human developers for complex tasks.'
  relevance_score: 9
  source: llm_enhanced
  text: I've often used developers on platforms like Upwork or Fiverr or something
    like that, and I've paid less than that to a human developer on those platforms
    to develop a complex system that was actually a fork from an open-source already
    existing very large system and so on.
  topic: Business/Hiring/Economics
- impact_reason: Highlights the genuine breakthrough moments where AI *does* deliver
    massive productivity gains, validating the technology's ultimate potential.
  relevance_score: 9
  source: llm_enhanced
  text: The moment the pachinko machine said, 'I won,' and I had won. I mean, from
    time to time, it did work. And it did create—I mean, I hadn't been able to successfully
    connect to any commerce on my own. I mean, I hadn't done productive coding in
    20 years.
  topic: Technology/Productivity
- impact_reason: Provides a historical framework for understanding technological abstraction
    layers, setting the stage for AI as the next major leap.
  relevance_score: 9
  source: llm_enhanced
  text: First, we had punch cards. Then we had to think... in terms of bits... Then
    assembly came in... Then the first real languages came in... Then object orientation
    came... Each one of those was a new level of abstraction that allowed us to forget
    about thinking so much at that low level and allowed us to think about bigger
    things...
  topic: Technology/History
- impact_reason: A provocative statement suggesting that natural language (English/prompting)
    might supersede traditional programming languages as the primary interface for
    software creation.
  relevance_score: 9
  source: llm_enhanced
  text: First, after reading all the passwords about the new development language
    is English, forget about software programming languages.
  topic: Technology/Future Trends
- impact_reason: A concise philosophical statement on the fundamental role of abstraction
    in human problem-solving, directly applicable to software engineering.
  relevance_score: 9
  source: llm_enhanced
  text: Abstractions are our way of dividing and conquering mentally.
  topic: Technology/Strategy
- impact_reason: A provocative statement suggesting that natural language (English)
    is becoming the primary interface for coding, diminishing the immediate need for
    deep syntax knowledge.
  relevance_score: 9
  source: llm_enhanced
  text: So, first, after reading all the passwords about the new development language
    is English, forget about software programming languages.
  topic: Technology/AI Coding
- impact_reason: 'Crucial advice for interacting with LLMs: avoid anthropomorphizing
    the tool; treat it as a probabilistic function to manage expectations.'
  relevance_score: 9
  source: llm_enhanced
  text: So, if you start to treat it like a person, it drives you crazy because it's
    not. If you see it as a function, then it's being extrapolated, and sometimes
    the extrapolations are just wrong because that's what extrapolations are.
  topic: Technology/AI Interaction
- impact_reason: Demonstrates that LLMs enable non-experts to make high-level architectural
    decisions, shifting focus from implementation details to system design.
  relevance_score: 9
  source: llm_enhanced
  text: I got the application running. And I'm interested in understanding. And I
    can say that I've taken architectural decisions, even though I'm not proficient
    in Swift or in iOS architecture.
  topic: Business/Productivity
- impact_reason: Highlights the LLM's role in bypassing the steep learning curve associated
    with boilerplate setup and tooling overhead.
  relevance_score: 9
  source: llm_enhanced
  text: It becomes more of a conversational manual, and it allows you to go past a
    bit of the accidental complexity.
  topic: Technology/Efficiency
- impact_reason: A successful, high-level debugging prompt that forces the LLM to
    reset its assumptions, proving that strategic prompting beats detailed error correction.
  relevance_score: 9
  source: llm_enhanced
  text: Take two steps back and rethink the whole way in which you are trying to develop
    this, and try to develop this simplest possible, most native, basic, YAGNI way
    of turning on checkboxes.
  topic: Technology/AI Prompting
- impact_reason: 'A crucial caveat: the speaker limits the current success of ''black
    box'' LLM development to small, personal projects, implying enterprise adoption
    requires different controls.'
  relevance_score: 9
  source: llm_enhanced
  text: I don't think this approach would ever work for enterprise-grade software,
    like bigger stuff.
  topic: Business/Scalability
- impact_reason: Illustrates the speed of idea validation using AI. A complex analytical
    concept (Monte Carlo simulation on JIRA data) can be prototyped in hours, bypassing
    team skepticism.
  relevance_score: 9
  source: llm_enhanced
  text: I was thinking whether to use Monte Carlo simulations or not for a team. So,
    I said, 'Okay,' I came up with an idea while I was on the bus. 'Why don't,' and
    I told the team about it, and they were very skeptical. So, I thought, 'Why don't
    I take the historical data of this team from JIRA... and I make a retroactive
    simulation...'
  topic: Business/Data Analysis/Startups
- impact_reason: 'Defines the new role of the developer when using advanced AI agents:
    shifting from writer to coach/manager of the AI entity.'
  relevance_score: 9
  source: llm_enhanced
  text: After a few iterations, you're almost like you are being the agile coach or,
    in this case, the coding coach for the machine.
  topic: Business/Role Shift
- impact_reason: Reinforces the importance of structured, multi-step prompting that
    forces the LLM into a consultative role before execution.
  relevance_score: 9
  source: llm_enhanced
  text: I kept what I—one of the things that I learned is that I need to ask for options.
    And I tell it—I need to explicitly tell the LLM, 'Give me the options. Don't code,'
    and 'Explain me the pros and cons of each of the options.'
  topic: Technology/AI Prompting
- impact_reason: This describes a highly innovative and practical application of AI/scripting
    to validate forecasting methodologies (Monte Carlo simulation) against real-world
    historical data, offering a concrete way to test planning accuracy.
  relevance_score: 9
  source: llm_enhanced
  text: Why don't I take the historical data of this team from JIRA, the user JIRA,
    and I make a retroactive simulation of what Monte Carlo would have said and compare
    it to the actual forecast they made?
  topic: Technology/Process Improvement
- impact_reason: Suggests a direct correlation between the chosen technology stack
    and the success/stability of AI-generated code, even when prompting techniques
    remain constant.
  relevance_score: 9
  source: llm_enhanced
  text: And when I tried with Svelte and doing it all web—I know the technology, the
    stack in itself is simpler—but it became more solid, way more stable, even though
    I was following the same prompting practices.
  topic: Technology/AI Interaction & Tech Stack
- impact_reason: 'Offers actionable best practices for working with AI: favor small,
    single-purpose tools (Unix philosophy), and adhere to Test-Driven Development
    (TDD) and You Ain''t Gonna Need It (YAGNI) principles.'
  relevance_score: 9
  source: llm_enhanced
  text: For Unix-like one-purpose applications, that's one [productive practice].
    In general, TDD, YAGNI.
  topic: Technology/Development Practices
- impact_reason: Uses a philosophical analogy to underscore the danger of becoming
    overly dependent on or subservient to technology (AI) without maintaining intellectual
    control.
  relevance_score: 8
  source: llm_enhanced
  text: It's like we ended up being slaves of the grain, let's say, and of some vegetables.
    [Referring to Harari's point about conquering the potato].
  topic: Technology/Strategy
- impact_reason: Connects the AI interaction loop directly to psychological reward
    mechanisms, explaining the persistence despite repeated failure.
  relevance_score: 8
  source: llm_enhanced
  text: I found myself going back to this belief that this time it was going to be
    Thermomix. It's almost like it was activating your reward centers in the brain...
  topic: Business/Psychology
- impact_reason: Quantifies the potential financial cost of inefficient AI usage,
    providing a concrete business metric for wasted resources.
  relevance_score: 8
  source: llm_enhanced
  text: I remember when we were in prep that you told me that you ended up spending
    what, $20 plus a day at some point?
  topic: Business/Cost Analysis
- impact_reason: Illustrates the extreme acceleration possible when AI succeeds, allowing
    developers to bypass massive documentation overhead.
  relevance_score: 8
  source: llm_enhanced
  text: I found myself in one day having developed things that I probably wouldn't
    have been able to even read the whole documentation in that time.
  topic: Technology/Productivity
- impact_reason: Highlights the current market distortion where VC funding artificially
    lowers the cost of using cutting-edge AI tools, masking the true operational expense.
  relevance_score: 8
  source: llm_enhanced
  text: I'm profiting from VC money being poured. So it's subsidized tokens that I'm
    using right now.
  topic: Business/Startups/Economics
- impact_reason: A critical finding regarding cost vs. performance in LLMs, suggesting
    that premium pricing does not guarantee superior coding output.
  relevance_score: 8
  source: llm_enhanced
  text: The more expensive models were not necessarily any better than the cheaper
    models.
  topic: Technology/AI Performance
- impact_reason: Captures the initial, frustrating, and often chaotic experience of
    early-stage prompt engineering before effective workflows are established.
  relevance_score: 8
  source: llm_enhanced
  text: I found it's—when I started before coming up with a potential coding, I call
    it rage coding because I felt like working with like a drunk PhD with amnesia.
  topic: Technology/AI Coding
- impact_reason: A critique of the poor developer experience (DevEx) in traditional
    tooling, which AI is now beginning to solve.
  relevance_score: 8
  source: llm_enhanced
  text: There's nobody thinks about UX for developers. And all the overhead of setting
    up environments and all that stuff, and we used to call it the act shaving.
  topic: Business/DevEx
- impact_reason: 'Reflects a shift in developer value proposition: if AI handles the
    implementation of specific languages, human value moves to problem definition
    and high-level architecture.'
  relevance_score: 8
  source: llm_enhanced
  text: I don't want my career to be based on developing iOS applications. So, I don't
    want to—I would feel like a waste of time in my case for this language.
  topic: Business/Career
- impact_reason: Quantifies the time sink of accidental complexity in traditional
    development (finding the right library/API integration) versus the speed achieved
    with AI assistance.
  relevance_score: 8
  source: llm_enhanced
  text: I tried to do it once using React Native. I couldn't even—I mean, it took
    me half a day to try and find a library that could connect to the birthday contact,
    to read the contacts.
  topic: Technology/Efficiency
- impact_reason: Suggests that for specific, contained tasks, deep language proficiency
    becomes optional, even for known languages, when using LLMs for scaffolding.
  relevance_score: 8
  source: llm_enhanced
  text: I have been developing, even without understanding much what was going on
    there with Python, even though I do do coding Python and I understand it, but
    I haven't had the need to really understand it.
  topic: Technology/Productivity
- impact_reason: 'Indicates a practical business application: using AI to interface
    with and extract value from disliked or cumbersome third-party enterprise tools.'
  relevance_score: 8
  source: llm_enhanced
  text: I have been using it for some other stuff like for my clients, for processing
    a lot of my clients use JIRA or Azure DevOps, even though I don't like those tools.
  topic: Business/Tooling
- impact_reason: A vivid, memorable analogy for resetting the LLM's context or state
    when debugging complex issues, effectively forcing a clean slate approach.
  relevance_score: 8
  source: llm_enhanced
  text: I gave it the white paint. And I said, 'The previous Roomba just did things
    wrong. Just paint everything white and think about it again.'
  topic: Technology/AI Debugging
- impact_reason: Provides direct, negative feedback on the stability/ease of development
    for specific modern cross-platform frameworks (React Native, Flutter) when using
    AI assistance, highlighting potential tooling friction.
  relevance_score: 8
  source: llm_enhanced
  text: I first tried to do it with React Native, and it was so brittle. It kept breaking,
    breaking, breaking, breaking, breaking, breaking, breaking. Then, I tried with
    Flutter, and it kept breaking, breaking, breaking.
  topic: Technology/Tech Stack
- impact_reason: Suggests the necessary evolution from passive consumption to active
    integration/coupling of AI output with human expertise.
  relevance_score: 7
  source: llm_enhanced
  text: I started developing a coupl[ing]... [The sentence is cut off, but the context
    implies the need to couple AI output with human control.]
  topic: Technology/Strategy
- impact_reason: Offers a direct, albeit brief, critique of a specific competitor's
    business model (Cursor), relevant for market analysis.
  relevance_score: 7
  source: llm_enhanced
  text: I never, I never wanted to try Cursor. I didn't like the, you know, the business
    model.
  topic: Business/Startups
- impact_reason: Touches upon the environmental cost (computational energy) of LLMs
    and the competitive pressure to adopt them regardless of personal reservations.
  relevance_score: 7
  source: llm_enhanced
  text: I feel a bit guilty because I know too many trees are being cut down because
    of this. But if I don't use it, someone else is going to use that.
  topic: Technology/Ethics
- impact_reason: A relatable anecdote highlighting the failure of generic, high-volume
    notifications, emphasizing the need for *contextual* and *prioritized* reminders
    (the problem the custom app solved).
  relevance_score: 7
  source: llm_enhanced
  text: I used to have a reminder in my iPhone to tell me every day there's a birthday,
    and I ended up remembering telling my wife, 'You know, remember that guy that
    we once met? Today's his birthday,' and she said, 'I don't care.'
  topic: Business/UX Failure
- impact_reason: Defines the speaker's standard for quality code (readability) and
    notes that even with AI, human oversight is required to enforce standards like
    refactoring.
  relevance_score: 7
  source: llm_enhanced
  text: I explicitly go over all that, even though sometimes it forgets about it,
    and I need to remind it. Refactoring to me means making the code more readable,
    making the code more—
  topic: Technology/Code Quality
- impact_reason: A specific feature request that highlights the value of *persistent,
    contextual nudges* over passive notifications—a potential niche for future productivity
    apps.
  relevance_score: 7
  source: llm_enhanced
  text: I would like a pestering mode to keep asking me, 'Have you said hi?' And for
    some very special people, I really would like to have a reminder, the pestering
    reminder of buying a gift.
  topic: Business/Product Features
- impact_reason: 'Illustrates a common startup/product motivation: building a solution
    because existing market offerings do not meet a specific, high-standard requirement.'
  relevance_score: 7
  source: llm_enhanced
  text: I start to develop an e-learning because I again myself, I don't like—I want
    to sell e-learning, and I don't like the e-learning platform that I see. So, I
    want to try to do an MVP of an e-learning application that has the way that I
    want to do it.
  topic: Business/Startups
- impact_reason: A vivid metaphor describing the failure of a large, monolithic, initial
    AI prompt—the result is unusable ('brown and tasteless') and non-functional ('didn't
    compile').
  relevance_score: 7
  source: llm_enhanced
  text: It was like, no, as if you would have cooked something brown and tasteless,
    and it didn't compile.
  topic: Technology/AI Interaction
source: Unknown Source
summary: '## Comprehensive Summary: Coding with AI – From "Vibe Coding" to "Mecha
  Coding"


  This episode of the Scrum Master Toolbox podcast, featuring consultant and trainer
  Alan Simont, dives deep into the practical, often frustrating, and ultimately transformative
  experience of coding with Large Language Models (LLMs). The discussion moves beyond
  the hype to explore the psychological pitfalls and emerging best practices for leveraging
  AI in software development.


  ---


  ### 1. Main Narrative Arc and Key Discussion Points


  The conversation follows Alan’s journey from initial skepticism and disappointment
  with early AI coding tools to developing complex applications rapidly. The arc moves
  from:


  1. **Defining "Vibe Coding":** Alan critiques the term, equating it to "Thermomix
  coding"—where the user passively receives a result without understanding or thinking,
  leading to disappointment.

  2. **The Addictive Cycle:** Alan details his early, frustrating loop of prompting,
  receiving flawed code, copying errors back, and repeating—a cycle he likens to **Pachinko
  addiction**, driven by the unfulfilled promise of instant success.

  3. **The Shift to Abstraction:** The turning point came when Alan realized AI could
  function as a new, higher **level of abstraction**, similar to the evolution from
  assembly to high-level languages.

  4. **"Mecha Coding" (Exoskeleton):** He redefines productive AI use as "Mecha Coding,"
  where the developer acts as the pilot controlling a powerful external system (the
  LLM) to expand their capabilities, requiring proficiency in piloting (prompting/guiding).

  5. **Actionable Success:** Alan shares the successful development of a personalized
  iOS birthday reminder app in less than a day, illustrating how strategic prompting
  overcame technical hurdles.


  ### 2. Major Topics, Themes, and Subject Areas Covered


  * **AI-Assisted Coding Methodologies:** Vibe Coding, Thermomix Coding, Pachinko
  Coding, Mecha Coding.

  * **Psychology of AI Interaction:** Addiction cycles, cognitive load, the frustration
  of being "wise and stupid at the same time."

  * **Software Development Evolution:** AI as the next major level of abstraction
  (comparing it to the shift from bits to assembly to OOP).

  * **Practical Application:** Developing personal tools (birthday reminder app) and
  client-side data processing (JIRA/Azure DevOps queries in Python).

  * **Tooling:** Mention of ChatGPT (early versions), Adept (open-source preference),
  and Cloud Code (current use due to subsidized tokens).


  ### 3. Technical Concepts, Methodologies, or Frameworks Discussed


  * **Levels of Abstraction:** The core framework used to understand AI''s role in
  development, allowing developers to bypass "accidental complexity."

  * **Inherent vs. Accidental Complexity:** AI helps developers bypass the accidental
  complexity (e.g., environment setup, specific language syntax) to focus on the inherent
  complexity of the business problem.

  * **TDD (Test-Driven Development):** Alan explicitly instructs the LLM to adhere
  to TDD principles.

  * **YAGNI (You Ain''t Gonna Need It):** A key principle used in later, successful
  prompting to force the AI to generate the simplest possible solution.

  * **Convention Files (e.g., `conventions.md`):** Pre-prepared prompt instructions
  defining hygienic coding standards (linting, testing, refactoring checks).


  ### 4. Business Implications and Strategic Insights


  * **Productivity Gains for Non-Experts:** Alan, despite not being an expert in Swift,
  rapidly built a functional iOS app, suggesting AI democratizes development for domain
  experts who lack deep coding proficiency in specific stacks.

  * **Cost vs. Value:** The realization that expensive models ($2.50 per round) were
  not inherently better than cheaper ones, and that high token spending ($20+ per
  day) often resulted in unmaintainable, complex code ("drunk PhD with amnesia").

  * **Focus Shift:** Strategic value moves from mastering syntax and tooling overhead
  (accidental complexity) to defining clear requirements and architectural decisions.


  ### 5. Key Personalities, Experts, or Thought Leaders Mentioned


  * **Alan Simont:** The guest, sharing his hands-on, evolving experience.

  * **Vasco:** The host, framing the discussion and providing context.

  * **Yuval Noah Harari:** Mentioned in reference to the concept of humans becoming
  "slaves" to technology (the potato analogy).

  * **Martin Fowler:** Quoted regarding the potential for AI to represent a new level
  of abstraction in software development.


  ### 6. Predictions, Trends, or Future-Looking Statements


  * **Mecha Coding as the Future:** The successful model involves the developer acting
  as a proficient pilot, guiding a powerful tool, rather than passively receiving
  output.

  * **Limitations for Enterprise:** Alan explicitly states that this highly abstract,
  "pestering" approach might **not work for enterprise-grade software**, suggesting
  complexity requires more rigorous human oversight.


  ### 7. Practical Applications and Real-World Examples


  * **Personal Project:** Developing a simple, custom birthday reminder app with "pestering
  mode" for gift reminders, which previously stalled when attempted with standard
  development practices.

  * **Client Work:** Using Python agents to query and process data from JIRA/Azure
  DevOps, even when the developer wasn''t deeply familiar with the specific Python
  libraries required for the task.


  ### 8. Controversies, Challenges, or Problems Highlighted


  * **The Pachinko Trap:** The primary challenge is the psychological loop where the
  user invests time and money chasing a successful output, leading to wasted effort
  on overly complex or incorrect code.

  * **Code Quality Degradation:** Uncontrolled AI output often leads to "horribly
  complicated, complex" code that the user cannot easily fix or'
tags:
- artificial-intelligence
- generative-ai
- ai-infrastructure
- startup
title: Pachinko Coding—What They Don't Tell You About Building Apps with Large Language
  Models | Alan Cyment
topics:
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 84
  prominence: 1.0
  topic: artificial intelligence
- keywords:
  - generative ai
  - genai
  - chatgpt
  - gpt
  - claude
  - text generation
  - image generation
  mentions: 8
  prominence: 0.8
  topic: generative ai
- keywords:
  - gpu
  - tensor
  - training
  - inference
  - model deployment
  - vector database
  mentions: 1
  prominence: 0.1
  topic: ai infrastructure
- keywords:
  - startup
  - entrepreneur
  - founder
  - venture
  mentions: 1
  prominence: 0.1
  topic: startup
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-10-08 14:03:31 UTC -->
