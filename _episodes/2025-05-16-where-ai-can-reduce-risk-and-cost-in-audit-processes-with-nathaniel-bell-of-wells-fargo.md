---
companies:
- category: unknown
  confidence: medium
  context: Welcome everyone to the AI and Business Podcast. I'm Matthew Demello, editorial
    director here at
  name: Business Podcast
  position: 31
- category: unknown
  confidence: medium
  context: come everyone to the AI and Business Podcast. I'm Matthew Demello, editorial
    director here at Emerge AI Research. T
  name: Matthew Demello
  position: 53
- category: unknown
  confidence: medium
  context: . I'm Matthew Demello, editorial director here at Emerge AI Research. Today's
    guest is Nathaniel Bell, director of Dat
  name: Emerge AI Research
  position: 97
- category: unknown
  confidence: medium
  context: ctor here at Emerge AI Research. Today's guest is Nathaniel Bell, director
    of Data Management at Wells Fargo. Nath
  name: Nathaniel Bell
  position: 134
- category: unknown
  confidence: medium
  context: rch. Today's guest is Nathaniel Bell, director of Data Management at Wells
    Fargo. Nathaniel returns to the show to
  name: Data Management
  position: 162
- category: unknown
  confidence: medium
  context: is Nathaniel Bell, director of Data Management at Wells Fargo. Nathaniel
    returns to the show to share how AI is
  name: Wells Fargo
  position: 181
- category: unknown
  confidence: medium
  context: back to the program. It's a pleasure having you. Thanks Matt. I'm glad
    to be here. Thanks for having me on the
  name: Thanks Matt
  position: 1105
- category: unknown
  confidence: medium
  context: g to deploy AI of any kind? Sure. Great question. So I would say from my
    experience, risk management and
  name: So I
  position: 1845
- category: unknown
  confidence: medium
  context: ancing our decision-making abilities. Absolutely. And I think just on the
    point of agentic AI, we'll get
  name: And I
  position: 2554
- category: unknown
  confidence: medium
  context: tive AI, the LLM explosion, ChatGPT's kind of big Ed Sullivan moment a
    few years ago, I think we kind of had th
  name: Ed Sullivan
  position: 2784
- category: unknown
  confidence: medium
  context: ays to go even before I'm touching an agentic AI. Agentic AI, oh, not that
    far away. You know, much more akin
  name: Agentic AI
  position: 3318
- category: unknown
  confidence: medium
  context: human on the phone to make sure that we do this. But I think it is recognizing
    that sometimes somebody i
  name: But I
  position: 15208
- category: unknown
  confidence: medium
  context: k channel in a Teams meeting, but they don't have Social Security cards
    so to speak. And that's one of the various
  name: Social Security
  position: 22933
- category: unknown
  confidence: medium
  context: general. The death of those jobs is to paraphrase Mark Twain long been
    over rumored, long been exaggerated. I'
  name: Mark Twain
  position: 23659
- category: unknown
  confidence: medium
  context: rd. Yeah, I think I would tend to agree with you. Now I have a very pragmatic
    outlook, maybe the visionar
  name: Now I
  position: 23902
- category: unknown
  confidence: medium
  context: pecific conversation than it was a few years ago. Now C-suite really understand
    this stuff. Their kids ar
  name: Now C
  position: 25149
- category: unknown
  confidence: medium
  context: tGPT, or maybe they're getting better out of her. All I know is, but there's
    a much more sophisticated co
  name: All I
  position: 25306
- category: ai_research
  confidence: high
  context: The podcast host's organization, which focuses on AI research.
  name: Emerge AI Research
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: The organization where the guest (Nathaniel Bell) is the Director of Data
    Management, applying AI in internal audit workflows.
  name: Wells Fargo
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: The sponsor of the special series on AI and financial workflows.
  name: Mindbridge
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as the catalyst for the LLM explosion and a common reference
    point for generative AI capabilities.
  name: ChatGPT
  source: llm_enhanced
- category: media/organization
  confidence: high
  context: The platform hosting the conversation, indicating an audience interested
    in the business application and strategy of AI.
  name: AI and Business Podcast
  source: llm_enhanced
date: 2025-05-16 06:00:00 +0000
duration: 30
has_transcript: false
insights:
- actionable: true
  confidence: medium
  extracted: be taxed based on these factors that I, that I deployed AI in very simple
    deterministic use cases to go find
  text: we should be taxed based on these factors that I, that I deployed AI in very
    simple deterministic use cases to go find.
  type: recommendation
layout: episode
llm_enhanced: true
original_url: https://traffic.libsyn.com/secure/techemergence/Business_-_5.16.25_-_Nathaniel_Bell_Ep_1.mp3?dest-id=151434
processing_date: 2025-10-05 17:08:04 +0000
quotes:
- length: 159
  relevance_score: 4
  text: I'm wondering, especially because agentic seems to be an extension of what
    we saw five, six years ago with the chatbot problem, right, versus conversational
    AI
  topics: []
- impact_reason: 'A crucial strategic insight: organizations should prioritize deploying
    ''simple AI'' (deterministic/rules-based) for immediate efficiency gains rather
    than waiting for advanced agentic models.'
  relevance_score: 10
  source: llm_enhanced
  text: AI can really benefit, as you said, simple AI doesn't have to be the brand
    new agentic models that everybody is talking about.
  topic: strategy
- impact_reason: Describes the shift from granular, siloed risk identification to
    holistic, firm-wide risk pattern detection enabled by AI analysis.
  relevance_score: 10
  source: llm_enhanced
  text: if we can use those models to pull that complex data analysis together, right?
    And then say, hey, this is what it's we're seeing. This seems to be a problem,
    not in this particular service, in this particular service, right? Across your
    services, this is an issue...
  topic: predictions
- impact_reason: 'Actionable business advice for AI deployment in conservative industries:
    target high-value, non-mission-critical areas first to build trust and demonstrate
    ROI.'
  relevance_score: 10
  source: llm_enhanced
  text: prevailing wisdom, wisdom is choose an important, but not do-or-die space,
    something important to the business to deploy this technology. Don't deploy it
    as a toy...
  topic: business
- impact_reason: 'Identifies a common organizational failure point: failing to aggregate
    small, siloed automation wins into a significant, enterprise-wide efficiency gain.'
  relevance_score: 10
  source: llm_enhanced
  text: these use cases are developed in teams, right? Again, at that kind of service
    level, they're granular and no one, because they're siloed, no one is taking them
    collectively to say, yeah, these are a bunch of small ones that we could fix,
    we could deploy. Collectively, it really fixes some problems.
  topic: business
- impact_reason: 'Articulates a fundamental legal/accountability challenge for AI
    deployment: the lack of recourse or liability transfer when an autonomous system
    fails.'
  relevance_score: 10
  source: llm_enhanced
  text: I can't hold an AI model accountable. Yeah, big problem. You can't punish,
    you can't fire an AI model, you can't punish them, you can't give them administrative
    leave.
  topic: safety
- impact_reason: 'This is a powerful metaphor for modern enterprise AI strategy: executives
    demand incremental, demonstrable value (the ''crumbs'') before committing to a
    grand, long-term vision.'
  relevance_score: 10
  source: llm_enhanced
  text: We have a much more sophisticated conversation of, okay, we see your vision,
    but I need the crumbs to get there. I need the trail of crumbs to get to the vision.
  topic: Business/Strategy
- impact_reason: 'This clearly defines the core pain point in audit/risk management
    that AI is intended to solve: manual complexity and high stakeholder overhead.'
  relevance_score: 9
  source: llm_enhanced
  text: risk management and audit processes are usually highly manual. They're very
    complex, and there's a lot of stakeholders involved.
  topic: business
- impact_reason: 'Provides a concise, executive-friendly definition of agentic AI
    focusing on its core capability: cross-platform task execution.'
  relevance_score: 9
  source: llm_enhanced
  text: Agentic AI, oh, not that far away. You know, much more akin to what we've
    been seeing on the conversational AI side, really is like in terms of the specific
    step-level change and painting with a broad brush here, but it's really the ability
    to jump between programs, jump between platforms to accomplish tasks.
  topic: technical
- impact_reason: A cautionary note on the current limitations of advanced AI (like
    agentic systems) in high-stakes environments like finance, emphasizing the need
    for human oversight.
  relevance_score: 9
  source: llm_enhanced
  text: I think we're not quite ready in so many industries, so many contexts to be
    handing over the keys for a lot of really important decision-making yet.
  topic: safety
- impact_reason: 'Directly addresses the current value proposition of human capital:
    high-level reasoning and judgment that current models cannot replicate effectively.'
  relevance_score: 9
  source: llm_enhanced
  text: Where are we seeing, especially for risk and compliance, the higher-level
    thinking where human beings have, have a lot better ROI right now, even than reasoning
    models or maybe some of the advanced stuff we see from agentic coming down the
    pike.
  topic: strategy
- impact_reason: 'Highlights the ultimate strategic benefit of widespread, even simple,
    AI deployment: breaking down data silos to enable cross-functional insights.'
  relevance_score: 9
  source: llm_enhanced
  text: The best part of AI can be when you have the systems fully implemented in
    the in these silos, but then they can end up talking to each other. And you can
    have a lot of crossover, you can start to see different insights and problems.
  topic: strategy
- impact_reason: A relatable critique of current reporting workflows, emphasizing
    the inefficiency of iterative 'drill-down' requests that force manual data retrieval
    across systems.
  relevance_score: 9
  source: llm_enhanced
  text: All right, here's a report. Okay, great. Well, let's double-click on that,
    right? I'm thinking everybody out on your audience has been there and done that,
    right? Double-click. Sure. You want more information. Okay, I'll get you more
    information, which is going back to the well of one, two, three, five systems
    to pull that information in, right?
  topic: business
- impact_reason: 'Addresses the critical organizational change management aspect of
    AI adoption: the need to re-skill and elevate human roles rather than simply replace
    them.'
  relevance_score: 9
  source: llm_enhanced
  text: It's not an overnight process. Not even just for, oh, hey, we don't want to
    lay these people off or we want to make sure everybody's elevated and feels valued
    in their jobs is being pushed to higher-level tasks...
  topic: strategy
- impact_reason: 'Provides a crucial status check on Agentic AI adoption in regulated
    industries: promising use cases exist, but widespread adoption is still pending.'
  relevance_score: 9
  source: llm_enhanced
  text: We'll talk about agentic AI. Here we are. Knowing that this is, a lot of this
    stuff is on the horizon. Correct me if I'm wrong, we've had a lot of conversation
    with folks on the show, especially in regulated industries. We're seeing promising
    use cases. We're not seeing a lot of widespread adoption just yet. Still, still
    very much on the horizon.
  topic: predictions
- impact_reason: Positions Agentic AI as a significant, potentially revolutionary
    step change beyond conversational AI, focusing on workflow transformation.
  relevance_score: 9
  source: llm_enhanced
  text: Now with agentic AI, I was describing a little bit of the step-level change
    before, but I'm sure as we get into the use cases, we can be more specific. But
    this really stands to really revolutionize a couple workflows.
  topic: predictions
- impact_reason: 'Poses a critical question for buyers and implementers: how to distinguish
    true agentic capabilities from marketing hype (i.e., advanced chatbots).'
  relevance_score: 9
  source: llm_enhanced
  text: What is going to be the defining line for them in terms of this is real agentic
    AI? And this is, it's a chatbot, especially for where we see it from third-party
    vendors.
  topic: business
- impact_reason: 'Brings the conversation back to the fundamental business requirement:
    proving that the investment in advanced AI (compute, governance) yields sufficient
    return.'
  relevance_score: 9
  source: llm_enhanced
  text: I think the other aspect is going to be ROI. I know that gets overplayed,
    but... at some point, is this AI and all the governance and all the compute power
    and all the spend that we're doing, is the juice worth the squeeze?
  topic: business
- impact_reason: States the current, near-universal requirement for human oversight
    in financial services deployments, emphasizing risk aversion.
  relevance_score: 9
  source: llm_enhanced
  text: I think from what I've seen, the financial service industry is very much for
    anything that we deploy, we have a human in the loop, right? Like it's almost,
    yeah. I'm just going to say that we don't.
  topic: safety
- impact_reason: Contrasts the cautious adoption in finance with the vision in manufacturing/pharma,
    where humans shift to high-level management/strategy roles overseeing digital
    agents ('robot soldiers').
  relevance_score: 9
  source: llm_enhanced
  text: When you talk to folks in pharmaceuticals, manufacturing, like they're even
    more cautious about the agentic AI, but they do see this future where a lot more
    of the human work actually is more like you're the general and you've got a bunch
    of robot soldiers.
  topic: predictions
- impact_reason: Notes the maturation of executive understanding of AI, shifting the
    conversation from abstract vision to demanding incremental, demonstrable ROI ('crumbs')
    for large-scale transformation.
  relevance_score: 9
  source: llm_enhanced
  text: Now C-suite really understand this stuff. Their kids are, you know, writing
    book, bad book reports with ChatGPT... But there's a much more sophisticated conversation
    of, okay, we see your vision, but we need, I need the crumbs to get there. I need
    the trail of crumbs to get to the vision.
  topic: business
- impact_reason: Highlights the necessity of human oversight and final sign-off, even
    when leveraging advanced AI, reinforcing the concept of human-in-the-loop for
    deployment.
  relevance_score: 9
  source: llm_enhanced
  text: if we're implementing something, if we're rolling out a new product, any of
    those types of things, there needs to be that human to say, yes, we are doing
    it.
  topic: Strategy/Implementation
- impact_reason: 'This frames the classic strategic tension in technology adoption:
    balancing immediate financial justification (short-term ROI) against long-term
    strategic goals.'
  relevance_score: 9
  source: llm_enhanced
  text: Here we get into short-term ROI, the short-term wins, and then the longer
    vision.
  topic: Business/Strategy
- impact_reason: Directly links the necessity of short-term wins to securing executive
    confidence and funding for larger AI initiatives.
  relevance_score: 9
  source: llm_enhanced
  text: And if there's no trail of crumbs, if there are no short-term wins, it's not
    going to really pay for itself, or at least give me that kind of confidence.
  topic: Business/ROI
- impact_reason: Poses a critical forward-looking question regarding how the upcoming
    wave of autonomous (agentic) AI will alter the required cadence of demonstrable
    ROI.
  relevance_score: 9
  source: llm_enhanced
  text: especially as agentic AI comes down the pike, what do you think those short-term
    wins are going to be versus [the long-term vision]?
  topic: Predictions/Agentic AI
- impact_reason: Describes the initial, often rigid, roadmap many executives perceived
    for AI adoption (Deterministic -> Generative).
  relevance_score: 8
  source: llm_enhanced
  text: I think when we started with generative AI, the LLM explosion, ChatGPT's kind
    of big Ed Sullivan moment a few years ago, I think we kind of had this model of,
    you got to start with the deterministic and then work your way up to the generative.
  topic: strategy
- impact_reason: 'Highlights the perfect initial use case for automation in compliance:
    highly structured, binary, rules-based tasks.'
  relevance_score: 8
  source: llm_enhanced
  text: a lot of just fill in this form, check this box, make sure you're following
    the rules. It's right there in the name. It's rules-based. It's a, you're either
    doing it or you're not.
  topic: technical
- impact_reason: Explains a practical application of LLMs in summarizing complex,
    structured information (like codified taxonomies) into actionable executive summaries.
  relevance_score: 8
  source: llm_enhanced
  text: I mean, kind of what large language models do, right? Let's pull it together.
    And then the taxonomy codify that in something that's AI-based to then spit out
    at the end that results to say, here you go. This is where you should look at
    it.
  topic: technical
- impact_reason: Acknowledges the significant technical debt and reliance on physical
    documents that slows down digital transformation and AI adoption in banking.
  relevance_score: 8
  source: llm_enhanced
  text: Financial services, it's still a very paper industry, a lot of legacy tech
    stacks out there.
  topic: business
- impact_reason: Uses a powerful metaphor ('aircraft carriers') to explain the inertia
    and difficulty of changing core, large-scale processes in major financial institutions.
  relevance_score: 8
  source: llm_enhanced
  text: I always make, you know, especially with the very large organizations, I'm
    always talking about them like aircraft carriers. Those big workflows, those big
    processes, even where they're like the kind of the spine of the division. It's
    hard to, you know, decommission the aircraft carrier.
  topic: strategy
- impact_reason: 'Highlights a key organizational barrier to realizing large-scale
    AI/automation benefits: siloed, granular use case development preventing collective
    impact assessment and deployment.'
  relevance_score: 8
  source: llm_enhanced
  text: you know, these use cases are developed in teams, right? Again, at that kind
    of service level, they're granular and no one, because they're siloed, no one
    is taking them collectively to say, yeah, these are a bunch of small ones that
    we could fix, we could deploy. Collectively, it really fixes some problems.
  topic: strategy
- impact_reason: 'Clearly delineates the functional limitation of older chatbot technology
    versus more advanced AI systems: answering vs. problem-solving.'
  relevance_score: 8
  source: llm_enhanced
  text: Chatbots can just answer a question whether it's accurate or not. They can
    keep a customer on the phone. They can't solve a problem.
  topic: technical
- impact_reason: 'Identifies the ideal initial deployment area for Agentic AI: high-volume,
    low-variability service calls where human agents already follow scripts.'
  relevance_score: 8
  source: llm_enhanced
  text: I think it is recognizing that sometimes somebody is calling to service alone.
    There's various prescriptive steps that they go through. They know what they want
    to do. And those back to what we said before, right? When a human is on the phone,
    they're actually probably following a script anyway.
  topic: business
- impact_reason: Notes a shift in industry thinking away from purely bespoke models
    toward greater acceptance of capable, out-of-the-box foundational models.
  relevance_score: 8
  source: llm_enhanced
  text: I think another big change that we saw from even a couple years ago... everybody
    was talking about, oh, you'll have foundational models and bespoke models. And
    it will be kind of this web of you'll have models for very specific tasks... But
    I think, you know, there was a dismissiveness of kind of out-of-the-box models.
  topic: technical
- impact_reason: 'Raises an ethical/strategic consideration about the purpose of AI
    deployment: augmentation versus complete avoidance of necessary human connection.'
  relevance_score: 8
  source: llm_enhanced
  text: Where do we also draw the line of these should be deployed to help, not deployed
    to avoid what is ultimately a human interaction?
  topic: safety
- impact_reason: Positions AI models as the necessary technological evolution required
    to effectively process and extract value from the current explosion of data.
  relevance_score: 8
  source: llm_enhanced
  text: So I also, you AI is kind of that natural evolution that we have so much data
    for us to really be effective. We have to bring it somehow. And these AI models,
    I think, are the answer to some of that.
  topic: technical
- impact_reason: 'Defines the role of the human in the loop for information retrieval:
    confirming AI synthesis, but benefiting from massive speed gains in data gathering.'
  relevance_score: 8
  source: llm_enhanced
  text: I am still going to want to make sure I confirm that. Yeah. I am the human
    in the loop at that point, but it really helps me gather a lot of the information
    that I need much quicker that I could probably do today.
  topic: safety
- impact_reason: 'Reinforces the current practical role of AI: data preparation and
    decision support, with humans retaining final implementation authority.'
  relevance_score: 8
  source: llm_enhanced
  text: We can use them to really wrangle, gather the data so that we can make informed
    decisions and figure out the best way to implement. But at the end of the day,
    there's a human or humans that are going to implement those products or implement
    that program, right?
  topic: strategy
- impact_reason: Addresses the psychological barrier to AI adoption—the need for human
    assurance and control—which is crucial for organizational buy-in.
  relevance_score: 8
  source: llm_enhanced
  text: at the end of the day, there's a human or humans that are going to implement
    those products or implement that program, right? And to your point, I think that
    gives everybody more comfort that there are some saying, what's going on?
  topic: Strategy/Adoption
- impact_reason: Identifies risk aversion as a primary inhibitor to AI adoption, directly
    linking it back to the accountability problem.
  relevance_score: 8
  source: llm_enhanced
  text: especially in an industry that is risk-averse, we come back to that, I can't
    hold an AI model accountable.
  topic: Strategy/Adoption
- impact_reason: Illustrates the boundary where deterministic AI struggles—areas requiring
    subjective judgment, which remains the domain of humans.
  relevance_score: 7
  source: llm_enhanced
  text: transfer pricing in global taxes... can be a little bit more of an art than
    a science.
  topic: strategy
- impact_reason: Provides context on the deep-seated risk aversion in highly regulated
    fields (nuclear, finance), explaining the slow pace of adoption.
  relevance_score: 7
  source: llm_enhanced
  text: I think that like you said, risk-averse in my particular industry and my experience
    all the way back to when I was in the nuclear space, right? Everybody's risk-averse
    there.
  topic: strategy
- impact_reason: Uses a strong metaphor ('aircraft carrier') to describe large, entrenched
    organizational processes, explaining why systemic change is difficult, even when
    smaller changes are easy.
  relevance_score: 7
  source: llm_enhanced
  text: Those big workflows, those big processes, even where they're like the kind
    of the spine of the division. It's hard to, you know, decommission the aircraft
    carrier.
  topic: strategy
- impact_reason: Offers a specific, actionable deployment recommendation for Agentic
    AI in customer service contexts.
  relevance_score: 7
  source: llm_enhanced
  text: I think that that is at least in my opinion where I would deploy first, not
    any other institutions.
  topic: business
- impact_reason: Presents a thought-provoking scenario about AI agents interacting
    with each other, questioning the ultimate goal of automation (e.g., replacing
    recruiters entirely).
  relevance_score: 7
  source: llm_enhanced
  text: But then I'm going to make a company that makes an agentic AI agent for my
    interviewers. So now I'm going to have an agentic AI agent talk to an AI agent,
    right? You literally remove this from the conversation.
  topic: predictions
- impact_reason: Highlights the psychological and trust barriers in highly regulated/sensitive
    sectors (like finance) regarding autonomous AI decision-making.
  relevance_score: 7
  source: llm_enhanced
  text: On a deep psychological level, I'm wondering how banks, financial institutions
    are thinking about human in the loop, especially with agentic AI systems.
  topic: safety
- impact_reason: Illustrates a common, low-stakes LLM use case (information synthesis)
    that demonstrates the value of AI agents over traditional search, even with human
    confirmation.
  relevance_score: 7
  source: llm_enhanced
  text: I could give you an easy, still human in the loop, but easy topic that everybody's
    using the large language models at home for, right? I go and I want to learn about
    something, Googling or Bing-ing or whatever you do, right? Sure. Is not, is not
    enough anymore, right? So we use the AI agents to really figure it out.
  topic: technical
- impact_reason: 'A surprising observation on data devaluation: the sheer volume of
    modern data reduces the individual value of any single data point compared to
    scarce, historical data.'
  relevance_score: 6
  source: llm_enhanced
  text: And you can talk about how every bit of data today is less valuable than what
    a piece of data was 40 years ago, right? The data four years ago had a lot, a
    lot of value.
  topic: strategy
source: Unknown Source
summary: '## Podcast Episode Summary: Where AI Can Reduce Risk and Cost in Audit Processes
  - with Nathaniel Bell of Wells Fargo


  This 29-minute episode features Nathaniel Bell, Director of Data Management at Wells
  Fargo, discussing the practical, proven application of AI, particularly deterministic
  models, within internal audit and risk management workflows at a major financial
  institution. The conversation emphasizes moving beyond theoretical discussions to
  focus on efficiency gains, cost reduction, and enhanced decision-making through
  automation in highly manual and complex banking processes.


  ---


  **1. Focus Area:**

  The primary focus is the **practical application of AI (specifically deterministic
  and simpler automation) in internal audit and risk compliance workflows** within
  the banking sector. Key themes include accelerating information gathering, testing
  internal controls, identifying risk patterns, and the necessary foundational capabilities
  (data quality, system integration) required for transitioning to continuous auditing.
  The discussion also touches upon the evolving roles of human oversight versus advanced
  AI (Generative and Agentic).


  **2. Key Technical Insights:**

  *   **Deterministic Models for Efficiency:** Simple, deterministic (rules-based)
  AI deployments are already delivering significant efficiency and cost savings by
  automating highly manual tasks like form filling and rule checking, even in complex
  areas.

  *   **Shifting from Granular to Holistic Risk View:** AI''s strength lies in aggregating
  granular data analysis across multiple services or silos to present high-level,
  firm-wide risk patterns to executive leadership, something difficult to achieve
  through traditional manual reviews.

  *   **Taxonomy Codification:** Applying AI/LLMs to codify existing, rule-based taxonomies
  allows for faster information retrieval and conversational querying, replacing inefficient
  "double-clicking" through reports to find underlying data.


  **3. Business/Investment Angle:**

  *   **Cost Savings via Efficiency:** The immediate ROI comes from increasing productivity
  and reducing the time spent on manual data gathering and control testing, even from
  seemingly small, siloed use cases when aggregated.

  *   **Risk Aversion Dictates Deployment:** Financial services leaders are risk-averse,
  preferring to deploy AI in important but non-critical areas first to prove value
  before scaling, leading to potential siloed implementations.

  *   **The Need for Foundational Capabilities:** Successful transition to continuous
  auditing and broader AI adoption hinges on strong foundational elements like **data
  quality** and **system integration** to ensure data flows across organizational
  silos.


  **4. Notable Companies/People:**

  *   **Nathaniel Bell (Wells Fargo):** The expert guest, providing real-world perspective
  from a major financial institution on current AI deployments in audit.

  *   **Wells Fargo:** Used as the primary case study for practical, proven AI implementation
  in a highly regulated environment.

  *   **Mindbridge:** Mentioned as the sponsor of this special series on AI and financial
  workflows.


  **5. Future Implications:**

  *   **Agentic AI Caution:** While agentic AI promises significant workflow revolution
  (e.g., jumping between platforms), widespread adoption in high-stakes regulated
  environments like banking is still on the horizon, requiring significant trust and
  governance.

  *   **Human Role Evolution:** The future role of human auditors/analysts will shift
  from manual data wrangling to higher-level decision-making, acting as "generals"
  overseeing automated agents, though complete removal of human oversight is unlikely
  due to accountability issues.

  *   **Human-in-the-Loop is Mandatory:** Due to regulatory and accountability requirements,
  a human must remain in the loop to confirm decisions, especially in critical processes,
  contrasting with the potential for "AI agent talking to AI agent" scenarios in less
  sensitive areas.


  **6. Target Audience:**

  This episode is highly valuable for **Audit and Compliance Leaders, Risk Management
  Professionals, Data Governance Officers, and Technology Strategists** within heavily
  regulated industries (especially Financial Services) who need practical insights
  on deploying current-generation AI tools rather than waiting for future, unproven
  technologies.'
tags:
- artificial-intelligence
- generative-ai
title: Where AI Can Reduce Risk and Cost in Audit Processes - with Nathaniel Bell
  of Wells Fargo
topics:
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 67
  prominence: 1.0
  topic: artificial intelligence
- keywords:
  - generative ai
  - genai
  - chatgpt
  - gpt
  - claude
  - text generation
  - image generation
  mentions: 11
  prominence: 1.0
  topic: generative ai
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-10-05 17:08:04 UTC -->
