---
companies:
- category: unknown
  confidence: medium
  context: Welcome back to the Stanford Psychology Podcast. I'm Souda Karajah, a pre-doctoral
    fellow at Stan
  name: Stanford Psychology Podcast
  position: 20
- category: unknown
  confidence: medium
  context: come back to the Stanford Psychology Podcast. I'm Souda Karajah, a pre-doctoral
    fellow at Stanford University. I'
  name: Souda Karajah
  position: 53
- category: unknown
  confidence: medium
  context: cast. I'm Souda Karajah, a pre-doctoral fellow at Stanford University.
    I'm excited to be joining the show as one of you
  name: Stanford University
  position: 93
- category: unknown
  confidence: medium
  context: today, I'm so happy to share my conversation with Professor D. Young, whose
    research I've long admired and who
  name: Professor D
  position: 245
- category: unknown
  confidence: medium
  context: tment at Stanford University, affiliated with the Stanford Natural Language
    Processing Group, Stanford Human Computer Interaction Group, Stanf
  name: Stanford Natural Language Processing Group
  position: 509
- category: unknown
  confidence: medium
  context: h the Stanford Natural Language Processing Group, Stanford Human Computer
    Interaction Group, Stanford AI Lab, and Stanford Human Center, Art
  name: Stanford Human Computer Interaction Group
  position: 553
- category: unknown
  confidence: medium
  context: Group, Stanford Human Computer Interaction Group, Stanford AI Lab, and
    Stanford Human Center, Art Schilling-Telgent
  name: Stanford AI Lab
  position: 596
- category: unknown
  confidence: medium
  context: Computer Interaction Group, Stanford AI Lab, and Stanford Human Center,
    Art Schilling-Telgent Center. She is also leadin
  name: Stanford Human Center
  position: 617
- category: unknown
  confidence: medium
  context: roup, Stanford AI Lab, and Stanford Human Center, Art Schilling-Telgent
    Center. She is also leading the Social an
  name: Art Schilling
  position: 640
- category: unknown
  confidence: medium
  context: AI Lab, and Stanford Human Center, Art Schilling-Telgent Center. She is
    also leading the Social and Language Tech
  name: Telgent Center
  position: 654
- category: unknown
  confidence: medium
  context: elgent Center. She is also leading the Social and Language Technologies
    Lab, where they study socially aware natural lang
  name: Language Technologies
  position: 705
- category: unknown
  confidence: medium
  context: elgent Center. She is also leading the Social and Language Technologies
    Lab, where they study socially aware natural language
  name: Language Technologies Lab
  position: 705
- category: unknown
  confidence: medium
  context: pproach to research, along with her recent paper, Social Skill Training
    with Large Language Models, which introduces a ne
  name: Social Skill Training
  position: 1193
- category: unknown
  confidence: medium
  context: with her recent paper, Social Skill Training with Large Language Models,
    which introduces a new framework that supports m
  name: Large Language Models
  position: 1220
- category: unknown
  confidence: medium
  context: raining in computer science and machine learning. When I moved to the US,
    I got very fascinated by differe
  name: When I
  position: 3987
- category: unknown
  confidence: medium
  context: lly got excited about all these kinds of factors. And I realized that language
    or language technology is
  name: And I
  position: 4453
- category: unknown
  confidence: medium
  context: a large language model training framework called AI Partner AI Mentor that
    makes social skills training more accessible
  name: AI Partner AI Mentor
  position: 7795
- category: unknown
  confidence: medium
  context: as quite a challenging one when I first got here. So I always want to learn
    all sorts of social skills.
  name: So I
  position: 8262
- category: unknown
  confidence: medium
  context: I think you mentioned our framework. It's called AI Partner and AI Mentor.
    I use it as more like a conceptual
  name: AI Partner
  position: 9965
- category: unknown
  confidence: medium
  context: ntioned our framework. It's called AI Partner and AI Mentor. I use it as
    more like a conceptual framework to
  name: AI Mentor
  position: 9980
- category: unknown
  confidence: medium
  context: on. Then you can actually talk to the AI Partner. This AI Partner there
    might be a roleplay of your roommate. And t
  name: This AI Partner
  position: 10220
- category: unknown
  confidence: medium
  context: ou can practice different types of conversations. And AI Mentor is tailored
    in a way that we will bring in or bui
  name: And AI Mentor
  position: 10578
- category: unknown
  confidence: medium
  context: main expertise into specific models so that those AI Mentors can actually
    give you very realistic feedback. So
  name: AI Mentors
  position: 10696
- category: unknown
  confidence: medium
  context: to a group of people, then you can have multiple AI Partners there. You
    can even have different AI Mentors. So
  name: AI Partners
  position: 11020
- category: ai_research_institution
  confidence: high
  context: The host and interviewee are affiliated with Stanford. The interviewee
    is in the Computer Science department and affiliated with several labs there.
  name: Stanford University
  source: llm_enhanced
- category: ai_research_institution
  confidence: high
  context: Affiliation of the professor being interviewed.
  name: Stanford Natural Language Processing Group
  source: llm_enhanced
- category: ai_research_institution
  confidence: high
  context: Affiliation of the professor being interviewed.
  name: Stanford Human Computer Interaction Group
  source: llm_enhanced
- category: ai_research_institution
  confidence: high
  context: Affiliation of the professor being interviewed.
  name: Stanford AI Lab
  source: llm_enhanced
- category: ai_research_institution
  confidence: medium
  context: Affiliation of the professor being interviewed (likely a typo/mishearing
    for a specific center name at Stanford).
  name: Stanford Human Center, Art Schilling-Telgent Center
  source: llm_enhanced
- category: ai_research_lab
  confidence: high
  context: The lab led by the interviewee, focusing on socially aware NLP.
  name: Social and Language Technologies Lab
  source: llm_enhanced
- category: ai_technology_class
  confidence: high
  context: Mentioned frequently as the core technology being researched and applied
    (e.g., AI Partner, AI Mentor). While not a specific company, it refers to the
    class of models developed by major players.
  name: Large Language Models (LLMs)
  source: llm_enhanced
- category: ai_application_framework
  confidence: high
  context: A conceptual framework/agent built using LLMs for role-playing practice
    scenarios.
  name: AI Partner
  source: llm_enhanced
- category: ai_application_framework
  confidence: high
  context: A conceptual framework/agent built using LLMs to provide coaching and feedback.
  name: AI Mentor
  source: llm_enhanced
- category: ai_application_system
  confidence: high
  context: A specific system built using the AI Partner/Mentor framework to help practice
    conflict resolution.
  name: Rehearsal
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: The research group is working with the medical school at Stanford to evaluate
    how students use the CARE system in therapy training classes.
  name: Stanford
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: A system developed for novice counselors to practice with AI patients and
    receive feedback from an AI Mentor, evaluated with around 100 counselors.
  name: CARE
  source: llm_enhanced
date: 2025-10-02 19:00:00 +0000
duration: 43
has_transcript: false
insights:
- actionable: false
  confidence: medium
  extracted: this type of human-AI collaboration, particularly in the fields traditionally
    focused on human interaction like therapy, education, or any system like this?
    Yeah, I think this
  text: the future of this type of human-AI collaboration, particularly in the fields
    traditionally focused on human interaction like therapy, education, or any system
    like this? Yeah, I think this is a great question.
  type: prediction
layout: episode
llm_enhanced: true
original_url: https://audio.listennotes.com/e/p/f4621f8c3cec4d7b9255441cd78d4fb0/
processing_date: 2025-10-06 03:48:47 +0000
quotes:
- length: 292
  relevance_score: 4
  text: Her research goal is to better understand human communication and social context
    and build socially aware language technologies via methods of MLP, deep learning
    and machine learning, as well as theories in social sciences and linguistics to
    support human-human and human-computer interaction
  topics: []
- length: 274
  relevance_score: 4
  text: In today's episode, we discussed her interdisciplinary approach to research,
    along with her recent paper, Social Skill Training with Large Language Models,
    which introduces a new framework that supports making social skills trainings
    more available, accessible, and inviting
  topics: []
- length: 77
  relevance_score: 4
  text: Before that, I did a lot of training in computer science and machine learning
  topics: []
- impact_reason: Highlights the crucial need to consider the societal impact (ethics/safety)
    as an integral part of NLP development, not an afterthought.
  relevance_score: 10
  source: llm_enhanced
  text: The last dimension is what I call implication or social implication. It refers
    to the broader impact of the NLP system on society, including understanding both
    the positive and negative effects.
  topic: safety/strategy
- impact_reason: A powerful encapsulation of the human-centric nature of AI development,
    emphasizing that biases and decisions exist at every stage.
  relevance_score: 10
  source: llm_enhanced
  text: The data comes from humans, the model is produced by humans, the choices to
    build architecture are made by humans, and even the end product is for humans.
  topic: safety/strategy
- impact_reason: A clear warning about the severe consequences of ignoring human factors,
    specifically mentioning misalignment, trust erosion, and psychological impact.
  relevance_score: 10
  source: llm_enhanced
  text: If we do not pay attention to those human-centric aspects, I think the consequences
    could be huge and really consequential in many ways. For example, our systems
    may not be aligned with human behavior. And in addition to the system themselves,
    when it comes to people, you imagine a lot of issues around the trust, or psychological
    impact of how AI systems may influence our behavior, all of those are very important
    today.
  topic: safety/predictions
- impact_reason: 'Highlights a significant technical challenge in using LLMs for realistic
    role-playing or simulation: the tendency to over-exaggerate traits (caricature
    effect).'
  relevance_score: 10
  source: llm_enhanced
  text: models tend to create a caricature and they tend to amplify a lot of the attributes
    if you tell them, okay, here is a specific person. So it's actually quite difficult
    to get the simulation to be realistic.
  topic: technical/limitations
- impact_reason: Details a specific, advanced technique (self-critique/self-improvement
    loop) used within the model generation process to ensure contextual appropriateness
    and realism in dynamic interactions.
  relevance_score: 10
  source: llm_enhanced
  text: We actually develop some techniques such as self-critique and self-improvement.
    So the key idea here is when the simulator, the AI Partner in the process or is
    trying to output a part of the sentence, we will try to let the model themselves,
    self-critique themselves. Like, is this a reasonable response to use here? Is
    it aligned with all the domain knowledge? Is it appropriate, etc., etc.?
  topic: technical
- impact_reason: Provides empirical evidence demonstrating the gap between declarative
    knowledge and procedural skill acquisition, validating the need for interactive
    practice systems.
  relevance_score: 10
  source: llm_enhanced
  text: We saw that people's knowledge about conflict resolution actually didn't change
    at all. Their knowledge didn't change. However, if you let them do an interactive
    conflict resolution, people who practiced with our systems actually did much better
    compared to people who haven't used the system.
  topic: business/predictions
- impact_reason: 'Offers a profound insight into learning efficacy: interactive simulation
    builds ''street smarts'' (procedural application) where traditional learning only
    builds ''book smarts'' (declarative knowledge).'
  relevance_score: 10
  source: llm_enhanced
  text: This was very, very surprising to us. But then later we realized that this
    is the difference between being book smart versus being street smart. Like it's
    more about how you use the knowledge in an interactive context rather than remembering
    the concepts or knowledge.
  topic: strategy/predictions
- impact_reason: Highlights the significant risk of over-reliance and the 'simulation-to-real-world
    difference,' a major ethical and practical concern for AI used in professional
    training.
  relevance_score: 10
  source: llm_enhanced
  text: the second kind of social-technical challenge is more about these kinds of
    scenarios that people may practice and then they may develop some kind of reliance
    there... we worry that one of the issues is this kind of over-reliance. People
    rely on the systems and not realizing that this is not what the real world of
    work looks like.
  topic: safety/ethics
- impact_reason: A direct summary of known LLM weaknesses (caricatures, bias, hallucination)
    applied specifically to the context of social simulation, emphasizing that foundational
    LLM issues persist.
  relevance_score: 10
  source: llm_enhanced
  text: a lot of the interesting issues and the limitations with large language models
    still hold here. For example, researchers found that large language models tend
    to produce caricatures when it comes to social simulation, or there may be cultural
    biases, or they might hallucinate when it comes to specific domains...
  topic: limitations/safety
- impact_reason: 'Crucial advice for aspiring researchers/builders in this field:
    the necessity of interdisciplinary expertise (computational methods + social science/insights).'
  relevance_score: 10
  source: llm_enhanced
  text: I feel like I would encourage people to have a more open mindset, understand
    the mindset about the space. It does not only require social science or social
    insights; it also requires some kind of computational methods. So I do believe
    people may want to kind of typically be both majors to get exposure to this kind
    of thing.
  topic: strategy/advice
- impact_reason: Provides a clear, high-level definition of 'socially aware language
    technology,' setting the research agenda for integrating social context into NLP.
  relevance_score: 9
  source: llm_enhanced
  text: Basically, it's about the study and the development of language technologies
    from a social perspective. The goal here is that we want to enable today's AI
    systems to better understand and respond to social signals expressed in language
    and also the broader physical and social environment.
  topic: strategy
- impact_reason: Outlines the core capabilities required for advanced, human-like
    NLP systems, moving beyond surface-level text processing to meaning and implication.
  relevance_score: 9
  source: llm_enhanced
  text: You can imagine that the socially aware systems can recognize social factors,
    such as social factors, cultural, emotion, perspectives, etc. And more importantly,
    they can help us produce or process implications and meanings behind the language
    in the same way humans do.
  topic: technical/strategy
- impact_reason: 'Identifies a key untapped application for LLMs: interactive, personalized
    training, leveraging their conversational strengths beyond traditional benchmarks
    like coding or math.'
  relevance_score: 9
  source: llm_enhanced
  text: I really want to see can they really also do well with social skills. When
    large language models get popular and the performance get very impressive, I realize
    if we use them well, it's a great way to help enable very interactive training
    because one of the big advantages of large language models is that you can have
    conversations with these AI systems and you can do a lot of chit-chat. We can
    even roleplay different characters there with large language models.
  topic: predictions/business
- impact_reason: Clearly explains the novel 'AI Partner/AI Mentor' (APAM) framework,
    detailing a practical, dual-agent system for skill acquisition.
  relevance_score: 9
  source: llm_enhanced
  text: So think about you want to learn conflict resolution. Then you can actually
    talk to the AI Partner. This AI Partner there might be a roleplay of your roommate.
    And then you practice different types of topics with this AI Partner there. And
    then the entire conversation is going to be coached by this AI Mentor.
  topic: technical/business
- impact_reason: 'Highlights a core limitation of current LLM simulation: the tendency
    to caricature rather than realistically model specific individuals, which is crucial
    for nuanced social training.'
  relevance_score: 9
  source: llm_enhanced
  text: Their simulation, like if you're going to use LLMs to simulate your roommate
    or simulate a typical learning partner, that process may not be very realistic
    because models tend to create a caricature and they tend to amplify a lot of the
    attributes if you tell them, okay, here is a specific person.
  topic: limitations
- impact_reason: Emphasizes the necessity of grounding AI development in established
    human science theories (psychology, communication) to ensure meaningful and grounded
    feedback, moving beyond purely technical metrics.
  relevance_score: 9
  source: llm_enhanced
  text: We have greater theories when it comes to social skills, from the communication
    field, from the psychology field, and also from the psychotherapy field. So we
    actually use a lot of theories from those different research fields, try to see
    whether we could let them in the development process so that a lot of the feedback
    is actually very grounded to users.
  topic: strategy/technical
- impact_reason: 'Points toward the future direction of social training AI: moving
    beyond text/voice into embodied or spatial computing (3D/physical world) to capture
    non-verbal cues.'
  relevance_score: 9
  source: llm_enhanced
  text: It's also about how you behave, your emotion, your posture, like how you do
    eye contact, a lot of those. So I think it will be very, very cool to think about
    how to make social skill training in a physical world or a 3D space so that we
    can actually bring in a lot of those to help people learn in the earlier stage.
  topic: predictions
- impact_reason: This highlights a core limitation of current knowledge recall in
    AI/training systems, emphasizing the need for interactive, contextual application
    (street smarts) over mere data retention (book smarts).
  relevance_score: 9
  source: llm_enhanced
  text: this is the difference between being book smart versus being street smart.
    Like it's more about how you use the knowledge in an interactive context rather
    than remembering the concepts or knowledge.
  topic: limitations/strategy
- impact_reason: 'A crucial cautionary note for the AI industry: tempering excitement
    with rigorous, multi-dimensional evaluation before claiming ''success'' for complex,
    real-world applications.'
  relevance_score: 9
  source: llm_enhanced
  text: I won't use the word success at this moment because it's still a very, very
    new and exciting direction. And we are trying to understand and evaluate these
    types of systems from different dimensions so that maybe in the next few years
    we could build a working system that works well when it comes to the real world.
  topic: strategy/safety
- impact_reason: Pinpoints the current modality limitation (text-only) in social AI
    and identifies the necessary technical evolution toward multimodal inputs (audio,
    visual behavior) for comprehensive social skill modeling.
  relevance_score: 9
  source: llm_enhanced
  text: the system admission is actually text-based. So you chat with AI Partner and
    then get feedback from AI Mentor. We can imagine that a lot of the social skills
    is actually more about talking or all-do or how we behave. So bringing additional
    modalities such as image or audio—that will be some of the technical challenges
    I perceive here.
  topic: technical
- impact_reason: A strong strategic call to action, urging developers to integrate
    social implication analysis alongside technical advancement, especially in socially
    sensitive AI.
  relevance_score: 9
  source: llm_enhanced
  text: I think it's a great time for us to think about how to build technology by
    not only leveraging the technical advances but also to think about a lot of the
    social implications around the space.
  topic: strategy/safety
- impact_reason: 'Articulates a philosophical role for advanced AI: not a replacement,
    but a ''support system'' or ''bridge'' enhancing human connection and understanding.'
  relevance_score: 9
  source: llm_enhanced
  text: I think this also goes back to a lot of the topics around what is the role
    of AI more broadly rather than just like socially aware AI when it comes to our
    everyday context, what are the roles of those technologies. I think I would argue
    that we want to make AI systems—socially aware AI systems—more like a support
    system, more like a bridge for human-human interaction and human-computer interaction.
  topic: strategy/philosophy
- impact_reason: Offers a structured, three-dimensional framework (Social Factors,
    Social Interactions, Social Implication) for analyzing and building socially aware
    systems.
  relevance_score: 8
  source: llm_enhanced
  text: There are three dimensions I often use when I think about socially aware language
    technologies. So the first one is what we call social factors. If you think about
    the language communication between people for a specific message, it's not only
    just about the content, it's also about who is a speaker, who is a receiver, what's
    their social relation, and what the context, gathered by what type of social norms,
    culture, and ideology, and for what type of community goals.
  topic: strategy
- impact_reason: 'Strong business/research advice: prioritize problems based on real-world,
    diverse impact rather than purely technical novelty.'
  relevance_score: 8
  source: llm_enhanced
  text: I think one side we really want to make sure the problems we are going to
    work on matter in diverse real-world domains. When we think about K-12 education
    or even in healthcare, I think taking real-world impact into the first place to
    think about what the problems to work on is quite important.
  topic: business/strategy
- impact_reason: 'Suggests a method for achieving high-quality, specialized feedback
    in LLM applications: fine-tuning or injecting domain expertise into the coaching
    agent.'
  relevance_score: 8
  source: llm_enhanced
  text: AI Mentor is tailored in a way that we will bring in or build domain expertise
    into specific models so that those AI Mentors can actually give you very realistic
    feedback.
  topic: technical
- impact_reason: 'Presents a practical workaround for the simulation realism problem:
    focusing on skill-based templates rather than individual mimicry.'
  relevance_score: 8
  source: llm_enhanced
  text: Instead of simulating a specific individual, we try to create a typical template
    for interacting on that specific skill.
  topic: technical/strategy
- impact_reason: Identifies cultural dynamics and broad social awareness as a major,
    unsolved challenge in developing sophisticated AI mentors/partners.
  relevance_score: 8
  source: llm_enhanced
  text: In terms of a lot of the cultural dynamics, a lot of the social awareness,
    we haven't figured out a great way to integrate them into the space. I think that
    itself is an open question.
  topic: limitations/safety
- impact_reason: Highlights the difficulty of establishing ground truth for complex
    cultural or individual simulations, contrasting sharply with standard quantitative
    AI evaluation.
  relevance_score: 8
  source: llm_enhanced
  text: If you think about how to evaluate whether the simulation is a really good
    simulation of a person from Brazil, this is a really hard question because there
    are all sorts of different individuals, etc. There may not be a ground-truth answer
    that you can use compared to other situations.
  topic: technical/limitations
- impact_reason: 'Identifies a crucial secondary market/use case: using AI to assist
    domain experts (supervisors, trainers) in scaling personalized feedback.'
  relevance_score: 8
  source: llm_enhanced
  text: Imagine at those moments, this kind of AI Mentor would be a great help to
    the people who are already helping others. So I think not only we want to help
    learners who want to learn those skills, we also hope that these two will also
    be very helpful for people who are helping others. This is like actually reflected
    in one of our paper titles called Helping the Helper from the AI perspective.
  topic: business/strategy
- impact_reason: Identifies the 'stiffness' or lack of realism in current conversational
    AI simulations, a key challenge in achieving high-fidelity training environments.
  relevance_score: 8
  source: llm_enhanced
  text: one thing sometimes we worry is that this kind of practice may not give people
    very realistic practice. Some of our participants when they use our systems shared
    that, oh, sometimes the conversation feels like they are very stiff...
  topic: limitations/safety
- impact_reason: 'Defines the dual purpose of socially aware AI: improving direct
    machine interaction and serving as a catalyst for better human-to-human relationships.'
  relevance_score: 8
  source: llm_enhanced
  text: eventually we want socially aware AI to hopefully help with both human-computer
    interaction and human-human interaction.
  topic: predictions/strategy
- impact_reason: Positions social skill training via AI as a direct mechanism for
    improving the quality and meaning of future human interactions.
  relevance_score: 8
  source: llm_enhanced
  text: I would argue that the topic we just talked about on social skill training
    is actually a great example of how we are thinking about how socially aware systems
    could be used to help people learn better so that people could have better conversations
    or more positive conversations with others.
  topic: predictions/business
- impact_reason: Provides actionable resources and keywords for individuals looking
    to enter the field of socially aware AI development.
  relevance_score: 8
  source: llm_enhanced
  text: courses such as computational social science or human-centered NLP or human-centered
    AI, and many, many other awesome courses like creative AI, generative AI agents,
    all sorts of things.
  topic: advice
- impact_reason: A grounding statement emphasizing that foundational technical reliability
    must precede the implementation of complex social awareness features.
  relevance_score: 7
  source: llm_enhanced
  text: Throughout those two different documents, the first challenge even before
    we get to these nuances or social awareness is actually to make sure the technology
    would work well in the first place.
  topic: technical/strategy
- impact_reason: Shows the reliance on human-in-the-loop evaluation (expert judgment)
    when quantitative metrics fail for subjective, social skills training.
  relevance_score: 7
  source: llm_enhanced
  text: For many of the evaluations here, we actually sometimes work with human experts.
    We ask, is this a simulation that looks or sounds like it is difficult to you?
    Is this a good reflection of the client you had in your interaction? So we actually
    developed a lot of these more human studies or evaluations to evaluate such simulation.
  topic: technical/strategy
- impact_reason: 'Defines the target user segment and primary value proposition: AI
    as a foundational training tool for beginners, not a replacement for expert instruction.'
  relevance_score: 7
  source: llm_enhanced
  text: We imagine that it's especially for novices, for beginners, for people who
    don't know the field very well, they can actually use this kind of AI Partner
    and AI Mentor in the starting stage.
  topic: business/strategy
- impact_reason: Shows the direct application of established domain theory (interest-based
    negotiation) to structure the AI interaction and learning objectives.
  relevance_score: 7
  source: llm_enhanced
  text: We actually leverage this theory called interest-based negotiation from conflict
    resolution.
  topic: technical/strategy
- impact_reason: Provides a concrete example of an AI training system (CARE) where
    synthetic data/personas are directly mapped to established curriculum requirements.
  relevance_score: 7
  source: llm_enhanced
  text: We built a system called CARE where novice counselors can actually practice
    with different types of AI patients. We created those AI patients based on the
    learning materials that counselors need to learn in their training.
  topic: business/technical
- impact_reason: A broad prediction about the societal impact of personalized learning
    facilitated by AI, particularly in education and therapy.
  relevance_score: 7
  source: llm_enhanced
  text: Such systems could also make the learning more personalized, and I think that
    this will have a huge impact on society.
  topic: predictions
- impact_reason: Shows the application of AI support extends beyond the trainee to
    the trainer/supervisor, optimizing the entire feedback loop in professional development.
  relevance_score: 7
  source: llm_enhanced
  text: we can also help senior supervisors who are providing feedback, who are training
    novice counselors in those contexts.
  topic: business
- impact_reason: An incomplete but powerful statement implying that the ultimate goal
    of technology development must be rooted in human purpose, not just technical
    capability (likely leading into the next thought about human benefit).
  relevance_score: 7
  source: llm_enhanced
  text: the more we realize that by the end of the day, the goal of how we build technology
    is not for the purpose of building
  topic: strategy/philosophy
- impact_reason: 'States a core philosophical stance for AI development: augmentation
    and empowerment over replacement.'
  relevance_score: 6
  source: llm_enhanced
  text: We want to build a system that can empower humans. This is like our true belief.
  topic: strategy/safety
source: Unknown Source
summary: '## Podcast Episode Summary: 157 - Diyi Yang: Socially Aware Large Language
  Models


  This episode of the Stanford Psychology Podcast, hosted by Souda Karajah, features
  Professor Diyi Yang discussing her research on **Socially Aware Natural Language
  Processing (NLP)** and the development of LLMs capable of understanding and responding
  to complex social contexts. The core focus is on leveraging LLMs to enhance human
  interaction, specifically through personalized social skills training.


  ---


  ### 1. Focus Area

  The discussion centers on **Socially Aware Language Technology**, an interdisciplinary
  field combining Computer Science, NLP, Machine Learning, social sciences, and linguistics.
  Key applications explored include using LLMs for interactive training in areas like
  conflict resolution and counseling, emphasizing the human element in AI development
  and deployment.


  ### 2. Key Technical Insights

  *   **Three Dimensions of Socially Aware NLP:** The framework involves understanding
  **Social Factors** (speaker/receiver relations, norms, culture), **Social Interactions**
  (governing norms of communication), and **Social Implication** (broader positive/negative
  societal impact).

  *   **AI Partner/AI Mentor (APAM) Framework:** This conceptual framework utilizes
  two LLM agents: the **AI Partner** (role-playing a scenario participant, e.g., a
  roommate or client) and the **AI Mentor** (providing domain-specific, expert feedback).

  *   **Mitigating Simulation Bias via Self-Critique and Domain Expertise:** To achieve
  realistic simulations, the team uses techniques like **self-critique** within the
  AI Partner to ensure responses align with domain knowledge, and they rely on **domain
  user collaboration** to build interaction templates rather than attempting to simulate
  specific individuals perfectly.


  ### 3. Business/Investment Angle

  *   **Transformative Training Market:** The APAM framework offers a scalable, accessible,
  and psychologically safe alternative to traditional, expensive, and time-consuming
  social skills coaching, opening significant market opportunities in professional
  development and education.

  *   **Shifting LLM Evaluation Metrics:** There is a growing need to move beyond
  traditional benchmarks (math, coding) toward evaluating LLMs on complex human qualities
  like empathy, personality alignment, and conversational nuance, which requires new
  evaluation methodologies.

  *   **Empowering the Helper Ecosystem:** The technology is positioned not to replace
  human trainers (supervisors, coaches) but to **empower them** by handling initial,
  personalized feedback for novices, allowing experts to focus on higher-level guidance.


  ### 4. Notable Companies/People

  *   **Professor Diyi Yang (Stanford University):** Assistant Professor, leading
  the Social and Language Technologies Lab, specializing in human-centric and socially
  aware NLP.

  *   **Souda Karajah (Stanford University):** Pre-doctoral fellow and co-host, whose
  admiration for Yang’s work frames the discussion.

  *   **Rehearsal System:** A specific implementation of the APAM framework used to
  help users practice **conflict resolution** based on interest-based negotiation
  theory.

  *   **CARE System:** An implementation used to train **novice counselors** on critical
  skills like empathy and reflection by simulating AI patients.


  ### 5. Future Implications

  The conversation suggests a future where LLMs are deeply integrated into soft-skill
  development, moving beyond factual knowledge transfer to interactive behavioral
  practice. A key future direction is integrating more complex **cultural dynamics**
  into the simulation and moving toward **physical/3D spaces** to incorporate non-verbal
  social cues (posture, eye contact) into the training loop.


  ### 6. Target Audience

  This episode is highly valuable for **AI researchers and practitioners** focusing
  on LLM alignment, safety, and human-computer interaction (HCI), as well as **professionals
  in EdTech, corporate training, and mental health/counseling fields** interested
  in scalable skill development solutions.'
tags:
- artificial-intelligence
- ai-infrastructure
- investment
- generative-ai
title: '157 - Diyi Yang: Socially Aware Large Language Models'
topics:
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 129
  prominence: 1.0
  topic: artificial intelligence
- keywords:
  - gpu
  - tensor
  - training
  - inference
  - model deployment
  - vector database
  mentions: 20
  prominence: 1.0
  topic: ai infrastructure
- keywords:
  - investment
  - funding
  - valuation
  - ipo
  - acquisition
  mentions: 6
  prominence: 0.6
  topic: investment
- keywords:
  - generative ai
  - genai
  - chatgpt
  - gpt
  - claude
  - text generation
  - image generation
  mentions: 2
  prominence: 0.2
  topic: generative ai
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-10-06 03:48:47 UTC -->
