---
companies:
- category: tech
  confidence: high
  context: offerings might be. No one knew this was coming. OpenAI and Nvidia announced
    a strategic partnership to d
  name: Openai
  position: 168
- category: tech
  confidence: high
  context: might be. No one knew this was coming. OpenAI and Nvidia announced a strategic
    partnership to deploy 10 gi
  name: Nvidia
  position: 179
- category: unknown
  confidence: medium
  context: unds like the proper ancient Greek pronunciation. So Doc Brown needed only
    1.21 gigawatts of power to get us to
  name: So Doc Brown
  position: 518
- category: unknown
  confidence: medium
  context: '1.21 gigawatts of power to get us to the future. Sam Altman needs 10.
    I''m totally tweeting that.


    Okay, so le'
  name: Sam Altman
  position: 592
- category: unknown
  confidence: medium
  context: 'e deployed in the second half of 2026 on Nvidia''s Vera Rubin platform.


    First of all, let''s talk about the sca'
  name: Vera Rubin
  position: 1223
- category: unknown
  confidence: medium
  context: nd 9 million homes. It's equivalent to about five Hoover Dams in terms
    of energy production and about 10 big nu
  name: Hoover Dams
  position: 1514
- category: unknown
  confidence: medium
  context: ors. Currently, the biggest single cluster is the XAI Colossus Memphis
    Phase Two. This number here is Nvidia's GPU H100 equivalent
  name: XAI Colossus Memphis Phase Two
  position: 1751
- category: unknown
  confidence: medium
  context: the single largest compute build disclosed by any Western AI lab. There
    are various anonymized Chinese systems
  name: Western AI
  position: 1900
- category: unknown
  confidence: medium
  context: 'there are more, we don''t know too much about it.


    Now OpenAI and Microsoft also announced earlier this year th'
  name: Now OpenAI
  position: 2059
- category: tech
  confidence: high
  context: 'we don''t know too much about it.


    Now OpenAI and Microsoft also announced earlier this year the Stargate pro'
  name: Microsoft
  position: 2074
- category: tech
  confidence: high
  context: out whether or not this will happen. We also have Amazon's AWS project,
    Rainier, depending on how you pron
  name: Amazon
  position: 2527
- category: tech
  confidence: high
  context: hers say Rainier. This is done interestingly with Anthropic and Trainium
    chips, which is kind of a separate t
  name: Anthropic
  position: 2679
- category: tech
  confidence: high
  context: e thing and hard to compare to GPUs. Then we have Google Cloud's TPUs,
    or tensor processing units. By the
  name: Google
  position: 2785
- category: unknown
  confidence: medium
  context: e thing and hard to compare to GPUs. Then we have Google Cloud's TPUs,
    or tensor processing units. By the way, i
  name: Google Cloud
  position: 2785
- category: unknown
  confidence: medium
  context: out how this is structured and how it will work. Will Nvidia have some
    ownership in OpenAI? How does their tra
  name: Will Nvidia
  position: 3768
- category: unknown
  confidence: medium
  context: 'of moving pieces and things we don''t understand.


    As Sam Altman says, everything starts with compute. Compute inf'
  name: As Sam Altman
  position: 3949
- category: unknown
  confidence: medium
  context: oughs and empower people and businesses at scale. Greg Brockman says we've
    been working with Nvidia since the ear
  name: Greg Brockman
  position: 4200
- category: unknown
  confidence: medium
  context: ly days of OpenAI. In fact, there are pictures of Jensen Huang hand-delivering
    the first crate with GPUs to the
  name: Jensen Huang
  position: 4313
- category: unknown
  confidence: medium
  context: t this does seem like a big deal. A few days ago, Elon Musk posted about
    1.21 gigawatts of training compute,
  name: Elon Musk
  position: 4773
- category: unknown
  confidence: medium
  context: 1 gigawatts of training compute, referring to the Colossus Stage Two, the
    system powering Brock for Brock for Fast and
  name: Colossus Stage Two
  position: 4849
- category: unknown
  confidence: medium
  context: ut the abilities of the models scale predictably. As Per Keshav says, Jensen
    finally believes in superintelligenc
  name: As Per Keshav
  position: 5527
- category: unknown
  confidence: medium
  context: Mississippi expansion, Solaris energy, and more. Can XAI afford it? Middle
    East funding, Tesla talent exod
  name: Can XAI
  position: 7094
- category: unknown
  confidence: medium
  context: ion, Solaris energy, and more. Can XAI afford it? Middle East funding,
    Tesla talent exodus, API revenue, consum
  name: Middle East
  position: 7113
- category: tech
  confidence: high
  context: OpenAI, even beating the others on the topic and meta. Colossus was built
    from zero to 200 megawatts in
  name: Meta
  position: 7819
- category: unknown
  confidence: medium
  context: awatt-scale energy hub right across the border in South Haven, Mississippi.
    They run Colossus in Memphis, Tenne
  name: South Haven
  position: 8295
- category: unknown
  confidence: medium
  context: 'ant in South Haven that they acquired.


    They have Tesla MegaPacks for battery energy storage. We''re not going to re'
  name: Tesla MegaPacks
  position: 8467
- category: unknown
  confidence: medium
  context: is project out and if they need any more funding. As Sam said a few days
    ago, they're going to be launchin
  name: As Sam
  position: 8885
- category: ai_research
  confidence: high
  context: Major AI lab partnering with Nvidia for 10 gigawatt AI data center project,
    creator of DALL-E, working on large language models
  name: OpenAI
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: Leading GPU manufacturer, investing up to $100B in OpenAI partnership,
    primary supplier of AI computing hardware
  name: Nvidia
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Partner with OpenAI on Stargate project (5 gigawatt initiative)
  name: Microsoft
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: Built Colossus data center (first gigawatt data center), developing AI
    models, mentioned regarding Colossus Memphis Phase Two
  name: XAI
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Project Rainier with Anthropic, developing AI infrastructure
  name: Amazon AWS
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: Working with Amazon on Trainium chips project
  name: Anthropic
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Developing TPUs (tensor processing units) for AI computing
  name: Google Cloud
  source: llm_enhanced
- category: ai_infrastructure
  confidence: medium
  context: Mentioned regarding MegaPacks for battery storage in AI infrastructure
  name: Tesla
  source: llm_enhanced
- category: ai_infrastructure
  confidence: medium
  context: Mentioned in context of data center build times
  name: Oracle
  source: llm_enhanced
- category: big_tech
  confidence: medium
  context: Mentioned in comparison with other AI labs' development
  name: Meta
  source: llm_enhanced
- category: research_analysis
  confidence: high
  context: Publication focused on AI data centers and chip analysis
  name: SemiAnalysis
  source: llm_enhanced
- category: ai_infrastructure
  confidence: low
  context: Mentioned in context of data center build times
  name: Grosso
  source: llm_enhanced
date: '2025-09-22 00:00:00 '
duration: 13
has_transcript: false
layout: episode
llm_enhanced: true
original_url: https://www.youtube.com/watch?v=K10txopUnaU
processing_date: 2025-09-28 00:07:05 +0000
quotes:
- length: 56
  relevance_score: 7
  text: OpenAI and Nvidiaâ€”Nvidia is the biggest supplier of GPUs
  topics: []
- length: 50
  relevance_score: 6
  text: How do you compare TPUs, training chips, GPUs, etc
  topics: []
- length: 106
  relevance_score: 6
  text: Middle East funding, Tesla talent exodus, API revenue, consumer growth, reinforcement
    learning environment
  topics:
  - funding
  - revenue
  - growth
- length: 275
  relevance_score: 6
  text: So it's likely that a lot of this compute coming online is not just going
    to be used for training and running large language models; we're probably going
    to see a lot more visual content because it seems to really attract new users
    and encourage them to test out the platform
  topics: []
- length: 60
  relevance_score: 5
  text: Then we have Google Cloud's TPUs, or tensor processing units
  topics: []
- length: 200
  relevance_score: 4
  text: This strategic partnership enables OpenAI to build and deploy at least 10
    gigawatts of AI data centers with Nvidia systems, representing millions of GPUs
    for OpenAI's next-generation AI infrastructure
  topics: []
- length: 115
  relevance_score: 4
  text: Jensen and Nvidia are no longer just selling the shovels; it seems like this
    is a fairly large investment in OpenAI
  topics:
  - investment
- length: 136
  relevance_score: 4
  text: As we've seen with image generation, things like DALL-E from OpenAI and the
    launch of Google, everything got "jibblefied," if you recall
  topics: []
- length: 210
  relevance_score: 4
  text: But both OpenAI and some Google engineers have noted that everybody's just
    melting the GPUs they have available, or whatever infrastructure was used basically
    needed to be upgraded because of the massive demand
  topics: []
- length: 75
  relevance_score: 3
  text: Currently, the biggest single cluster is the XAI Colossus Memphis Phase Two
  topics: []
- length: 131
  relevance_score: 3
  text: This number here is Nvidia's GPU H100 equivalents, meaning this is the single
    largest compute build disclosed by any Western AI lab
  topics: []
- length: 123
  relevance_score: 3
  text: This is done interestingly with Anthropic and Trainium chips, which is kind
    of a separate thing and hard to compare to GPUs
  topics: []
- length: 46
  relevance_score: 3
  text: This sounds like the biggest announced project
  topics: []
- length: 143
  relevance_score: 3
  text: In fact, there are pictures of Jensen Huang hand-delivering the first crate
    with GPUs to the OpenAI headquarters, which he signed very early on
  topics: []
- length: 92
  relevance_score: 3
  text: All these companiesâ€”Nvidia, Microsoft, OpenAI, and XAIâ€”are still betting on
    the scaling laws
  topics: []
- length: 267
  relevance_score: 3
  text: If the models don't get better, if they don't have some return on investment,
    if they can't do any economically valuable work and OpenAI is just burning through
    billions with no ROI in sight, then of course that investment will be worth lessâ€”close
    to zero or whatever
  topics:
  - investment
- impact_reason: Represents one of the largest AI infrastructure investments ever
    announced, signaling massive scaling of AI compute capabilities
  relevance_score: 10
  source: llm_enhanced
  text: OpenAI and Nvidia announced a strategic partnership to deploy 10 gigawatts
    of Nvidia systems... representing millions of GPUs for OpenAI's next-generation
    AI infrastructure
  topic: business
- impact_reason: Key strategic insight about the fundamental importance of compute
    in AI development
  relevance_score: 9
  source: llm_enhanced
  text: As Sam Altman says, everything starts with compute. Compute infrastructure
    will be the basis for the economy of the future
  topic: future_predictions
- impact_reason: Important technical insight about the relationship between compute
    scale and model capabilities
  relevance_score: 9
  source: llm_enhanced
  text: All these companiesâ€”Nvidia, Microsoft, OpenAI, and XAIâ€”are still betting on
    the scaling laws. The idea is that as we increase the scale of compute, the abilities
    of these models increase predictably
  topic: technical
- impact_reason: Signals a strategic shift in Nvidia's business model from pure hardware
    supplier to AI company investor
  relevance_score: 9
  source: llm_enhanced
  text: This is a little bit of a turn. Jensen and Nvidia are no longer just selling
    the shovels; it seems like this is a fairly large investment in OpenAI
  topic: business
- impact_reason: Highlights significant differences in infrastructure deployment capabilities
    between companies
  relevance_score: 8
  source: llm_enhanced
  text: XAI built that in six months, while it took 15 months for Oracle, Grosso,
    and OpenAI
  topic: business
- impact_reason: Predicts shift in AI applications toward more compute-intensive visual
    content generation
  relevance_score: 8
  source: llm_enhanced
  text: It's likely that a lot of this compute coming online is not just going to
    be used for training and running large language models; we're probably going to
    see a lot more visual content
  topic: future_predictions
- impact_reason: Provides important context about current state of AI infrastructure
    deployment
  relevance_score: 8
  source: llm_enhanced
  text: Currently, the biggest single cluster is the XAI Colossus Memphis Phase Two...
    the single largest compute build disclosed by any Western AI lab
  topic: technical
- impact_reason: Reveals important strategic considerations in AI infrastructure deployment
    regarding power supply
  relevance_score: 8
  source: llm_enhanced
  text: XAI's genius move was to develop a gigawatt-scale energy hub right across
    the border in South Haven, Mississippi
  topic: business
- impact_reason: Highlights current infrastructure limitations and demand challenges
  relevance_score: 7
  source: llm_enhanced
  text: Both OpenAI and some Google engineers have noted that everybody's just melting
    the GPUs they have available
  topic: technical
- impact_reason: Insightful analysis of Nvidia's historical business strategy in AI
  relevance_score: 7
  source: llm_enhanced
  text: If you think about it, everybody kept saying that Nvidia's the winner because
    they're selling shovels while everyone else is chasing AGI
  topic: business
source: Wes Roth
summary: '**AI Focus Area**: The podcast episode primarily discusses the strategic
  partnership between OpenAI and NVIDIA, focusing on the deployment of large-scale
  AI data centers. It highlights the infrastructure needed to support next-generation
  AI models and the implications of such massive computational power. The conversation
  touches on the scaling laws of AI, the role of GPUs, and potential applications
  in video generation.


  **Key Technical Insights**:

  1. **Scale of Compute**: The partnership aims to deploy 10 gigawatts of Nvidia systems,
  equivalent to millions of GPUs, marking the largest compute build disclosed by any
  Western AI lab. This scale is compared to significant energy producers like nuclear
  reactors and Hoover Dams.

  2. **Infrastructure and Energy**: The discussion emphasizes the challenges of building
  and powering such large-scale data centers. Examples include XAI''s Colossus, which
  utilizes a gigawatt-scale energy hub and Tesla MegaPacks for energy storage, illustrating
  the complexity of energy management in AI infrastructure.


  **Business/Investment Angle**:

  1. **NVIDIA''s Strategic Investment**: NVIDIA plans to invest up to $100 billion
  in OpenAI, indicating a shift from merely supplying hardware to actively participating
  in the AI development ecosystem. This move suggests NVIDIA''s deeper integration
  into the AI race beyond just selling GPUs.

  2. **Market Trends and Opportunities**: The episode highlights the growing demand
  for compute power in AI, driven by applications like video generation and large
  language models. This trend presents opportunities for companies involved in AI
  infrastructure and energy solutions.


  **Notable AI Companies/People**:

  - **OpenAI**: A leading AI research organization partnering with NVIDIA to expand
  its computational capabilities.

  - **NVIDIA**: A major supplier of GPUs, now investing heavily in AI infrastructure,
  signaling a strategic shift.

  - **Sam Altman**: CEO of OpenAI, emphasizing the importance of compute infrastructure
  for future AI breakthroughs.

  - **Jensen Huang**: CEO of NVIDIA, involved in the strategic partnership with OpenAI.


  **Future Implications**:

  The conversation suggests that AI development will increasingly rely on massive
  computational infrastructure, with companies like NVIDIA playing a crucial role.
  The focus on scaling laws implies that as compute power increases, AI models will
  continue to improve, potentially leading to breakthroughs in areas like superintelligence.
  The partnership between OpenAI and NVIDIA could set a precedent for future collaborations
  in the AI industry.


  **Target Audience**: This episode is most valuable for AI researchers, engineers,
  and investors interested in AI infrastructure and market trends. Entrepreneurs in
  the AI space may also find insights into potential opportunities and challenges
  in scaling AI technologies.


  **Comprehensive Summary**:

  The podcast episode titled "OpenAI and NVIDIA just broke the AI industry" delves
  into the groundbreaking partnership between OpenAI and NVIDIA to deploy 10 gigawatts
  of AI data centers. This collaboration represents a significant leap in AI infrastructure,
  with NVIDIA investing up to $100 billion in OpenAI. The scale of this project is
  unprecedented, comparable to the energy output of multiple nuclear reactors and
  Hoover Dams, highlighting the massive computational power required for next-generation
  AI models.


  The discussion underscores the importance of compute infrastructure in driving AI
  advancements. Sam Altman, CEO of OpenAI, emphasizes that compute will be the foundation
  of future economies, enabling new AI breakthroughs. The episode also touches on
  the scaling laws of AI, where increased compute power leads to predictable improvements
  in AI models, albeit at an exponential cost.


  NVIDIA''s strategic investment marks a shift from its traditional role as a hardware
  supplier to a more integrated participant in the AI ecosystem. This move suggests
  NVIDIA''s commitment to the AI race, as it no longer merely sells GPUs but actively
  invests in AI development. The partnership with OpenAI could redefine industry dynamics,
  with NVIDIA poised to benefit from the success of AI models developed using its
  hardware.


  The episode also explores the challenges of building and powering large-scale data
  centers. Examples like XAI''s Colossus, which utilizes a gigawatt-scale energy hub
  and Tesla MegaPacks, illustrate the complexity of managing energy needs for AI infrastructure.
  The conversation hints at potential applications in video generation, driven by
  the demand for visual content that attracts users to AI platforms.


  Overall, the podcast provides valuable insights into the future of AI infrastructure
  and market trends. It highlights the strategic importance of compute power in AI
  development and the potential for new applications and business opportunities. The
  partnership between OpenAI and NVIDIA sets a precedent for future collaborations,
  with significant implications for the AI industry. This episode is particularly
  relevant for AI researchers, engineers, and investors interested in the evolving
  landscape of AI infrastructure and market dynamics.'
tags:
- artificial-intelligence
- ai-infrastructure
- investment
- generative-ai
- openai
- nvidia
- microsoft
- anthropic
title: OpenAI and NVIDIA just broke the AI industry
topics:
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 63
  prominence: 1.0
  topic: artificial intelligence
- keywords:
  - gpu
  - tensor
  - training
  - inference
  - model deployment
  - vector database
  mentions: 11
  prominence: 1.0
  topic: ai infrastructure
- keywords:
  - investment
  - funding
  - valuation
  - ipo
  - acquisition
  mentions: 6
  prominence: 0.6
  topic: investment
- keywords:
  - generative ai
  - genai
  - chatgpt
  - gpt
  - claude
  - text generation
  - image generation
  mentions: 2
  prominence: 0.2
  topic: generative ai
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-09-28 00:07:05 UTC -->
