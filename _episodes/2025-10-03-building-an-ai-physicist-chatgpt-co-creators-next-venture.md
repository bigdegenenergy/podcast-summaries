---
companies:
- category: unknown
  confidence: medium
  context: s in the real world. That's what we're doing with Periodic Labs. We're
    taking these precursor technologies and sa
  name: Periodic Labs
  position: 93
- category: unknown
  confidence: medium
  context: 'science?


    Today''s conversation features Dosh and Liam Vettas, co-founders of Periodic Labs,
    a frontier researc'
  name: Liam Vettas
  position: 897
- category: tech
  confidence: high
  context: 'rt Periodic.


    I believe we met eight years ago at Google Brain while flipping over a large tire.


    Yep. I n'
  name: Google
  position: 1750
- category: unknown
  confidence: medium
  context: 'rt Periodic.


    I believe we met eight years ago at Google Brain while flipping over a large tire.


    Yep. I need to'
  name: Google Brain
  position: 1750
- category: unknown
  confidence: medium
  context: 'check because the ground truth is the experiment. The RL environment nature
    is our setting.


    Let''s clarify'
  name: The RL
  position: 4892
- category: unknown
  confidence: medium
  context: 'op. That becomes our reward function for agents.


    As Joe mentioned, our agents perform tasks similar to co'
  name: As Joe
  position: 6673
- category: unknown
  confidence: medium
  context: 'the basis for what the system optimizes against.


    In AI, when people refer to a lab, they often mean some'
  name: In AI
  position: 6980
- category: unknown
  confidence: medium
  context: literature that spanned many orders of magnitude. If I train a system on
    that, these systems aren't magi
  name: If I
  position: 9575
- category: tech
  confidence: high
  context: ese systems aren't magic; the best they can do is replicate that distribution,
    but they won't gain a deeper u
  name: Replicate
  position: 9656
- category: tech
  confidence: high
  context: and proposed scaling laws. A follow-up paper from OpenAI showed that scaling
    up computing and data in the
  name: Openai
  position: 13199
- category: unknown
  confidence: medium
  context: "specific pipelines that your lab will focus on? \n\nIn Periodic, the first\
    \ lines of inquiry you mentioned are sup"
  name: In Periodic
  position: 15800
- category: unknown
  confidence: medium
  context: and researchers in advanced industries. Being in Silicon Valley, we often
    think about computer-oriented work, but
  name: Silicon Valley
  position: 17907
- category: unknown
  confidence: medium
  context: d to teach LLMs how to reason about their fields. Frontier AI labs have
    figured out how to train LLMs on math a
  name: Frontier AI
  position: 19118
- category: unknown
  confidence: medium
  context: ies this diversity, with various expertise areas. As Liam mentioned, everyone
    has much to learn, and that's
  name: As Liam
  position: 21304
- category: tech
  confidence: high
  context: 'great researcher at Periodic from one at OpenAI, Anthropic, or DeepMind?


    There''s significant overlap, but o'
  name: Anthropic
  position: 21715
- category: tech
  confidence: high
  context: s are becoming better, with groups like DeepMind, Meta, and Microsoft open-sourcing
    new methods for simu
  name: Meta
  position: 26476
- category: tech
  confidence: high
  context: ming better, with groups like DeepMind, Meta, and Microsoft open-sourcing
    new methods for simulating and pred
  name: Microsoft
  position: 26486
- category: unknown
  confidence: medium
  context: superconductivity expertise from individuals like ZX Chan from Stanford
    and Steve Kielsen from the theory s
  name: ZX Chan
  position: 28290
- category: unknown
  confidence: medium
  context: e from individuals like ZX Chan from Stanford and Steve Kielsen from the
    theory side, as well as synthesis expert
  name: Steve Kielsen
  position: 28316
- category: unknown
  confidence: medium
  context: theory side, as well as synthesis expertise from Mercury Kanatzeides from
    Northwestern University and Chris Walberton
  name: Mercury Kanatzeides
  position: 28388
- category: unknown
  confidence: medium
  context: synthesis expertise from Mercury Kanatzeides from Northwestern University
    and Chris Walberton on high-throughput DFT. We al
  name: Northwestern University
  position: 28413
- category: unknown
  confidence: medium
  context: cury Kanatzeides from Northwestern University and Chris Walberton on high-throughput
    DFT. We also have Kostia from
  name: Chris Walberton
  position: 28441
- category: unknown
  confidence: medium
  context: on high-throughput DFT. We also have Kostia from Manchester University,
    known for discovering graphene, to advise us on
  name: Manchester University
  position: 28506
- category: ai_research
  confidence: high
  context: Frontier research lab building experiment-in-the-loop AI for physics and
    chemistry, co-founded by Dosh and Liam Vettas
  name: Periodic Labs
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: Liam Vettas was co-creator of ChatGPT at OpenAI, mentioned for RLHF pipeline
    and scaling laws research
  name: OpenAI
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: Dosh ran physics teams at DeepMind, mentioned alongside their AGI goals
    and approach
  name: DeepMind
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Where Dosh and Liam first met 8 years ago, Google's AI research division
  name: Google Brain
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: AI chatbot co-created by Liam, used as example of RLHF pipeline and evolution
    from autocompletion to assistant
  name: ChatGPT
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: Referenced as demonstrating that language models are few-shot learners
    and proposing scaling laws
  name: GPT-3
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: Mentioned as a comparison point for distinguishing researchers at Periodic
    from those at other AI companies
  name: Anthropic
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Mentioned as open-sourcing new methods for simulating and predicting properties
    in physics research
  name: Meta
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Referenced as open-sourcing new methods for simulating and predicting properties
    in physics research
  name: Microsoft
  source: llm_enhanced
- category: ai_research
  confidence: medium
  context: Referenced through Stanford physics lab work on evaluating AI models for
    scientific analysis, and ZX Chan from Stanford mentioned as superconductivity
    expert
  name: Stanford AI Lab
  source: llm_enhanced
- category: ai_research
  confidence: medium
  context: Mercury Kanatzeides mentioned as synthesis expert from Northwestern University
    for Periodic's advisory board
  name: Northwestern University
  source: llm_enhanced
- category: ai_research
  confidence: medium
  context: Kostia from Manchester University mentioned as advisor, known for discovering
    graphene and expertise in novel electronic states
  name: Manchester University
  source: llm_enhanced
- category: investment
  confidence: high
  context: Venture capital firm hosting the podcast and mentioned as having investments
    in companies discussed
  name: A16Z
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: Company mentioned in context of scaling up speed and operations, with career
    opportunities being highlighted
  name: Periodic
  source: llm_enhanced
- category: investment_firm
  confidence: high
  context: Venture capital firm hosting the podcast, mentioned as maintaining investments
    in AI/ML companies discussed
  name: A16Z (Andreessen Horowitz)
  source: llm_enhanced
date: 2025-10-03 06:23:06 +0000
duration: 54
has_transcript: false
layout: episode
llm_enhanced: true
original_url: https://mgln.ai/e/1344/afp-848985-injected.calisto.simplecastaudio.com/3f86df7b-51c6-4101-88a2-550dba782de8/episodes/1621ab71-2bcf-454f-8c75-d19dfb194a71/audio/128/default.mp3?aid=rss_feed&awCollectionId=3f86df7b-51c6-4101-88a2-550dba782de8&awEpisodeId=1621ab71-2bcf-454f-8c75-d19dfb194a71&feed=JGE3yC0V
processing_date: 2025-10-03 06:23:06 +0000
quotes:
- length: 218
  relevance_score: 5
  text: Is there something about how you're building Periodic that allows you to leverage
    all that progress, or do you have to start everything from scratch, making it
    difficult to integrate advancements from mainstream models
  topics: []
- length: 96
  relevance_score: 4
  text: We believe teaching LLMs to be foundation models for quantum mechanics will
    be the next frontier
  topics: []
- length: 107
  relevance_score: 4
  text: It's hard to manipulate, unlike other LLM training techniques; the signal
    comes from real-life observations
  topics: []
- length: 68
  relevance_score: 4
  text: For the LLM side, we focused on mid-training, RL, and infrastructure
  topics: []
- length: 198
  relevance_score: 4
  text: For instance, if we want to learn from experimental data in literature for
    synthesis, the formation enthalpy labels are so high that training a machine learning
    model on them isn't predictive enough
  topics: []
- length: 207
  relevance_score: 4
  text: A productive approach has been for physicists and chemists to consider what
    steps to include in mid-training and RL training to teach LLMs how to reason correctly
    about quantum mechanics and physical systems
  topics: []
- length: 78
  relevance_score: 3
  text: If a model is underperforming, you have to ask if you trained it for that
    task
  topics: []
- length: 133
  relevance_score: 3
  text: There's significant overlap, but one of the biggest determinants is whether
    candidates care about the mission of accelerating science
  topics: []
- impact_reason: Establishes the core thesis that AI must move beyond digital simulations
    to real-world experimentation to advance scientific discovery
  relevance_score: 9
  source: llm_enhanced
  text: Ultimately, science is driven by experiments in the real world. That's what
    we're doing with Periodic Labs. We're taking these precursor technologies and
    saying, if you care about advancing science, we need to have experiments in the
    loop.
  topic: technical
- impact_reason: Defines the ambitious vision of creating an 'AI physicist' and its
    potential impact across multiple industries
  relevance_score: 9
  source: llm_enhanced
  text: The applications of building an AI physicist, for lack of a better word, that
    can design for the real world are broad. You can apply them to advanced manufacturing,
    material science, and chemistry. Any process involving R&D with the physical world
    seems likely to benefit from the breakthroughs that Periodic is working on.
  topic: predictions
- impact_reason: Provocative question that frames the paradigm shift from AI as a
    knowledge tool to AI as an active scientific researcher
  relevance_score: 9
  source: llm_enhanced
  text: What if AI could move from discussing science to conducting science?
  topic: strategy
- impact_reason: Explains the technical breakthrough of using real-world physics experiments
    as reward functions for AI training, moving beyond digital verification
  relevance_score: 9
  source: llm_enhanced
  text: The objective is to replace the reward function from math graders and code
    graders that we're using today... By having the lab, we create a physically grounded
    reward function that becomes the basis for our optimization. If a simulator has
    deficiencies or issues, we always error-check because the ground truth is the
    experiment.
  topic: technical
- impact_reason: Challenges the common assumption that scaling laws alone will solve
    all problems, highlighting the critical importance of domain-specific data and
    expertise in AI applications
  relevance_score: 9
  source: llm_enhanced
  text: However, that model won't cure cancer. The knowledge simply doesn't exist.
    You need to optimize against the distribution you care about. While a coding model
    may assist a cancer researcher, it lacks the data, knowledge, or expertise to
    iterate in that environment.
  topic: technical
- impact_reason: Provides crucial insight into the limitations of scaling laws for
    generalization, which is fundamental to understanding AI model capabilities and
    limitations
  relevance_score: 9
  source: llm_enhanced
  text: When examining scaling laws for vision models, we found that in-domain generalization
    and out-of-domain generalization are correlated but not necessarily linear. You
    can improve your model and see power law improvements in in-domain performance,
    but out-of-domain tasks may improve at a slower rate, making them less useful.
  topic: technical
- impact_reason: Identifies a major gap in current LLM capabilities and suggests a
    path forward for domain-specific AI reasoning
  relevance_score: 9
  source: llm_enhanced
  text: Physicists and chemists need to teach LLMs how to reason about their fields.
    Frontier AI labs have figured out how to train LLMs on math and logic, but not
    yet on physics and chemistry.
  topic: technical
- impact_reason: Illustrates the profound scientific implications of AI-driven materials
    discovery beyond just commercial applications
  relevance_score: 8
  source: llm_enhanced
  text: For example, if you could find a 200 Kelvin superconductor, even before we
    make any product with it, being able to observe such quantum effects at high temperatures
    would significantly update people's views of the universe.
  topic: predictions
- impact_reason: Captures the key insight that scientific discovery requires iteration
    and experimentation, not just knowledge retrieval
  relevance_score: 8
  source: llm_enhanced
  text: Science is inherently iterative, and we feel LLMs, using all the tools available
    to humans, can do a great job accelerating physical R&D.
  topic: technical
- impact_reason: Identifies physics as the next major frontier for AI advancement
    and explains the strategic focus on quantum mechanical scales
  relevance_score: 8
  source: llm_enhanced
  text: As mentioned, LLMs have excelled in logic and math, but the next frontier
    is physics. Within physics, there are different energy scales... We felt our first
    lab should probe that quantum mechanical energy scale, focusing on cell state
    physics, material science, and chemistry.
  topic: strategy
- impact_reason: Highlights a fundamental limitation of current AI systems - intelligence
    without iteration cannot lead to scientific discovery
  relevance_score: 8
  source: llm_enhanced
  text: Even the smartest humans have tried many times before making discoveries.
    This is a confusing point for LLMs. They can be very smart, but if they're not
    iterating on science, they won't discover it.
  topic: technical
- impact_reason: Important reality check about AI limitations - models can only replicate
    training distributions, not develop true understanding without proper training
    paradigms
  relevance_score: 8
  source: llm_enhanced
  text: Fundamentally, machine learning models excel at what you train them to do.
    If a model is underperforming, you have to ask if you trained it for that task...
    these systems aren't magic; the best they can do is replicate that distribution,
    but they won't gain a deeper understanding of physics or chemistry.
  topic: technical
- impact_reason: Provides a concrete, measurable benchmark for AI-driven materials
    discovery with significant real-world implications
  relevance_score: 8
  source: llm_enhanced
  text: One simple measure is high-temperature superconductivity. What is the highest
    temperature superconductor synthesized? Currently, the best number for ambient
    pressure is around 135 Kelvin. We'll know we're doing well if we can exceed that
    number.
  topic: business
- impact_reason: Frames the ultimate goal as AI systems that can actively design and
    create new materials, not just analyze existing ones
  relevance_score: 8
  source: llm_enhanced
  text: Can you design the world around you? Can the system discover and produce materials
    with specific properties? This applies to fundamental scientific discovery and
    industry.
  topic: predictions
- impact_reason: Bold prediction about the next major advancement in AI - foundation
    models specifically trained for quantum mechanical understanding
  relevance_score: 8
  source: llm_enhanced
  text: We believe teaching LLMs to be foundation models for quantum mechanics will
    be the next frontier.
  topic: predictions
- impact_reason: Defines the key capability needed for AI to become truly scientific
    - learning the methodology of inquiry, not just facts
  relevance_score: 8
  source: llm_enhanced
  text: The important thing is to teach LLMs the method of scientific inquiry. They
    need to perform simulations, theoretical calculations, and experiments, get results,
    and iterate on them.
  topic: technical
- impact_reason: Offers a practical strategy for AI development that challenges the
    'scale everything' approach, emphasizing targeted data curation
  relevance_score: 8
  source: llm_enhanced
  text: This is why we believe the best way to progress is to make your target as
    close to your in-domain training set as possible. We aim to iterate on changing
    the training set to align more closely with our goals.
  topic: strategy
- impact_reason: Illustrates a critical challenge in scientific AI applications where
    data quality, not just quantity, becomes the limiting factor
  relevance_score: 8
  source: llm_enhanced
  text: For superconductivity, while there are datasets, the noise floor is so high
    that training on them usually doesn't help.
  topic: technical
- impact_reason: Describes a fundamental shift in AI deployment strategy from RAG-based
    systems to trained models, with significant implications for enterprise AI
  relevance_score: 8
  source: llm_enhanced
  text: We're moving from retrieval to proper training, which requires a shift in
    thinking. We need to explain how high-compute reinforcement learning is effective
    and how to create effective tools for their problems.
  topic: strategy
- impact_reason: Identifies a key challenge in enterprise AI deployment and suggests
    a fundamental shift in approach from retrieval to training
  relevance_score: 8
  source: llm_enhanced
  text: Currently, they don't have a great solution for distilling all their knowledge
    into a single model or set of models. We're moving from retrieval to proper training,
    which requires a shift in thinking.
  topic: business
- impact_reason: Describes how AI systems can be designed to replicate and enhance
    human scientific workflows
  relevance_score: 8
  source: llm_enhanced
  text: Teaching the LLM to discover a superconductor involves reading literature,
    running simulations, performing theoretical calculations, and conducting experiments.
    This mirrors the workflow of physical R&D researchers in companies.
  topic: technical
- impact_reason: Describes advanced multi-modal training strategy for domain expertise,
    showing how specialized AI models can be developed for scientific applications
  relevance_score: 8
  source: llm_enhanced
  text: We aim to connect different distributions to ensure that including one dataset
    enhances performance on others. The goal is to make the model an expert in physics
    and chemistry, addressing areas where it was previously deficient.
  topic: technical
- impact_reason: Shows how AI companies can leverage foundation models and open-source
    advances rather than building from scratch, demonstrating ecosystem benefits
  relevance_score: 8
  source: llm_enhanced
  text: We benefit from various advances. LLMs are improving, and we take pre-trained
    models and then mid-train them. Additionally, physical simulation tools are becoming
    better, with groups like DeepMind, Meta, and Microsoft open-sourcing new methods.
  topic: business
- impact_reason: Identifies a critical gap in scientific literature that AI experimentation
    can fill, providing valuable negative results often missing from publications
  relevance_score: 7
  source: llm_enhanced
  text: Another point is that it's uncommon to publish negative results. Most published
    results are positive, and valid negative results are very valuable... Our lab
    will produce these valid negative results.
  topic: technical
- impact_reason: Explains why this approach is now possible - the convergence of multiple
    advanced fields that were previously siloed
  relevance_score: 7
  source: llm_enhanced
  text: This combination has never been part of a concerted effort before. To achieve
    this, you need all these areas of expertise... physicists, chemists, simulation
    experts, and some of the best machine learning researchers in the world.
  topic: business
- impact_reason: Identifies the timing advantage and data challenges that make this
    approach both newly possible and difficult to replicate
  relevance_score: 7
  source: llm_enhanced
  text: The technology necessary to achieve this has emerged in the last couple of
    years. This data isn't available on a Reddit forum; you need to produce experimental
    and simulation data, which is siloed across advanced industries.
  topic: strategy
- impact_reason: Demonstrates how relatively simple automation can enable breakthrough
    materials discovery when combined with AI guidance
  relevance_score: 7
  source: llm_enhanced
  text: If you've seen a coffee-making robot at an airport, a robot at that level
    can mix powders and place them in a furnace. This method can lead to discovering
    new superconductors, magnets, and materials essential for technologies around
    us.
  topic: technical
- impact_reason: Illustrates the fundamental problem with training on literature alone
    - massive uncertainty and inconsistency in reported data
  relevance_score: 7
  source: llm_enhanced
  text: There's an epistemic uncertainty that you aren't really addressing unless
    you're running experiments... one of our engineers looked at a reported physical
    property in the literature that spanned many orders of magnitude.
  topic: technical
- impact_reason: Highlights a key advantage of physics-based training - the reward
    signal is grounded in objective reality rather than subjective human preferences
  relevance_score: 7
  source: llm_enhanced
  text: It's hard to manipulate, unlike other LLM training techniques; the signal
    comes from real-life observations.
  topic: technical
- impact_reason: Connects the research to immediate commercial applications in critical
    industries, showing practical near-term value
  relevance_score: 7
  source: llm_enhanced
  text: If someone is working in space, defense, or semiconductors, they might face
    issues trying to achieve specific material properties. Can this system accelerate
    the development of those technologies?
  topic: business
- impact_reason: Reveals the convergence of scaling laws in both AI and physical sciences
    that enabled this approach
  relevance_score: 7
  source: llm_enhanced
  text: We were looking at improvements in language models and reasoning, seeing what
    high-compute reinforcement learning could do. On the material science side, we
    were observing scaling laws within physics and chemistry, both in simulations
    and experiments.
  topic: technical
- impact_reason: Articulates the motivation to move beyond conversational AI to AI
    that creates tangible technological advancement
  relevance_score: 7
  source: llm_enhanced
  text: For both of us and many in the field, the goal of this technology is to accelerate
    science and physical R&D. Chatbots were a great milestone, but we wanted to see
    technology in the world.
  topic: strategy
- impact_reason: Explains why physics is an ideal domain for AI advancement - clear
    reward signals and fast feedback loops essential for RL
  relevance_score: 7
  source: llm_enhanced
  text: Physics is very viable; it has a great reward function and a fairly fast iteration
    loop. You have simulators for large classes of physical systems.
  topic: technical
- impact_reason: Provides clear explanation of an important AI training technique
    that addresses knowledge currency and domain specialization
  relevance_score: 7
  source: llm_enhanced
  text: Mid-training refers to the process of adding new knowledge that isn't in the
    model. Before search worked well, there was an issue of freshness due to knowledge
    cutoffs. Users wanted more real-time knowledge, so mid-training became a solution.
  topic: technical
- impact_reason: Highlights an underserved market for AI applications beyond software,
    pointing to significant commercial opportunities in physical industries
  relevance_score: 7
  source: llm_enhanced
  text: Our goal is to create co-pilot tools for engineers and researchers in advanced
    industries. Being in Silicon Valley, we often think about computer-oriented work,
    but many industries—like space, defense, and semiconductors—deal with material
    iteration as part of their workflow.
  topic: business
- impact_reason: Connects AI research to fundamental scientific breakthroughs that
    could transform our understanding of physics
  relevance_score: 7
  source: llm_enhanced
  text: If we could find a 200 Kelvin superconductor, it would reveal much about the
    universe that we don't yet know. Observing such quantum effects at high temperatures
    would significantly update people's views of the universe.
  topic: predictions
- impact_reason: Reveals a fundamental challenge in scientific data that affects AI
    training - the subjective nature of experimental results
  relevance_score: 7
  source: llm_enhanced
  text: Additionally, negative results are often context-dependent. What might be
    a negative result for one person could be positive for another.
  topic: technical
- impact_reason: Articulates a clear business model for scientific AI that balances
    commercial viability with scientific advancement
  relevance_score: 7
  source: llm_enhanced
  text: We can accelerate science if we become a successful commercial entity. Our
    aim is to enhance advanced manufacturing across various industries, acting as
    an intelligence layer for teams to speed up their workflows.
  topic: business
- impact_reason: Illustrates why AI systems need to integrate multiple domains of
    expertise to solve complex scientific problems
  relevance_score: 7
  source: llm_enhanced
  text: Discovering an amazing superconductor requires knowledge of chemistry, physics,
    synthesis, and characterization, which no single human can master alone. Collaboration
    is essential.
  topic: technical
- impact_reason: Identifies a critical market need for AI in preserving and transferring
    domain expertise in traditional industries
  relevance_score: 7
  source: llm_enhanced
  text: They understand that technology is shifting quickly, but their work isn't
    changing as rapidly as they think it should. Some industries are losing key expertise
    and are looking for ways to preserve that knowledge.
  topic: business
- impact_reason: Provides a practical approach to AI deployment in conservative industries,
    emphasizing incremental value demonstration
  relevance_score: 7
  source: llm_enhanced
  text: We're not coming in to transform everything overnight; instead, we aim to
    solve a well-scoped, critical problem with clear evaluations. By collaborating
    with them, we can show how powerful our technology can be when optimized for their
    specific needs.
  topic: strategy
- impact_reason: Explains why certain scientific problems are more amenable to AI
    approaches than others, based on their fundamental physics
  relevance_score: 7
  source: llm_enhanced
  text: Superconductivity is a phase transition, which is more robust to details we
    cannot yet simulate. For example, the superconducting temperature is usually dominated
    by its crystal properties rather than defects or microstructure.
  topic: technical
- impact_reason: Reveals the cultural and conceptual gaps between AI researchers and
    domain scientists, and how to bridge them
  relevance_score: 7
  source: llm_enhanced
  text: Computer scientists often think in terms of APIs, while scientists focus on
    mapping inputs and outputs. We've built a team with people who bridge these different
    perspectives, facilitating active learning and creating APIs.
  topic: strategy
- impact_reason: Compares different AI approaches (retrieval vs pre-training) in enterprise
    contexts and their relative advantages
  relevance_score: 7
  source: llm_enhanced
  text: However, as we've seen with models like ChatGPT, pre-training on data allows
    for a richer understanding of the material. For this customer, they can grant
    privileges to employees, allowing retrieval to act on their behalf.
  topic: technical
- impact_reason: Provides concrete example of how mid-training can be applied to scientific
    domains with multi-level data integration
  relevance_score: 7
  source: llm_enhanced
  text: In the context of Periodic, does mid-training mean injecting custom data from
    experimental implementations in specific industries? Yes, it involves incorporating
    all relevant knowledge, including low-level descriptions of physical objects like
    crystal structures and higher-level semantic descriptions of materials.
  topic: technical
- impact_reason: Acknowledges current limitations of general AI models in specialized
    scientific domains, highlighting need for domain-specific training
  relevance_score: 7
  source: llm_enhanced
  text: The results indicated that the models were deficient in scientific analysis
    because they weren't trained for that purpose. However, many existing research
    teams are working to improve these capabilities.
  topic: technical
- impact_reason: Reveals innovative approach to AI agents using neural networks as
    tools rather than just traditional programming, expanding the concept of AI tooling
  relevance_score: 7
  source: llm_enhanced
  text: We consider tools for agents as not just programming languages but also other
    neural networks. Much of the physics code isn't particularly deep; it's often
    basic scripts.
  topic: technical
- impact_reason: Highlights critical enterprise AI considerations around access control,
    knowledge segmentation, and security in AI systems
  relevance_score: 7
  source: llm_enhanced
  text: For this customer, they can grant privileges to employees, allowing retrieval
    to act on their behalf. However, if we start pre-training or mid-training on different
    parts, we need to consider how to bucket that knowledge and create different types
    of systems.
  topic: business
- impact_reason: Shows how domain experts can improve AI model reasoning and performance,
    highlighting the value of interdisciplinary collaboration in AI development
  relevance_score: 7
  source: llm_enhanced
  text: A physicist might analyze the reasoning strategies of our models and suggest
    improvements based on established scientific principles. Collaborating with academia
    can be powerful, as industry often lacks awareness of these analyses and tools.
  topic: strategy
- impact_reason: Identifies a market opportunity where advanced AI techniques haven't
    yet penetrated traditional R&D industries
  relevance_score: 6
  source: llm_enhanced
  text: While there's a desire for innovation, many companies may not be aware of
    the recent techniques driving this wave in AI.
  topic: business
- impact_reason: Shows how current AI tools are already accelerating scientific work
    as research assistants, setting the stage for more advanced capabilities
  relevance_score: 6
  source: llm_enhanced
  text: One way they helped was when I needed to recall information about chemistry
    or physics; I could just talk to the chatbot and learn a lot of things I had forgotten.
    They were also helpful for coding, as we were writing simulations.
  topic: business
- impact_reason: Provides insight into building interdisciplinary AI teams that combine
    domain expertise with technical capabilities
  relevance_score: 6
  source: llm_enhanced
  text: For each area, we sought world-class talent. Each team has sub-teams, like
    a fractal. For the experimental side, we wanted to cover cell state chemistry,
    cell state physics, automation, and operational aspects of experiments.
  topic: strategy
- impact_reason: Challenges assumptions about expertise requirements in AI teams and
    emphasizes the importance of continuous learning
  relevance_score: 6
  source: llm_enhanced
  text: We joke that even our best physicists know less about physics than they think.
    For new candidates, the amount they need to learn about what we're doing isn't
    much different from what our best physicists need to learn about chemistry and
    material science.
  topic: strategy
- impact_reason: Highlights the importance of mission alignment in building specialized
    AI teams focused on scientific advancement
  relevance_score: 6
  source: llm_enhanced
  text: One of the biggest determinants is whether candidates care about the mission
    of accelerating science. If that's their primary goal, Periodic Labs is the best
    place for them.
  topic: strategy
- impact_reason: Provides a clear go-to-market strategy for AI companies targeting
    traditional industries
  relevance_score: 6
  source: llm_enhanced
  text: One thesis is to understand their biggest bottlenecks and map our systems
    to address those problems. We can demonstrate how we can dramatically accelerate
    their processes.
  topic: business
- impact_reason: Emphasizes the importance of academia-industry collaboration in AI
    development, particularly for specialized scientific applications
  relevance_score: 6
  source: llm_enhanced
  text: There's a significant connection between academia and industry. Much of the
    simulation tooling we use has been developed in academia. We benefit from deep
    technical progress in academia, and there's a strong synergy.
  topic: strategy
- impact_reason: Demonstrates strategic approach to building domain-specific AI companies
    through expert advisory boards and alignment with research funding trends
  relevance_score: 6
  source: llm_enhanced
  text: We're starting an advisory board with expertise spanning superconductivity,
    solstice chemistry, and physics. We want to ensure we're in touch with long-term
    research directions, as important government funding goes to these groups.
  topic: business
- impact_reason: Shows innovative approach to industry-academia collaboration through
    direct funding, potentially accelerating research in AI applications
  relevance_score: 6
  source: llm_enhanced
  text: We plan to establish a grant program to enable significant work in academia
    that may not fit well in industry. We want to accept grant proposals and support
    research that will benefit the community.
  topic: strategy
- impact_reason: Defines key hiring criteria for AI companies working on real-world
    applications, emphasizing curiosity and scientific motivation over pure technical
    skills
  relevance_score: 6
  source: llm_enhanced
  text: We're looking for deeply curious individuals who want to understand machine
    learning and science at a deeper level, who want to make contact with reality
    and advance science. This must be a driving motivation.
  topic: business
- impact_reason: Highlights the multidisciplinary nature of advanced AI applications
    and the need for diverse expertise beyond just ML engineering
  relevance_score: 6
  source: llm_enhanced
  text: What we're trying to achieve is incredibly challenging, so we need people
    who are process-oriented and goal-driven. We're looking for world-class talent
    across all pillars, including machine learning, experimental work, and simulation.
  topic: business
- impact_reason: Emphasizes the importance of speed and urgency in AI development
    for scientific applications, reflecting competitive pressures in the field
  relevance_score: 6
  source: llm_enhanced
  text: Liam and I are looking for candidates with a sense of urgency. We want these
    technologies to start improving science not in ten years but as soon as possible.
  topic: strategy
- impact_reason: Shows the complexity of multi-level knowledge integration in domain-specific
    AI models, from atomic to semantic levels
  relevance_score: 6
  source: llm_enhanced
  text: It involves incorporating all relevant knowledge, including low-level descriptions
    of physical objects like crystal structures and higher-level semantic descriptions
    of materials.
  topic: technical
- impact_reason: Simple but important insight about leveraging existing tools and
    advances rather than rebuilding everything, crucial for AI startup efficiency
  relevance_score: 5
  source: llm_enhanced
  text: You don't have to replicate everything.
  topic: business
- impact_reason: Illustrates the technology transfer pipeline from academia to industry,
    particularly relevant for AI and simulation tools
  relevance_score: 5
  source: llm_enhanced
  text: Recently, large-scale simulations have been conducted in industry labs, but
    many of those tools were developed in academia and then passed on.
  topic: strategy
source: a16z
summary: "# Building an AI Physicist: ChatGPT Co-Creator's Next Venture\n\n## **Focus\
  \ Area**\nThis episode centers on **experiment-in-the-loop AI for physics and chemistry**,\
  \ featuring Periodic Labs' mission to create an \"AI physicist.\" The discussion\
  \ covers reinforcement learning with physical reward functions, quantum mechanics\
  \ simulations, automated materials synthesis, and the integration of LLMs with real-world\
  \ laboratory experiments. Key technologies include high-compute RL, mid-training\
  \ techniques, powder synthesis automation, and quantum mechanical simulations.\n\
  \n## **Key Technical Insights**\n• **Physical Reward Functions**: Moving beyond\
  \ digital reward functions (math/code graders) to real-world experimental validation,\
  \ where nature itself becomes the RL environment for training AI systems on physics\
  \ and chemistry\n\n• **Experiment-Loop Integration**: Combining LLMs with automated\
  \ laboratory equipment (powder synthesis robots) and quantum mechanics simulations\
  \ to create iterative scientific discovery systems that can generate and test hypotheses\n\
  \n• **Mid-Training for Domain Knowledge**: Extending pre-training with specialized\
  \ physics/chemistry data to inject domain-specific knowledge that doesn't exist\
  \ in standard internet-scraped datasets\n\n## **Business/Investment Angle**\n• **Co-pilot\
  \ Tools Market**: Targeting advanced industries (space, defense, semiconductors,\
  \ manufacturing) with AI tools to accelerate R&D workflows, addressing massive existing\
  \ R&D budgets in these sectors\n\n• **Data Scarcity Opportunity**: Exploiting the\
  \ gap where critical experimental data doesn't exist online or is too noisy in literature,\
  \ creating proprietary datasets through automated experimentation\n\n• **Knowledge\
  \ Preservation**: Addressing industry concerns about losing key expertise by capturing\
  \ and scaling institutional knowledge through AI systems\n\n## **Notable Companies/People**\n\
  • **Liam Vettas**: ChatGPT co-creator, now co-founder of Periodic Labs\n• **Dosh\
  \ Vettas**: Former DeepMind physics team leader, co-founder of Periodic Labs  \n\
  • **Periodic Labs**: 30-person frontier AI research lab building experiment-in-the-loop\
  \ AI\n• **References to**: OpenAI, DeepMind, Anthropic, Google Brain as context\
  \ for the founders' backgrounds\n\n## **Future Implications**\nThe conversation\
  \ suggests AI is evolving from discussing science to conducting science through\
  \ autonomous experimentation. This points toward AI systems that can make fundamental\
  \ scientific discoveries (like room-temperature superconductors) and dramatically\
  \ accelerate materials R&D across critical industries. The integration of physical\
  \ experimentation with AI training represents a new frontier beyond current LLM\
  \ capabilities.\n\n## **Target Audience**\n**AI/ML researchers and executives**\
  \ in frontier AI labs, **materials scientists and physicists** interested in AI\
  \ applications, **R&D leaders** in advanced manufacturing, space, defense, and semiconductor\
  \ industries, and **investors** focused on deep tech and scientific AI applications.\n\
  \n---\n\n## **Comprehensive Analysis**\n\nThis podcast episode presents a fascinating\
  \ convergence of frontier AI research and experimental physics, centered around\
  \ Periodic Labs' ambitious mission to create an \"AI physicist\" capable of autonomous\
  \ scientific discovery. The conversation reveals a fundamental shift in AI development\
  \ philosophy—moving from purely digital optimization to systems that interact with\
  \ and learn from the physical world.\n\n**The Core Innovation and Technical Framework**\n\
  \nThe central thesis of Periodic Labs revolves around replacing traditional AI reward\
  \ functions with real-world experimental validation. While current frontier models\
  \ excel at tasks with programmatically checkable outputs (math problems, code compilation),\
  \ they struggle with scientific discovery because the necessary experimental data\
  \ either doesn't exist or is too noisy to be useful. The founders argue that true\
  \ scientific progress requires iterative experimentation—something that even the\
  \ smartest humans cannot achieve without the ability to test hypotheses in the real\
  \ world.\n\nTheir technical approach combines three critical components: large language\
  \ models trained on scientific literature, quantum mechanics simulations for theoretical\
  \ predictions, and automated laboratory equipment for experimental validation. The\
  \ lab focuses initially on powder synthesis—a relatively simple process where robots\
  \ can mix materials and heat them to create new compounds, potentially discovering\
  \ novel superconductors and magnetic materials.\n\n**The Superconductivity North\
  \ Star**\n\nThe choice of high-temperature superconductivity as their primary goal\
  \ is both scientifically and commercially strategic. Currently, the best ambient-pressure\
  \ superconductor operates at 135 Kelvin, and discovering materials that work at\
  \ higher temperatures (ideally room temperature) would revolutionize technology\
  \ from power transmission to quantum computing. Scientifically, superconductivity\
  \ represents a robust target because it's primarily determined by crystal properties\
  \ rather than difficult-to-simulate defects, making it more amenable to their simulation-experiment\
  \ loop.\n\nThe discovery of a 200 Kelvin superconductor would not only have massive\
  \ commercial implications but would fundamentally update our understanding of quantum\
  \ mechanics at macroscopic scales. This represents the kind of breakthrough that\
  \ could validate their entire approach while opening up entirely new technological\
  \ possibilities.\n\n**Bridging Scientific Cultures**\n\nOne of the most intriguing\
  \ aspects of Periodic Labs is their approach to team building and culture. With\
  \ roughly 30 people split between ML researchers and physical scientists, they've\
  \ had to create systems for knowledge transfer between traditionally separate domains.\
  \ Their weekly teaching sessions, where ML researchers explain reinforcement learning\
  \ while physicists cover quantum mechanics, represent a microcosm of the broader\
  \ challenge in applying AI to scientific domains.\n\nThis cultural integration challenge\
  \ reflects a broader trend in modern science, where the depth of knowledge required\
  \ in any specific field makes true interdisciplinary work increasingly difficult.\
  \ The founders argue that discovering breakthrough materials requires expertise\
  \ spanning chemistry, physics, synthesis, and character"
tags:
- artificial-intelligence
- ai-infrastructure
- generative-ai
- investment
- startup
- google
- openai
- anthropic
title: 'Building an AI Physicist: ChatGPT Co-Creator’s Next Venture'
topics:
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 125
  prominence: 1.0
  topic: artificial intelligence
- keywords:
  - gpu
  - tensor
  - training
  - inference
  - model deployment
  - vector database
  mentions: 23
  prominence: 1.0
  topic: ai infrastructure
- keywords:
  - generative ai
  - genai
  - chatgpt
  - gpt
  - claude
  - text generation
  - image generation
  mentions: 11
  prominence: 1.0
  topic: generative ai
- keywords:
  - investment
  - funding
  - valuation
  - ipo
  - acquisition
  mentions: 7
  prominence: 0.7
  topic: investment
- keywords:
  - startup
  - entrepreneur
  - founder
  - venture
  mentions: 2
  prominence: 0.2
  topic: startup
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-10-03 06:23:06 UTC -->
