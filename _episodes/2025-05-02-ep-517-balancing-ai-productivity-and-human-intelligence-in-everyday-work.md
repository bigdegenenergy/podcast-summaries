---
companies:
- category: unknown
  confidence: medium
  context: This is the Everyday AI Show, the everyday podcast where we simplify AI
    and br
  name: Everyday AI Show
  position: 12
- category: unknown
  confidence: medium
  context: some time. It's going to make me more productive. Am I just going to get
    dumb over time, the more I blin
  name: Am I
  position: 551
- category: unknown
  confidence: medium
  context: . I can't wait. What's going on, y'all? My name's Jordan Wilson, and welcome
    to Everyday AI. This is your daily l
  name: Jordan Wilson
  position: 1061
- category: unknown
  confidence: medium
  context: n, y'all? My name's Jordan Wilson, and welcome to Everyday AI. This is
    your daily live stream podcast and free
  name: Everyday AI
  position: 1091
- category: unknown
  confidence: medium
  context: o the show, bringing him on. There we go. We have Sumit Gupta, who is the
    lead BI engineer at Notion. Sumit, th
  name: Sumit Gupta
  position: 1830
- category: tech
  confidence: high
  context: have Sumit Gupta, who is the lead BI engineer at Notion. Sumit, thank you
    so much for joining the Everyda
  name: Notion
  position: 1874
- category: unknown
  confidence: medium
  context: u could describe that as well. Yeah, sounds good. So I lead the BI engineering
    at Notion. I support the
  name: So I
  position: 2419
- category: unknown
  confidence: medium
  context: I in professional life for a couple of years now. And I'm pretty excited
    to talk about the topic. I'm act
  name: And I
  position: 2986
- category: unknown
  confidence: medium
  context: b is to create dashboards and reports in Tableau. Before AI, let's say
    if I wanted to create a Tableau report
  name: Before AI
  position: 3481
- category: tech
  confidence: high
  context: 'uch anything, every AI that you can imagine: GPT, Perplexity, Claude,
    all the AIs have their own strengths. In'
  name: Perplexity
  position: 4051
- category: unknown
  confidence: medium
  context: ancial year and comparing financial year metrics. If Claude will spit out
    200 calculated fields, if I was to
  name: If Claude
  position: 4241
- category: unknown
  confidence: medium
  context: e me at least four to five hours to get it right. With Claude, it does
    not even take four to five minutes. It t
  name: With Claude
  position: 4371
- category: unknown
  confidence: medium
  context: re were like article writer services, right, like Copy AI and those kind
    of companies, or more AI, etc. And
  name: Copy AI
  position: 5824
- category: unknown
  confidence: medium
  context: companies, or more AI, etc. And those were great. But GPT came along, and
    then you're like, wait a minute,
  name: But GPT
  position: 5900
- category: tech
  confidence: high
  context: his is like, life-changing, right, where I was at Snowflake, I was tasked
    to build like a simulator report. A
  name: Snowflake
  position: 6084
- category: unknown
  confidence: medium
  context: debug my code because previously you would go on Stack Overflow, you would
    research, you would spend a couple of
  name: Stack Overflow
  position: 6299
- category: tech
  confidence: high
  context: t I am already an expert. Right? I'm an expert in Google search. But nowadays
    with the largest launch web
  name: Google
  position: 8323
- category: unknown
  confidence: medium
  context: r speakers, they have a call for speakers, right? And Perplexity gave like
    quantifiable different things. If I was
  name: And Perplexity
  position: 8771
- category: unknown
  confidence: medium
  context: rplexity gave like quantifiable different things. If I was to do that,
    right, it would take me a couple
  name: If I
  position: 8827
- category: unknown
  confidence: medium
  context: here. I think a couple of weeks back, YC, right, Y Combinator, published
    a post where 90% of the YC-backed star
  name: Y Combinator
  position: 9900
- category: unknown
  confidence: medium
  context: based off AI coding, right? I mean, that's great. But I think I have a
    couple of examples that I would wa
  name: But I
  position: 10061
- category: unknown
  confidence: medium
  context: al stakeholders vibe coded and wrote a SQL query. The SQL query with the
    joins and everything else should h
  name: The SQL
  position: 10731
- category: unknown
  confidence: medium
  context: e this chart? Right? How do I improve this query? Can I make this query
    more efficient? Right? And I have
  name: Can I
  position: 13309
- category: tech
  confidence: high
  context: emotional topic for me itself. I'm like, it's an inflection point where
    I'm like, I don't want to get this cu
  name: Inflection
  position: 13879
- category: tech
  confidence: high
  context: we covered this one in our newsletter. It was for Microsoft. It was a great
    study. It was called "The Impact
  name: Microsoft
  position: 14379
- category: unknown
  confidence: medium
  context: r Microsoft. It was a great study. It was called "The Impact of Generative
    AI on Critical Thinking," and it fo
  name: The Impact
  position: 14427
- category: unknown
  confidence: medium
  context: t was a great study. It was called "The Impact of Generative AI on Critical
    Thinking," and it found that for know
  name: Generative AI
  position: 14441
- category: unknown
  confidence: medium
  context: dy. It was called "The Impact of Generative AI on Critical Thinking," and
    it found that for knowledge recall, 72% of
  name: Critical Thinking
  position: 14458
- category: unknown
  confidence: medium
  context: less effort or less effort compared to not using Gen AI. So to me, I think,
    right, and maybe this isn't a
  name: Gen AI
  position: 14607
- category: tech
  confidence: high
  context: ery podcast. Companies like Adobe, Microsoft, and Nvidia have partnered
    with us because they trust our exp
  name: Nvidia
  position: 15713
- category: unknown
  confidence: medium
  context: ng it, we had to do it because GPT did not exist. Like I wrote a book on
    Tableau dashboards, it took me a
  name: Like I
  position: 17931
- category: unknown
  confidence: medium
  context: quick search tool, Perplexity, deep research, or Open AI deep research.
    So I feel I'm able to bring in all
  name: Open AI
  position: 18999
- category: unknown
  confidence: medium
  context: oogle says, "Did you mean," let's say a word like X Y Z, and you don't
    even try to correct it, you just c
  name: X Y Z
  position: 19510
- category: unknown
  confidence: medium
  context: te SQL queries myself, I would know how to write `CASE WHEN` statements,
    and I would know how to write, let's
  name: CASE WHEN
  position: 19998
- category: unknown
  confidence: medium
  context: look up things on ChatGPT, search for Perplexity, Google Search, whatever,
    on a certain topic that I'm trying to
  name: Google Search
  position: 20660
- category: unknown
  confidence: medium
  context: es, a lot of the first sources are myself, right? Because I covered something
    six months ago, or I had a gues
  name: Because I
  position: 20835
- category: unknown
  confidence: medium
  context: r knowledge base in the company, and that's where Notion AI shines. The
    fact that I have had so many instance
  name: Notion AI
  position: 24105
- category: unknown
  confidence: medium
  context: '''s a whole concept of a "second brain" on Notion. Just Google that term,
    "second brain on Notion," and you woul'
  name: Just Google
  position: 25092
- category: unknown
  confidence: medium
  context: ker anytime soon? I know folks talk a lot about, "Is AI going to take my
    job?" or "Is AI going to replace
  name: Is AI
  position: 25681
- category: unknown
  confidence: medium
  context: AI can help. We all know that. AI is not perfect. Anytime I see an AI output
    for a metric or something, I gen
  name: Anytime I
  position: 26220
- category: ai_application
  confidence: high
  context: Mentioned as a premium subscription service the speaker uses, referring
    to OpenAI's models (like ChatGPT).
  name: GPT
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as a premium subscription service the speaker uses, specifically
    for research and finding speaking opportunities.
  name: Perplexity
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as a premium subscription service the speaker uses, specifically
    for generating complex calculated fields in Tableau quickly.
  name: Claude
  source: llm_enhanced
- category: ai_startup
  confidence: high
  context: Mentioned as an example of an 'article writer service' that existed before
    GPT.
  name: Copy AI
  source: llm_enhanced
- category: ai_startup
  confidence: high
  context: Mentioned alongside Copy AI as an example of an 'article writer service'
    that existed before GPT.
  name: More AI
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: The platform where the speaker (Sumit) worked and encountered a high-cost
    SQL query execution issue due to AI-generated code.
  name: Snowflake
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as a tool that utilizes advanced coding output capabilities,
    likely referring to an AI-powered code editor.
  name: Cursor
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Mentioned as a company that partnered with the podcast host's organization
    and conducted a study on Generative AI's impact on critical thinking.
  name: Microsoft
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: Mentioned as a company that has partnered with the podcast host's organization.
  name: Nvidia
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Mentioned as a company that has partnered with the podcast host's organization.
  name: Adobe
  source: llm_enhanced
- category: ai_ecosystem
  confidence: high
  context: Mentioned for publishing a post stating that 90% of YC-backed startups
    are 'vibe coding' (using AI for development).
  name: YC (Y Combinator)
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: Mentioned in the context of a security breach where an AI-generated code
    snippet exposed an AWS access key.
  name: AWS
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: The company where the guest, Sumit Gupta, works as the lead BI engineer.
    They utilize AI heavily for productivity.
  name: Notion
  source: llm_enhanced
- category: ai_tooling
  confidence: high
  context: The data visualization tool Sumit uses, where AI (Claude) is used to generate
    complex calculations.
  name: Tableau
  source: llm_enhanced
- category: ai_ecosystem
  confidence: medium
  context: Mentioned as the traditional resource for debugging code before AI tools
    like GPT became effective.
  name: Stack Overflow
  source: llm_enhanced
- category: ai_research
  confidence: low
  context: Mentioned in passing regarding a post about teaching database concepts,
    implying a connection to academic research/education in AI/DB.
  name: Berkeley professor (unnamed)
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned multiple times as a specific large language model/AI tool being
    used by students and professionals.
  name: ChatGPT
  source: llm_enhanced
- category: ai_research
  confidence: medium
  context: Referenced via a professor at the institution discussing student reliance
    on AI.
  name: Berkeley
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: Mentioned in the context of deep research capabilities, likely referring
    to the company behind ChatGPT.
  name: Open AI
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Mentioned in the context of its search correction feature, contrasting
    with AI recall ability.
  name: Google
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: The specific AI assistant feature within Notion, highlighted for its ability
    to search proprietary company data.
  name: Notion AI
  source: llm_enhanced
date: 2025-05-02 13:00:00 +0000
duration: 34
has_transcript: false
layout: episode
llm_enhanced: true
original_url: https://pscrb.fm/rss/p/www.buzzsprout.com/2175779/episodes/17085736-ep-517-balancing-ai-productivity-and-human-intelligence-in-everyday-work.mp3
processing_date: 2025-10-05 20:34:51 +0000
quotes:
- length: 200
  relevance_score: 5
  text: So whether you're looking for ChatGPT training for thousands or just need
    help building your front-end AI strategy, you can partner with us too, just like
    some of the biggest companies in the world do
  topics: []
- length: 273
  relevance_score: 4
  text: And you know, we hear constantly about how these LLMs and the benchmarks and
    these pseudo IQ tests, and it's getting to the point, as we quote unquote approach
    AGI or ASI or whatever you want to say, right, that any large language model is
    going to know more than any human
  topics: []
- length: 157
  relevance_score: 4
  text: Companies like Adobe, Microsoft, and Nvidia have partnered with us because
    they trust our expertise in educating the masses around generative AI to get ahead
  topics: []
- length: 234
  relevance_score: 4
  text: Yeah, so anyone that's listening to the show, you all know I hate when people
    come on here and pitch their products, but Michelle is asking, and I feel, Sumit,
    you have to take this one because she's asking, "Tell us more about Notion
  topics: []
- length: 205
  relevance_score: 3
  text: We're going to be recapping some of the most important points and takeaways
    from this very conversation and laying it all out for you so you can actually
    take this info to grow your company and your career
  topics: []
- length: 50
  relevance_score: 3
  text: And you know, you have to start keeping that check
  topics: []
- impact_reason: This is the central, philosophical question driving the entire discussion,
    highlighting the core concern about cognitive atrophy due to AI reliance.
  relevance_score: 10
  source: llm_enhanced
  text: Am I just going to get dumb over time, the more I blindly hand off knowledge
    work to a large language model?
  topic: safety/ethics
- impact_reason: 'Articulates the desired outcome: achieving productivity gains without
    sacrificing critical thinking skills—the key challenge for AI adoption.'
  relevance_score: 10
  source: llm_enhanced
  text: How can we still use the best technology that I think any of us have ever
    seen maybe in our lifetime, yet still keep our brains sharp, right? How can we
    find that balance of being productive, but not just getting dumber at the same
    time?
  topic: strategy
- impact_reason: A stark warning for professionals in the tech industry about the
    necessity of continuous skill development in the age of AI.
  relevance_score: 10
  source: llm_enhanced
  text: If you're not learning, if you're not critical thinking, you'll be out of
    a job in less than six months.
  topic: business/strategy
- impact_reason: A critical, real-world security failure resulting directly from 'vibe
    coding'—failing to implement basic security guardrails.
  relevance_score: 10
  source: llm_enhanced
  text: Someone wrote a code and they used AWS access key, etc., and the backend was
    in police secure, right? And then hackers were able to access the backend, and
    the founder saw like a million-dollar bill, right?
  topic: safety/technical
- impact_reason: A powerful example of AI-generated inefficiency leading to massive,
    unexpected operational costs (FinOps risk) when guardrails are absent.
  relevance_score: 10
  source: llm_enhanced
  text: Another instance is recently, one of our non-technical stakeholders vibe coded
    and wrote a SQL query. The SQL query with the joins and everything else should
    have taken this, let's say, a few dollars to execute on our platform, like on
    Snowflake, but it took over $10,000 because when you're querying like three billion
    rows, if you're not careful, if you're not efficient in writing a query, the `SELECT
    *` statement can cost you thousands of dollars.
  topic: business/technical
- impact_reason: 'Defines the essential human role in the AI workflow: acting as the
    necessary safety and efficiency supervisor (the ''guardrail'').'
  relevance_score: 10
  source: llm_enhanced
  text: When I think of AI, I think of myself as a guardrail for AI, right? AI can
    do what I ask it to do, but it's my job to make sure there are guardrails around
    the gun, make sure that it's working, but it's not costing me dollars, right?
  topic: safety/strategy
- impact_reason: Highlights a crucial personal guardrail for maintaining fundamental
    skills and expertise, directly addressing the fear of over-reliance.
  relevance_score: 10
  source: llm_enhanced
  text: the first iteration is always mine. Right? I'll go ahead and build the chart,
    right, because I don't want to lose that touch.
  topic: safety/strategy
- impact_reason: Provides quantitative evidence supporting the anecdotal concern that
    Gen AI significantly reduces cognitive effort in knowledge recall tasks.
  relevance_score: 10
  source: llm_enhanced
  text: It was called "The Impact of Generative AI on Critical Thinking," and it found
    that for knowledge recall, 72% of participants reported using much less effort
    or less effort compared to not using Gen AI.
  topic: safety/data
- impact_reason: A powerful, relatable analogy summarizing the core argument against
    over-reliance on AI for cognitive tasks.
  relevance_score: 10
  source: llm_enhanced
  text: I think of the brain as a muscle, right? And the more you use it, the smarter
    you get. The less you use it, the more you turn it off, right, the dumber you
    get.
  topic: safety/strategy
- impact_reason: A strong warning against pervasive AI adoption, framing it as a trade-off
    where immediate productivity masks future skill degradation.
  relevance_score: 10
  source: llm_enhanced
  text: You cannot be bringing AI into your life for everything. I mean, you might
    be tempted to, right, but it's like the way I think of it is like you're getting
    short-term results for long-term losses.
  topic: safety/strategy
- impact_reason: 'Captures the paradox of modern AI use: increased perceived knowledge
    and productivity coupled with decreased long-term retention.'
  relevance_score: 10
  source: llm_enhanced
  text: I've never felt so productive in my life. I've never felt that I've learned
    so much in my life since AI came out. ... but then I just feel I forget it, right?
    Like, do you ever find yourself, yes, now I'm more productive and more knowledgeable,
    but I'm still not retaining anything?
  topic: safety/strategy
- impact_reason: A specific, technical example (SQL syntax recall) demonstrating how
    reliance on LLMs erodes foundational, non-repetitive technical knowledge.
  relevance_score: 10
  source: llm_enhanced
  text: I have started noticing that when I used to write SQL queries myself, I would
    know how to write `CASE WHEN` statements... But now, if I don't have GPT, I have
    to like, okay, how do I write even a `CASE` statement, right?
  topic: technical/safety
- impact_reason: Draws a sharp distinction between generations raised with and without
    ubiquitous AI, predicting a structural deficit in cognitive 'muscle' for younger
    cohorts.
  relevance_score: 10
  source: llm_enhanced
  text: For folks younger than us, like if you're 15 or 16 right now, you have the
    whole computer in your palms, right, and you are using AI for everything in your
    life, right? So the fact that you do not go through that muscle-bending exercise
    for like a decade or two, you don't have that retention ability to recall or retain
    that much. Your muscle's not built, your brain muscle's just not built.
  topic: predictions/safety
- impact_reason: 'Provides a clear definition of the ideal human-AI relationship:
    AI as a complementary tool, not a replacement for human agency or comprehensive
    capacity.'
  relevance_score: 10
  source: llm_enhanced
  text: AI is your decision, not your personal full-fledged human who can do everything
    that you can imagine. It should be complimentary. AI should always be complimentary
    to you, not be the way down.
  topic: strategy/safety
- impact_reason: 'Demonstrates a powerful use case for LLMs: contextual retrieval
    across disparate, proprietary communication channels (like Slack) to provide verifiable
    sourcing.'
  relevance_score: 10
  source: llm_enhanced
  text: Notion here actually goes through the whole Slack history that we have and
    gives me the exact link and conversation context of, "Okay, this is when demand
    generation was talking about this."
  topic: Technical/Enterprise Search & Context
- impact_reason: 'Presents the productivity multiplier effect: AI as an augmentation
    tool that allows skilled workers to dramatically increase output (the ''40 jobs''
    analogy).'
  relevance_score: 10
  source: llm_enhanced
  text: But the counterargument to that is, if you're a knowledge worker and if you
    were doing, let's say, 10 tasks a week, with AI, if you upgrade yourself, if you
    know how to use AI to complement your job, instead of doing 10 jobs, if you're
    doing 40 jobs now because of AI, right?
  topic: Business/Productivity
- impact_reason: 'Crucial advice for AI adoption: the necessity of human verification,
    especially for high-stakes data or metrics, due to potential hallucinations or
    inaccuracies.'
  relevance_score: 10
  source: llm_enhanced
  text: Anytime I see an AI output for a metric or something, I generally go about
    and verify that myself, right?
  topic: Safety/Validation & Trust
- impact_reason: 'Defines the future role of the knowledge worker: shifting from information
    gathering to critical validation and synthesis.'
  relevance_score: 10
  source: llm_enhanced
  text: And as a knowledge worker, if your job wouldn't be now to research a lot,
    but to validate what the research is saying, instead of doing 10 tasks, if you
    upgrade yourself to do, let's say, 30 tasks, you're always going to be in demand.
  topic: Strategy/Future of Work
- impact_reason: 'A strong warning: workers who rely on AI without adding validation
    will be replaced by those who leverage AI for amplification.'
  relevance_score: 10
  source: llm_enhanced
  text: But if you are one of those lazy workers where you're still stuck at 10 and
    you ask AI to do 90% of your job, and let's say you do a report for a city of
    your company, and the city of your users that number in a board, and that number
    is absolutely weird and it does not make sense, you're not going to be in your
    job because your job is to validate and verify and obviously get that info.
  topic: Safety/Accountability & Job Risk
- impact_reason: A provocative, direct admission that sets the stage for a nuanced
    discussion, acknowledging the immediate negative potential.
  relevance_score: 9
  source: llm_enhanced
  text: What is using AI making us dumb? Yes, the short answer is yes, but let me
    have a couple of minutes to explain that part.
  topic: safety/ethics
- impact_reason: Provides a concrete, quantifiable example of AI's massive productivity
    boost in a specialized task (writing calculated fields in Tableau), demonstrating
    immediate ROI.
  relevance_score: 9
  source: llm_enhanced
  text: If I was to do that, it would take me at least four to five hours to get it
    right. With Claude, it does not even take four to five minutes. It takes like
    less than a minute. It makes me productive, 100%.
  topic: business/technical
- impact_reason: Directly links productivity gains to laziness and subsequent cognitive
    decline, reinforcing the initial concern with personal testimony.
  relevance_score: 9
  source: llm_enhanced
  text: But the counter of that is it's made me lazy, let's put it that way. Right?
    And when you're lazy, you're not thinking really hard. I mean, when you're not
    thinking hard, you're dumb.
  topic: safety/ethics
- impact_reason: 'Offers a clear strategy for AI usage: augmenting existing expertise
    rather than outsourcing core professional identity or high-level creation.'
  relevance_score: 9
  source: llm_enhanced
  text: I only use AI for things that I am already great at or you need some support.
    I wouldn't go about and be like, oh, I'm an AI researcher, technical writer, research
    paper of 30 pages.
  topic: strategy
- impact_reason: 'A concise, actionable principle for AI adoption: automate repetition
    within known domains.'
  relevance_score: 9
  source: llm_enhanced
  text: So in short, I want AI to do the repetitive tasks that I generally used to
    do previously, and in the area that I am already an expert.
  topic: strategy
- impact_reason: 'Provides a practical method for maintaining core skills: always
    perform the initial, foundational work yourself before seeking AI augmentation
    or iteration.'
  relevance_score: 9
  source: llm_enhanced
  text: Anything, let's say, and as I mentioned, especially in my case, right, when
    I'm SQL querying or when I'm writing or building, the first iteration is always
    mine. Right? I'll go ahead and build the chart, right, because I don't want to
    lose that touch.
  topic: strategy
- impact_reason: Emphasizes the critical need for self-imposed 'cutoffs' or boundaries
    when using AI to prevent skill atrophy, framing it as a personal responsibility.
  relevance_score: 9
  source: llm_enhanced
  text: Without that cutoff, I would be even more dumb. I mean, I keep using "dumb"
    very loosely, but not that I'm dumb—I work for Notion, right? I mean, obviously
    we're all sorted here. But the fact that that cutoff is really important for me.
  topic: safety/strategy
- impact_reason: 'Expresses a core anxiety about the future: that the perceived necessity
    of human input (the cutoff) will decrease as AI improves, leading to greater dependency.'
  relevance_score: 9
  source: llm_enhanced
  text: I am hoping and praying that that cutoff does not get lower and lower as the
    days go by, and it should—it should ideally get higher and higher.
  topic: safety/predictions
- impact_reason: 'Articulates the central philosophical dilemma of the AGI era: whether
    to embrace AI''s superior knowledge or prioritize human skill development.'
  relevance_score: 9
  source: llm_enhanced
  text: any large language model is going to know more than any human. So how should
    we be addressing this, right? Because part of me is like, okay, maybe it's good
    to just give more and more to these large language models because they're smarter
    and they know it, and I don't, versus, okay, well, I'm not then developing new
    skills.
  topic: predictions/strategy
- impact_reason: Provides a concrete, high-stakes example (academic performance) illustrating
    the failure mode of AI use when critical understanding is required.
  relevance_score: 9
  source: llm_enhanced
  text: I think I saw a post last week from a Berkeley professor... during tests,
    right, midterms, the average score was the lowest it has been in the last 10 years,
    right, because students actually, without even trying to understand or learn,
    they're using AI to write assignments...
  topic: safety/predictions
- impact_reason: Quantifies the potential speed-up (1.5 years to 3 months) and elevates
    the importance of setting AI usage boundaries to the same level as product quality.
  relevance_score: 9
  source: llm_enhanced
  text: Nowadays, if I was to do the same thing again, it would take me less than
    three months because I know for a fact a lot of things would be GPT-driven, right?
    So the fact that having that cutoff for when to use AI and when not to use AI
    is going to be as critical as the fact that your product is supposed to be great.
  topic: business/strategy
- impact_reason: A concise, impactful statement summarizing the fear of cognitive
    assimilation by the tools being used.
  relevance_score: 9
  source: llm_enhanced
  text: I am becoming more of an AI than a human.
  topic: safety
- impact_reason: 'A long-term prediction about workforce stratification: AI might
    shrink the pool of truly capable critical thinkers, making the remaining few disproportionately
    valuable.'
  relevance_score: 9
  source: llm_enhanced
  text: I hope that as much as AI is a boom, it's helping folks, it does not turn
    into a curse in five to 10 years where there's, let's say now, there's 10% of
    the world population who can get a job in tech because of their critical thinking
    ability. But in 10 years, I hope that number still stays at 10 or does not go
    down to let's say one or two percentage...
  topic: predictions/business
- impact_reason: A strategic call to action emphasizing that societal and business
    complexity requires a broad base of capable humans, not just a tiny elite augmented
    by AI.
  relevance_score: 9
  source: llm_enhanced
  text: the top one or two percent are not going to run the world. You need more people.
    You need critical thinking ability. You need people who can retain and recall
    and use AI as an assistant, not replace a real human with the AI.
  topic: strategy
- impact_reason: Highlights the immediate, practical value of enterprise-specific
    AI in quickly onboarding new employees by synthesizing historical company knowledge.
  relevance_score: 9
  source: llm_enhanced
  text: The fact that I have had so many instances with Notion here, I'm like, "Hmm,
    did someone talk about a metric?" because I have been at Notion for less than
    a year, so there have been metrics that the company has been using for multiple
    years.
  topic: Business/Practical AI Application
- impact_reason: Poses the central, high-stakes question regarding AI's impact on
    white-collar employment.
  relevance_score: 9
  source: llm_enhanced
  text: She's asking, "Could this be the end of the knowledge worker?"
  topic: Predictions/Societal Impact
- impact_reason: Offers a nuanced view that AI will target the repetitive aspects
    of knowledge work, rather than eliminating the entire role outright.
  relevance_score: 9
  source: llm_enhanced
  text: I think that's partially true for jobs which have a lot of repetitive aspects
    to it, right? And I believe knowledge workers fall in that category.
  topic: Predictions/Job Displacement
- impact_reason: Concise summary of the career risk associated with failing to implement
    human oversight on AI outputs.
  relevance_score: 9
  source: llm_enhanced
  text: But if you don't validate and verify, you're going to be out of a job, and
    that's sort of the thing.
  topic: Strategy/Career Advice
- impact_reason: Highlights the extreme adoption rate of AI-assisted coding ('vibe
    coding') even within top-tier startup accelerators like Y Combinator.
  relevance_score: 8
  source: llm_enhanced
  text: I think the vibe coding moment is here. I think a couple of weeks back, YC,
    right, Y Combinator, published a post where 90% of the YC-backed startups are
    vibe coding, like their apps completely based off AI coding, right?
  topic: business/predictions
- impact_reason: Reiterates the core strategic advice for maximizing AI utility while
    minimizing cognitive risk.
  relevance_score: 8
  source: llm_enhanced
  text: My way of thinking of the best use case of AI is a repetitive task.
  topic: strategy
- impact_reason: Frames LLMs as vast repositories of best practices (like visualization
    patterns) that can be leveraged for iterative improvement rather than initial
    creation.
  relevance_score: 8
  source: llm_enhanced
  text: Think of AI, what's an LLM? LLMs are being said like a million visualizations,
    right? And they know what to look for, what's good, what's great, what's bad.
    Right? So you can take the suggestion, and that's what I do. I take the suggestion.
  topic: technical/strategy
- impact_reason: Connects skill maintenance directly to career viability in a competitive
    job market, framing critical thinking as a non-negotiable asset.
  relevance_score: 8
  source: llm_enhanced
  text: I want to keep a high bar of making sure that I stay on top of my feet, I
    get to critical thinking, and I nail the job. The market is already rough. You
    don't want to make it easy for folks to not hire you.
  topic: business/strategy
- impact_reason: 'Identifies a key competitive differentiator for enterprise AI tools:
    the ability to securely integrate and reason over proprietary, internal knowledge
    bases.'
  relevance_score: 8
  source: llm_enhanced
  text: GPT works great, but it does not have access to your personal information,
    or your company information or knowledge base in the company, and that's where
    Notion AI shines.
  topic: business/technical
- impact_reason: Points to the emergent community-driven ecosystem around productivity
    tools integrated with AI, emphasizing the 'second brain' concept as a key user
    paradigm.
  relevance_score: 8
  source: llm_enhanced
  text: If you are new to Notion AI, I would highly recommend you just Google "Notion
    templates." People have the whole brain on Notion. That is the whole concept,
    Jordan, you would know. There's a whole concept of a "second brain" on Notion.
  topic: Strategy/Ecosystem
- impact_reason: Frames the core value proposition of the knowledge worker economy,
    setting the stage for how AI disruption will affect established business models.
  relevance_score: 8
  source: llm_enhanced
  text: For decades, we've gotten jobs, we've gotten promoted, companies have grown
    into unicorns, trillion-dollar companies, based on what? It's people's knowledge.
  topic: Business/Strategy
- impact_reason: Illustrates how specialized AI tools (like Perplexity) excel at complex,
    multi-step research tasks that previously required significant manual effort.
  relevance_score: 7
  source: llm_enhanced
  text: I'm an expert in Google search. But nowadays with the largest launch web search,
    right, I'll do it. But before that complexity, I would ask Perplexity to be like,
    you know what? Like literally the early last week, I've been looking to do a lot
    more speaking. Speaking exists here. I went to Perplexity. I'm like, Perplexity,
    go about and search like data conferences or analytics conferences which are still
    open for speakers, they have a call for speakers, right?
  topic: technical/business
- impact_reason: 'Introduces a counterpoint to the universal benefit narrative: AI
    usage might sometimes increase operational costs, balancing the productivity gains.'
  relevance_score: 7
  source: llm_enhanced
  text: from some of your personal examples and how using AI might just be more expensive,
    it might be making us much better,
  topic: Business/Cost Analysis
- impact_reason: Introduces a popular productivity concept ('Second Brain') and links
    it to the utility of modern knowledge management tools like Notion.
  relevance_score: 6
  source: llm_enhanced
  text: There's a whole concept of a "second brain" on Notion. Just Google that term,
    "second brain on Notion," and you would be amazed with what people can create.
  topic: business/strategy
source: Unknown Source
summary: '## Podcast Summary: EP 517: Balancing AI Productivity and Human Intelligence
  in Everyday Work


  This episode of the Everyday AI Show, featuring Sumit Gupta, Lead BI Engineer at
  Notion, dives into the critical dichotomy of leveraging powerful AI tools for massive
  productivity gains without allowing them to erode fundamental human cognitive skills,
  such as critical thinking and knowledge retention.


  ### 1. Focus Area

  The primary focus is the **balance between AI-driven productivity and the maintenance
  of human intelligence** in knowledge work. Specific topics included the impact of
  LLMs on skill degradation (e.g., coding, writing, SQL), the concept of setting "cutoffs"
  for AI usage, and the real-world risks associated with over-reliance on AI generation
  (e.g., security vulnerabilities and massive cloud costs).


  ### 2. Key Technical Insights

  *   **AI for Repetitive Tasks:** The most effective use case for AI is automating
  repetitive tasks within an area where the user is already an expert (e.g., Sumit
  using AI to generate complex SQL calculated fields in minutes instead of hours).

  *   **The "Vibe Coding" Risk:** Over-reliance on AI coding tools (like Cursor) without
  critical review leads to severe downstream consequences, exemplified by security
  breaches (exposing AWS keys) and massive, inefficient cloud queries (a $10,000 Snowflake
  bill from a poorly optimized AI-generated query).

  *   **AI as a Knowledge Assistant vs. Replacement:** Tools like Notion AI excel
  by acting as a personalized knowledge layer, searching internal company data (Slack,
  documents) that general LLMs cannot access, providing context-specific recall assistance.


  ### 3. Business/Investment Angle

  *   **Productivity vs. Long-Term Loss:** Using AI for everything yields short-term
  results but risks long-term skill atrophy, potentially creating a future workforce
  lacking the foundational knowledge needed for high-level problem-solving.

  *   **The Critical Skill Gap:** The market will increasingly demand a small percentage
  of top performers who possess the critical thinking skills to effectively guide
  and audit AI, rather than those who simply rely on it entirely.

  *   **Cost Management as a New Skill:** As seen with inefficient SQL generation,
  understanding the underlying mechanics (like database query optimization) becomes
  crucial to prevent AI-driven tools from incurring massive operational costs.


  ### 4. Notable Companies/People

  *   **Sumit Gupta (Lead BI Engineer, Notion):** Shared personal anecdotes from his
  role in BI engineering, detailing how AI drastically reduced the time spent on complex
  calculations and reporting, while also voicing concerns about becoming "lazy."

  *   **Notion:** Mentioned as the "everything app" and its integrated Notion AI,
  which functions as a powerful internal knowledge retrieval system by indexing Slack
  and documents.

  *   **Y Combinator (YC):** Referenced a post indicating that 90% of YC-backed startups
  are now "vibe coding," highlighting the widespread adoption of AI in early-stage
  development.

  *   **Microsoft:** Mentioned in context of a study on Generative AI''s impact on
  critical thinking.


  ### 5. Future Implications

  The conversation suggests a future where **cognitive muscle maintenance** becomes
  a deliberate, necessary practice. If younger generations, who grow up with AI as
  their primary tool, do not build foundational skills, the pool of truly critical
  thinkers capable of high-level innovation may shrink significantly. AI must remain
  a **complementary assistant**, not a replacement for human decision-making.


  ### 6. Target Audience

  This episode is highly valuable for **AI Professionals, Data Analysts, Software
  Developers, and Knowledge Workers** who are actively integrating LLMs into their
  daily workflows and are concerned about the long-term impact on their expertise
  and career longevity.'
tags:
- artificial-intelligence
- generative-ai
- startup
- ai-infrastructure
- investment
- google
- microsoft
- nvidia
title: 'EP 517: Balancing AI Productivity and Human Intelligence in Everyday Work'
topics:
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 128
  prominence: 1.0
  topic: artificial intelligence
- keywords:
  - generative ai
  - genai
  - chatgpt
  - gpt
  - claude
  - text generation
  - image generation
  mentions: 25
  prominence: 1.0
  topic: generative ai
- keywords:
  - startup
  - entrepreneur
  - founder
  - venture
  mentions: 2
  prominence: 0.2
  topic: startup
- keywords:
  - gpu
  - tensor
  - training
  - inference
  - model deployment
  - vector database
  mentions: 1
  prominence: 0.1
  topic: ai infrastructure
- keywords:
  - investment
  - funding
  - valuation
  - ipo
  - acquisition
  mentions: 1
  prominence: 0.1
  topic: investment
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-10-05 20:34:51 UTC -->
