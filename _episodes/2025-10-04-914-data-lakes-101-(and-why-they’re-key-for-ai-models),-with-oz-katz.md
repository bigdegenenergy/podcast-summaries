---
companies:
- category: unknown
  confidence: medium
  context: Welcome to episode number 914 of the Super Data Science podcast. I'm your
    host, John Cron. In today's epi
  name: Super Data Science
  position: 37
- category: unknown
  confidence: medium
  context: of the Super Data Science podcast. I'm your host, John Cron. In today's
    episode, we've got Oz Katz, who is co
  name: John Cron
  position: 80
- category: unknown
  confidence: medium
  context: ur host, John Cron. In today's episode, we've got Oz Katz, who is co-founder
    and CTO of the company Lake FS
  name: Oz Katz
  position: 121
- category: unknown
  confidence: medium
  context: Oz Katz, who is co-founder and CTO of the company Lake FS. Lake FS provides
    data storage for AI application
  name: Lake FS
  position: 171
- category: unknown
  confidence: medium
  context: ve you here. Where are you calling in from today? So I'm in New York. And
    thank you, John, for having me
  name: So I
  position: 676
- category: unknown
  confidence: medium
  context: e. Where are you calling in from today? So I'm in New York. And thank you,
    John, for having me, by the way.
  name: New York
  position: 686
- category: unknown
  confidence: medium
  context: . And thank you, John, for having me, by the way. As I'm usually in New
    York, that is my most likely pla
  name: As I
  position: 744
- category: unknown
  confidence: medium
  context: ly place that you would find me, but today I'm in San Francisco. And I
    suspect that you make your way out to the
  name: San Francisco
  position: 842
- category: unknown
  confidence: medium
  context: ou would find me, but today I'm in San Francisco. And I suspect that you
    make your way out to the Bay Are
  name: And I
  position: 857
- category: unknown
  confidence: medium
  context: . And I suspect that you make your way out to the Bay Area from time to
    time as well, Oz. I sometimes do, ye
  name: Bay Area
  position: 905
- category: unknown
  confidence: medium
  context: omething like that, but I land before I take off. Somehow I always feel
    like I'm not smart enough to understa
  name: Somehow I
  position: 1750
- category: unknown
  confidence: medium
  context: ust doesn't make sense to me. No, I know exactly. Sometimes I think when
    I'm wrestling with it that I should ge
  name: Sometimes I
  position: 1884
- category: unknown
  confidence: medium
  context: I've found so far, there's this thing called the International Date Line.
    And you would expect it to be a straight line go
  name: International Date Line
  position: 2308
- category: unknown
  confidence: medium
  context: e we got cache invalidation right, at least that. So Lake FS stands for
    Lake as in data lake, which is typical
  name: So Lake FS
  position: 3620
- category: unknown
  confidence: medium
  context: d of like visually, it's a little bit like iOS or Mac OS. But yeah, I've
    never seen a name quite like it a
  name: Mac OS
  position: 4458
- category: tech
  confidence: high
  context: on. It's not necessarily like AWS's definition or Snowflake's definition,
    but I'll try to give mine. So a dat
  name: Snowflake
  position: 5246
- category: unknown
  confidence: medium
  context: or the company and I have something coming from a European CRM, whatever
    it is, and we all want to be able to pu
  name: European CRM
  position: 5687
- category: unknown
  confidence: medium
  context: on, reality is a bit more dirty than that. Right. If I have images, yeah,
    I might have those images on m
  name: If I
  position: 10142
- category: unknown
  confidence: medium
  context: ways. First, it's a very error-prone environment. Maybe I'm okay. I looked
    at that images folder. I see 100
  name: Maybe I
  position: 11448
- category: unknown
  confidence: medium
  context: to introduce a change. I'll open a pull request. And John's team, they
    have to sign off on that change befo
  name: And John
  position: 12542
- category: tech
  confidence: high
  context: implemented to bring that same concept, that same notion to the data itself.
    Right? Not just the code, but
  name: Notion
  position: 12728
- category: unknown
  confidence: medium
  context: ut there, released support for tabular data using Apache Iceberg recently,
    and also being a vector database as wel
  name: Apache Iceberg
  position: 15460
- category: unknown
  confidence: medium
  context: And that's not one that I'm familiar with. Yeah. So Apache Iceberg is an
    open source project been around about five,
  name: So Apache Iceberg
  position: 16809
- category: tech
  confidence: high
  context: imagine you have a table on top of something like Amazon's S3 or whatever
    storage plans you're using. Apac
  name: Amazon
  position: 17063
- category: unknown
  confidence: medium
  context: things we need to be prepared for in the future. Before I let you go, I
    always ask my guests for a book rec
  name: Before I
  position: 21007
- category: unknown
  confidence: medium
  context: nk they can benefit the most from it. It's called Designing Data-Intensive
    Applications by Martin Kleppmann. It wa
  name: Designing Data
  position: 21270
- category: unknown
  confidence: medium
  context: efit the most from it. It's called Designing Data-Intensive Applications
    by Martin Kleppmann. It walks you through pretty
  name: Intensive Applications
  position: 21285
- category: unknown
  confidence: medium
  context: s called Designing Data-Intensive Applications by Martin Kleppmann. It
    walks you through pretty much everything invo
  name: Martin Kleppmann
  position: 21311
- category: ai_application
  confidence: high
  context: The primary subject of the discussion, a tool that provides Git-like version
    control and branching capabilities for data lakes, essential for reproducible
    AI/ML workflows.
  name: LakeFS
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: An open source project mentioned as a table format that allows representing
    database-like tables on top of object stores, crucial for managing structured
    data for AI/ML.
  name: Apache Iceberg
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: Mentioned as the most popular object store, serving as the underlying storage
    layer where data (including Iceberg tables and vector data) converges.
  name: Amazon S3
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: Mentioned as a compute engine that can consume data managed by Apache Iceberg,
    used for data manipulation often preceding model building.
  name: Pandas
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: Mentioned as a compute engine that can consume data managed by Apache Iceberg,
    used for querying data lakes.
  name: AWS Athena
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: Mentioned as a compute engine/data platform that can consume data managed
    by Apache Iceberg, centralizing data access.
  name: Snowflake
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Used as an analogy for LakeFS, representing a system for version control
    and collaboration, applied here to data management for ML.
  name: GitHub
  source: llm_enhanced
- category: ai_research
  confidence: medium
  context: A book recommended by the guest, which covers the fundamentals of building
    data systems, databases, and distributed systems relevant to modern AI infrastructure.
  name: Designing Data-Intensive Applications
  source: llm_enhanced
- category: ai_research
  confidence: medium
  context: The author of the recommended book, known for his work in distributed systems
    and data infrastructure.
  name: Martin Kleppmann
  source: llm_enhanced
date: 2025-10-04 14:39:17 +0000
duration: 26
has_transcript: false
layout: episode
llm_enhanced: true
original_url: https://www.podtrac.com/pts/redirect.mp3/chrt.fm/track/E581B9/arttrk.com/p/VI4CS/pscrb.fm/rss/p/traffic.megaphone.fm/SUPERDATASCIENCEPTYLTD7728592050.mp3
processing_date: 2025-10-04 14:39:17 +0000
quotes:
- length: 237
  relevance_score: 4
  text: So we in this era of AI, what are the particular kinds of needs that data
    scientists, AI engineers, people who are fine-tuning, pre-training, running AI
    models, what are the particular needs that they have in terms of their data solution
  topics: []
- length: 211
  relevance_score: 4
  text: Well, that's interesting to hear and something that occurs to me is that we're
    in this era now where we have more and more data types that we are throwing into
    particularly like multimodal, large language models
  topics: []
- length: 197
  relevance_score: 4
  text: If I have images, yeah, I might have those images on my day, just the raw
    data lake, just as image files, but I'm probably also going to have an embedding
    of those images toward the vector database
  topics: []
- length: 103
  relevance_score: 3
  text: So imagine you have a table on top of something like Amazon's S3 or whatever
    storage plans you're using
  topics: []
- impact_reason: Crucial insight into the evolution of data needs driven by AI. It
    explicitly states that AI requires moving beyond traditional tabular data to handle
    multimodal data (images, embeddings, labels).
  relevance_score: 10
  source: llm_enhanced
  text: It used to be that the data that we get value from and that we can actually
    derive business impact out of was your, let's say, tabular data, right? Tables
    organized into a database, it's all very well structured. But that's not necessarily
    the case nowadays, right? Especially with advances around AI models, what we can
    do with them, we can extract value from a lot of different other kinds of data
    as well, right? So it could be images, it could be embeddings out of those images,
    labels attached to them, right? All different kinds of modalities that are representative
    of the information we have at the company.
  topic: AI technology trends
- impact_reason: 'Identifies a major pain point in modern AI data management: the
    fragmentation of multimodal data across different specialized stores (object store,
    vector DB, feature store), leading to data inconsistency (''multiple sources of
    lies'').'
  relevance_score: 10
  source: llm_enhanced
  text: The place where this kind of gets difficult is that even though the dream
    or the idea of a data lake is that everything streams into that one centralized
    location, reality is a bit more dirty than that. Right. If I have images, yeah,
    I might have those images on my day, just the raw data lake, just as image files,
    but I'm probably also going to have an embedding of those images toward the vector
    database. And maybe I have some features that were extracted from those images
    in a database. Maybe labels in some other third-party labeling solution. Now instead
    of having that one source of truth that I was expecting to have, I have multiple
    sources of lies, right? They get out of sync very easily.
  topic: AI technology trends/technical
- impact_reason: 'This is the central analogy: applying software development best
    practices (like version control workflows) directly to data management, which
    is critical for reproducible AI/ML.'
  relevance_score: 10
  source: llm_enhanced
  text: I'd have a very structured workflow to how changes get implemented to bring
    that same concept, that same notion to the data itself. Right. Not just the code,
    but also the data itself regardless of what modality it is or what type of actual
    business value it represents.
  topic: strategy/technical
- impact_reason: The most powerful analogy used in the discussion. Comparing data
    management to Git workflows (commits, pull requests) immediately communicates
    the need for versioning, collaboration control, and auditability in data pipelines.
  relevance_score: 10
  source: llm_enhanced
  text: Just like Git and GitHub, the same idea that they brought to right. I want
    to introduce a change. I'll open a pull request. And John's team, they have to
    sign off on that change before it gets introduced.
  topic: strategy
- impact_reason: This is a powerful analogy applying software development best practices
    (Git/PRs) directly to data management, emphasizing governance and structured iteration
    for data assets.
  relevance_score: 10
  source: llm_enhanced
  text: I want to introduce a change. I'll open a pull request. And John's team, they
    have to sign off on that change before it gets introduced. I'd have a very structured
    workflow to how changes get implemented to bring that same concept, that same
    notion to the data itself. Right? Not just the code, but also the data itself
    regardless of what modality it is or what type of actual business value it represents.
  topic: strategy
- impact_reason: Directly addresses the critical AI/ML need for reproducibility by
    linking model output determinism to versioned, immutable input data snapshots.
  relevance_score: 10
  source: llm_enhanced
  text: What this guarantees is kind of a side effect is that whatever I'm building
    now is going to be reproducible later. Right? As long as my code doesn't introduce
    any variability into it, if it's deterministic, same code, same input data would
    guarantee the same result.
  topic: technical
- impact_reason: Clearly contrasts the rigidity and cost of data warehouses with the
    flexibility and speed offered by data lakes, explaining the trade-off between
    structure and agility.
  relevance_score: 9
  source: llm_enhanced
  text: In a data warehouse, everything has to be well organized into tables that
    have this rigid structure behind them. Typically, there's a team in place that's
    kind of the gatekeeper, if you will, because they're the only ones with the expertise
    that can all use kind of complex. It's also expensive, right? Whereas with that
    big shared folder, first of all, you throw your data in, right? If anyone wants
    to get access to it and wants to answer some business question, they can do it
    even if the data is not well formed or even if it's not optimally designed to
    meet a specific query.
  topic: technical
- impact_reason: 'Describes the core value proposition of Lake FS: unifying access
    to disparate data types (modalities) under a single interface, solving the synchronization
    and complexity problem.'
  relevance_score: 9
  source: llm_enhanced
  text: Part of the idea behind Lake FS is essentially to create one facade, one way
    of working with the data across all these different modalities. And now we all
    speak the same language.
  topic: business/technical
- impact_reason: Illustrates the practical danger of concurrent, uncoordinated work
    on shared data in AI projects—a direct argument for version control on data.
  relevance_score: 9
  source: llm_enhanced
  text: Maybe I'm okay. I looked at that images folder. I see 100 images. Great. I'll
    start working on my model to build something out of that. But here, John comes
    along from some other team and says, oh, okay, these images are not great. Let's
    replace a few of them. And that's also add a few others to the mix. And he doesn't
    know that I'm working on some other thing that depends on those images. Right.
    So now we have people stepping on each other's toes.
  topic: safety/practical lessons
- impact_reason: Highlights the integration of automated data quality checks (validation)
    directly into the version control workflow, essential for maintaining high-quality
    training datasets.
  relevance_score: 9
  source: llm_enhanced
  text: you can do the same for that new data that you just introduced. Right? These
    are all images, are all above a certain, I don't know, sharpness level, all at
    least 500 pixels wide. You can run those checks automatically and then have the
    system commit and merge those changes for you.
  topic: technical
- impact_reason: 'A significant industry trend observation: the object store (like
    S3) is solidifying as the foundational, unified storage layer for all data types,
    including structured and vector data.'
  relevance_score: 9
  source: llm_enhanced
  text: if I look at broader than just Lake FS, looking at the industry as a whole,
    one thing we are seeing happening is that everything tends to converge around
    the object store. It's kind of the source of truth that's emerging.
  topic: predictions
- impact_reason: A clear, concise explanation of vector databases and their primary
    value proposition (rapid similarity search), highly relevant given the rise of
    LLMs and RAG architectures.
  relevance_score: 9
  source: llm_enhanced
  text: The idea of a vector database is that you have some numeric representation
    of the similarity between typically some large number of documents or files. And
    it allows you to retrieve similar information or some particular type of information
    very rapidly across millions, billions of documents in fractions of a second.
  topic: technical
- impact_reason: Describes the practical, user-friendly mechanism for creating isolated,
    versioned data environments (branches) without incurring massive storage costs,
    a key feature for experimentation.
  relevance_score: 9
  source: llm_enhanced
  text: I'll go ahead and look at the data that I need and I'll branch out of it.
    Right? I click the big green button on my screen and now I have for all intents
    and purposes, my own isolated copy of everything. Right? LakeFS does this intelligently
    without actually copying everything to another location.
  topic: technical
- impact_reason: 'Illustrates the power of data versioning for controlled experimentation:
    the ability to safely modify data subsets and explicitly reference the exact dataset
    used for training/testing.'
  relevance_score: 9
  source: llm_enhanced
  text: I can remove half of it to see what happens. I can add new stuff in to improve
    my results. And when I address that data from my code, I have to specify which
    version I'm using. So it's no longer just here is the data lake and that's hope
    for the best.
  topic: strategy
- impact_reason: Provides a clear, technical definition of the company's name, linking
    it directly to the core data architecture (data lake) and the underlying technology
    (file system), which is crucial for understanding its function.
  relevance_score: 8
  source: llm_enhanced
  text: Lake FS stands for Lake as in data lake, which is typically the architecture
    where you would put Lake FS into. FS stands for file system.
  topic: business/technical
- impact_reason: Offers a simple, accessible definition of a data lake, contrasting
    it with more rigid structures and emphasizing its role in data collaboration.
  relevance_score: 8
  source: llm_enhanced
  text: A data lake at its most basic form of it would be just a shared folder. Right?
    Some central location where John, a member of one team and also a member of some
    other team can collaborate on top of data.
  topic: technical
- impact_reason: 'Reinforces the key differentiator for data lakes: their ability
    to handle unstructured or semi-structured data, which is increasingly important
    for modern AI workloads.'
  relevance_score: 8
  source: llm_enhanced
  text: It's very much that [unstructured data], right. The maybe if I contrast it
    with what we typically had before, which is a data warehouse. In a data warehouse,
    everything has to be well organized into tables that have this rigid structure
    behind them.
  topic: technical
- impact_reason: Provides concrete evidence of the object store convergence trend,
    noting recent integrations of Iceberg (tabular) and vector database capabilities
    directly into object storage services.
  relevance_score: 8
  source: llm_enhanced
  text: We see S3, probably the most popular object store out there, released support
    for tabular data using Apache Iceberg recently, and also being a vector database
    as well. All of this is from the last few months.
  topic: technical
- impact_reason: Explains the function of Apache Iceberg—bringing database-like transactional
    capabilities and schema management to data lakes—which is critical for reliable
    data pipelines feeding AI models.
  relevance_score: 8
  source: llm_enhanced
  text: Apache Iceberg is an open source project... What it does is essentially lets
    you represent a table, just like a database table, on top of an object store...
    Regardless of the tool that's consuming it, they all see the same state of the
    table, the same abstraction.
  topic: technical
- impact_reason: 'A strategic shift in mindset: elevating data from a transient byproduct
    to a managed, governed corporate asset, which is foundational for mature AI operations
    (MLOps).'
  relevance_score: 8
  source: llm_enhanced
  text: the idea is that now I'm treating the data not as just this random thing that
    flows in and out without anyone actually controlling it as something that's actually
    an asset of the company, right, which typically it is. And now we just manage
    it that way.
  topic: strategy
- impact_reason: Reinforces the integration of automated quality gates (testing) into
    the data lifecycle, ensuring only validated data changes are merged into the main
    asset.
  relevance_score: 8
  source: llm_enhanced
  text: I can open the pull request, I can have those tests that automatically run
    to ensure the quality, I can do all that.
  topic: technical
- impact_reason: A classic, humorous, and highly relatable quote for anyone in software
    engineering, highlighting the inherent difficulty in system design and product
    branding.
  relevance_score: 7
  source: llm_enhanced
  text: There are two things that are hard in computer science. One is cache invalidation.
    The other one is naming things.
  topic: strategy
- impact_reason: A strong statement on transparency and open-source commitment, which
    builds trust and allows the community to inspect the core versioning technology.
  relevance_score: 7
  source: llm_enhanced
  text: We pride ourselves on building like a face out in the open and the core of
    Lake FS versioning engine at all scales is fully open source as well.
  topic: business
- impact_reason: 'A succinct summary of the goal: applying the proven collaboration
    and management paradigm of Git to the data layer.'
  relevance_score: 7
  source: llm_enhanced
  text: all the power that GitHub gives you in terms of collaboration and manageability
    just for the data itself.
  topic: strategy
- impact_reason: A strong recommendation for a foundational text ('Designing Data-Intensive
    Applications') that covers the core principles underlying modern data infrastructure
    necessary for large-scale AI.
  relevance_score: 7
  source: llm_enhanced
  text: It walks you through pretty much everything involved in actually building
    a data system. I think of how is the database actually how does it work? What's
    an index? How does a database represent its actual data on the storage layer?
  topic: general technology
source: Unknown Source
summary: '## Podcast Summary: 914: Data Lakes 101 (and Why They’re Key for AI Models),
  with Oz Katz


  This episode of the Super Data Science podcast, hosted by John Cron, features Oz
  Katz, Co-founder and CTO of Lake FS, focusing on the critical role of modern data
  storage architectures, specifically Data Lakes, in supporting advanced AI and Machine
  Learning applications.


  ---


  ### 1. Focus Area

  The primary focus is the evolution of data storage for AI, contrasting traditional
  **Data Warehouses** with **Data Lakes**. Key discussions centered on the challenges
  introduced by **multimodal AI data** (images, text, embeddings, etc.), the need
  for versioning and collaboration in data pipelines, and how modern systems must
  manage this complexity. The conversation heavily featured the analogy of **Git for
  Data**.


  ### 2. Key Technical Insights

  *   **Data Lake Definition:** A Data Lake is fundamentally a centralized, shared
  repository (like a "shared folder") designed to ingest data of any structure (structured
  or unstructured), allowing for faster iteration compared to the rigid structure
  required by Data Warehouses.

  *   **Multimodal Data Complexity:** Modern AI requires managing diverse data modalities
  (images, text, vector embeddings) simultaneously. This often leads to "multiple
  sources of lies" (data scattered across object stores, vector databases, feature
  stores) that easily fall out of sync.

  *   **LakeFS as Data Version Control:** LakeFS introduces **Git-like versioning**
  (branching, committing, merging, pull requests) directly onto the data lake (object
  store). This allows data scientists to experiment in isolated environments without
  copying massive datasets, ensuring reproducibility and controlled collaboration.


  ### 3. Business/Investment Angle

  *   **Data as a Managed Asset:** The core business value of tools like LakeFS is
  treating data as a managed, auditable company asset, similar to how code is managed
  via Git, reducing operational risk and improving governance.

  *   **Convergence on Object Storage:** The industry trend shows that various data
  types (tabular via **Apache Iceberg**, vectors, raw files) are increasingly converging
  onto the **Object Store** (e.g., S3) as the single organizational source of truth.

  *   **Enabling Complex Pipelines:** By unifying data access and versioning, these
  solutions reduce friction in complex, multi-stage AI pipelines involving pre-processing,
  feature extraction, and model training across different modalities.


  ### 4. Notable Companies/People

  *   **Oz Katz (Lake FS):** Co-founder and CTO, providing the technical perspective
  on data storage needs for AI.

  *   **Lake FS:** The company providing the solution, which offers a unified facade
  and version control layer over object stores.

  *   **Apache Iceberg:** Mentioned as an open-source table format that allows structured,
  schema-managed tables to exist on top of object stores, enabling updates and consistent
  reads across different compute engines.


  ### 5. Future Implications

  The future of data infrastructure for AI points toward **complete convergence on
  the object store** as the foundational layer. Solutions must provide robust **versioning,
  governance, and schema management** (like Iceberg) directly on this storage layer
  to handle the increasing complexity of multimodal data and large-scale model training/deployment.
  Reproducibility, guaranteed by data snapshots, will become non-negotiable.


  ### 6. Target Audience

  This episode is highly valuable for **AI/ML Engineers, Data Engineers, Data Architects,
  and CTOs** involved in building or scaling data platforms specifically designed
  to support large-scale, multimodal AI model development and MLOps.


  ---


  ### Comprehensive Summary Narrative


  The podcast opens with a lighthearted discussion on time zones before diving into
  the core topic: the data infrastructure required for modern AI. Oz Katz defines
  the **Data Lake** as a flexible, centralized repository contrasting it with the
  rigid structure of a Data Warehouse. He emphasizes that the needs of AI have drastically
  changed the required data landscape, moving beyond simple tabular data to encompass
  complex, **multimodal data** like images, labels, and vector embeddings.


  The central challenge identified is managing the resulting data sprawl. When data
  scientists work with these different modalities, the data often fragments across
  specialized systems (vector databases, feature stores), leading to synchronization
  issues and making it difficult to trace the exact input data used for a specific
  model run.


  Katz introduces **LakeFS** as the solution, drawing a direct parallel to **Git for
  Data**. LakeFS sits as a facade over the object store, allowing users to **branch**
  the entire data lake for experimentation. This branching is efficient, as it only
  tracks changes, not full copies. Users can modify, add, or remove data within their
  branch, knowing their work is isolated and **reproducible** because they reference
  a specific, frozen snapshot (version) of the data. Changes can then be merged back
  via a controlled **pull request** workflow, often incorporating automated quality
  checks.


  Looking ahead, Katz notes the industry trend of **data convergence on the object
  store**. He highlights the importance of technologies like **Apache Iceberg**, which
  enables structured table definitions on top of object storage, allowing different
  compute engines to access the same consistent data state. Ultimately, the conversation
  stresses that as AI models become more sophisticated, the underlying data management
  must evolve from simple storage to sophisticated, version-controlled asset management
  to ensure reliability and scalability.'
tags:
- artificial-intelligence
- ai-infrastructure
- startup
title: '914: Data Lakes 101 (and Why They’re Key for AI Models), with Oz Katz'
topics:
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 27
  prominence: 1.0
  topic: artificial intelligence
- keywords:
  - gpu
  - tensor
  - training
  - inference
  - model deployment
  - vector database
  mentions: 8
  prominence: 0.8
  topic: ai infrastructure
- keywords:
  - startup
  - entrepreneur
  - founder
  - venture
  mentions: 1
  prominence: 0.1
  topic: startup
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-10-04 14:39:17 UTC -->
