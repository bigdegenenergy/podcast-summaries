---
companies:
- category: unknown
  confidence: medium
  context: This is the Everyday AI Show, the everyday podcast where we simplify AI
    and br
  name: Everyday AI Show
  position: 12
- category: tech
  confidence: high
  context: your career, business, and everyday life. Why is Anthropic in hot water
    with Reddit? Well, OpenAI's ChatGPT
  name: Anthropic
  position: 204
- category: tech
  confidence: high
  context: Why is Anthropic in hot water with Reddit? Well, OpenAI's ChatGPT become
    the de facto business AI tool. D
  name: Openai
  position: 246
- category: unknown
  confidence: medium
  context: I's ChatGPT become the de facto business AI tool. Did Apple make a huge
    mistake in its buzz-worthy AI study t
  name: Did Apple
  position: 301
- category: tech
  confidence: high
  context: ChatGPT become the de facto business AI tool. Did Apple make a huge mistake
    in its buzz-worthy AI study t
  name: Apple
  position: 305
- category: tech
  confidence: high
  context: d on large reasoning models? And why the heck did Google release a brand
    new version of Google Gemini when
  name: Google
  position: 429
- category: unknown
  confidence: medium
  context: he heck did Google release a brand new version of Google Gemini when it
    was already on top? Yeah, a lot happening
  name: Google Gemini
  position: 467
- category: unknown
  confidence: medium
  context: Instead, just spend your Mondays with us here on Everyday AI as we break
    down the AI news that matters. All ri
  name: Everyday AI
  position: 814
- category: unknown
  confidence: medium
  context: rs. All right, what's going on, y'all? My name is Jordan Wilson, and welcome
    to Everyday AI. This is your daily l
  name: Jordan Wilson
  position: 915
- category: unknown
  confidence: medium
  context: om Jamaica, Kimberly on the LinkedIn machine from New York City, J woke
    up somehow in West Virginia, Dr. Harvey C
  name: New York City
  position: 2339
- category: unknown
  confidence: medium
  context: machine from New York City, J woke up somehow in West Virginia, Dr. Harvey
    Castro. Thanks everyone for joining u
  name: West Virginia
  position: 2375
- category: unknown
  confidence: medium
  context: ork City, J woke up somehow in West Virginia, Dr. Harvey Castro. Thanks
    everyone for joining us. All right, let's
  name: Harvey Castro
  position: 2394
- category: unknown
  confidence: medium
  context: lled out a major new advanced voice mode upgrade. So OpenAI has launched
    a significant upgrade to its advance
  name: So OpenAI
  position: 2616
- category: unknown
  confidence: medium
  context: fit anyone relying on voice AI for communication. So I gave this a try.
    One thing I think this does a li
  name: So I
  position: 3767
- category: unknown
  confidence: medium
  context: you guys tested the new advanced voice mode out. And I think probably I
    haven't actually done a lot of c
  name: And I
  position: 4579
- category: unknown
  confidence: medium
  context: know if I should do the new advanced voice mode. Google Live is obviously
    really good. Perplexity has theirs.
  name: Google Live
  position: 5004
- category: tech
  confidence: high
  context: voice mode. Google Live is obviously really good. Perplexity has theirs.
    I just don't know if our audience pod
  name: Perplexity
  position: 5042
- category: unknown
  confidence: medium
  context: mething you want to see. Dr. Harvey Castro says, "Eleven Labs and Hume
    AI are better at emotional intelligence.
  name: Eleven Labs
  position: 5388
- category: unknown
  confidence: medium
  context: to see. Dr. Harvey Castro says, "Eleven Labs and Hume AI are better at
    emotional intelligence." Yeah, we d
  name: Hume AI
  position: 5404
- category: unknown
  confidence: medium
  context: did talk about this on the show last week on the AI News that Matters.
    Eleven Labs has their V3. I don't k
  name: AI News
  position: 5509
- category: unknown
  confidence: medium
  context: Anthropic is just trying to grab it all for free. So Reddit has filed a
    lawsuit against Anthropic in Californ
  name: So Reddit
  position: 6837
- category: unknown
  confidence: medium
  context: o Reddit has filed a lawsuit against Anthropic in California Superior Courts,
    accusing the AI startup of illegally scraping Re
  name: California Superior Courts
  position: 6888
- category: unknown
  confidence: medium
  context: sting AI lawsuit to keep an eye on outside of the New York Times versus
    OpenAI and Microsoft because this one is h
  name: New York Times
  position: 9884
- category: tech
  confidence: high
  context: n outside of the New York Times versus OpenAI and Microsoft because this
    one is huge just because of the valu
  name: Microsoft
  position: 9917
- category: unknown
  confidence: medium
  context: So OpenAI has introduced a new record feature in ChatGPT Teams for macOS,
    letting users record, transcribe, and
  name: ChatGPT Teams
  position: 11155
- category: tech
  confidence: high
  context: tGPT now as a new competitor to companies such as Otter.ai or Zoom's transcription
    features. The OpenAI upda
  name: Otter.Ai
  position: 11613
- category: unknown
  confidence: medium
  context: uch as Otter.ai or Zoom's transcription features. The OpenAI update also
    brings cloud connectors, and this one
  name: The OpenAI
  position: 11656
- category: unknown
  confidence: medium
  context: brings cloud connectors, and this one is big for Google Drive, OneDrive,
    Dropbox, Box, and SharePoint, allowing
  name: Google Drive
  position: 11728
- category: unknown
  confidence: medium
  context: entioned things like Google Drive, Gmail, I mean, Google Calendar, SharePoint,
    Outlook, Teams. One I'm excited to t
  name: Google Calendar
  position: 12683
- category: unknown
  confidence: medium
  context: ean, Google Calendar, SharePoint, Outlook, Teams. One I'm excited to try
    is HubSpot, right? Being able to
  name: One I
  position: 12728
- category: unknown
  confidence: medium
  context: allenging tests such as GPQA, and even Humanity's Last Exam, which is one
    of the most challenging AI benchmar
  name: Last Exam
  position: 17439
- category: unknown
  confidence: medium
  context: es. And in terms of Elo, right, we talk about the LM Arena pretty often
    here on the show. This is where you
  name: LM Arena
  position: 17852
- category: unknown
  confidence: medium
  context: e which is better, and then you get an Elo score. And Gemini 2.5 Pro, the
    new version, the June 5th version, a
  name: And Gemini
  position: 18093
- category: unknown
  confidence: medium
  context: d. So, the model upgrade is available through the Gemini API or via Google
    AI Studio and Vertex AI. So, pretty
  name: Gemini API
  position: 18337
- category: unknown
  confidence: medium
  context: pgrade is available through the Gemini API or via Google AI Studio and
    Vertex AI. So, pretty exciting. And if you re
  name: Google AI Studio
  position: 18355
- category: unknown
  confidence: medium
  context: hrough the Gemini API or via Google AI Studio and Vertex AI. So, pretty
    exciting. And if you remember when I
  name: Vertex AI
  position: 18376
- category: unknown
  confidence: medium
  context: ideos with native audio generation. Try it with a Google AI Pro plan or
    get the highest access with the Ultra pla
  name: Google AI Pro
  position: 19514
- category: unknown
  confidence: medium
  context: 'aking of Google, our next piece of AI news: Well, Chinese AI lab DeepSeek
    is accused of using Google Gemini''s'
  name: Chinese AI
  position: 19785
- category: unknown
  confidence: medium
  context: m Google Gemini's family of models. So, developer Sam Pek and others have
    published evidence that DeepSeek'
  name: Sam Pek
  position: 20164
- category: unknown
  confidence: medium
  context: rival AI outputs. So, OpenAI previously told the Financial Times that it
    found evidence that DeepSeek had used dis
  name: Financial Times
  position: 20672
- category: unknown
  confidence: medium
  context: rce. I'm all for open source, open-weight models. But I don't know, do
    you want to send all of your data
  name: But I
  position: 22882
- category: unknown
  confidence: medium
  context: OpenAI is acquiring Windsurf for $3 billion. So, Jared Kaplan, Anthropic's
    co-founder and chief science officer
  name: Jared Kaplan
  position: 23937
- category: unknown
  confidence: medium
  context: tomorrow. So, a new Apple research paper called "The Illusion of Thinking"
    argues that AI reasoning models offe
  name: The Illusion
  position: 27030
- category: unknown
  confidence: medium
  context: especially as the company's own AI products like Apple Intelligence and
    Siri 2.0 face AI challenges, but Apple mainta
  name: Apple Intelligence
  position: 28200
- category: unknown
  confidence: medium
  context: most questionable research paper I've ever read. Like I said, the observations
    are sound, but this seemed
  name: Like I
  position: 30577
- category: unknown
  confidence: medium
  context: rug. Interesting, right? Yeah, Joe here saying, "Apple Marketing commissioned
    a study to prove that AI reasoning m
  name: Apple Marketing
  position: 31575
- category: tech
  confidence: high
  context: 'takes. All right, and our last piece of AI news: Meta is reportedly in
    talks for a $10 billion-plus inv'
  name: Meta
  position: 32381
- category: tech
  confidence: high
  context: dly in talks for a $10 billion-plus investment in Scale AI. So, according
    to Bloomberg reports and writers,
  name: Scale Ai
  position: 32446
- category: unknown
  confidence: medium
  context: . So, according to Bloomberg reports and writers, Meta Platforms is exploring
    an investment in Scale AI that could
  name: Meta Platforms
  position: 32504
- category: tech
  confidence: high
  context: t specializes in data labeling and already counts Amazon and Meta as backers.
    The company also operates a
  name: Amazon
  position: 32905
- category: ai_application
  confidence: high
  context: In hot water with Reddit over alleged illegal scraping of data to train
    its Claude chatbots. A major AI startup competitor to OpenAI and Google.
  name: Anthropic
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Released a major new advanced voice mode upgrade for ChatGPT. Has a lucrative
    licensing agreement with Reddit. Its ChatGPT is the de facto business AI tool.
  name: OpenAI
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Released a buzz-worthy AI study on large reasoning models that the host
    believes got things wrong.
  name: Apple
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Released a brand new version of Google Gemini (2.5 Pro). Has a lucrative
    licensing agreement with Reddit. A major player in the LLM space.
  name: Google
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: The name of Google's large language model family, with a new version (2.5
    Pro) being rolled out.
  name: Google Gemini
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: OpenAI's flagship product, mentioned for its new advanced voice mode, business
    connectors, and meeting recorder.
  name: ChatGPT
  source: llm_enhanced
- category: ai_startup
  confidence: medium
  context: Mentioned by a listener as being better than OpenAI's new voice mode at
    emotional intelligence.
  name: Hume AI
  source: llm_enhanced
- category: ai_startup
  confidence: high
  context: Mentioned by a listener as being better than OpenAI's new voice mode at
    emotional intelligence, specifically referencing their V3 model.
  name: Eleven Labs
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as having a good voice mode and having Reddit data available
    on its platform.
  name: Perplexity
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Anthropic's chatbot, mentioned in comparison to ChatGPT's new features
    (like cloud connectors) and previous coverage on the show.
  name: Claude
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as a competitor to OpenAI's new ChatGPT meeting recorder feature.
  name: Otter.ai
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: Mentioned as having transcription features that ChatGPT is now competing
    with via its new meeting recorder.
  name: Zoom
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Mentioned as a defendant alongside OpenAI in the New York Times lawsuit.
  name: Microsoft
  source: llm_enhanced
- category: media/legal_target
  confidence: high
  context: Mentioned as being in a major lawsuit against OpenAI and Microsoft regarding
    copyright infringement.
  name: New York Times
  source: llm_enhanced
- category: big_tech
  confidence: medium
  context: Mentioned implicitly via Google AI Studio and Vertex AI, platforms for
    accessing Gemini models.
  name: Google AI
  source: llm_enhanced
- category: ai_model_product
  confidence: high
  context: Google's powerful large language model, with a new version (June 5th) released,
    showing significant benchmark improvements.
  name: Gemini 2.5 Pro
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: The interface through which the Gemini 2.5 Pro model upgrade is available.
  name: Gemini API
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: A platform provided by Google for accessing and using Gemini models.
  name: Google AI Studio
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: Google's machine learning platform where the Gemini model upgrade is available.
  name: Vertex AI
  source: llm_enhanced
- category: ai_model_product
  confidence: high
  context: Google's state-of-the-art AI video generation model, accessible via the
    Gemini app.
  name: Veo
  source: llm_enhanced
- category: ai_company
  confidence: high
  context: A Chinese AI lab accused of using data from Google Gemini, OpenAI (ChatGPT),
    and Microsoft models to train its R1 model at a fraction of the cost.
  name: DeepSeek
  source: llm_enhanced
- category: ai_research_analysis
  confidence: high
  context: Mentioned as the source of reports that analyzed DeepSeek's actual training
    costs.
  name: SemiAnalysis
  source: llm_enhanced
- category: ai_startup
  confidence: high
  context: An AI-vibe coding platform (formerly Codeium) that had its access to Anthropic's
    Claude models revoked due to its rumored acquisition by OpenAI.
  name: Windsurf
  source: llm_enhanced
- category: ai_startup
  confidence: high
  context: Mentioned as another AI-vibe coding platform similar to Windsurf.
  name: Cursor
  source: llm_enhanced
- category: ai_startup
  confidence: high
  context: The former name of Windsurf.
  name: Codeium
  source: llm_enhanced
- category: ai_personnel
  confidence: high
  context: Anthropic's co-founder and chief science officer, who confirmed the decision
    to withdraw Claude access from Windsurf.
  name: Jared Kaplan
  source: llm_enhanced
- category: ai_product
  confidence: high
  context: Apple's suite of AI features mentioned in relation to their WWDC announcements.
  name: Apple Intelligence
  source: llm_enhanced
- category: ai_product
  confidence: high
  context: Apple's updated voice assistant mentioned in the context of their AI challenges.
  name: Siri 2.0
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Reportedly in talks for a $10 billion-plus investment in Scale AI. Also
    mentioned for taking an open-source/open-weight approach with their Llama models.
  name: Meta Platforms
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: The subject of a potential $10 billion-plus investment from Meta. Specializes
    in data labeling and already counts Amazon and Meta as backers.
  name: Scale AI
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Mentioned as an existing backer of Scale AI.
  name: Amazon
  source: llm_enhanced
date: 2025-06-09 14:00:00 +0000
duration: 46
has_transcript: false
insights:
- actionable: true
  confidence: medium
  extracted: all be keeping an eye on
  text: we should all be keeping an eye on.
  type: recommendation
- actionable: false
  confidence: medium
  extracted: AI because they can train their models at a fraction of the cost," well,
    according to reports and executives at these exact same companies, they're doing
    this because they're literally just distilling from the companies that are actually
    paying the money to create, train, fine-tune the models. So, yeah, hey, where
    are you at, all you DeepSeek people? I'm pretty sure you were in the comments
    back in December saying how, "In a couple of months, OpenAI and Google are going
    to be irrelevant because DeepSeek can train models for one-hundredth of the cost."
    Yeah, no, they can't, right? Go look at the SemiAnalysis reports on that. I'm
    going to go pull up what show this was. I did a deep dive on DeepSeek a couple
    of weeks after all the hoopla. So, go listen to episode 460 on that, and I break
    down the SemiAnalysis report that essentially looked at DeepSeek, and they're
    like, "Wait, they did not train this model for $5.6 million, which
  text: the future of AI because they can train their models at a fraction of the
    cost," well, according to reports and executives at these exact same companies,
    they're doing this because they're literally just distilling from the companies
    that are actually paying the money to create, train, fine-tune the models. So,
    yeah, hey, where are you at, all you DeepSeek people? I'm pretty sure you were
    in the comments back in December saying how, "In a couple of months, OpenAI and
    Google are going to be irrelevant because DeepSeek can train models for one-hundredth
    of the cost." Yeah, no, they can't, right? Go look at the SemiAnalysis reports
    on that. I'm going to go pull up what show this was. I did a deep dive on DeepSeek
    a couple of weeks after all the hoopla. So, go listen to episode 460 on that,
    and I break down the SemiAnalysis report that essentially looked at DeepSeek,
    and they're like, "Wait, they did not train this model for $5.6 million, which
    is like 5% or 2% of what it would actually cost to train.
  type: prediction
- actionable: false
  confidence: medium
  extracted: large language models, literally hours before their announcement where
    their future of large language models
  text: the future of large language models, literally hours before their announcement
    where their future of large language models is being swept under the rug.
  type: prediction
layout: episode
llm_enhanced: true
original_url: https://pscrb.fm/rss/p/www.buzzsprout.com/2175779/episodes/17305177-ep-542-apple-s-controversial-ai-study-google-s-new-model-and-more-ai-news-that-matters.mp3
processing_date: 2025-10-05 11:12:02 +0000
quotes:
- length: 131
  relevance_score: 5
  text: So, according to Bloomberg reports and writers, Meta Platforms is exploring
    an investment in Scale AI that could exceed $10 billion
  topics:
  - investment
- length: 192
  relevance_score: 5
  text: So, the deal, if finalized, would be one of the largest investments in an
    artificial intelligence startup ever and underscores the intensifying race among
    tech giants to secure AI capabilities
  topics:
  - investment
- length: 261
  relevance_score: 4
  text: It might bring in things from its own internal training data, which could
    be extremely outdated, it could be wrong, it could not have the level of expertise
    that you'd expect by being a subject matter expert and being a marketer in the
    logistics industry, right
  topics:
  - market
- length: 254
  relevance_score: 4
  text: Competing on the application layer is how companies like Google, OpenAI, and
    even Claude are going to compete in the long run, as we talk about knowledge being
    commoditized, but also that large language models could largely just be swappable,
    replaceable
  topics: []
- length: 178
  relevance_score: 4
  text: Instead, they predict responses based on statistical patterns from their training
    data, casting doubt on the practical value of chain-of-thought outputs or these
    reasoning models
  topics: []
- length: 273
  relevance_score: 4
  text: And the way that they're framed, I'm like, this seems like a company with
    a huge agenda that is trying to shift markets because they know by putting this
    out at this time is getting a ton of news coverage, and news coverage, whether
    you believe it or not, it shifts markets
  topics:
  - market
- length: 115
  relevance_score: 4
  text: 'All right, and our last piece of AI news: Meta is reportedly in talks for
    a $10 billion-plus investment in Scale AI'
  topics:
  - investment
- length: 211
  relevance_score: 4
  text: So, according to this new report on Meta's reported $10 billion investment,
    terms of the potential deal are not yet finalized and could still change, with
    Meta and Scale AI both declining to comment on the talks
  topics:
  - investment
- length: 197
  relevance_score: 4
  text: The completed investment could further accelerate the advancements in AI technology
    and provide new opportunities for professionals and companies seeking to leverage
    large-scale data infrastructure
  topics:
  - investment
- length: 174
  relevance_score: 3
  text: So Reddit has filed a lawsuit against Anthropic in California Superior Courts,
    accusing the AI startup of illegally scraping Reddit user comments to train its
    Claude chatbots
  topics: []
- length: 172
  relevance_score: 3
  text: So unlike other lawsuits targeting copyright infringement, Reddit's case focuses
    on a breach of its terms of use and claims Anthropic's actions amount to unfair
    competition
  topics:
  - competition
- length: 224
  relevance_score: 3
  text: So, Anthropic's CEO and researchers have previously documented the value of
    Reddit's subject matter forums for AI training, and the company maintains its
    use of web data is lawful and essential for developing language models
  topics: []
- length: 220
  relevance_score: 3
  text: So, essentially now you have a pretty serious, at least whether it's accusations
    or you could say solid proof that DeepSeek has distilled or kind of just borrowed
    from OpenAI, Microsoft, and Google to help train its data
  topics: []
- length: 77
  relevance_score: 3
  text: We've seen reports on this OpenAI acquisition on Windsurf now for three weeks
  topics:
  - acquisition
- length: 292
  relevance_score: 3
  text: So, according to this Apple study, standard large language models outperform
    reasoning models on simple tasks, while both types collapse on highly complex
    problems with reasoning models regressing as complexity increases, contradicting
    claims that chain-of-thought reasoning yields smarter AI
  topics: []
- length: 285
  relevance_score: 3
  text: And the paper's conclusion that large-scale reasoning offers limited benefits
    also happens to coincide with Apple's public strategy of focusing on smaller,
    efficient on-device models, leading to accusations that the research is just marketing
    designed to justify their current position
  topics:
  - market
- length: 237
  relevance_score: 3
  text: And we are essentially, according to reports, Bloomberg said that Apple is
    taking a 'gap year' on AI, whereas last year at their WWDC conference, they just
    said, 'Hey, everything AI, AI, AI, Apple Intelligence, Apple Intelligence,' right
  topics: []
- length: 96
  relevance_score: 3
  text: So, you have to question the validity of this research, even though the research
    itself is valid
  topics: []
- length: 154
  relevance_score: 3
  text: I've obviously read hundreds of research papers over the last three to five
    years as I become more interested and more involved in artificial intelligence
  topics: []
- length: 108
  relevance_score: 3
  text: Yeah, Joe here saying, "Apple Marketing commissioned a study to prove that
    AI reasoning models are overhyped
  topics:
  - market
- impact_reason: This is a critical legal development concerning data rights, consent,
    and the legality of using publicly available, user-generated content for LLM training.
  relevance_score: 10
  source: llm_enhanced
  text: Reddit has filed a lawsuit against Anthropic in California Superior Courts,
    accusing the AI startup of illegally scraping Reddit user comments to train its
    Claude chatbots.
  topic: safety/ethics/legal
- impact_reason: This is a strong, controversial statement asserting the unique value
    of Reddit's niche, expert, and nuanced user-generated content over traditional
    published media for LLM training.
  relevance_score: 10
  source: llm_enhanced
  text: I would even venture to say Reddit data is more valuable ultimately than data
    from the New York Times.
  topic: strategy/data value
- impact_reason: This is a massive step toward making LLMs truly useful within secure
    enterprise environments by connecting them directly to proprietary data silos.
  relevance_score: 10
  source: llm_enhanced
  text: The OpenAI update also brings cloud connectors, and this one is big for Google
    Drive, OneDrive, Dropbox, Box, and SharePoint, allowing ChatGPT business users
    to search and analyze documents from these platforms while respecting existing
    user permissions.
  topic: technical/deployment/business
- impact_reason: This is a crucial summary of the democratization of RAG. It contrasts
    the past high-cost, manual process (fine-tuning/vector DBs) with the current low-cost,
    click-based solution offered by native connectors.
  relevance_score: 10
  source: llm_enhanced
  text: By having it first look at your data, that is huge. That is essentially the
    promise of retrieval augmented generation, which is, companies two to three years
    ago, spent millions of dollars essentially fine-tuning models with RAG, creating
    these embeddings in their vector databases, essentially creating their own version
    of a large language model, but that first and primarily used its own internal
    data, which was a very expensive and laborious process. And now we're getting
    that with a couple of clicks, right?
  topic: business
- impact_reason: 'A strong strategic prediction: the long-term competitive moat in
    AI will shift from the base model itself to the quality and depth of application-layer
    integrations with proprietary data.'
  relevance_score: 10
  source: llm_enhanced
  text: I was never pushing RAG super hard because I knew that this day would come,
    right? Competing on the application layer is how companies like Google, OpenAI,
    and even Claude are going to compete in the long run, as we talk about knowledge
    being commoditized, but also that large language models could largely just be
    swappable, replaceable.
  topic: strategy
- impact_reason: Defines and highlights the controversial practice of 'distillation'—using
    outputs of a proprietary model to train a smaller/cheaper one—as a key ethical/legal
    issue.
  relevance_score: 10
  source: llm_enhanced
  text: OpenAI previously told the Financial Times that it found evidence that DeepSeek
    had used distillation on OpenAI's models, which is a method that extracts training
    data from larger models...
  topic: safety
- impact_reason: A critical warning regarding data security and geopolitical risk
    associated with using certain foreign-based AI services, especially for enterprises.
  relevance_score: 10
  source: llm_enhanced
  text: If you're using DeepSeek, FYI, via the API or on their website, you are sending
    all of the information that you upload straight to the Chinese government.
  topic: safety
- impact_reason: Introduces a significant counter-narrative challenging the prevailing
    belief in the efficacy of Chain-of-Thought (CoT) and explicit reasoning models.
  relevance_score: 10
  source: llm_enhanced
  text: A new Apple research paper called "The Illusion of Thinking" argues that AI
    reasoning models offer only marginal improvements over standard language models
    and often fail as tasks grow complex, challenging a central narrative in recent
    AI developments.
  topic: technical/predictions
- impact_reason: Details the specific, counter-intuitive findings of the Apple paper
    regarding model performance scaling with complexity, directly questioning CoT
    benefits.
  relevance_score: 10
  source: llm_enhanced
  text: According to this Apple study, standard large language models outperform reasoning
    models on simple tasks, while both types collapse on highly complex problems with
    reasoning models regressing as complexity increases, contradicting claims that
    chain-of-thought reasoning yields smarter AI.
  topic: technical
- impact_reason: Quantifies a major limitation of current LLMs (brittleness to minor
    prompt variations), suggesting they rely on surface-level pattern matching rather
    than deep understanding.
  relevance_score: 10
  source: llm_enhanced
  text: 'The study highlights a critical vulnerability: introducing small, irrelevant
    changes to prompts can degrade model performance by up to 65%, revealing the model''s
    reliance on pattern recognition rather than genuine logic or deductive reasoning.'
  topic: technical/limitations
- impact_reason: 'This is the core philosophical challenge of the paper: LLMs are
    sophisticated interpolators, not true reasoners, undermining the marketing around
    ''reasoning'' capabilities.'
  relevance_score: 10
  source: llm_enhanced
  text: Apple in their study found no evidence that current reasoning models perform
    true logical problem-solving. Instead, they predict responses based on statistical
    patterns from their training data, casting doubt on the practical value of chain-of-thought
    outputs or these reasoning models.
  topic: technical/limitations
- impact_reason: Highlights a massive potential investment signaling the critical
    importance of high-quality, large-scale data labeling and infrastructure (Scale
    AI) in the current AI arms race.
  relevance_score: 10
  source: llm_enhanced
  text: Meta is reportedly in talks for a $10 billion-plus investment in Scale AI.
    So, according to Bloomberg reports and writers, Meta Platforms is exploring an
    investment in Scale AI that could exceed $10 billion.
  topic: business/strategy
- impact_reason: This highlights the industry trend toward more human-like, emotionally
    aware conversational AI, closing the gap between synthetic and natural speech.
  relevance_score: 9
  source: llm_enhanced
  text: The revamped voice mode delivers much more natural speech with improved annotation,
    realistic cadence, and expressiveness that can capture emotions like empathy and
    sarcasm.
  topic: technical/breakthrough
- impact_reason: Real-time, continuous translation integrated directly into a leading
    LLM interface is a significant practical application, especially for global business
    and travel.
  relevance_score: 9
  source: llm_enhanced
  text: Users can now access real-time language translation as well by simply requesting
    it, allowing continuous two-way translation throughout conversations.
  topic: predictions/application
- impact_reason: This frames the data scraping debate around contract law (Terms of
    Service) rather than just copyright, setting a potentially different legal precedent
    for AI training data.
  relevance_score: 9
  source: llm_enhanced
  text: Unlike other lawsuits targeting copyright infringement, Reddit's case focuses
    on a breach of its terms of use and claims Anthropic's actions amount to unfair
    competition.
  topic: safety/ethics/legal
- impact_reason: 'This explains *why* Reddit data is so valuable: it contains unique
    human nuance and expertise often missing from redundant factual data found elsewhere.'
  relevance_score: 9
  source: llm_enhanced
  text: A lot of time data on Reddit is exclusive to Reddit. And sometimes it's more
    of the nuance and human expertise that really helps make these large language
    models better and more capable.
  topic: technical/data value
- impact_reason: 'This offers a strategic justification for the slower speed: the
    ''deep research mode'' likely employs superior models or techniques (like dual
    GPT-4 usage) that inherently reduce hallucination rates.'
  relevance_score: 9
  source: llm_enhanced
  text: I don't think that's necessarily a bad thing because in almost everyone's
    experience, you have a lower likelihood of hallucinations when you do the deep
    research mode. It uses a more powerful tool.
  topic: technical/safety
- impact_reason: Provides concrete, measurable evidence (24-point Elo jump) of significant
    performance improvement in a new model iteration, validated by community benchmarks.
  relevance_score: 9
  source: llm_enhanced
  text: Gemini 2.5 Pro, the new version, the June 5th version, actually got a 24-point
    jump over its previous version. So, now Google, their 2.5 Pro is number one and
    number two on the LM Arena board.
  topic: technical
- impact_reason: Raises serious concerns about data provenance and intellectual property
    theft in the AI ecosystem, specifically pointing to potential misuse of proprietary
    model outputs for training.
  relevance_score: 9
  source: llm_enhanced
  text: Chinese lab DeepSeek's newly released R1 (and this is the May 28th version)
    is making headlines for its strong performance on math and coding benchmarks,
    but some researchers suspect it was partly trained on data from Google Gemini's
    family of models.
  topic: safety
- impact_reason: A sharp critique of low-cost AI competitors, suggesting their cost
    advantage is derived from illicitly leveraging the massive R&D investment of leading
    labs.
  relevance_score: 9
  source: llm_enhanced
  text: Well, according to reports and executives at these exact same companies, they're
    doing this because they're literally just distilling from the companies that are
    actually paying the money to create, train, fine-tune the models.
  topic: business
- impact_reason: Illustrates how M&A activity in the AI tooling space immediately
    triggers strategic, defensive actions (model access revocation) between competing
    foundational model providers.
  relevance_score: 9
  source: llm_enhanced
  text: Anthropic has withdrawn nearly all access to its Claude 3.x model—so, 3.5
    and 3.7 models—from Windsurf after reports surfaced that OpenAI is acquiring Windsurf
    for $3 billion.
  topic: strategy
- impact_reason: Provides direct confirmation from an Anthropic leader regarding the
    strategic rationale for cutting off a partner (Windsurf/Codeium) due to competitive
    concerns, revealing internal prioritization.
  relevance_score: 9
  source: llm_enhanced
  text: Jared Kaplan, Anthropic's co-founder and chief science officer, confirmed
    the move was driven by a desire to avoid enabling a direct competitor to focus
    and to focus on lasting partnerships, citing limited computing resources as a
    secondary factor.
  topic: strategy
- impact_reason: Offers a strategic interpretation of Anthropic's move, linking model
    access revocation directly to competitive maneuvering (preventing data leakage
    to an OpenAI-backed entity).
  relevance_score: 9
  source: llm_enhanced
  text: The timing suggests Anthropic wants to prevent its Claude models from supporting
    a soon-to-be OpenAI-owned rival and possibly to protect its proprietary data from
    leaking into a competitor's ecosystem.
  topic: strategy
- impact_reason: Provides a strong critique of the study's methodology, arguing that
    its narrow focus on abstract puzzles invalidates its conclusions for real-world
    LLM use cases (like coding).
  relevance_score: 9
  source: llm_enhanced
  text: The research exclusively uses abstract logic puzzles with a single correct
    answer as its benchmark. That was a terrible study, ignoring the primary real-world
    applications of reasoning models, which often involve creative collaboration,
    coding, and drafting, where the step-by-step thinking process itself is a valuable
    output.
  topic: technical/strategy
- impact_reason: Suggests the research paper was strategically timed and potentially
    commissioned by business interests (WWDC announcements) rather than pure research,
    linking academic output to corporate strategy.
  relevance_score: 9
  source: llm_enhanced
  text: This seemed like someone high up in the business development side of Apple
    said, 'Hey, FYI, June 9th today, right? Today is our big WWDC announcement. And
    we are essentially, according to reports, Bloomberg said that Apple is taking
    a 'gap year' on AI...'
  topic: strategy/business
- impact_reason: Distinguishes between the technical validity of the data points and
    the ethical/strategic validity of how the research was framed and released, calling
    out disingenuous framing.
  relevance_score: 9
  source: llm_enhanced
  text: So, you have to question the validity of this research, even though the research
    itself is valid. How they framed it, I think, actually, is extremely disingenuous
    to the research field...
  topic: safety/ethics
- impact_reason: Contextualizes the Scale AI investment as a major marker in the escalating
    competition among Big Tech for foundational AI resources.
  relevance_score: 9
  source: llm_enhanced
  text: The deal, if finalized, would be one of the largest investments in an artificial
    intelligence startup ever and underscores the intensifying race among tech giants
    to secure AI capabilities.
  topic: business
- impact_reason: Suggests that securing a partnership with Scale AI could significantly
    boost Meta's competitive standing, particularly given their commitment to open-weight
    models (Llama).
  relevance_score: 9
  source: llm_enhanced
  text: I think this is a potential deal that could catapult Meta into this one-tier-one
    discussion. And I don't know, maybe it's because Meta takes is the only big tech
    trillionaire company to take this primarily open-source, open-weight approach
    with their Llama models...
  topic: strategy
- impact_reason: 'Provides a clear, current competitive landscape ranking of the major
    AI players (1A: Google/OpenAI, 1B: Anthropic/Microsoft, followed by a gap before
    Meta).'
  relevance_score: 9
  source: llm_enhanced
  text: at least since Quarter 4 of last year, so around November, December, it's
    really just been Google and OpenAI at the top, right? You could say they're flip-flopping
    in the 1A spot, and then you have kind of Anthropic and Microsoft in that 1B spot.
    But you kind of have a big drop-off, I would say, until you get to Meta and their
    Llama models...
  topic: strategy
- impact_reason: This signals a major push by OpenAI to make voice interaction a core,
    high-quality feature for its paid user base, moving beyond basic text interaction.
  relevance_score: 8
  source: llm_enhanced
  text: OpenAI has launched a significant upgrade to its advanced voice mode in ChatGPT,
    which is now available to all paid users across platforms.
  topic: technical/product update
- impact_reason: This is a direct assessment of OpenAI regaining a leading position
    in voice technology quality relative to competitors following the update.
  relevance_score: 8
  source: llm_enhanced
  text: I'd say right now this new advanced voice mode update that just rolled out
    hours ago would at least put OpenAI in the 1A or 1B conversation, where I think
    maybe before there was a little bit of a drop-off in terms of quality.
  topic: business/competition
- impact_reason: This signals OpenAI's aggressive expansion into enterprise productivity
    tools, directly challenging established players like Otter.ai and Zoom.
  relevance_score: 8
  source: llm_enhanced
  text: ChatGPT and OpenAI making a huge play in the business sphere here with its
    new connectors for paid users as well as a new ChatGPT meeting recorder.
  topic: business/strategy
- impact_reason: This is a direct move to integrate LLMs into the core workflow of
    knowledge workers by automating meeting documentation and follow-up actions.
  relevance_score: 8
  source: llm_enhanced
  text: OpenAI introduced a new record feature in ChatGPT Teams for macOS, letting
    users record, transcribe, and summarize meetings on voice notes directly within
    the app.
  topic: application/business
- impact_reason: Highlighting integration with CRM/dynamic business data (like HubSpot)
    shows the shift from static knowledge retrieval to active, dynamic data interaction.
  relevance_score: 8
  source: llm_enhanced
  text: One I'm excited to try is HubSpot, right? Being able to chat with your dynamic
    data is huge.
  topic: business/application
- impact_reason: This provides a specific technical insight into how OpenAI might
    be achieving higher quality/lower hallucination rates in advanced modes—by running
    parallel model inferences.
  relevance_score: 8
  source: llm_enhanced
  text: The last we heard from OpenAI, they actually use dual GPT-4 models.
  topic: technical/architecture
- impact_reason: 'Highlights the core value proposition of new enterprise integration
    features: making proprietary, dynamic data accessible via conversational AI.'
  relevance_score: 8
  source: llm_enhanced
  text: Being able to chat with your dynamic data is huge.
  topic: business
- impact_reason: Provides a specific, timely comparison of feature rollout and availability
    between major LLM providers (OpenAI vs. Anthropic) regarding enterprise data access.
  relevance_score: 8
  source: llm_enhanced
  text: The downside, at least on the OpenAI side, and maybe one reason that Anthropic's
    Claude still has an advantage at least in connecting to this enterprise user data,
    is because right now, at least in ChatGPT, it's only available in deep research
    mode.
  topic: technical
- impact_reason: Highlights the aggressive pace of iteration by Google, suggesting
    that even 'best-in-class' models are immediately superseded, setting a new bar
    for capability.
  relevance_score: 8
  source: llm_enhanced
  text: Google has just woken up and chosen to dominate even more because they released
    a new version of its Gemini 2.5 Pro model, even though their previous version
    of Gemini 2.5 Pro was already by far the most powerful and capable large language
    model.
  topic: technical
- impact_reason: Illustrates the extreme volatility of LLM performance rankings, where
    competitive leads (like Claude's perceived lead in software engineering) are fleeting.
  relevance_score: 8
  source: llm_enhanced
  text: Sure enough, within about 10 days, they wipe out at least external benchmarks
    that Anthropic's Claude had. They're gone.
  topic: strategy
- impact_reason: Offers a balanced judgment on a controversial business move, criticizing
    the execution (short notice) while validating the underlying strategic necessity.
  relevance_score: 8
  source: llm_enhanced
  text: I don't blame Anthropic for this. I think it was in bad taste that they cut
    off access to these models with, I think they said five days' notice, right? We've
    seen reports on this OpenAI acquisition on Windsurf now for three weeks.
  topic: strategy
- impact_reason: Highlights a major industry conflict regarding model access control,
    setting a precedent for how platform providers might react to sudden API changes
    from foundational model creators.
  relevance_score: 8
  source: llm_enhanced
  text: So, Windsurf, formerly Codeium, has criticized the decision from Anthropic
    as anti-industry and warned it could negatively impact many other companies reliant
    on AI model access.
  topic: business/strategy
- impact_reason: Critiques the poor communication and short notice period, emphasizing
    that even strategically correct decisions can be executed poorly, damaging customer
    relations.
  relevance_score: 8
  source: llm_enhanced
  text: I think it was in bad taste that they cut off access to these models with,
    I think they said five days' notice, right? ... with only five days' notice is
    kind of bad form, right?
  topic: business/safety
- impact_reason: Identifies the core user base for advanced LLM providers like Anthropic—developers
    engaged in agentic workflows—and notes the risk of alienating them.
  relevance_score: 8
  source: llm_enhanced
  text: their future customer base, if I'm being honest, for the most part, is software
    developers, web developers, people doing agentic coding, and they're using tools
    like Windsurf and Cursor for that.
  topic: business/strategy
- impact_reason: 'Provides clear business advice: execution matters as much as strategy,
    especially when dealing with a core user demographic.'
  relevance_score: 8
  source: llm_enhanced
  text: Don't piss off your biggest user base, and they did by doing this, even though
    I think ultimately they made the right decision, you probably should have given
    at least a couple of weeks of notice.
  topic: business
- impact_reason: A harsh assessment that Apple's research release is an attempt to
    manage negative optics regarding their lagging AI product rollout by undermining
    the technology sector they are struggling to adopt.
  relevance_score: 8
  source: llm_enhanced
  text: This seemed like Apple bending over backwards to try to cherry-pick and frame
    certain research data to justify how they're absolutely so bad at AI.
  topic: strategy
- impact_reason: This provides a competitive benchmark, suggesting that while OpenAI
    is improving, specialized models (like those from Eleven Labs for voice synthesis)
    still hold an edge in specific emotional fidelity.
  relevance_score: 7
  source: llm_enhanced
  text: Eleven Labs and Hume AI are better at emotional intelligence.
  topic: business/competition
- impact_reason: This acknowledges the ongoing relevance of RAG techniques even as
    new, more integrated retrieval methods (like these cloud connectors) are introduced.
  relevance_score: 7
  source: llm_enhanced
  text: I'm not saying that RAG is dead, right? So, traditional retrieval augmented
    generation.
  topic: technical/architecture
- impact_reason: 'This points out a current limitation/trade-off in deployment: accessing
    proprietary data requires using a slower, more resource-intensive mode, impacting
    real-time usability.'
  relevance_score: 7
  source: llm_enhanced
  text: The downside, at least on the OpenAI side... right now, at least in ChatGPT,
    it's only available in deep research mode.
  topic: technical/deployment
- impact_reason: Illustrates the intense, rapid competitive cycle among top-tier AI
    labs, where a feature introduced by one is immediately matched by others.
  relevance_score: 7
  source: llm_enhanced
  text: I said this is going to be rolling out to all the major labs. Obviously, OpenAI
    responded like that day.
  topic: strategy
- impact_reason: Shows the downstream impact on smaller companies and developers when
    foundational model providers engage in competitive maneuvering, highlighting ecosystem
    fragility.
  relevance_score: 7
  source: llm_enhanced
  text: Windsurf, formerly Codeium, has criticized the decision from Anthropic as
    anti-industry and warned it could negatively impact many other companies reliant
    on AI model access.
  topic: business
- impact_reason: Provides a quick, relatable categorization for emerging AI coding
    tools, helping the audience place Windsurf and similar platforms (like Cursor)
    in the current developer ecosystem.
  relevance_score: 7
  source: llm_enhanced
  text: So, Windsurf users—if you don't know what Windsurf is, it's one of these AI-vibe
    coding platforms. It's much more than that, but if you had to put it in a category,
    it's a vibe coding platform like Cursor, right?
  topic: business/strategy
- impact_reason: A strong indictment of Anthropic's public relations and communication
    strategy, suggesting a systemic failure in managing high-stakes business decisions.
  relevance_score: 7
  source: llm_enhanced
  text: Internally, I don't understand how a company as big as Anthropic is essentially
    just doing a dismally bad—I don't even know if that's a word—but they're just
    very, very bad at comms, right?
  topic: business
source: Unknown Source
summary: '## Podcast Summary: EP 542: Apple’s controversial AI study, Google’s new
  model and more AI News That Matters


  This episode of the Everyday AI Show provides a rapid-fire breakdown of the most
  significant and controversial AI news of the week, focusing heavily on major model
  updates, data rights disputes, and the evolving competitive landscape among the
  leading AI labs.


  ---


  ### 1. Focus Area

  The primary focus is on **Large Language Model (LLM) Developments and Ecosystem
  Wars**, covering:

  *   **Model Updates:** OpenAI''s voice advancements and Google''s new Gemini release.

  *   **Data Rights & Legal Battles:** The lawsuit between Reddit and Anthropic over
  data scraping.

  *   **Enterprise Integration:** The rise of cloud connectors (RAG alternatives)
  from OpenAI.

  *   **Competitive Strategy:** Anthropic''s strategic moves regarding partnerships
  and model access.


  ### 2. Key Technical Insights

  *   **OpenAI Advanced Voice Mode Upgrade:** The latest update significantly improves
  naturalness, cadence, and emotional expressiveness (empathy, sarcasm) in ChatGPT
  voice interactions, and crucially, introduces **real-time, two-way language translation**
  accessible via simple voice commands.

  *   **Google Gemini 2.5 Pro Dominance:** The newly released version (June 5th) shows
  substantial gains, particularly in coding benchmarks and challenging reasoning tests
  like GPQA and Humanity''s Last Exam. It achieved the **top Elo score in every category**
  on the LM Arena, surpassing recent gains made by Anthropic''s Claude 4.

  *   **Shift from Traditional RAG to Connectors:** The introduction of deep cloud
  connectors (Google Drive, SharePoint, etc.) by OpenAI is seen as democratizing the
  core benefit of Retrieval Augmented Generation (RAG)—accessing proprietary data—making
  it available with minimal setup, potentially commoditizing the expensive, laborious
  process of traditional RAG implementation.


  ### 3. Business/Investment Angle

  *   **The Value of Exclusive Data:** The Reddit lawsuit against Anthropic underscores
  the immense commercial value of high-quality, nuanced user-generated content for
  training LLMs, suggesting Reddit data may be more valuable than traditional news
  sources for model improvement.

  *   **Strategic Partnership Control:** Anthropic''s decision to pull Claude access
  from the coding platform Windsurf immediately following reports of its acquisition
  by OpenAI highlights a strategic move to prevent its technology from supporting
  a direct competitor, prioritizing "lasting partnerships" over broad distribution.

  *   **Cost vs. Ethics in Model Training:** The scrutiny over Chinese firm DeepSeek,
  which is accused of distilling training data from OpenAI and Google, raises serious
  questions about the true cost and ethical sourcing behind models that claim ultra-low
  training expenses.


  ### 4. Notable Companies/People

  *   **OpenAI:** Launched significant upgrades to ChatGPT''s advanced voice mode
  and introduced cloud connectors for enterprise data integration.

  *   **Google:** Released the upgraded **Gemini 2.5 Pro (June 5th version)**, solidifying
  its lead in reasoning and coding benchmarks.

  *   **Anthropic:** Facing a major lawsuit from **Reddit** for alleged unauthorized
  data scraping and strategically cutting off access to its models for **Windsurf**
  (a coding platform being acquired by OpenAI).

  *   **DeepSeek:** A Chinese AI lab under fire for allegedly using distillation techniques
  to train its R1 model using outputs from Gemini and ChatGPT.

  *   **Jordan Wilson (Host):** Provides analysis and context, emphasizing the practical
  implications of these updates for businesses and careers.


  ### 5. Future Implications

  The industry is rapidly moving toward **application-layer competition**, where the
  core LLMs become increasingly swappable, and differentiation hinges on deep, dynamic
  integrations with enterprise data (via connectors). Furthermore, the legal battles
  surrounding data scraping (Reddit vs. Anthropic) will set critical precedents for
  data rights and licensing in the AI training pipeline. The ethical concerns surrounding
  data distillation (DeepSeek) suggest increased regulatory and industry scrutiny
  on model provenance.


  ### 6. Target Audience

  This episode is highly valuable for **AI/ML Professionals, Technology Executives,
  Product Managers, and Business Leaders** who need a concise, professional overview
  of the week''s most impactful AI advancements, competitive shifts, and legal risks.'
tags:
- artificial-intelligence
- generative-ai
- ai-infrastructure
- investment
- startup
- anthropic
- openai
- apple
title: 'EP 542: Apple’s controversial AI study, Google’s new model and more AI News
  That Matters'
topics:
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 176
  prominence: 1.0
  topic: artificial intelligence
- keywords:
  - generative ai
  - genai
  - chatgpt
  - gpt
  - claude
  - text generation
  - image generation
  mentions: 39
  prominence: 1.0
  topic: generative ai
- keywords:
  - gpu
  - tensor
  - training
  - inference
  - model deployment
  - vector database
  mentions: 7
  prominence: 0.7
  topic: ai infrastructure
- keywords:
  - investment
  - funding
  - valuation
  - ipo
  - acquisition
  mentions: 7
  prominence: 0.7
  topic: investment
- keywords:
  - startup
  - entrepreneur
  - founder
  - venture
  mentions: 5
  prominence: 0.5
  topic: startup
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-10-05 11:12:02 UTC -->
