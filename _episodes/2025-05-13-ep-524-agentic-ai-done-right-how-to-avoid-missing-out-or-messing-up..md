---
companies:
- category: unknown
  confidence: medium
  context: This is the Everyday AI Show, the everyday podcast where we simplify AI
    and br
  name: Everyday AI Show
  position: 12
- category: unknown
  confidence: medium
  context: of these sessions, and it was standing room only. But I think one thing
    that business leaders are constan
  name: But I
  position: 301
- category: unknown
  confidence: medium
  context: going to be talking about today and a lot more on Everyday AI. What's going
    on? My name's Jordan Wilson. I'm th
  name: Everyday AI
  position: 681
- category: unknown
  confidence: medium
  context: t more on Everyday AI. What's going on? My name's Jordan Wilson. I'm the
    host of Everyday AI. This is your daily
  name: Jordan Wilson
  position: 721
- category: unknown
  confidence: medium
  context: this is quite a different setup. I'm here at the IBM Think Conference,
    a very excited partner with IBM to be able to te
  name: IBM Think Conference
  position: 1074
- category: unknown
  confidence: medium
  context: 'king about today: how you can not miss out on it. So I''m very excited
    for our guest, Dr. Maryam Asuri, w'
  name: So I
  position: 1307
- category: unknown
  confidence: medium
  context: out on it. So I'm very excited for our guest, Dr. Maryam Asuri, who is
    the Senior Director of Product Management
  name: Maryam Asuri
  position: 1346
- category: unknown
  confidence: medium
  context: cited for our guest, Dr. Maryam Asuri, who is the Senior Director of Product
    Management at Watson X. Maryam, thank
  name: Senior Director
  position: 1371
- category: unknown
  confidence: medium
  context: ', Dr. Maryam Asuri, who is the Senior Director of Product Management at
    Watson X. Maryam, thank you so much for joinin'
  name: Product Management
  position: 1390
- category: unknown
  confidence: medium
  context: o is the Senior Director of Product Management at Watson X. Maryam, thank
    you so much for joining the Everyd
  name: Watson X
  position: 1412
- category: unknown
  confidence: medium
  context: for having me. Yeah, the special edition here at IBM Think. But before
    we get into all the new announcements
  name: IBM Think
  position: 1538
- category: unknown
  confidence: medium
  context: Absolutely. I'm the head of product for Watson X. The AI, and the past
    to an informed miles have been supe
  name: The AI
  position: 1745
- category: unknown
  confidence: medium
  context: we are delivering. We have some new products like Watson X Code Assistant
    that are powered up by the granted code models, a
  name: Watson X Code Assistant
  position: 2945
- category: unknown
  confidence: medium
  context: ng able to trace and monitor a little bit better. And I love seeing the
    chain of thought reasoning in an
  name: And I
  position: 6444
- category: unknown
  confidence: medium
  context: have these workloads, they can be accelerated by Gen AI. But then, the
    opportunity that agents represent
  name: Gen AI
  position: 13774
- category: unknown
  confidence: medium
  context: business, and two, focus on problems, workflows. Can I use agents to automate
    some of them? If the answe
  name: Can I
  position: 14297
- category: unknown
  confidence: medium
  context: ', when you can just go in, I know there''s the new Code Assistant that
    you all updated. Is that just going to be th'
  name: Code Assistant
  position: 15546
- category: big_tech
  confidence: high
  context: The host is at the IBM Think Conference, and the guest is from IBM's Watson
    X division. IBM is a major enterprise technology provider implementing AI solutions.
  name: IBM
  source: llm_enhanced
- category: ai_platform
  confidence: high
  context: The specific AI platform/division within IBM that the guest, Dr. Maryam
    Asuri, works for. It focuses on enterprise AI solutions, including foundation
    models and agentic AI capabilities.
  name: Watson X
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: A specific product announced by IBM/Watson X, powered by foundation models,
    designed for code generation/assistance.
  name: Watson X Code Assistant
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: Mentioned as one of IBM's software products enriched with foundation models.
  name: intelligent environmental intelligence to eat
  source: llm_enhanced
date: 2025-05-13 14:00:00 +0000
duration: 19
has_transcript: false
layout: episode
llm_enhanced: true
original_url: https://pscrb.fm/rss/p/www.buzzsprout.com/2175779/episodes/17151368-ep-524-agentic-ai-done-right-how-to-avoid-missing-out-or-messing-up.mp3
processing_date: 2025-10-05 18:05:22 +0000
quotes:
- length: 142
  relevance_score: 4
  text: Every day a new piece of technology is coming to the market, and mid-year
    last year, we saw the excitement around LLMs taking action as agents
  topics:
  - market
- length: 132
  relevance_score: 4
  text: So the pattern that we are seeing in the market is moving toward getting and
    grabbing much smaller LLMs, even for powering up agents
  topics:
  - market
- length: 162
  relevance_score: 3
  text: We have a series of products like intelligent environmental intelligence to
    eat that are powered up and enriched with the foundation models that we are delivering
  topics: []
- length: 232
  relevance_score: 3
  text: What would you say with everything that was announced, and there's a ton that
    was announced here at IBM Think, what would you say is the biggest solution for
    those enterprise customers that are already maybe on the Watson X platform
  topics: []
- impact_reason: Crucially points out that agentic systems inherit all existing LLM
    risks (hallucinations, bias) and amplify them due to their ability to take action.
  relevance_score: 10
  source: llm_enhanced
  text: There are major challenges that are amplified with agents, and I'll tell you
    why. Let's start with ensuring the responsible implementation of AI. All the limitations
    that the LLMs historically had, now they are carried forward to agents because
    agents are powered up by LLMs.
  topic: safety
- impact_reason: 'Identifies the core security/safety risk of agents: action-taking
    capabilities leading to data leakage, making traceability non-negotiable.'
  relevance_score: 10
  source: llm_enhanced
  text: But at the same time, these agents are taking actions that can access data,
    they interpret code, they connect to external services, right? They can leak data
    potential if not designed well. So the transparency and the traceability of actions
    is essential for agents.
  topic: safety
- impact_reason: Strongly advocates for the trend of using smaller, fine-tuned LLMs
    over massive general models for enterprise use cases to achieve cost-efficiency
    and differentiation via proprietary data.
  relevance_score: 10
  source: llm_enhanced
  text: So the pattern that we are seeing in the market is moving toward getting and
    grabbing much smaller LLMs, even for powering up agents. Why do you need unproprietary
    data of the enterprise, that data value users, that's their domain-specific data,
    to create something differentiated that delivers the performance they need for
    a fraction of the cost for their target use case, right?
  topic: technical
- impact_reason: 'Provides crucial strategic advice: problem-first approach over technology-first
    approach for successful AI adoption.'
  relevance_score: 10
  source: llm_enhanced
  text: I would say that they should focus on the problem they are solving. Versus,
    hey, there is an agent, how can I use that agent?
  topic: strategy
- impact_reason: 'Articulates the critical concept of risk-based deployment: the necessity
    of Human-In-The-Loop (HITL) is entirely dependent on the stakes of the use case
    (e.g., dinner recommendation vs. critical decision).'
  relevance_score: 10
  source: llm_enhanced
  text: Looking to the sensitivity of the workloads. For some of the workloads, the
    risk is just too high that you need to make sure a human is in the loop. But for
    some of the use cases, like the example that I'm using is if I am using agents
    to provide recommendations for dinner, I probably don't care about shares of human
    in the loop or explainability of why I arrived at that decision.
  topic: safety
- impact_reason: Provides crucial strategic advice against technology-first adoption,
    emphasizing a problem-first approach, which is vital for successful AI implementation.
  relevance_score: 10
  source: llm_enhanced
  text: Don't go out there and try to use agents. Go out there and find a problem
    to solve and find the right agent that aligns with it.
  topic: strategy
- impact_reason: Provides a powerful, real-world anecdote illustrating the radical
    acceleration in the product development lifecycle due to AI coding assistance,
    moving from idea to functional prototype almost instantly.
  relevance_score: 10
  source: llm_enhanced
  text: I run a team of product managers, and my product managers are prototyping.
    When we think about a new feature or idea, they are showing me the fully functional
    prototype that they had coded in their like, this is it, and I'm like, is it real?
    What am I looking at? So, I feel like this is literally changing everything. The
    way that we are thinking about technology, the way that we are thinking about
    solving problems, our problem-solving process is already changed.
  topic: predictions
- impact_reason: 'This is the single most important piece of advice for AI adoption
    safety and governance: risk assessment must precede implementation.'
  relevance_score: 10
  source: llm_enhanced
  text: Know your limits and lines. It's like what are the risks associated with your
    use cases that can't be jeopardized? Understanding the risks gives them a true
    and good lens to assess the technology.
  topic: safety
- impact_reason: Highlights the massive current industry interest and hype surrounding
    agentic AI, signaling a major focus area for 2024/2025.
  relevance_score: 9
  source: llm_enhanced
  text: AI agents are all the rage. I literally just left one of these sessions, and
    it was standing room only.
  topic: strategy
- impact_reason: 'Frames the adoption of agentic AI as a high-stakes decision for
    enterprises: significant productivity gains versus major failure/missed opportunity.'
  relevance_score: 9
  source: llm_enhanced
  text: But I think one thing that business leaders are constantly thinking about
    when it comes to agentic AI is getting it right. And you can either mess up or
    miss out, or you can do it correctly and really see a new level of productivity
    for your enterprise that you maybe haven't experienced in a very long time.
  topic: business
- impact_reason: 'Clearly outlines the trade-off triangle for large models: capability
    vs. cost, latency, and environmental impact, highlighting the optimization challenge.'
  relevance_score: 9
  source: llm_enhanced
  text: Observability is challenge number one. Challenge number two, optimization.
    When you're looking for a value factor, the larger the model, the more capable
    the model is, but we all know that the larger the model, it also requires larger
    compute. That translates to an increased cost. That translates to an increased
    latency. That translates to an increased carbon footprint and energy consumption.
  topic: technical
- impact_reason: 'Explains *why* agent costs scale faster than simple LLM inference:
    advanced reasoning (CoT, planning) increases compute time significantly.'
  relevance_score: 9
  source: llm_enhanced
  text: Agents, they have advanced planning capabilities, they have chain of thought
    reasoning. Inference time is scaling. That translates to additional compute. So
    think about the scale of enterprise, the cost adds up, and that brings it back
    to optimization, cost performance optimization, and why custom enterprises should
    pay attention to this.
  topic: technical
- impact_reason: Highlights deployment friction as a critical bottleneck (18 hours
    for generic apps) and positions streamlined deployment (seconds/minutes for agents)
    as a key enterprise value proposition.
  relevance_score: 9
  source: llm_enhanced
  text: I'm going to pick one in the middle. There we go. The deploy one, right? Enterprises,
    on average, the developers and enterprises are spending 18 hours in deploying
    and scaling a generic application, 18 hours. We don't want the developers to spend
    18 hours. We want them to deploy their agents as a matter of seconds and scale
    it as a matter of minutes, right?
  topic: business
- impact_reason: Addresses enterprise security concerns by detailing granular access
    control mechanisms (projects/spaces) necessary for deploying powerful agents securely.
  relevance_score: 9
  source: llm_enhanced
  text: The last factor that I like to highlight here is access control. Enterprises
    are very concerned about security. Even for some of them, like some of the telecommunication
    companies that we work with, they have very unique security requirements. We have
    designed this deployment services in a way that the access control is managed
    by projects and spaces. So you have full control of who can access this agent
    under what circumstances to do what, which is essential for enterprises.
  topic: safety
- impact_reason: Provides quantitative evidence (1-2 hours/day saved) for the immediate
    productivity boost AI coding assistants offer to developers.
  relevance_score: 9
  source: llm_enhanced
  text: We ran a study with a thousand developers across the states, the developers
    that are building AI applications, and we asked them, are you using AI-assisted
    coding for development? The majority of them, the answer was yes. We said, how
    much time saving are you getting? Most of them said one to two hours a day.
  topic: business
- impact_reason: Quantifies the immediate productivity benefit of AI tools (1-2 hours
    saved daily), framing it as a massive societal shift toward higher-value work,
    which is a core business argument for adoption.
  relevance_score: 9
  source: llm_enhanced
  text: The additional value that you can create by that two extra hours per day.
    That translates to acceleration in the speed of creation, that translates into
    freeing up the time of developers, or it's not just developers, every single one
    of us to do higher-value work...
  topic: business
- impact_reason: Offers a concrete, actionable list of the most common and immediate
    high-value use cases for LLMs in the enterprise, serving as a starting roadmap
    for business leaders.
  relevance_score: 9
  source: llm_enhanced
  text: Two things. The first one is looking to LLMs itself and how they can help
    businesses. The most common use cases for LLMs are content-grounded question and
    answering. Customer care is a very good example of that, code generation or content
    generation, classification, information extraction, summarization.
  topic: business
- impact_reason: 'Clearly defines the next evolution beyond basic LLM application:
    agents enabling integration and action across the entire enterprise via function/tool
    calling.'
  relevance_score: 9
  source: llm_enhanced
  text: But then, the opportunity that agents represent is bringing that all into
    every single corner of your enterprise, blending these two words together to function,
    calling and tool calling.
  topic: technical
- impact_reason: A strong cautionary note against stifling innovation out of fear.
    It advocates for empowering employees while setting necessary guardrails.
  relevance_score: 9
  source: llm_enhanced
  text: And allowing these lines is don't limit your people. Closing your eyes doesn't
    erase the problem. It just lets you not be able to solve it and see it on it.
  topic: strategy
- impact_reason: 'A comprehensive, actionable blueprint for responsible AI governance:
    Risk assessment + Guidelines + Expert consultation + Empowerment/Trust.'
  relevance_score: 9
  source: llm_enhanced
  text: So I would say that understand the risk, provide guidelines, establish the
    guidelines, go talk to the experts in the field to understand how you can mitigate
    those risks, and be open to that and make it accessible to your staff, and trust
    your workforce to find the right way and help them and empower them to move forward
    as the AI moves.
  topic: safety
- impact_reason: Distinguishes between current market experimentation with agents
    and the enterprise requirement for production-ready, scalable solutions.
  relevance_score: 8
  source: llm_enhanced
  text: The market is still experimenting with agents. They are still looking for
    a value factor and a home moment. But what we are designing is for production
    and scale.
  topic: strategy
- impact_reason: 'Defines the essential MLOps/LLMOps framework for agents: Build,
    Deploy, Monitor.'
  relevance_score: 8
  source: llm_enhanced
  text: Thinking about agents, lifecycle managing the lifecycle, all the way from
    building it to deploying it and monitoring the performance of the agents is what
    we've been talking about.
  topic: strategy
- impact_reason: Captures the psychological shift and fear among leaders moving from
    controlled LLM use to powerful, easily deployable, autonomous agents.
  relevance_score: 8
  source: llm_enhanced
  text: One big, I guess, mindset shift that we're seeing a lot with enterprise leaders
    is they've been looking at the past maybe two years since large language models
    became popularized, and they're like, okay, we probably made some mistakes along
    the way, and that's with our smartest humans in control, right? But when we talk
    about now multi-agentic orchestration and these agents that are actually so easy
    to get out, less than five minutes, but then they're so powerful, there is this
    fear of maybe messing up.
  topic: safety
- impact_reason: 'Offers forward-looking regulatory advice: build systems anticipating
    future compliance needs, not just current minimums.'
  relevance_score: 8
  source: llm_enhanced
  text: The stakes matter, right? And the third one is like just the industry, like
    what are the regulations, and think about the future, not the regulations for
    today.
  topic: safety
- impact_reason: 'Philosophical takeaway: AI''s greatest value is freeing up human
    time for higher-value, meaningful work, not just task automation.'
  relevance_score: 8
  source: llm_enhanced
  text: That translates to acceleration in the speed of creation, that translates
    into freeing up the time of developers, or it's not just developers, every single
    one of us to do higher-value work, and I feel like that's really where the opportunity
    lies and where I'm personally excited about because I feel like collectively as
    humans now we have made more time in our hands to do more higher-value and well
    work.
  topic: strategy
- impact_reason: 'Addresses a major enterprise concern: compatibility with legacy
    infrastructure, suggesting agents can bridge the gap and accelerate existing systems.'
  relevance_score: 8
  source: llm_enhanced
  text: So, literally, all of that acceleration can be mapped to even your legacy
    systems in enterprise.
  topic: business
- impact_reason: 'Offers a pragmatic decision-making framework for adopting agentic
    workflows: if a solution exists, use it; if not, adopt an iterative exploration
    strategy.'
  relevance_score: 8
  source: llm_enhanced
  text: Can I use agents to automate some of them? If the answer is yes, go for it.
    If the answer is like, explore and build your own and watch and see how the market
    evolves to solve your problem, then that's the path forward.
  topic: strategy
- impact_reason: Highlights the obsolescence of traditional, slow internal processes
    (like lengthy presentations) when rapid prototyping via AI tools is possible.
  relevance_score: 8
  source: llm_enhanced
  text: Our internal presentations and internal long rollouts are those that think
    of the past, when you can just go in, I know there's the new Code Assistant that
    you all updated. Is that just going to be the thing in the past where it's just
    like, no, I'm just going to go solve the problem first and then talk about it
    and see how we can use it?
  topic: strategy
- impact_reason: 'Provides a two-step prioritization model: 1. Implement core LLM
    capabilities. 2. Strategically deploy agents to scale that capability enterprise-wide
    by targeting workflows.'
  relevance_score: 8
  source: llm_enhanced
  text: I would start with LLMs application itself and then looking to one, how can
    I bring that acceleration to every single corner of my business, and two, focus
    on problems, workflows.
  topic: strategy
- impact_reason: Provides a concrete example of the speed and resilience achieved
    in agent deployment/scaling (minutes vs. hours), emphasizing high availability.
  relevance_score: 7
  source: llm_enhanced
  text: The other one automatically to load balancing comes up. So easily as a matter
    of let's say two minutes, the one that I tried yesterday in three, you can increase
    the scale and increase the scale of your agents.
  topic: technical
- impact_reason: Cites a specific, large-scale financial metric ($3.5B savings) attributed
    to internal AI/automation efforts, serving as a powerful case study for business
    leaders.
  relevance_score: 7
  source: llm_enhanced
  text: IBM had this massive, right, $3.5 billion in savings because of AI and automation.
  topic: business
- impact_reason: Identifies the current, most common, and likely lowest-risk entry
    points for LLM adoption in the enterprise.
  relevance_score: 7
  source: llm_enhanced
  text: The most common use cases for LLMs are conten[t generation and summarization].
  topic: business
- impact_reason: Philosophical framing of AI's benefit—not just efficiency, but a
    fundamental shift in human capacity for meaningful work.
  relevance_score: 7
  source: llm_enhanced
  text: I feel like collectively as humans now we have made more time in our hands
    to do more higher-value and well work.
  topic: predictions
- impact_reason: 'Articulates the core challenge facing business leaders today: decision
    paralysis due to the overwhelming proliferation of AI tools and applications.'
  relevance_score: 7
  source: llm_enhanced
  text: Where should businesses be looking because it's almost like there are so many
    different agents, there are so many different places you can apply?
  topic: business
source: Unknown Source
summary: '## Podcast Summary: EP 524: Agentic AI Done Right - How to avoid missing
  out or messing up


  This episode of the Everyday AI Show, recorded live from the IBM Think Conference,
  focuses on the critical need for enterprises to adopt **Agentic AI** correctly to
  maximize productivity gains while mitigating significant risks. Host Jordan Wilson
  interviews **Dr. Maryam Asuri, Senior Director of Product Management at Watson X,
  IBM**, to discuss the challenges and solutions for deploying AI agents at scale.


  ### 1. Focus Area

  The primary focus is on the practical, production-ready implementation of **Agentic
  AI** within large enterprises. Key themes include overcoming deployment hurdles,
  ensuring responsible AI practices, and optimizing the cost/performance trade-off
  associated with scaling autonomous agents powered by Large Language Models (LLMs).


  ### 2. Key Technical Insights

  *   **Agent Challenges Amplified:** Agents inherit LLM limitations but amplify risks
  due to their ability to take actions, access data, interpret code, and connect to
  external services, making **transparency and traceability of actions** paramount
  for observability.

  *   **Optimization via Smaller Models:** The industry trend is moving toward using
  **smaller, domain-specific LLMs** to power agents. This is driven by the need to
  reduce the high compute costs, latency, and carbon footprint associated with larger
  models, especially as agentic reasoning (chain-of-thought) scales inference time.

  *   **Lifecycle Management Focus:** Successful agent deployment requires robust
  management across the entire lifecycle: **Building, Deploying, and Monitoring**.
  IBM''s focus is on streamlining deployment to seconds/minutes for enterprise scalability,
  including built-in high availability and load balancing.


  ### 3. Business/Investment Angle

  *   **Value Realization is Key:** Enterprises are still experimenting to find the
  "value factor" or "home moment" for agents. Success requires focusing on **solving
  specific business problems** rather than simply adopting the technology.

  *   **Risk Sensitivity Dictates Approach:** The level of **human-in-the-loop** intervention
  required depends entirely on the stakes of the use case (e.g., high-stakes finance
  vs. low-stakes dinner recommendations).

  *   **LLM Acceleration to Enterprise Corners:** The immediate business opportunity
  lies in leveraging common LLM use cases (Q&A, summarization, code generation) and
  then using agents to **blend this acceleration into legacy systems** via tool calling
  and workflow automation.


  ### 4. Notable Companies/People

  *   **Dr. Maryam Asuri (IBM Watson X):** Guest expert detailing IBM''s strategy
  for production-ready agent deployment, focusing on observability, optimization,
  and deployment speed.

  *   **IBM Think Conference:** The context for the discussion, highlighting recent
  announcements from IBM regarding Watson X capabilities.

  *   **Watson X:** IBM''s AI platform offering tools, services, and foundation models
  designed to help enterprises customize and deploy AI solutions.


  ### 5. Future Implications

  Agentic AI is fundamentally changing how work is done, leading to significant productivity
  boosts. Developers are already reporting **1-2 hours of time savings daily** using
  AI-assisted coding, freeing up time for higher-value work. The future involves a
  shift where non-technical users can assemble powerful, data-connected agents rapidly,
  accelerating the entire problem-solving process.


  ### 6. Target Audience

  This episode is highly valuable for **AI/ML Professionals, Enterprise Technology
  Leaders (CTOs, CIOs), Product Managers, and Business Leaders** who are past the
  initial experimentation phase and are now strategizing for the secure, scalable,
  and responsible production deployment of autonomous AI agents.


  ---

  ### Comprehensive Narrative Summary


  The podcast addresses the urgent enterprise dilemma regarding Agentic AI: the fear
  of **missing out** versus the risk of **messing up** deployment. Dr. Maryam Asuri
  frames the discussion around moving agents from experimentation to **production
  and scale**, highlighting that the path to success is fraught with amplified challenges.


  The core technical hurdles identified are **Observability** and **Optimization**.
  Because agents act autonomously, ensuring transparency and traceability of their
  actions is critical, especially in regulated industries where adherence to policy
  must be monitored. Furthermore, the computational demands of complex agent reasoning
  (chain-of-thought) drive up costs and latency. Asuri advocates for a strategic shift
  toward **smaller, custom-tuned LLMs** for agents to achieve necessary performance
  at a fraction of the cost.


  When advising leaders on where to focus first, Asuri suggests prioritizing the **Deployment**
  phase, noting that reducing the time developers spend deploying and scaling agents
  from hours to minutes is a massive efficiency gain. This deployment service must
  include enterprise necessities like high availability and granular **access control**.


  A key mindset shift discussed is moving away from "How can I use this agent?" to
  **"What problem am I solving?"** The stakes of the use case must dictate the level
  of governance required (e.g., human-in-the-loop).


  Finally, Asuri offers crucial advice for avoiding mistakes: **Know your limits and
  lines.** Leaders must understand the specific risks associated with their use cases,
  establish clear guidelines, seek expert consultation for mitigation, and simultaneously
  empower their workforce by making the technology accessible rather than restricting
  access out of fear. The overall message is that Agentic AI is already transforming
  workflows, offering substantial time savings, and the key to success lies in disciplined,
  problem-focused implementation.'
tags:
- artificial-intelligence
- ai-infrastructure
title: 'EP 524: Agentic AI Done Right - How to avoid missing out or messing up.'
topics:
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 53
  prominence: 1.0
  topic: artificial intelligence
- keywords:
  - gpu
  - tensor
  - training
  - inference
  - model deployment
  - vector database
  mentions: 1
  prominence: 0.1
  topic: ai infrastructure
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-10-05 18:05:22 UTC -->
