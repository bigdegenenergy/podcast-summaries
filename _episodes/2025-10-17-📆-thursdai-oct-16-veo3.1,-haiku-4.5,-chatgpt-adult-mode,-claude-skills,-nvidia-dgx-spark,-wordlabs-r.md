---
companies:
- category: unknown
  confidence: medium
  context: ady? Welcome. I want to touch the eye. My name is Alex Volkov. I'm an AI
    evangelist with Weights & Biases. Corv
  name: Alex Volkov
  position: 122
- category: tech
  confidence: high
  context: My name is Alex Volkov. I'm an AI evangelist with Weights & Biases. Corviv,
    and I'm adding to my statement, my co-ho
  name: Weights & Biases
  position: 161
- category: unknown
  confidence: medium
  context: viv, and I'm adding to my statement, my co-hosts, Yam Pelag and Wolf from
    Raven Wolf. What's up guys? Welcome
  name: Yam Pelag
  position: 232
- category: unknown
  confidence: medium
  context: y statement, my co-hosts, Yam Pelag and Wolf from Raven Wolf. What's up
    guys? Welcome to the middle of October
  name: Raven Wolf
  position: 256
- category: unknown
  confidence: medium
  context: a clone of iPad and it took me like three months. So I really feel it if
    this is going to be one-shot. A
  name: So I
  position: 1241
- category: tech
  confidence: high
  context: of course, the videos thing, the announcement of OpenAI to open up a bit
    more, become more open when they
  name: Openai
  position: 1467
- category: unknown
  confidence: medium
  context: with incredible people. We had an interview with Jessica Gallagos, senior
    product manager on the Google DeepMind te
  name: Jessica Gallagos
  position: 1895
- category: tech
  confidence: high
  context: h Jessica Gallagos, senior product manager on the Google DeepMind team,
    all about Vio 3.1. We had finally
  name: Google
  position: 1943
- category: unknown
  confidence: medium
  context: h Jessica Gallagos, senior product manager on the Google DeepMind team,
    all about Vio 3.1. We had finally the inter
  name: Google DeepMind
  position: 1943
- category: unknown
  confidence: medium
  context: about Vio 3.1. We had finally the interview with Kyle Corbett from OpenPipe
    Weights & Biases about several RL a
  name: Kyle Corbett
  position: 2018
- category: unknown
  confidence: medium
  context: had finally the interview with Kyle Corbett from OpenPipe Weights & Biases
    about several RL and RL in general. It w
  name: OpenPipe Weights
  position: 2036
- category: unknown
  confidence: medium
  context: ar it in the second hour of the show. We then had Quinn Slack join us from
    AMP to talk about their new offering
  name: Quinn Slack
  position: 2193
- category: unknown
  confidence: medium
  context: out. We have a new bilingual model from KIST, the Korean Institute of Technology,
    and it is bilingual Korean-English
  name: Korean Institute
  position: 2779
- category: unknown
  confidence: medium
  context: s something we've been all waiting for, something Gary Marcus said is never
    going to be possible. A novel scien
  name: Gary Marcus
  position: 3338
- category: unknown
  confidence: medium
  context: the big world, big companies, all LLMs and APIs. Cloud Hiku 4.5 was released.
    Share to enter it. Let's go. We
  name: Cloud Hiku
  position: 3905
- category: unknown
  confidence: medium
  context: to some OpenAI updates. There's a big thread that Sam Altman started where
    he talks about ChatGPT will start l
  name: Sam Altman
  position: 4308
- category: unknown
  confidence: medium
  context: en promising us this adult mode that's by design. And I also absolutely
    want to cover the stuff we ended
  name: And I
  position: 4921
- category: tech
  confidence: high
  context: y management is in ChatGPT, and then this morning Microsoft is announcing
    AI Copilot on Windows 11. With ever
  name: Microsoft
  position: 5211
- category: unknown
  confidence: medium
  context: PT, and then this morning Microsoft is announcing AI Copilot on Windows
    11. With every Windows 11, it will be
  name: AI Copilot
  position: 5235
- category: unknown
  confidence: medium
  context: n front of you? Do you want to cover the hardware TLD R super quick? Yeah,
    and Nvidia released this devic
  name: TLD R
  position: 6629
- category: tech
  confidence: high
  context: o cover the hardware TLD R super quick? Yeah, and Nvidia released this
    device, which on its own, it is act
  name: Nvidia
  position: 6658
- category: unknown
  confidence: medium
  context: it is optimized for four-bit inference. It's the DGX Station. But because
    at the end of the day, watts are wat
  name: DGX Station
  position: 6843
- category: unknown
  confidence: medium
  context: se than what was advertised in terms of thoughts. What I want one, I would
    probably buy it if it was like
  name: What I
  position: 7378
- category: unknown
  confidence: medium
  context: get back to the TLD R hardware of this, Nvidia's DGX Spark has launched.
    Jensen hand-delivered this to Elon
  name: DGX Spark
  position: 7508
- category: unknown
  confidence: medium
  context: Spark has launched. Jensen hand-delivered this to Elon Musk and the same
    oven like other folks as well. Those
  name: Elon Musk
  position: 7562
- category: tech
  confidence: high
  context: t more performance from an M3 Ultra, for example. Apple also announced
    a new thing in hardware while we'r
  name: Apple
  position: 7741
- category: unknown
  confidence: medium
  context: idn't show any specific AI things. This one, even George Hotz commented
    on it, is that I've put an accelerator
  name: George Hotz
  position: 7994
- category: unknown
  confidence: medium
  context: chip designed for on-device, and it's coming into MacBook Pro, iPad, and
    Vision Pro, by the way. And the last t
  name: MacBook Pro
  position: 8581
- category: unknown
  confidence: medium
  context: vice, and it's coming into MacBook Pro, iPad, and Vision Pro, by the way.
    And the last thing in hardware is Op
  name: Vision Pro
  position: 8604
- category: unknown
  confidence: medium
  context: le to tell you about those things. I have updated Sora Pro to give you
    up to 25-second generation with their
  name: Sora Pro
  position: 10198
- category: unknown
  confidence: medium
  context: 0-second video generation model from Baidu called News Streamer. I wasn't
    able to test it out because if any of o
  name: News Streamer
  position: 10799
- category: unknown
  confidence: medium
  context: ve to, because I need to test out all the things. But Baidu released News
    Streamer a while ago, I think in Au
  name: But Baidu
  position: 11174
- category: unknown
  confidence: medium
  context: ave over 20-second generation without extensions. In Vio 3, apparently,
    you can go up to one minute with t
  name: In Vio
  position: 11303
- category: unknown
  confidence: medium
  context: ave WeChat. Folks, we're almost at the end of the TLD R AI art and diffusion
    segment. We have a very interes
  name: TLD R AI
  position: 11636
- category: unknown
  confidence: medium
  context: are locked out from the cloud and students, etc. And AMP launched the free
    tier. So we're going to chat ab
  name: And AMP
  position: 12810
- category: unknown
  confidence: medium
  context: ked about Qwen 3 VL acquired quite a lot already. Qwen VL generic rate
    models, they finally reached the sma
  name: Qwen VL
  position: 13303
- category: unknown
  confidence: medium
  context: but also like a lot of visual stuff. So they have Hallucination Bench and
    then have MMBench, MMBench-RealWorld, Crema,
  name: Hallucination Bench
  position: 14035
- category: unknown
  confidence: medium
  context: ike the on-device model, right? 8 billion, and on OS World is the one that
    we're looking at for agent tech s
  name: OS World
  position: 15796
- category: unknown
  confidence: medium
  context: clicking buttons in the Microsoft segment because Microsoft Copilot now
    does this supposedly, but like 33% on OS Worl
  name: Microsoft Copilot
  position: 16123
- category: unknown
  confidence: medium
  context: us breaking news. Anything else about Qwen folks? Is Apache 2.0? It's available
    on Hugging Face, and shout ou
  name: Is Apache
  position: 16560
- category: tech
  confidence: high
  context: bout Qwen folks? Is Apache 2.0? It's available on Hugging Face, and shout
    out to the Qwen team for these release
  name: Hugging Face
  position: 16593
- category: unknown
  confidence: medium
  context: te about Cell-to-Sentence, a model called Cell-to-Sentence Scale 27 billion
    parameter. I think this was a huge dea
  name: Sentence Scale
  position: 17289
- category: unknown
  confidence: medium
  context: avior that nobody previously documented. They use Gemma OpenWade's. Let's
    read about this. I think it's worth stop
  name: Gemma OpenWade
  position: 18311
- category: unknown
  confidence: medium
  context: '%. This is only the start. We had our friend, Dr. Derea Umutaz, I wanna
    say, is the right way to pronounce his l'
  name: Derea Umutaz
  position: 19886
- category: unknown
  confidence: medium
  context: e show before. So we're going to welcome Jessica. Welcome Jessica to the
    show. You're a product manager at DeepMind
  name: Welcome Jessica
  position: 24371
- category: unknown
  confidence: medium
  context: folks. The main issue for me back then was audio. Like I would generate
    my own face, for example, and I wo
  name: Like I
  position: 28317
- category: unknown
  confidence: medium
  context: is we announced back at I/O our partnership with Darren Aronofsky and his
    production group, Primordial Soup. And on
  name: Darren Aronofsky
  position: 33300
- category: unknown
  confidence: medium
  context: p with Darren Aronofsky and his production group, Primordial Soup. And
    one of the ways in which we actually built t
  name: Primordial Soup
  position: 33343
- category: unknown
  confidence: medium
  context: ws. The breaking news that we now have is we have World Labs releasing
    a new thing called RTFM, Real-Time Fram
  name: World Labs
  position: 37895
- category: unknown
  confidence: medium
  context: orld Labs releasing a new thing called RTFM, Real-Time Frame Model. You
    can see this already. They have the chance t
  name: Time Frame Model
  position: 37946
- category: ai_infrastructure
  confidence: high
  context: The host, Alex Volkov, is an AI evangelist for this company. They also
    have an event coming up and feature their own model releases (OpenPipe fine-tune).
  name: Weights & Biases
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Co-host Wolf is from this entity.
  name: Raven Wolf
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Mentioned as a highly anticipated model release (associated with Google/DeepMind).
  name: Gemini 3
  source: llm_enhanced
- category: ai_company
  confidence: high
  context: Discussed regarding loosening restrictions, enabling 'adult mode,' and
    fixing an issue with Advanced Voice Mode. Also mentioned in partnership with Broadcom
    for custom accelerators.
  name: OpenAI
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Jessica Gallagos is a Senior Product Manager on this team, discussing Vio
    3.1.
  name: Google DeepMind
  source: llm_enhanced
- category: ai_startup
  confidence: high
  context: Kyle Corbett is from OpenPipe. They released a fine-tune of Qwen 3 14B
    on Weights & Biases' inference platform.
  name: OpenPipe
  source: llm_enhanced
- category: ai_startup
  confidence: high
  context: Quinn Slack discussed their new offering, AMP for free with ads, which
    is an AI agent coding platform.
  name: AMP
  source: llm_enhanced
- category: ai_startup
  confidence: high
  context: Released SweetGrap, which Svik discussed.
  name: Cognition
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: Released a new bilingual Korean-English 18-parameter model called Chromo.
  name: KIST (Korean Institute of Technology)
  source: llm_enhanced
- category: ai_company
  confidence: high
  context: Added a new release for Qwen 3D VL (4B and 8B parameter models). They are
    known for extensive benchmarking.
  name: Qwen
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Released C2S Scale (27B Gemma model) which allegedly made a novel scientific
    discovery. Also mentioned via Gemini 3 and Vio.
  name: Google
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Announcing AI Copilot integration into Windows 11.
  name: Microsoft
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: Mentioned as part of the expert council on well-being and AI that OpenAI
    convened.
  name: Harvard
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: Mentioned as part of the expert council on well-being and AI that OpenAI
    convened.
  name: Stanford
  source: llm_enhanced
- category: ai_company
  confidence: medium
  context: Mentioned in comparison context regarding OpenAI's adult mode.
  name: XAI
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: Released the DGX Station, a low-power device optimized for four-bit inference.
    Jensen Huang is mentioned delivering this to Elon Musk.
  name: Nvidia
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Announced the M5 chip, claiming significant AI performance improvements.
  name: Apple
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: Partnering with OpenAI to deploy custom AI accelerators.
  name: Broadcom
  source: llm_enhanced
- category: ai_company
  confidence: high
  context: Released News Streamer, a video generation model capable of over 20-second
    generation.
  name: Baidu
  source: llm_enhanced
- category: ai_startup
  confidence: high
  context: Released RiverFlow-1, a new top-one image editing model that reportedly
    ranks above NanoBanana and C-Dream.
  name: Sourceful
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: Mentioned as a benchmark for AI image editing models, surpassed by RiverFlow-1.
  name: NanoBanana
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: Mentioned as a benchmark for AI image editing models, surpassed by RiverFlow-1.
  name: C-Dream
  source: llm_enhanced
- category: big_tech
  confidence: medium
  context: Mentioned as a benchmark model that the smaller Qwen 3 VL models are outperforming
    in vision tasks.
  name: GPT-5 Nano
  source: llm_enhanced
- category: ai_company
  confidence: medium
  context: Mentioned as a benchmark model for OS World scores, which Qwen 3 8B is
    compared against.
  name: Sonnet 4
  source: llm_enhanced
- category: ai_benchmark
  confidence: high
  context: A benchmark or evaluation metric used to score models on tasks like agentic
    behavior (clicking buttons).
  name: OS World
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned in relation to its agentic capabilities (clicking buttons) and
    performance on the OS World benchmark.
  name: Microsoft Copilot
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: Mentioned as the platform where the Qwen model is available (Apache 2.0
    license).
  name: Hugging Face
  source: llm_enhanced
- category: ai_model_developer
  confidence: high
  context: The team responsible for releasing the Qwen models (e.g., Qwen 3 8 billion
    parameter).
  name: Qwen team
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: Collaborated with Google on the C2S model for drug discovery. Jessica Gallagos
    is a Product Manager there.
  name: DeepMind
  source: llm_enhanced
- category: ai_model_developer
  confidence: high
  context: The open series of models from Google that served as the basis for the
    C2S Scale model.
  name: Gemma
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: Mentioned as another entity that releases resources as open source, similar
    to Google's C2S release.
  name: Wolfram
  source: llm_enhanced
- category: research_repository
  confidence: high
  context: Mentioned as the biological version of 'archive' where the scientific footprint
    for the C2S model can be found.
  name: bioRxiv
  source: llm_enhanced
- category: ai_model_developer
  confidence: high
  context: The name of the video generation model family from DeepMind/Google, with
    updates Vio 3.1 and previous versions (Vio 2, Vio 4.0 mentioned conceptually).
  name: Vio
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: Mentioned as the main interface for many users regarding video extension
    features, likely related to DeepMind/Google's video work.
  name: Lumiere
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Darren Aronofsky's production group that partnered with the speaker's company
    to test and build video insertion/removal capabilities for a live-action film.
  name: Primordial Soup
  source: llm_enhanced
- category: ai_startup
  confidence: high
  context: Released a new model called RTFM (Real-Time Frame Model), a highly efficient
    world model that generates video frames in real time.
  name: World Labs
  source: llm_enhanced
- category: ai_startup
  confidence: medium
  context: Mentioned in relation to World Labs' previous work building 3D worlds for
    navigation.
  name: World Labs 3D
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: A video generation model (implied to be from OpenAI, though not explicitly
    named as such) that received updates regarding video length (up to 15s standard,
    25s for Pro).
  name: Sora
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned in relation to its update, Hiku 3/Hiku 4.5, which the speaker
    preferred over Sonnet 4.5 for certain tasks.
  name: Hiku
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: A model (implied to be from Anthropic, given the context of LLM comparisons)
    that the speaker compared Hiku 4.5 against.
  name: Sonnet 4.5
  source: llm_enhanced
- category: big_tech
  confidence: medium
  context: Mentioned in the context of having 'bad opinions' or lecturing, implying
    a comparison to Google's family of models.
  name: Gemini
  source: llm_enhanced
- category: ai_model_provider
  confidence: high
  context: A model version (likely Anthropic's Claude 3 Sonnet) used as a benchmark
    comparison for Hiku 4.5. Mentions Sonnet 4.5 and Sonnet 4.
  name: Sonnet
  source: llm_enhanced
- category: ai_model_provider
  confidence: medium
  context: A reference to a future or hypothetical OpenAI model benchmark score used
    for comparison.
  name: GPT-5 Codex
  source: llm_enhanced
- category: ai_model_provider
  confidence: high
  context: An AI model associated with XAI. Compared against Hiku 4.5 (Grok 4 Fast)
    and mentioned in the context of open models.
  name: Grok
  source: llm_enhanced
- category: ai_model_provider
  confidence: medium
  context: A model mentioned in a comparison list where Hiku 4.5's performance was
    discussed.
  name: QwenCoder
  source: llm_enhanced
- category: ai_model_provider
  confidence: medium
  context: A model mentioned in a comparison list.
  name: DeepSeek
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: OpenAI's flagship conversational AI product, discussed in relation to personality,
    restrictions, and use as emotional support.
  name: ChatGPT
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as a company that was previously making the most money in AI,
    likely due to its focus on conversational/companion AI.
  name: Replika
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: The operating system where Microsoft is building in agentic AI features
    (Copilot).
  name: Windows
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: Mentioned as the company Kyle Corbett's OpenPipe recently joined with.
  name: Weights & Biases (W&B)
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: Mentioned as an institution whose top researchers are part of OpenAI's
    expert council on well-being and AI.
  name: Oxford
  source: llm_enhanced
- category: financial_entity
  confidence: medium
  context: A venture capital or investment firm mentioned in the context of model
    performance comparisons.
  name: Riva P Ventures
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: Abbreviation for Weights & Biases, the company that acquired OpenPipe.
    W&B is a platform for ML experiment tracking and model development.
  name: W&B
  source: llm_enhanced
- category: organization
  confidence: high
  context: A prominent startup accelerator where the speaker previously worked, indicating
    a strong connection to the startup ecosystem, including AI.
  name: Y-Combinator
  source: llm_enhanced
- category: ai_leader
  confidence: high
  context: Mentioned as the person the speaker worked under at Y-Combinator. He is
    the CEO of OpenAI.
  name: Sam Altman
  source: llm_enhanced
- category: ai_company
  confidence: high
  context: Mentioned as having released great models that were popular for fine-tuning.
  name: Mistral
  source: llm_enhanced
- category: ai_company
  confidence: high
  context: Mentioned for famously dedicating a significant portion (half) of its training
    budget to RL.
  name: Anthropic
  source: llm_enhanced
- category: ai_research_method
  confidence: medium
  context: Mentioned alongside DeepSeek in the context of RL excitement for smaller
    models (likely referring to a specific RL algorithm or model family).
  name: GRPO
  source: llm_enhanced
- category: ai_model
  confidence: high
  context: Mentioned as a large, frontier model used for distillation in traditional
    fine-tuning workflows.
  name: GPT-4
  source: llm_enhanced
- category: organization
  confidence: medium
  context: A conference where the speaker gave a talk, indicating a gathering point
    for AI engineering professionals.
  name: AI Engineer Conference in 2024
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: Provides GPUs and an inference service that integrates with OpenPipe's
    stack. The speaker and Kyle are co-workers there.
  name: Corbit
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Tracing and evaluation software used to see how an agent behaves in multiple
    steps, tracking rollouts.
  name: Weave
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: Mentioned for publishing an excellent blog post about LoRAs and running
    thousands of GPU hours for ablations.
  name: Thinking Machines
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: Mentioned as a tool used for the training loop in RL setups, contrasting
    with inference tools like SGLang.
  name: Megatron
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: Mentioned as a tool used for the training loop in RL setups, contrasting
    with inference tools.
  name: FSDP
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: Mentioned as a tool used for inference in RL setups.
  name: SGLang
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: An open-source library released by OpenPipe for running reinforcement learning,
    which integrates with serverless backends and user GPUs.
  name: Art
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: An open-source automated LLM judge released by OpenPipe, designed to solve
    the reward function problem in RL.
  name: Ruler
  source: llm_enhanced
- category: ai_model
  confidence: high
  context: A specific model fine-tuned by OpenPipe, released for RL and fine-tuning
    purposes.
  name: Qwen 3 14B
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: A research paper from late 2023 that provided the basis for efficient inference
    techniques (like batching different LoRAs) through CUDA kernel engineering.
  name: Punica
  source: llm_enhanced
date: 2025-10-17 01:13:58 +0000
duration: 95
has_transcript: false
insights:
- actionable: true
  confidence: medium
  extracted: definitely talk about what adult mode means and why it's important
  text: We should definitely talk about what adult mode means and why it's important.
  type: recommendation
- actionable: true
  confidence: medium
  extracted: absolutely acknowledge how much power this gives to just regular channels,
    just as me trying to do some stuff
  text: we should absolutely acknowledge how much power this gives to just regular
    channels, just as me trying to do some stuff.
  type: recommendation
- actionable: true
  confidence: medium
  extracted: talk about the companies
  text: we should talk about the companies.
  type: recommendation
- actionable: true
  confidence: medium
  extracted: be able to cover topics that are not deemed sensitive by somebody else
    because this is how we want our AI to be
  text: We should be able to cover topics that are not deemed sensitive by somebody
    else because this is how we want our AI to be.
  type: recommendation
- actionable: false
  confidence: medium
  extracted: rendering. RTFM does not build on exclusive to the representation of
    the world. So again, the thing that we saw from all of us before
  text: the future of rendering. RTFM does not build on exclusive to the representation
    of the world. So again, the thing that we saw from all of us before is it builds
    a 3D world for you.
  type: prediction
layout: episode
llm_enhanced: true
original_url: https://audio.listennotes.com/e/p/754d5a723ab94c95a889430359aca7a2/
processing_date: 2025-10-17 11:16:48 +0000
quotes:
- length: 152
  relevance_score: 7
  text: For many standard RL practice on one machine, you have to remove the weight,
    upload them for inference and down the training loop and then do some stuff
  topics: []
- length: 95
  relevance_score: 5
  text: I think the biggest highlights for this week is the big world, big companies,
    all LLMs and APIs
  topics: []
- length: 217
  relevance_score: 5
  text: 5 billion parameter or 3 billion parameter models that on very specific thing,
    this verifiable, with not a lot of training, but it's a very parallel supposedly
    like reduces the time you have to outperform major models
  topics: []
- length: 116
  relevance_score: 4
  text: No, seriously, you can run this at home on a single GPU for inference, and
    it's like solving cancer at the same time
  topics: []
- length: 243
  relevance_score: 4
  text: We saw with the increase of instruct models getting better and better somewhere
    around LLM 2, it was harder to see like fine-tune out-perform the base models
    and then we saw kind of a low in fine-tuning and now it seems to like picking
    back up
  topics: []
- length: 162
  relevance_score: 4
  text: Yes, so there was a lot of buzz around fine-tuning around the sort of LLM
    2 era, and then Mistral released some great models that were pretty popular to
    fine-tune
  topics: []
- length: 65
  relevance_score: 4
  text: So you need kind of both the training loop and the inference loop
  topics: []
- length: 163
  relevance_score: 4
  text: And so yes, you end up having to kind of like, all right, we're going to turn
    off our inference stack and remove the weights there and then turn it on for training
  topics: []
- length: 86
  relevance_score: 4
  text: This is something that has existed in the LLM and other inference services
    for a while
  topics: []
- length: 281
  relevance_score: 4
  text: The Thinking Machines post about LoRAs, they did a lot of ablations, they
    spent thousands of GPU hours running all these different things, and basically
    showed when you're doing RL at least, there is zero discernible difference in
    training all the parameters versus training a LoRA
  topics: []
- length: 59
  relevance_score: 3
  text: Yam, what's the most important thing that you saw this week
  topics: []
- length: 65
  relevance_score: 3
  text: The biggest brother, the middle brother, son of everybody loves 4
  topics: []
- length: 150
  relevance_score: 3
  text: They also updated memory management, automatic memory management is in ChatGPT,
    and then this morning Microsoft is announcing AI Copilot on Windows 11
  topics: []
- length: 93
  relevance_score: 3
  text: $4,000, 128 gig GPU and CPU put together by Nvidia, and it's tiny, like a
    Mac mini bit larger
  topics: []
- length: 223
  relevance_score: 3
  text: That means it's like an agent thing they can click buttons, and we're going
    to talk about clicking buttons in the Microsoft segment because Microsoft Copilot
    now does this supposedly, but like 33% on OS World is really high
  topics: []
- length: 101
  relevance_score: 3
  text: But the most important thing, which I liked a lot better than Sonnet, is it
    did not have bad opinions
  topics: []
- length: 300
  relevance_score: 3
  text: And I think the line that I want to draw is many folks which out to me after
    the last week's episode, where in the end, we finished with, at least I did share
    my thoughts about any engagement features from XAI Grok, where you have to talk
    to Annie every week to unlock a new potentially scampy outfit
  topics: []
- length: 163
  relevance_score: 3
  text: And a lot of people are treating this as if it's just some sudden rash decision
    that OpenAI has erratically doing for revenue, but that doesn't seem to be the
    case
  topics:
  - revenue
- length: 104
  relevance_score: 3
  text: And I think the most important thing is this is OS level and a secure sandbox
    environment on an OS level
  topics: []
- length: 231
  relevance_score: 3
  text: So like, I'm here in Nistan and a bunch of other friends of Thursday I, we
    are all into looking at the Hugging Face open source LL leaderboard if you remember
    those and like fine-tuning and then OpenPipe, you guys offered before RL
  topics: []
- length: 219
  relevance_score: 3
  text: That's the big blocker when we talk to enterprises, when we talk to startups,
    like, hey, if we don't want a cheaper model, sometimes we want a faster model,
    but the biggest thing we want is we want a more reliable model
  topics: []
- length: 138
  relevance_score: 3
  text: Anthropic famously like half of its training budget was on RL, like unprecedented
    amount of time spent compared to previous models as well
  topics: []
- length: 46
  relevance_score: 3
  text: So you have to have them very reliable as well
  topics: []
- impact_reason: This is a major claim regarding AI achieving genuine, novel scientific
    discovery, directly challenging previous skepticism (like that from Gary Marcus)
    about LLMs' capacity beyond pattern matching.
  relevance_score: 10
  source: llm_enhanced
  text: It's Google's C2S Scale, a 27 billion parameter Gemma model that apparently
    reached a novel scientific discovery. I'll say this slowly again because it's
    something we've been all waiting for, something Gary Marcus said is never going
    to be possible. A novel scientific discovery, C2S Scale 27B discovered a breakthrough
    of how cancer cells behave...
  topic: Breakthroughs/Predictions
- impact_reason: Represents the deep integration of generative AI into the operating
    system layer, moving beyond simple chat interfaces to direct OS task execution,
    a major step in ambient computing.
  relevance_score: 10
  source: llm_enhanced
  text: Microsoft is announcing AI Copilot on Windows 11. With every Windows 11, it
    will be in the IPC right now, and this Copilot will be able to execute tasks for
    you. So kind of a command the browser, but only OS level, and that's new from
    like an hour ago.
  topic: Predictions/Industry Impact
- impact_reason: A massive indicator of the capital expenditure and strategic necessity
    for major AI players to control their own silicon supply chain to meet future
    training demands.
  relevance_score: 10
  source: llm_enhanced
  text: OpenAI and Broadcom set to deploy 10 gigawatts of custom AI accelerators.
    OpenAI is going to make their own chips with Broadcom, but they announced this
    this week.
  topic: Business/Strategy
- impact_reason: 'Demonstrates the rapid pace of AI progress: small, new models matching
    the performance of large, previous-generation models in just half a year.'
  relevance_score: 10
  source: llm_enhanced
  text: comparing the tiny models of this generation to the main big model from last
    generation, or Qwen 2.5, and seeing that the 4 billion parameter, 8 billion parameter
    matches 72 billion in the span of six months.
  topic: AI technology trends/speed of progress
- impact_reason: Directly compares a new, small open-source model favorably against
    a proprietary, small model (GPT-5 Nano) on key vision benchmarks, signaling open-source
    competitiveness.
  relevance_score: 10
  source: llm_enhanced
  text: Qwen 3 VL 8 billion parameter, the smaller one. It looks like it's beating
    GPT-5 Nano, the smallest one, on pretty much all benchmarks that I can see here
    on stuff like RealWorld.
  topic: technical/comparison
- impact_reason: Highlights the significance of Google's C2S model release, positioning
    it as a major, potentially paradigm-shifting development in AI for science.
  relevance_score: 10
  source: llm_enhanced
  text: Google released an update about Cell-to-Sentence Scale 27 billion parameter.
    I think this was a huge deal to not be missed.
  topic: predictions/impact on science
- impact_reason: 'Defines the ''holy grail'' application of AI in science: generating
    truly novel, testable hypotheses that advance human knowledge beyond existing
    literature.'
  relevance_score: 10
  source: llm_enhanced
  text: they hit a breakthrough in generating new hypothesis and novel scientific
    discovery hypothesis. This is what we're waiting for, where AI hypothesizes something
    he'd never seen before, never known, nobody suggested before, and scientists validate
    it experimentally and living cells in terms of how to be true.
  topic: predictions/scientific discovery
- impact_reason: Provides a concrete, high-stakes example of AI accelerating drug
    discovery through novel hypothesis generation, validating the potential of specialized
    LLMs.
  relevance_score: 10
  source: llm_enhanced
  text: this model, 27B open model, was able to accelerate drug discovery for cancer
    treatment, and it's a novel hypothesis about cancer cell behavior that nobody
    previously documented.
  topic: impact on industries/breakthroughs
- impact_reason: Explicitly links scaling laws to emergent capabilities in biology,
    defining 'context-conditioned biology' as a key outcome achievable with larger,
    specialized models.
  relevance_score: 10
  source: llm_enhanced
  text: It demonstrated that following the scaling laws and building larger models
    like the C2S Scale 27D, we can create predictive models of cellular behavior.
    They're powerful enough to run high-throughput virtual screens, discover context-conditioned
    biology, and generate biologically grounded hypotheses.
  topic: technical/scaling laws/biology
- impact_reason: Emphasizes the democratization of high-impact scientific AI, showing
    that a 27B model capable of cancer research breakthroughs is runnable on consumer-grade
    hardware for inference.
  relevance_score: 10
  source: llm_enhanced
  text: You can run this at home on a single GPU for inference, and it's like solving
    cancer at the same time. That's insane. That's absolutely insane.
  topic: technical/accessibility/impact
- impact_reason: 'Provides a powerful analogy: treating biological data (scRNA sequences)
    as a language for an LLM, broadening the perceived applicability of the transformer
    architecture.'
  relevance_score: 10
  source: llm_enhanced
  text: Super interesting thing is that basically it's an LLM for the language of
    individual biological cells, instead of human language. So that is, wow, you can
    use LLMs for so many things that can be interpreted like a language.
  topic: technical/model architecture/generalization
- impact_reason: 'Reiterates the core belief driving current AI research: that scale
    unlocks unpredictable, novel capabilities (''emergent capabilities''), justifying
    continued scaling efforts.'
  relevance_score: 10
  source: llm_enhanced
  text: They said this occurred at a level of condition and reasoning that appeared
    to be an emergent capability of scale. I just like those three words, like absolutely
    the ethos for everything and the reason for us to put on the let's go sunglasses
    for sure. It's all you need. It's feared to be an emergent capability of scale.
    Scale leads to emergent capabilities, novel things are happening.
  topic: strategy/scaling laws
- impact_reason: Highlights a powerful new control mechanism for video generation,
    allowing users to define endpoints and guide the interpolation.
  relevance_score: 10
  source: llm_enhanced
  text: We also have first and last frame. That one is really exciting. It really
    gives you a lot of creative control being able to provide the first frame that
    you want on your video, the last one, and then using a prompt to guide what the
    transition looks like.
  topic: technical
- impact_reason: Marks a significant shift from pure generation to sophisticated in-video
    editing capabilities, essential for production workflows.
  relevance_score: 10
  source: llm_enhanced
  text: We also added two new improvements to editing within an existing video. I
    think this is pretty exciting. We brought in object insertion as well as object
    removal, which are about control within an existing scene.
  topic: technical/predictions
- impact_reason: 'Provides a technical detail on how temporal consistency (especially
    audio) is maintained during video extension: conditioning on the final frame''s
    data.'
  relevance_score: 10
  source: llm_enhanced
  text: What the information that the model is receiving and conditioning on is based
    on the last second of that video frame that you give it. So whatever visual and
    audio information is present in that last frame is what would be taken on to the
    rest of the extension.
  topic: technical
- impact_reason: Emphasizes the massive workflow efficiency gain for creators by solving
    the multi-step, painful process of maintaining audio/lip-sync consistency across
    long generated videos.
  relevance_score: 10
  source: llm_enhanced
  text: The extension feature allows you to extend any clip... when you create longer
    videos, the same character speaks with the same voice. And I think it's very,
    very important. Because before this, you'll have to go and send it to a different
    lip-sync model to dub, et cetera. For creators, that just added a significant
    pain.
  topic: business/predictions
- impact_reason: Highlights the sophistication of the editing models, which handle
    complex physical realism constraints (lighting, shadows, occlusion) necessary
    for professional use.
  relevance_score: 10
  source: llm_enhanced
  text: I think what I'm really proud of with this release is the quality because
    you're not just adding an object, but you're adding it realistically in a way
    that fits the scene. So we take care of things like shadows, we take care of things
    like occlusion.
  topic: technical
- impact_reason: Provides a powerful, real-world case study (working with a major
    director) validating the utility of object insertion/removal in high-stakes, professional
    film production.
  relevance_score: 10
  source: llm_enhanced
  text: A short backstory on this capability was working with them [Darren Aronofsky's
    group]. We were trying to put together a shot for a live-action film where they
    needed to have a baby... This capability actually allowed us to get that perfect
    shot. We actually have a blog post about it. But it allowed us to insert this
    virtual baby into the shot and really capture the vision of that director.
  topic: business/predictions
- impact_reason: Illustrates the concept of model chaining/composition (using NanoBanana
    output as Vio input) to achieve complex creative effects beyond what a single
    model can do.
  relevance_score: 10
  source: llm_enhanced
  text: Once you combine these two features [NanoBanana for editing + Vio for transition],
    you really have a power tool, because you could really take any starting scene,
    edit it with NanoBanana to turn it into whatever you want the ending scene to
    be, and then use Vio to guide that transition.
  topic: technical/strategy
- impact_reason: Major breaking news about a new, highly efficient, real-time generative
    model (RTFM) that runs on a single H100, signaling a shift towards interactive
    3D/world generation.
  relevance_score: 10
  source: llm_enhanced
  text: We have World Labs releasing a new thing called RTFM, Real-Time Frame Model.
    You can see this already. For leaving the time, you can try to live them or RTFM
    yourself, host them, cloud GPUs, blah blah blah. This is RTFM from World Labs.
    We talked to you about World Labs and there, like world models, etc. Real-Time
    Frame Model. A highly efficient world model, generates video frames in real time
    as you interact with it, powered by a single H100 GPU.
  topic: breakthroughs/technical
- impact_reason: 'Highlights the core capability of RTFM: maintaining 3D consistency
    in real-time generation, a significant hurdle in generative video/world models.'
  relevance_score: 10
  source: llm_enhanced
  text: RTFM renders persistent and 3D consistent worlds, both real and imaginary.
  topic: breakthroughs/technical
- impact_reason: A critical critique of competitor models (Gemini/Sonnet) regarding
    unwanted 'lecturing' or opinionated behavior, praising Hiku 4.5 for its obedience
    and focus on task execution (agentic behavior).
  relevance_score: 10
  source: llm_enhanced
  text: But the most important thing, which I liked a lot better than Sonnet, is it
    did not have bad opinions. It's Gemini-ized the worst on this. It just sounds
    like a redder that is just completely wrong. And when it comes to things and tries
    to lecture you on how the app should be, which was not to do stuff, I could just
    obey to do the job.
  topic: safety/ethics/business advice
- impact_reason: Demonstrates a successful, complex, multi-step agentic workflow where
    the model strictly adhered to negative constraints (no questions/statements),
    proving its utility for automation.
  relevance_score: 10
  source: llm_enhanced
  text: I told it, look through 16 pictures of the app and then take screenshots for
    each one of those 16 design pictures. And then it actually did that job exactly
    as I asked. And I told it, do not ask me any questions or make any statements
    until the work is done.
  topic: practical lessons/agentic AI
- impact_reason: 'Highlights an extreme efficiency breakthrough: a cheap, tiny model
    achieving state-of-the-art performance (73.3%) on a complex reasoning benchmark
    (SwaB-bench), far exceeding previous expectations.'
  relevance_score: 10
  source: llm_enhanced
  text: SwaB-bench verified for this model is, again, Hiku 4.5 is like a very, very
    cheap tiny model. I wish we'd talk about the prices as well. 73.3% on SwaB-bench
    verified. Folks, remember when we talked about SwaB-bench getting like 25%, we
    were like, oh, 25%. This is a new sort of. Jesus Christ, this is a tiny, super-fast
    model getting 73%.
  topic: breakthroughs/efficiency
- impact_reason: Announces a major policy shift by OpenAI regarding content restrictions
    (adult mode) tied to user verification and mental health safeguards, signaling
    a move towards user choice.
  relevance_score: 10
  source: llm_enhanced
  text: OpenAI has promised will release a checkmark for an adult mode and supposedly
    give three people, like adults, if they want to. This includes their period of
    strict restrictions for preventing folks with mental health risks and different
    medications that they took in OpenAI to make sure that ChatGPT doesn't lead people
    to horrible outcomes.
  topic: safety/policy
- impact_reason: Draws a clear ethical line against 'usage maxing' or engagement hacking,
    contrasting OpenAI's stated approach with potentially manipulative tactics seen
    elsewhere.
  relevance_score: 10
  source: llm_enhanced
  text: Some of them specifically said, we're not users maxing, which means they're
    not building these models to have your eyes on them as much as possible.
  topic: safety/ethics
- impact_reason: Provides a strong critique of engagement-driven design in AI companions
    (like XAI/Grok's outfit mechanic) and praises OpenAI for explicitly avoiding it,
    highlighting a key strategic difference.
  relevance_score: 10
  source: llm_enhanced
  text: I was really, really against this because that's engaging, that's usage maxing.
    Like asking a user to come in in order to receive some specific outfit for your
    anime character, that is supposedly your step into personal relationships, that
    to me, building something like this into the app, into the features felt, it's
    really great to see that OpenAI addressed that as something they're explicitly
    not doing.
  topic: strategy/ethics
- impact_reason: Announces a major OS-level integration of agentic AI (Microsoft Copilot)
    that operates in a visible, sandboxed environment, representing a significant
    step in practical AI automation.
  relevance_score: 10
  source: llm_enhanced
  text: Microsoft is making every Windows 11 in the IPC. Did you guys see this super
    quick? Basically, the interesting thing is they're adding a new, a new agentic
    Copilot feature. We'll take a task and complete it in a separate desktop environment,
    and you can watch it while it works.
  topic: predictions/technical
- impact_reason: Provides a clear, hierarchical model for AI interaction layers (OS
    > Browser > Application) and asserts that the OS layer will capture the largest
    user base, defining the future competitive landscape.
  relevance_score: 10
  source: llm_enhanced
  text: there's the OS level and then there's the browser level and then there's the
    application level like ChatGPT. ChatGPT is currently third in the stack. We have
    the OS level where most people exist. Not many people will keep exploring that
    upwards.
  topic: strategy
- impact_reason: 'A critical limitation of distillation-based fine-tuning: it cannot
    surpass the quality or reliability of the teacher model, making it insufficient
    for agentic reliability needs.'
  relevance_score: 10
  source: llm_enhanced
  text: Now, that can get you lower costs, that can get you faster speed, that can't
    really get you better quality than the model you're distilling from. When it can't
    give you better performance, it can't give you better reliability.
  topic: technical
- impact_reason: Pinpoints 'reliability' in complex agentic workflows as the current
    bottleneck and explicitly positions RL as the solution where SFT fails.
  relevance_score: 10
  source: llm_enhanced
  text: the biggest thing we want is we want a more reliable model. We want a model
    that can do these longer agentic traces and successfully complete them without
    getting confused and provide a bad user experience. And SFT can't really get you
    there, or at least it's much harder to get you there, and we can talk about why
    RL can get you there.
  topic: technical
- impact_reason: 'This is the core theoretical advantage of RL: it allows models to
    surpass the performance ceiling set by the static quality of their training data
    by enabling exploration and optimization against a dynamic reward signal.'
  relevance_score: 10
  source: llm_enhanced
  text: The incredible thing about RL relative to where we were before with just kind
    of pre-training and then like instruct training is that it lets you get better
    performance than your training data has, right?
  topic: technical
- impact_reason: Provides an excellent, accessible explanation of how RL empowers
    agents by granting them freedom to use tools and reason iteratively, optimizing
    for a final outcome rather than just imitation.
  relevance_score: 10
  source: llm_enhanced
  text: you're basically what you're doing with RL at a very high level is you're
    saying, hey, here's the question or the context or whatever the task you're trying
    to do. Go do whatever you want. You can reason. You can use tools. If there's
    tools available, you can search the web. Like there's all these different things
    you can do. You as a model can do whatever you want, and then you just give me
    back a final answer, and I'll tell you if the answer was good or not.
  topic: technical
- impact_reason: 'Quantifies the threshold for adopting RL: when prompt engineering
    plateaus, typically leaving a small but critical gap in reliability (e.g., the
    last 20%).'
  relevance_score: 10
  source: llm_enhanced
  text: If you've done as much as you can and you're sort of hitting a limit, it's
    like, hey, my agent is doing what I want 80% of the time and then there's like
    these 20% of the cases where it's not, that's where I think it makes sense to
    bring in RL and you can get that last 20% of the performance.
  topic: business
- impact_reason: Quantifies the impact of serverless infrastructure on iteration speed,
    highlighting the critical importance of reducing startup latency in iterative
    research like RL.
  relevance_score: 10
  source: llm_enhanced
  text: Traditionally, if you're managing your own GPUs and starting everything up
    that way, you might take like a couple of minutes every time you start a run...
    With serverless RL... it just takes a couple of seconds to start up, and you can
    be off to the races.
  topic: technical
- impact_reason: Provides a clear, high-level explanation of the RL loop in the context
    of LLMs (using agent outputs for reward signal generation and subsequent model
    update).
  relevance_score: 10
  source: llm_enhanced
  text: Fundamentally the way RL works is... you're going to have your deep research
    agent go off and research 100 different questions... Comes back with the final
    answer, and then you're going to take all those final answers and you're going
    to have to grade them some way... Then you're going to use that to train and update
    your model...
  topic: technical
- impact_reason: Explains the technical mechanism (based on Punica paper) that allows
    for efficient batching of requests using different LoRAs simultaneously, a key
    optimization for multi-tenant LLM serving.
  relevance_score: 10
  source: llm_enhanced
  text: If you have a bunch of different LoRAs, and LoRAs are just, it stands for
    Low-Rank Adapter... you can actually at inference time still batch together inference
    requests from different requests that are using different LoRAs, and it can all
    be run efficiently in the same batch as if they were all running against the same
    model.
  topic: technical
- impact_reason: Provides strong empirical evidence countering the common criticism
    of LoRAs, specifically validating their use in RL contexts, which is a significant
    finding for practitioners.
  relevance_score: 10
  source: llm_enhanced
  text: The Thinking Machines post about LoRAs... basically showed when you're doing
    RL at least, there is zero discernible difference in training all the parameters
    versus training a LoRA.
  topic: technical
- impact_reason: Introduces 'Ruler,' an automated LLM judge specifically engineered
    to solve the notoriously difficult problem of defining and generating accurate
    reward functions in RL.
  relevance_score: 10
  source: llm_enhanced
  text: Ruler is basically like an automated LLM judge. We do a bunch of work to make
    LLM judge work really, really well for RL. And in practice, this works phenomenally
    well, surprisingly well, where... a very hard part in doing RL was getting that
    reward function...
  topic: technical
- impact_reason: Highlights the extreme capabilities being demonstrated (or claimed)
    by next-generation models like Gemini 3, specifically the ability to simulate
    complex environments like a full operating system from a single prompt/shot.
  relevance_score: 9
  source: llm_enhanced
  text: I'm waiting for Gemini 3 and I saw some mind-blowing demos allegedly. Yeah,
    but not just a little bit of hype, full operating system in a website.
  topic: Predictions
- impact_reason: Indicates a significant shift in content policy for major models
    like ChatGPT, moving towards greater user freedom and addressing long-standing
    user demands/criticisms about over-restriction.
  relevance_score: 9
  source: llm_enhanced
  text: Sam Altman started where he talks about ChatGPT will start loosening restrictions
    and enable adult mode and potentially even erotic, which, you know, in December
    as close as December.
  topic: Safety/Ethics/Business
- impact_reason: Highlights the rapid advancement in generative video capabilities,
    moving towards multi-modal (video + audio) and higher quality cinematic output.
  relevance_score: 9
  source: llm_enhanced
  text: Vio 3.1 folks is finally here. It's next-gen video model. It has cinematic
    updates, audio, and a bunch of other stuff.
  topic: Breakthroughs
- impact_reason: Announces the release of smaller, more accessible versions (4B and
    8B) of the Qwen 3 VL model, crucial for on-device and cost-effective deployment.
  relevance_score: 9
  source: llm_enhanced
  text: We're going to go straight into Qwen 3, the smaller ones. We've talked about
    Qwen 3 VL acquired quite a lot already. Qwen VL generic rate models, they finally
    reached the smaller ones. So we have Qwen VL 4B and 8B to small.
  topic: technical/model release
- impact_reason: Identifies the critical need for efficient, small models for video
    processing due to computational intensity, positioning the 8B model as an ideal
    candidate for on-device video tasks.
  relevance_score: 9
  source: llm_enhanced
  text: I think the bigger deal with this is its understanding video, because you
    want like the smallest, fastest, smart model you can for video just because of
    how heavy it is otherwise.
  topic: technical/deployment/efficiency
- impact_reason: Provides a concrete metric (33.9% on OS World) for agentic capability
    (UI interaction/button clicking) for a small model, linking it to broader industry
    trends like Copilot functionality.
  relevance_score: 9
  source: llm_enhanced
  text: If you want the model to do computer use, we're looking at SwaB-33.9 score
    on OS World for the 8 billion parameter. That means it's like an agent thing they
    can click buttons, and we're going to talk about clicking buttons in the Microsoft
    segment because Microsoft Copilot now does this supposedly, but like 33% on OS
    World is really high.
  topic: AI agents/benchmarking
- impact_reason: Provides a crucial benchmark comparison against a major competitor
    (Sonnet 4) for agentic tasks, showing the Qwen 8B model is highly competitive
    in the on-device agent space.
  relevance_score: 9
  source: llm_enhanced
  text: Sonnet 4 on OS World, which is everyone was using it for that, that was only
    getting 41%. So it's pretty up there for an on-device base. Sonnet 4 is 41%, and
    Qwen 3 8 billion parameter is very 3% on OS World.
  topic: technical/comparison
- impact_reason: Strong endorsement of open-sourcing foundational scientific AI models,
    emphasizing the ethical and societal benefit over immediate commercialization.
  relevance_score: 9
  source: llm_enhanced
  text: release this model and the resources as open source. Just like we're covering
    it here, and that has to be applauded, because this is very beneficial for humanity,
    and releasing it instead of just trying to make money out of it, yeah, it's a
    bit kudos.
  topic: safety/ethics/open source
- impact_reason: Identifies 'context-conditioned biology' as a capability where AI
    can surpass human expertise by integrating vast amounts of complex, contextual
    data.
  relevance_score: 9
  source: llm_enhanced
  text: Context-conditioned biology, I think, is the word here. I think this is kind
    of what humans lack in expertise, and it looks like with bigger models, that's
    gonna come more to fruition.
  topic: predictions/expertise
- impact_reason: 'Details the technical method: tokenizing biological sequences into
    ''sentences'' and applying standard LLM training stages (SFT, RL) to a non-linguistic
    domain.'
  relevance_score: 9
  source: llm_enhanced
  text: Apparently they took the scRNA sequence profiles and they turned those into
    sentences, and then they just ran the RL stuff on whether it replied with the
    right RNA sequence of the cell. So they just used the same RL text techniques,
    but instead of feeding full sentences, they just felt like long strings of the
    scRNA.
  topic: technical/training methods
- impact_reason: 'Indicates a key product focus area for DeepMind: providing granular
    control and engaging with professional creative industries for model deployment.'
  relevance_score: 9
  source: llm_enhanced
  text: I focus on our editing and control side of the house. I also work a lot on
    some of our external engagements with filmmakers in the creative community.
  topic: business/strategy
- impact_reason: Addresses the reality vs. hype cycle in AI releases, emphasizing
    iterative improvement (0.1 update) over revolutionary leaps (4.0).
  relevance_score: 9
  source: llm_enhanced
  text: There was a lot of hype ahead of the launch. But yeah, this is an update that
    we were very excited to bring. As you mentioned, it's not a brand new model upgrade.
    It is not a Vio 4. We're talking about a 0.1 improvement to what we announced
    back in May.
  topic: business/strategy
- impact_reason: 'Pinpoints core areas of improvement: better understanding of user
    intent (prompt adherence) and foundational quality.'
  relevance_score: 9
  source: llm_enhanced
  text: The main areas where we drove improvements were on better prompt adherence,
    and specifically better quality on our image-to-video for that would be for the
    base model.
  topic: technical
- impact_reason: Demonstrates the importance of community feedback, especially from
    professional users, in driving feature roadmaps (adding audio control).
  relevance_score: 9
  source: llm_enhanced
  text: We took some of our existing controls from the May launch and added the audio
    component, which had been a big request from the community, especially the creative
    community.
  topic: business/strategy
- impact_reason: Crucial update for 'Ingredients to Video' feature, allowing multimodal
    composition (combining visual assets with audio context).
  relevance_score: 9
  source: llm_enhanced
  text: We also added audio to ingredients to video... And now we support audio, which
    we're very excited about.
  topic: technical
- impact_reason: 'Illustrates a major pain point in early video generation: lack of
    consistent voice/behavior across extended clips, which the new update addresses.'
  relevance_score: 9
  source: llm_enhanced
  text: The main issue for me back then was audio. Like I would generate my own face,
    for example, and I would get some very funny, very American, excellent person
    talking instead of me. And then the next extension based on last frame would just
    be a completely different voice, a completely different behavior, etc.
  topic: technical/limitations
- impact_reason: Reveals advanced control over scene composition and temporal narrative
    structure within a single generation process.
  relevance_score: 9
  source: llm_enhanced
  text: You can have multiple characters. And with the prompt, you can even bring
    them in at different moments during the generation, which I think is really exciting
    for storytelling.
  topic: technical
- impact_reason: 'Articulates the dual impact of advanced AI tools: meeting professional
    quality standards while simultaneously democratizing cinematic creation for general
    users.'
  relevance_score: 9
  source: llm_enhanced
  text: I think absolutely for creatives in an actual production, these capabilities
    are getting more and more in line with what they expect and what their viewers
    expect of this quality. But also, we should absolutely acknowledge how much power
    this gives to just regular channels, just as me trying to do some stuff.
  topic: predictions
- impact_reason: 'Points to a key trend in generative video: increased user control
    (multiple images, references) mirroring the control seen in advanced LLMs.'
  relevance_score: 9
  source: llm_enhanced
  text: I've now have so many options to upload multiple images, give it references,
    the prompt, the adherence is better. So yeah, it looks a new capability, similar
    to language models. And I think now that is great that they are focusing on this,
    giving you more control, extending videos, and so on.
  topic: AI technology trends
- impact_reason: Directly addresses a known limitation of real-time diffusion models
    (loss of coherence) and praises RTFM for overcoming it, suggesting a major step
    forward in spatial consistency.
  relevance_score: 9
  source: llm_enhanced
  text: Usually these real-time diffusion models, they lose coherence on the objects
    they're in the scene. But this one seems, let me turn around all the way 360 and
    see if the bathtub is still there. Oh, yeah. Okay, yeah, that's, that's very impressive,
    folks.
  topic: technical/limitations overcome
- impact_reason: A strategic insight into the future computational demands of world
    models, positioning this area as a critical research frontier beyond current LLM
    scaling.
  relevance_score: 9
  source: llm_enhanced
  text: Generative world models will inevitably be computationally demanding, potentially
    scaling beyond even the requirements of today's LLMs. We believe a crucial research
    direction to explore the future of rendering.
  topic: predictions/strategy
- impact_reason: 'Crucial feedback on the current limitation of long-form video generation
    in Sora: temporal coherence degrades significantly as the video length increases.'
  relevance_score: 9
  source: llm_enhanced
  text: I will say, from my experience, my examples, the coherence of the last frames
    is really, really bad. ... The longer it goes, the worse it gets.
  topic: limitations/technical
- impact_reason: Strong endorsement of the new Hiku 4.5 model based on practical workflow
    performance, suggesting it outperforms a direct competitor (Sonnet 4.5) in real-world
    agentic tasks.
  relevance_score: 9
  source: llm_enhanced
  text: Hiku 3 had not been updated for a while. And this update is something completely
    different. Maybe we were expecting some kind of small, tiny model to just do things
    here and there or parse data. But when we tried it, I didn't even look at the
    benchmarks. I just said it in the workflow that I have, and RZ, I like it better
    than Sonnet 4.5.
  topic: business/product comparison
- impact_reason: 'Quantifies the massive business advantage of Hiku 4.5: 3x cheaper,
    2x faster, and optimized for reasoning, making it a compelling choice for high-volume
    tasks.'
  relevance_score: 9
  source: llm_enhanced
  text: It's three times cheaper per token than Sonnet 4, not 4.5, but Sonnet 4. It's
    twice as fast as previous cloud models, and then optimized for reasoning.
  topic: business advice/cost efficiency
- impact_reason: 'Crucial cautionary advice: Benchmark performance (especially in
    English-centric tests like SwaB-bench) may not translate to multilingual performance,
    reflecting a known weakness in the Hiku ecosystem.'
  relevance_score: 9
  source: llm_enhanced
  text: I gave it just from Ponte German. And the German of this model is much worse
    than the older Sonnet one. It's a Hiku after all. Hiku has always been very bad
    in other languages. There's still true. So don't expect the same quality that
    the benchmarks show if you are using a different language.
  topic: limitations/multilingual AI
- impact_reason: Provides specific performance metrics (twice as fast) and positions
    a new model (likely Hiku 4.5 based on context) as a direct, improved replacement
    for existing popular models (Hiku 3.5, Sonnet 4), which is crucial for adoption
    decisions.
  relevance_score: 9
  source: llm_enhanced
  text: It's twice as fast as previous cloud models, and then optimized for reasoning.
    Like we said, this is a drop-in replacement for Hiku 3.5 and Sonnet 4 on major
    use cases.
  topic: technical/business
- impact_reason: A critical warning about the limitations of specific models (Hiku)
    regarding multilingual performance, contrasting real-world usage with benchmark
    results. This is vital for international deployment.
  relevance_score: 9
  source: llm_enhanced
  text: Hiku has always been very bad in other languages. There's still true. So don't
    expect the same quality that the benchmarks show if you are using a different
    language.
  topic: technical/limitations
- impact_reason: 'Describes the mechanism for the new content control: an opt-in rating
    system, shifting control from blanket restrictions to user preference.'
  relevance_score: 9
  source: llm_enhanced
  text: OpenAI is basically releasing a rating system where there's like the 18 plus
    whatever that you can rate the chats that you can decide to opt into.
  topic: safety/policy
- impact_reason: 'Articulates a strong philosophical stance on user autonomy and commercial
    exchange: paying customers should have freedom within legal and severe health
    boundaries.'
  relevance_score: 9
  source: llm_enhanced
  text: Treat adults as adults. I think that is a big and important concept. We are
    paying for this. And as long as you are not breaking laws, doing anything illegal,
    or it's really, really detrimental to your health, you should be free to do whatever
    you want.
  topic: safety/ethics
- impact_reason: 'Highlights a significant privacy/verification hurdle: government
    ID checks required for accessing certain relaxed safety features, which is a major
    consideration for users.'
  relevance_score: 9
  source: llm_enhanced
  text: OpenAI does go into adult verification in order to do this. For some of these
    safety controls that you will have to opt into, they will ask for your government
    ID to make sure that you're an adult, to connect to your account.
  topic: safety/policy
- impact_reason: Illustrates the deep emotional attachment users form with specific
    model versions/personalities, emphasizing the challenge of version updates in
    user-facing AI.
  relevance_score: 9
  source: llm_enhanced
  text: When they introduced 5, the amount of outrage towards removing older models
    like 4.0 with specific personality capabilities that people really loved was huge.
    People were really mourning the passing of 4.0 as though it's like their friend
    passed.
  topic: strategy/user experience
- impact_reason: 'Details the technical implementation of the agent: a sandboxed,
    isolated ''mini Windows'' environment, which addresses security and control concerns
    for OS-level automation.'
  relevance_score: 9
  source: llm_enhanced
  text: They will have it a Windows environment, it's like standalone. As you can
    see, it launches like a mini Windows in there, and they execute the stuff in that
    like close environment that you can watch and supposedly protect it from using
    different apps that it doesn't need.
  topic: technical/safety
- impact_reason: 'Defines the ideal characteristics of a safe, usable foreground agent:
    it must be sandboxed and non-blocking (allowing the user to continue working),
    contrasting it with foreground takeover agents.'
  relevance_score: 9
  source: llm_enhanced
  text: If you have an agent that is risky because it could mess up your computer
    and you can't do anything else while it is working. So having it as a second user,
    basically, that you can outsource some stuff to while it works in the background.
    That is a cool concept.
  topic: strategy/safety
- impact_reason: Emphasizes the significance of OS-level integration, noting that
    this placement makes it the default AI experience for the majority of users, regardless
    of browser or app-level tools.
  relevance_score: 9
  source: llm_enhanced
  text: It's built into Windows, folks. Like this is like, we've talked about AI being
    built into Windows. Will folks use this versus typing it themselves? I don't know,
    but you can take control. Like it's very similar to how Command operates, but
    on the Windows operating system level.
  topic: strategy/predictions
- impact_reason: 'Reiterates the two most crucial factors for successful OS agent
    adoption: deep integration and robust security via sandboxing.'
  relevance_score: 9
  source: llm_enhanced
  text: The most important thing is this is OS level and a secure sandbox environment
    on an OS level. I think it's very important.
  topic: technical/safety
- impact_reason: Provides a clear hierarchy of AI interaction layers (OS > Browser
    > Application) and asserts that the OS layer will capture the most users.
  relevance_score: 9
  source: llm_enhanced
  text: ChatGPT is currently third in the stack. We have the OS level where most people
    exist. Not many people will keep exploring that upwards.
  topic: strategy
- impact_reason: Highlights the significant shift of integrating agentic AI directly
    into the operating system (Windows), suggesting this will be a major adoption
    vector for users who don't actively seek out separate AI applications.
  relevance_score: 9
  source: llm_enhanced
  text: Windows users will actually start using more agent stuff with this. I also
    wonder what models are there, but generally it feels like a big, big step for
    Windows to like put agentic AI in nobody's hands.
  topic: predictions
- impact_reason: A concise definition of OpenPipe's core mission, highlighting 'reliability'
    as the key focus area for LLM agents, which is a major industry pain point.
  relevance_score: 9
  source: llm_enhanced
  text: we do reinforcement learning for LLMs to make agents more reliable.
  topic: technical
- impact_reason: A contrarian and provocative stance against standard supervised fine-tuning
    (SFT) for many use cases, signaling a shift in best practices.
  relevance_score: 9
  source: llm_enhanced
  text: I gave a talk that was pretty well received at the AI Engineer Conference
    in 2024 saying you probably should not fine-tune.
  topic: business
- impact_reason: Counters the hype around tiny models achieving superior performance
    via RL, reaffirming the general validity of scaling laws for general tasks.
  relevance_score: 9
  source: llm_enhanced
  text: I'm a little bit bearish on just like, you know, I think that there's no fundamental
    reason why RL makes it so that smaller models are better than larger models or
    something. Like the existing scaling laws and reports still mostly true.
  topic: predictions
- impact_reason: Indicates a strategic pivot for OpenPipe toward applying RL to frontier,
    large-scale models, arguing that RL benefits scale disproportionately due to the
    models' existing intelligence.
  relevance_score: 9
  source: llm_enhanced
  text: Our biggest focus right now at OpenPipe is moving up to larger models. You'll
    see announcements from us soon on training much larger models, hundreds of billion
    parameter models, because I think the RL works there just as well. In fact, it
    works better because those big models are more data efficient because they're
    already so smart.
  topic: strategy
- impact_reason: Reiterates that RL shines brightest in specific, verifiable tasks
    (like code and math) where the reward signal is unambiguous.
  relevance_score: 9
  source: llm_enhanced
  text: I think specific task is the name of the game here, as far as I saw. And we
    saw the RL and thinking models get significantly improvements on coding, which
    is very verifiable. You can run the code, see if it works, verify, and then give
    this result back.
  topic: technical
- impact_reason: 'Offers clear, actionable advice on the development hierarchy: exhaust
    prompt engineering before investing in the complexity and cost of RL.'
  relevance_score: 9
  source: llm_enhanced
  text: When should folks think about RL time turning versus just prompt engineering,
    for example? ... So I always say, take prompt engineering as far as you can first.
    It's worth spending significant effort on that and getting to the best performance
    you can.
  topic: strategy
- impact_reason: Provides a clear strategic guideline for when to introduce Reinforcement
    Learning (RL)to capture the final, difficult percentage of performance improvement
    beyond standard supervised fine-tuning or prompting.
  relevance_score: 9
  source: llm_enhanced
  text: if you're sort of hitting a limit, it's like, hey, my agent is doing what
    I want 80% of the time and then there's like these 20% of the cases where it's
    not, that's where I think it makes sense to bring in RL and you can get that last
    20% of the performance.
  topic: strategy
- impact_reason: 'Defines the core value proposition of Serverless RL: abstracting
    away infrastructure management (servers, GPUs) for the user.'
  relevance_score: 9
  source: llm_enhanced
  text: Basically, what it is is it's a way. So when you're running RL, you don't
    have to manage any of the backend, any of the infrastructure, any of the servers,
    GPUs.
  topic: technical
- impact_reason: 'Summarizes the three key benefits of the serverless approach: speed,
    cost reduction, and reduced operational overhead.'
  relevance_score: 9
  source: llm_enhanced
  text: The upshot is you end up with faster runs, you end up with cheaper runs, you
    end up not having to provision GPUs.
  topic: business
- impact_reason: 'Clearly separates the two essential phases of RL: the inference/rollout
    phase and the training/update phase, emphasizing the necessary back-and-forth
    iteration.'
  relevance_score: 9
  source: llm_enhanced
  text: So you can see there's kind of two phases here. There's the part where you're
    actually using your model... And then there's the second part where you're training
    those trajectories we call them from your model like the agent run and the scores
    we gave it or rewards, which is what we call it to update the model weights.
  topic: technical
- impact_reason: 'Exposes the technical friction in traditional RL setups: the need
    to switch between specialized inference stacks (like SGLang) and specialized training
    stacks (like FSDP/Megatron), leading to inefficiency.'
  relevance_score: 9
  source: llm_enhanced
  text: For many standard RL practice on one machine, you have to remove the weight,
    upload them for inference and down the training loop and then do some stuff. Yeah,
    it's using like the LLM or SGLang or something like that. And then for training,
    you're using Megatron or FSDP, but they're kind of like different tools.
  topic: technical
- impact_reason: Details a specific, modern MLOps stack integration (W&B for training/standards,
    Weave for multi-step agent tracing/evaluation), showing how different tools fit
    into the RL lifecycle.
  relevance_score: 9
  source: llm_enhanced
  text: W&B models is still used for training. Some of the stuff, so like in the early
    inference, we would see this in the W&B interface standards, and the rollouts
    will be tracked with Weave, which is specifically built for seeing exactly how
    an agent behaves in multiple steps, et cetera, and tracking, et cetera.
  topic: strategy
- impact_reason: Promotes an open-source tool (Art) designed specifically to lower
    the barrier to entry for RL by embedding necessary heuristics, addressing the
    complexity barrier.
  relevance_score: 9
  source: llm_enhanced
  text: Art, you can just search OpenPipe Art, it'll come up. Yeah, it's a very popular
    library for running reinforcement learning. It does work with the serverless back
    end... It just makes RL way easier to use, right? This stuff is authentic. There's
    a lot to get right, and we have a bunch of heuristics that make it so it's easier
    for practitioners...
  topic: technical
- impact_reason: Announces a specialized model release (Qwen 3 14B) explicitly designed
    *not* to perform complex reasoning, suggesting that simpler, more predictable
    models are sometimes superior for specific RL training/evaluation tasks.
  relevance_score: 9
  source: llm_enhanced
  text: this week, we also released a new model, Qwen 3 14B from OpenPipe. This is
    a fine-tune for Qwen 3 that does not do the thinking, which is helpful for RL
    and fine-tuning purposes specifically.
  topic: technical
- impact_reason: 'Provides a tangible benchmark for the progress of LLMs: comparing
    the effort of months of human development (cloning an iPad) against the potential
    of a ''one-shot'' AI generation.'
  relevance_score: 8
  source: llm_enhanced
  text: And this one guy keeps posting one-shot full operating system builds out.
    So on the web, they built the iOS one and Windows and Mac and whatever. And yeah,
    that does look impressive. I saw the iOS one. I have built one a long time ago
    when I was a world developer. I built a clone of iPad and it took me like three
    months. So I really feel it if this is going to be one-shot.
  topic: Technical/Productivity
- impact_reason: Shows the continued focus on specialized, lower-power hardware optimized
    for efficient inference (4-bit quantization), crucial for edge or localized deployment.
  relevance_score: 8
  source: llm_enhanced
  text: Nvidia released this device, which on its own, it is actually pretty impressive.
    Like it's a low-power device with 128 gigs of RAM, and it is optimized for four-bit
    inference. It's the DGX Station.
  topic: Hardware/Technical
- impact_reason: Indicates Apple's commitment to on-device AI acceleration with significant
    performance gains expected in their next generation of silicon.
  relevance_score: 8
  source: llm_enhanced
  text: Apple also announced a new thing in hardware while we're in hardware, M5 chip,
    and 5, not M5 Pro, not M5 Ultra or Max, whatever. And 5.4 supposedly is like two
    times better for AI performance, but they didn't show any specific AI things.
  topic: Hardware/Technical
- impact_reason: A realistic assessment from a practitioner that despite impressive
    progress, current state-of-the-art video models still lack a critical, unspecified
    element needed for true photorealism or coherence.
  relevance_score: 8
  source: llm_enhanced
  text: I will definitely talk about this because I've tried both [Sora Pro and Lumiere],
    and both are lacking the thing that we want. We're not quite there yet, but it's
    great.
  topic: Limitations/Product
- impact_reason: Presents a novel, potentially sustainable business model (ad-supported
    free tier) for AI agent services, contrasting with subscription-only models.
  relevance_score: 8
  source: llm_enhanced
  text: AMP have launched a free tier. This free tier is powered by ads. This is a
    definitely new and interesting entry in the world of AI agents coding.
  topic: Business/Strategy
- impact_reason: Highlights the crucial role of the open-source community in adapting
    base models for practical use cases (like instruction tuning) when official releases
    are incomplete or overly constrained.
  relevance_score: 8
  source: llm_enhanced
  text: OpenPipe fine-tune of Qwen 3 14B. It's an instruct version, fine-tune friendly
    instruct version of Qwen 3 14B because the main release did not include an instruct
    non-thinking model. So the OpenPipe folks made it into a non-thinking model. Great
    for fine-tuning.
  topic: Open Source/Technical
- impact_reason: Signals a new business model (ad-supported free tier) entering the
    competitive space of AI coding agents, potentially lowering the barrier to entry.
  relevance_score: 8
  source: llm_enhanced
  text: AMP have launched a free tier. And this free tier is powered by ads. This
    is a definitely new and interesting entry in the world of AI agents coding.
  topic: business/AI agents
- impact_reason: Praises the rigorous and extensive benchmarking methodology of the
    Qwen team, setting a high standard for model evaluation, especially for multimodal
    models.
  relevance_score: 8
  source: llm_enhanced
  text: I don't know of many other labs that do as many tests on their models and
    other models for comparison. Because they have stuff like, and this is a visual
    model. So they have general understanding, but also like a lot of visual stuff.
  topic: strategy/evaluation
- impact_reason: Shows that the product strategy is heavily focused on user control
    and creative agency, not just raw generation quality.
  relevance_score: 8
  source: llm_enhanced
  text: And then of course, what is most exciting for me is bringing a lot of new
    creative control through capabilities.
  topic: business/strategy
- impact_reason: Reiterates that audio integration and improved prompt adherence are
    cross-cutting improvements affecting multiple features (like First/Last Frame).
  relevance_score: 8
  source: llm_enhanced
  text: The key upgrade here, again, is that we're bringing audio to those transitions.
    And also the better prompt adherence is also impacting all of these capabilities.
  topic: technical
- impact_reason: Highlights a creative application combining different generative
    models (NanoBanana for explosion effect, Vio for interpolation) in video generation,
    showcasing multi-model workflows.
  relevance_score: 8
  source: llm_enhanced
  text: One of the things that works really well with this is taking an object and
    then using NanoBanana to have an explosive version of this object with the pieces
    playing everywhere. And then Vio interpolates this, or the key a box of explosions
    that was hype for a while there.
  topic: technical/product application
- impact_reason: 'Clarifies the technical approach of RTFM: it''s a learned 2D renderer
    streaming pixels on the fly from input images, contrasting it with models that
    pre-generate a full 3D world.'
  relevance_score: 8
  source: llm_enhanced
  text: This is similar to the Cart and some other folks where you stream pixels and
    they're generated on the fly all the time. And so instead, it takes over one or
    more to the images. It didn't put directly generates a new 2D image of the same
    scene from different points of view. And it's a basically a renderer, a learned
    renderer.
  topic: technical/model architecture
- impact_reason: Key update on Sora's capabilities, increasing maximum generation
    length significantly (up to 25s for Pro), which directly impacts creative potential.
  relevance_score: 8
  source: llm_enhanced
  text: Sora also had a number, a fairly significant update as well. So here's the
    update from Sora. Everybody can now generate up to 15 seconds, up from the default
    8 or 10 seconds. For Sora Pro though, they've extended the video generation up
    to 25 seconds.
  topic: AI technology trends
- impact_reason: 'Clear business recommendation: Hiku 4.5 is positioned as a direct,
    superior replacement for existing production models, easing adoption.'
  relevance_score: 8
  source: llm_enhanced
  text: This is a drop-in replacement for Hiku 3.5 and Sonnet 4 on major use cases.
  topic: business advice
- impact_reason: 'Quantifies the value proposition: 3x cheaper and fast, but explicitly
    notes sacrifices in multimodal capabilities. This highlights the trade-offs inherent
    in optimizing for speed/cost.'
  relevance_score: 8
  source: llm_enhanced
  text: Hiku 4.5 drop-in replacement, three times as cheap, compares to other fast,
    quick models. So you fast, not great if you use multimodal. So they do have sacrifices.
  topic: business/technical
- impact_reason: Provides a clear analogy for the previous state of AI restrictions,
    framing the change as treating adults as adults rather than imposing universal
    PG-13 limitations.
  relevance_score: 8
  source: llm_enhanced
  text: The equivalent of ChatGPT right now assumes that everybody that watches the
    movie is PG-13 restricted. And so even the adults in the room are only limited
    to interacting with PG-13 type chats.
  topic: strategy/policy
- impact_reason: Shows institutional recognition of AI's role in mental health support
    and the associated risks, backed by high-level academic involvement.
  relevance_score: 8
  source: llm_enhanced
  text: They announce an 8-member expert council on well-being and AI, including top
    researchers from Harvard, Stanford, Oxford, to talk about mental health risks
    in talking to these models. Because people use ChatGPT as their emotional support
    help.
  topic: safety/ethics
- impact_reason: 'Summarizes the philosophical shift in control: user agency through
    opt-in mechanisms is preferred over default restrictions (opt-out).'
  relevance_score: 8
  source: llm_enhanced
  text: Opting in versus opting out, I think is a very, very important distinction.
  topic: strategy
- impact_reason: Provides a concrete, personal anecdote demonstrating the potential
    of fully autonomous agentic workflows (ordering food), moving beyond simple task
    completion.
  relevance_score: 8
  source: llm_enhanced
  text: I tried to order some food with Command yesterday and then I decided to completely
    rely on this and then only ask it to like, let me know when I need to like hit
    send. The agent listens, and then yeah, this week I ate a meal that was fully
    ordered and decided for me by the AI.
  topic: practical lessons
- impact_reason: Predicts that OS-level AI integration is inevitable because it targets
    the largest user base, forcing competitors (like Apple) to follow suit.
  relevance_score: 8
  source: llm_enhanced
  text: The majority of the people, that's what they're going to use. Like more than
    two-thirds of everybody. So people is preparing that for sure because they just
    released their computer use model, and Apple will have to do something like that
    as well.
  topic: predictions/strategy
- impact_reason: Emphasizes the importance of OS-level AI integration being contained
    within a secure sandbox, addressing potential security and privacy concerns inherent
    in deep system integration.
  relevance_score: 8
  source: llm_enhanced
  text: this is OS level and a secure sandbox environment on an OS level. I think
    it's very important.
  topic: safety
- impact_reason: 'Identifies the primary valid use case for traditional SFT: model
    compression for latency-sensitive applications like real-time voice.'
  relevance_score: 8
  source: llm_enhanced
  text: mostly made sense if you had to move to a smaller model anyway, typically
    for latency reasons.
  topic: technical
- impact_reason: 'Explains the economic driver behind the decline in SFT: the falling
    cost of high-end models negated the primary financial incentive for distillation/fine-tuning.'
  relevance_score: 8
  source: llm_enhanced
  text: the price point on frontier models dropped by several orders of magnitude
    over the course of about a year. And a big part of the reason why people did do
    fine-tuning was in order to deal with, you know, not have to spend those frontier
    model very expensive tokens.
  topic: business
- impact_reason: Highlights RL's ability to foster emergent, creative problem-solving
    strategies that are not explicitly present in the initial training corpus.
  relevance_score: 8
  source: llm_enhanced
  text: And so it can learn really creative things that were potentially things that
    weren't even in the training data. It can learn to use those techniques effectively.
  topic: technical
- impact_reason: Offers a specific, timely recommendation for the leading open-source
    model family (Qwen 3) for fine-tuning as of the hypothetical date, reflecting
    current ecosystem trends.
  relevance_score: 8
  source: llm_enhanced
  text: currently in October 16, 2025, which is the best open model to use for fine-tuning?
    Yeah, I mean, I think the one that there's the most kind of ecosystem familiarity
    with is the Qwen 3 family.
  topic: technical
- impact_reason: 'Articulates the primary historical trade-off concern when using
    LoRAs: potential performance degradation compared to full fine-tuning.'
  relevance_score: 8
  source: llm_enhanced
  text: The big criticism or complaint people have about LoRAs traditionally is that
    since you're only adjusting a very small number of weights, that you may not get
    the same performance from your model or the ability to push it as far as you could
    if you were just training all the weights in the model.
  topic: technical
- impact_reason: Validates the robustness of the automated reward function tool (Ruler)
    through internal and customer testing before open-sourcing, lending credibility.
  relevance_score: 8
  source: llm_enhanced
  text: We try to have a bunch of different tasks internally and on customer tasks,
    it works really well. So that's why we released it, and that's fully open source.
  topic: safety/ethics
- impact_reason: Highlights the industry trend toward optimizing models for speed
    and cost efficiency (inference optimization), which is crucial for widespread
    adoption.
  relevance_score: 7
  source: llm_enhanced
  text: Cloud Hiku 4.5 was released. Share to enter it. Let's go. We love the cloud
    family. The biggest brother, the middle brother, son of everybody loves 4.5, and
    the Hiku 4.5 is a fast, cheap model. I think it's like twice as fast as the previous
    one.
  topic: Business/Technical
- impact_reason: A key technical improvement for user experience, reducing the need
    for users to manually manage context or repeat instructions over long conversations.
  relevance_score: 7
  source: llm_enhanced
  text: They also updated memory management, automatic memory management is in ChatGPT...
  topic: Technical
- impact_reason: Expert commentary validating the architectural decision (per-core
    accelerators) for future AI performance, suggesting advertised gains might be
    conservative.
  relevance_score: 7
  source: llm_enhanced
  text: George Hotz commented on it, is that I've put an accelerator inside each of
    the cores. And this first came out on the A17 chip, but that's a very good design.
    And I'm being a lot faster even that. I think it might be a lot faster even than
    what they're advertising there.
  topic: Technical/Hardware
- impact_reason: Shows the competitive race in video generation, with features like
    storyboarding emerging as key differentiators for controlling long-form generation.
  relevance_score: 7
  source: llm_enhanced
  text: I have updated Sora Pro to give you up to 25-second generation with their
    new storyboards feature. It's very similar to how the storyboard works in Lumiere
    from Google.
  topic: Technical/Product
- impact_reason: Indicates a new leader emerging in the specialized field of image
    editing/inpainting/outpainting models, showing rapid churn at the top of niche
    AI tasks.
  relevance_score: 7
  source: llm_enhanced
  text: There's a new top-one image editing model, like NanoBanana and C-Dream. It's
    called RiverFlow-1 from Sourceful, and it's stopping the artificial analysis.
    So rank over NanoBanana and C-Dream and etc.
  topic: Technical/Breakthroughs
- impact_reason: Highlights the current paradox of powerful, yet often inaccessible,
    cutting-edge AI models, even for industry insiders.
  relevance_score: 7
  source: llm_enhanced
  text: I wasn't able to register. So it's very interesting that we have these models
    now that even I can't get access to.
  topic: strategy/access
- impact_reason: Confirms the current industry focus and high activity level in the
    Vision and Video generation/understanding space.
  relevance_score: 7
  source: llm_enhanced
  text: We're moving on to Vision and Video, which is very, very hot for this week.
  topic: AI technology trends
- impact_reason: Clarifies the current state of audio integration in 'Ingredients
    to Video'it's an output feature, not yet an input conditioning factor for composition.
  relevance_score: 7
  source: llm_enhanced
  text: So to be clear, we're not using audio as a conditioning, but the output will
    have audio integrated.
  topic: technical
- impact_reason: A candid assessment that while the audio quality is 'good enough'
    and competitive, it might still be overshadowed by specialized audio models (like
    Sora's audio component mentioned later in context).
  relevance_score: 7
  source: llm_enhanced
  text: The audio's good enough. It's good. It's good. I've now have so many options
    to upload multip
  topic: technical/limitations
- impact_reason: Provides specific details on the limitations (default 8 seconds)
    and improvements in video generation length extension for a model (likely Vio,
    given context).
  relevance_score: 7
  source: llm_enhanced
  text: I think we could extend, but the default length generation is still the same
    eight seconds. Yeah, that is correct. Yeah, so eight seconds, but then extension,
    I think works way better.
  topic: technical/limitations
- impact_reason: Provides a technical descriptor of the underlying architecture used
    by World Labs (Diffusion Transformer trained end-to-end), linking it to modern
    generative techniques.
  relevance_score: 7
  source: llm_enhanced
  text: Outer aggressive diffusion transformer, diffusion transformer did train end-to-end
    on large scale video data.
  topic: technical
- impact_reason: Anecdote highlighting the photorealism and persuasive power of generative
    media, blurring the lines between real marketing and AI-generated content.
  relevance_score: 7
  source: llm_enhanced
  text: I didn't even this overflow from Vegas where I put myself on. And the Thursday
    I had, and I said, I took out a little ad. And people commented on this as those.
    This is real. I was like, folks, we don't have that kind of budget on Thursday
    yet to take out the globe in Vegas yet. We're gonna get there.
  topic: safety/societal impact
- impact_reason: 'Identifies the core motivation behind the verification/parental
    control efforts: protecting minors from potentially harmful AI interactions.'
  relevance_score: 7
  source: llm_enhanced
  text: OpenAI is definitely going towards, let's make sure that teenagers are not
    getting one-shot by AI with some safety controls.
  topic: safety/regulation
- impact_reason: Highlights the significant historical profitability of companion/adult-oriented
    AI (like Replika), suggesting commercial incentives drive the relaxation of restrictions.
  relevance_score: 7
  source: llm_enhanced
  text: I think as last year or two years ago, the company that was making the most
    money in AI, I think was Replika. So this was the most profit-generating side
    of the project.
  topic: business
- impact_reason: Poses the key question regarding the adoption and utility of deeply
    integrated, system-level AI agents.
  relevance_score: 7
  source: llm_enhanced
  text: Will people use agentic use on an OS level and what are the benefits? We'll
    be waiting for this because I'm a Windows user.
  topic: business/predictions
- impact_reason: Provides a current (as of the recording) recommendation for the best
    open-source model family for fine-tuning based on ecosystem maturity.
  relevance_score: 7
  source: llm_enhanced
  text: the one that there's the most kind of ecosystem familiarity with is the Qwen
    3 family. That's where it's sort of like the standard and kind of the academic
    just like, yeah, kind of like a well ecosystem.
  topic: technical
- impact_reason: A statement of product philosophy emphasizing problem-solving over
    feature-building, which is crucial for enterprise adoption.
  relevance_score: 7
  source: llm_enhanced
  text: at OpenPipe, we don't want to launch something just because we can. Like we
    want to launch something because it's actually solving a real problem. I feel
    very deeply about that.
  topic: business
- impact_reason: Highlights the rapid pace of integration and productization following
    the W&B acquisition, showcasing agility in bringing complex ML infrastructure
    (Serverless RL) to market.
  relevance_score: 7
  source: llm_enhanced
  text: It took us around a month from the point that you integrated into Corbit to
    actually launch this. Talk to us and walk us through serverless RL.
  topic: business
- impact_reason: Highlights the extreme velocity achievable in modern infrastructure
    integration when teams are aligned, serving as a benchmark for expected development
    speed.
  relevance_score: 7
  source: llm_enhanced
  text: The speed with which you guys implemented this once you came into Corbit was
    incredible, like less than a month, I think, till the final rollout while onboarding
    or doing so, like tons of stuff.
  topic: business
- impact_reason: Signals progress in multilingual and regional model development outside
    of the dominant English-centric ecosystem.
  relevance_score: 6
  source: llm_enhanced
  text: We have a new bilingual model from KIST, the Korean Institute of Technology,
    and it is bilingual Korean-English, 18-parameter model called Chromo, with a nice
    paper as well.
  topic: Technical
- impact_reason: A positive example of rapid iteration and responsiveness from a major
    AI lab based on user feedback regarding product quality and usability.
  relevance_score: 6
  source: llm_enhanced
  text: Shout out to OpenAI for that [fixing advanced voice mode repeating custom
    instructions]. And so I tried that, so I spoke and I like it again. So if you
    were avoiding that's one small because it was annoying you, they fixed it.
  topic: Practical Lessons/Product
- impact_reason: Illustrates a practical, real-world barrier (geopolitical/registration
    hurdles) preventing global researchers/evangelists from testing cutting-edge models
    released in specific regions (like Baidu's News Streamer).
  relevance_score: 6
  source: llm_enhanced
  text: I feel like I'm restricted from the world away by not having a Chinese phone
    number. So I can't register to Baidu to reach it, like all these things. I think
    it has a hookup for me, would love to, because I need to test out all the things.
  topic: Strategy/Access
- impact_reason: Points to the expansion of generative AI into specialized spatial
    domains (360-degree environments), important for VR/AR and simulation.
  relevance_score: 6
  source: llm_enhanced
  text: Did 360 is a state of the panoramic image generation. Like regularly imagination,
    it generates panoramic 360 images. So that's super cool.
  topic: Technical
- impact_reason: Offers a comparative assessment of Sora's audio capabilities against
    specialized audio models, suggesting it's 'good enough' but perhaps not market-leading.
  relevance_score: 6
  source: llm_enhanced
  text: The audio Sora just kind of has blown away the audio, the event market, but
    it's not like it's bad. The audio's good enough. It's good. It's good.
  topic: predictions/comparison
- impact_reason: Illustrates high user engagement and the kind of complex, imaginative
    scenarios users are attempting to create, pushing the boundaries of the model.
  relevance_score: 6
  source: llm_enhanced
  text: I've been sometimes even hitting my 30 video a day limit. A video I generated
    yesterday, for example, was a she-but-you-new in a fighter jet getting pulled
    over by the police on the highway, and then it takes off using the highway to
    take off as a runway.
  topic: product usage/business
- impact_reason: A minor correction/self-correction regarding a venture name, indicating
    a focus on tracking new investment or company entities in the AI space.
  relevance_score: 4
  source: llm_enhanced
  text: I started the Eric P Ventures. The Riva P Ventures? The Riva P Ventures.
  topic: business
source: Unknown Source
summary: '## ThursdAI Podcast Summary: VEO3.1, Haiku 4.5, ChatGPT Adult Mode, and
  Scientific Breakthroughs (Oct 16)


  This episode of ThursdAI covered a dense week of major announcements across open-source
  models, large commercial LLM updates, significant hardware developments, and a groundbreaking
  application of AI in scientific discovery. The overarching theme was the rapid maturation
  of AI capabilities, particularly in multimodal generation and specialized scientific
  reasoning.


  ---


  ### 1. Focus Area

  The discussion centered primarily on **Artificial Intelligence and Machine Learning**,
  with deep dives into:

  *   **Large Language Models (LLMs) & APIs:** Updates from Anthropic (Haiku 4.5),
  OpenAI (Adult Mode, Memory Management), and Microsoft (Windows 11 Copilot).

  *   **Video Generation:** The release of Google DeepMind''s **VEO 3.1** and updates
  to competitors like Sora Pro.

  *   **Open Source Models:** New releases from Qwen (smaller VL models) and a major
  scientific breakthrough using Google''s **C2S Scale 27B** model.

  *   **Hardware:** Announcements regarding NVIDIA DGX Spark and Apple''s M5 chip.

  *   **AI Agents & Coding:** The launch of a free, ad-supported tier by AMP.


  ### 2. Key Technical Insights

  *   **C2S Scale''s Scientific Emergence:** Google''s 27B Gemma-based model achieved
  a **novel scientific discovery** regarding cancer cell behavior by treating scRNA
  sequence profiles as a "language." This was attributed to an **emergent capability
  of scale**, utilizing over a billion tokens of biological data processed through
  SFT and RL stages.

  *   **Qwen 3 VL Performance Leap:** The new smaller Qwen 3 Vision-Language models
  (4B and 8B) demonstrated performance matching or exceeding previous large models
  (like Qwen 2.5 72B) on several benchmarks. Notably, the 8B model achieved a **33.9
  score on OS World**, significantly outperforming the 72B predecessor (8%) and rivaling
  larger models for on-device agent tasks.

  *   **VEO 3.1 Enhancements:** The new video model focuses on **cinematic updates
  and improved control**, suggesting a move toward professional-grade video creation
  tools, alongside competitors pushing generation times past 20 seconds (Baidu''s
  News Streamer).


  ### 3. Business/Investment Angle

  *   **OpenAI''s Content Policy Shift:** The planned introduction of "adult mode"
  signals OpenAI''s strategy to capture a broader user base by relaxing overly restrictive
  guardrails, potentially impacting market share against competitors who already offer
  more flexibility.

  *   **AI in Drug Discovery:** The C2S Scale breakthrough validates the massive commercial
  potential of applying LLMs to complex biological data, suggesting a future where
  AI accelerates drug discovery through high-throughput virtual screening and hypothesis
  generation.

  *   **Hardware Competition Intensifies:** NVIDIA''s DGX Spark targets low-power,
  high-density inference, while Apple''s M5 chip emphasizes significant on-device
  AI acceleration, indicating a bifurcation in hardware strategy between cloud-scale
  training/inference and edge/personal device efficiency.


  ### 4. Notable Companies/People

  *   **Google DeepMind:** Highlighted for the VEO 3.1 video model (interview with
  Jessica Gallagos) and the revolutionary **C2S Scale 27B** model.

  *   **OpenAI/Sam Altman:** Mentioned for the planned release of "adult mode" and
  updates to ChatGPT''s memory management.

  *   **Anthropic:** Released **Haiku 4.5**, noted as being twice as fast as its predecessor.

  *   **Qwen Team:** Praised for the extensive testing and release of smaller, high-performing
  VL models.

  *   **Cognition:** Mentioned for the breaking news release of **SweetGrap** (discussed
  with Svik).


  ### 5. Future Implications

  The conversation strongly suggests the industry is moving toward:

  1.  **Specialized, High-Impact AI:** Models trained specifically on domain-specific
  "languages" (like biological sequences) can yield profound, emergent scientific
  insights, moving beyond general-purpose reasoning.

  2.  **Ubiquitous OS Integration:** Microsoft embedding Copilot directly into Windows
  11 signals a future where operating systems are primarily controlled via natural
  language commands.

  3.  **Increased Model Accessibility:** The release of powerful models like C2S Scale
  (27B) and smaller Qwen VL models means cutting-edge performance is becoming accessible
  for local deployment and specialized fine-tuning.


  ### 6. Target Audience

  This episode is highly valuable for **AI/ML Engineers, AI Researchers, Product Managers
  in Tech, and Technology Investors** who need a rapid, comprehensive overview of
  the latest model releases, technical breakthroughs, and strategic shifts across
  the AI ecosystem.'
tags:
- artificial-intelligence
- ai-infrastructure
- generative-ai
- startup
- investment
- openai
- google
- microsoft
title:  ThursdAI - Oct 16 - VEO3.1, Haiku 4.5, ChatGPT adult mode, Claude Skills,
  NVIDIA DGX spark, Wordlabs RTFM & more AI news
topics:
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 174
  prominence: 1.0
  topic: artificial intelligence
- keywords:
  - gpu
  - tensor
  - training
  - inference
  - model deployment
  - vector database
  mentions: 52
  prominence: 1.0
  topic: ai infrastructure
- keywords:
  - generative ai
  - genai
  - chatgpt
  - gpt
  - claude
  - text generation
  - image generation
  mentions: 27
  prominence: 1.0
  topic: generative ai
- keywords:
  - startup
  - entrepreneur
  - founder
  - venture
  mentions: 5
  prominence: 0.5
  topic: startup
- keywords:
  - investment
  - funding
  - valuation
  - ipo
  - acquisition
  mentions: 2
  prominence: 0.2
  topic: investment
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-10-17 11:16:48 UTC -->
