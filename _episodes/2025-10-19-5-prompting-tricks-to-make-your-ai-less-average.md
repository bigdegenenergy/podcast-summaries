---
companies:
- category: unknown
  confidence: medium
  context: Today on the AI Daily Brief, how to make your LLM not average. The AI Daily
    B
  name: AI Daily Brief
  position: 13
- category: unknown
  confidence: medium
  context: AI Daily Brief, how to make your LLM not average. The AI Daily Brief is
    a daily podcast and video about the most impor
  name: The AI Daily Brief
  position: 63
- category: unknown
  confidence: medium
  context: in. First of all, thank you to today's sponsors, Super Intelligent, Robots
    and Pencils, Notion, and Blitzy, to get a
  name: Super Intelligent
  position: 257
- category: tech
  confidence: high
  context: sponsors, Super Intelligent, Robots and Pencils, Notion, and Blitzy, to
    get an ad-free version of the sho
  name: Notion
  position: 296
- category: unknown
  confidence: medium
  context: ings/long reads episode is that technology writer Alex Cantrowitz actually
    dropped a quick essay on his blog, bigte
  name: Alex Cantrowitz
  position: 1660
- category: tech
  confidence: high
  context: 'is called the AI sameness problem, and it reads: OpenAI''s video generation
    app Sora sits atop the app sto'
  name: Openai
  position: 2256
- category: unknown
  confidence: medium
  context: ore charts, but I anticipate it'll fall off soon. Creating Sora videos
    is a genuine but momentary thrill. You can
  name: Creating Sora
  position: 2361
- category: unknown
  confidence: medium
  context: 'ilarious, scary, or fantastical scenarios and add Jake Paul or Mark Cuban
    where appropriate. Editor''s note: o'
  name: Jake Paul
  position: 2509
- category: unknown
  confidence: medium
  context: 'ry, or fantastical scenarios and add Jake Paul or Mark Cuban where appropriate.
    Editor''s note: or where highly'
  name: Mark Cuban
  position: 2522
- category: unknown
  confidence: medium
  context: it's present in almost all AI-generated content. Generative AI tends to
    produce the average of averages, seeking
  name: Generative AI
  position: 2869
- category: unknown
  confidence: medium
  context: its output and the mean of human-generated work. So AI images, video, and
    text often exhibit a uniformit
  name: So AI
  position: 3012
- category: tech
  confidence: high
  context: broken. It's why Instagram co-founder and current Anthropic Chief Product
    Officer Mike Krieger didn't appear
  name: Anthropic
  position: 3406
- category: unknown
  confidence: medium
  context: broken. It's why Instagram co-founder and current Anthropic Chief Product
    Officer Mike Krieger didn't appear to think Sora is the successor to t
  name: Anthropic Chief Product Officer Mike Krieger
  position: 3406
- category: unknown
  confidence: medium
  context: ness problem reappears. This is the case with the Studio Ghibli moment
    that OpenAI's 4.0 model kicked off. After
  name: Studio Ghibli
  position: 4249
- category: unknown
  confidence: medium
  context: nt to minimize how impressive this technology is. The Sora videos are a
    breakthrough, demonstrating AI has s
  name: The Sora
  position: 4915
- category: unknown
  confidence: medium
  context: r example, have you asked an LLM something like, "Should I do this or should
    I do that?" And instead of pick
  name: Should I
  position: 8345
- category: unknown
  confidence: medium
  context: alue. And their partnerships don't end at launch. As AI changes, Robots
    and Pencils stays by your side so
  name: As AI
  position: 11410
- category: unknown
  confidence: medium
  context: livery centers across the US, Canada, Europe, and Latin America, clients
    get local expertise and global scale. Fo
  name: Latin America
  position: 11623
- category: unknown
  confidence: medium
  context: ca, clients get local expertise and global scale. For AI that delivers
    progress, not promises, visit robot
  name: For AI
  position: 11684
- category: unknown
  confidence: medium
  context: ry own super user to help you onboard in minutes. Your AI teammates are
    ready to work. Try Notion AI for fr
  name: Your AI
  position: 12601
- category: unknown
  confidence: medium
  context: 'in minutes. Your AI teammates are ready to work. Try Notion AI for free
    at the link in our show notes.


    This epi'
  name: Try Notion AI
  position: 12638
- category: unknown
  confidence: medium
  context: form, bringing in their development requirements. The Blitzy platform provides
    a plan that generates and pre-c
  name: The Blitzy
  position: 13093
- category: unknown
  confidence: medium
  context: crease on a real development project in your org. Visit Blitzy.com and
    press "Book Demo" to learn how Blitzy tra
  name: Visit Blitzy
  position: 13738
- category: unknown
  confidence: medium
  context: project in your org. Visit Blitzy.com and press "Book Demo" to learn how
    Blitzy transforms your SDLC from AI
  name: Book Demo
  position: 13766
- category: unknown
  confidence: medium
  context: approaches that these different models represent. Something I did yesterday
    is I was architecting a whole new p
  name: Something I
  position: 16527
- category: ai_application
  confidence: high
  context: Sponsor of the podcast; company that maps AI use cases and helps create
    executable agent plans.
  name: Super Intelligent
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Sponsor of the podcast; works with organizations to implement AI, modernizes
    infrastructure, and applies AI to create business value. AWS certified partner.
  name: Robots and Pencils
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Sponsor of the podcast; mentioned for its new AI agents that complete entire
    workflows and act as purpose-built Notion super users.
  name: Notion
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Sponsor of the podcast; an enterprise autonomous software development platform
    using specialized AI agents to generate and pre-compile code.
  name: Blitzy
  source: llm_enhanced
- category: ai_company
  confidence: high
  context: Mentioned regarding their video generation app Sora and the GPT-4.0 model,
    specifically referencing the 'Studio Ghibli moment' trend.
  name: OpenAI
  source: llm_enhanced
- category: ai_company
  confidence: high
  context: Mentioned because Mike Krieger, the current Chief Product Officer, is associated
    with the company.
  name: Anthropic
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as the primary example of popular and helpful AI text generation.
  name: ChatGPT
  source: llm_enhanced
- category: ai_model_or_service
  confidence: high
  context: Mentioned as a specific model used by the host for architectural work,
    contrasted with O3.
  name: GPT-5 thinking
  source: llm_enhanced
- category: ai_model_or_service
  confidence: high
  context: Mentioned as a specific OpenAI model that feels fundamentally different
    from GPT-5 thinking.
  name: O3
  source: llm_enhanced
- category: media_or_platform
  confidence: medium
  context: The blog/platform where technology writer Alex Cantrowitz published an
    essay on the 'AI sameness problem.' (While a publication, it hosts significant
    AI commentary/analysis.)
  name: bigtechnology.com
  source: llm_enhanced
- category: irrelevant_mention
  confidence: low
  context: Mentioned in the context of content that can be inserted into Sora videos,
    not an AI company itself, but relevant to AI application output.
  name: Jake Paul
  source: llm_enhanced
- category: irrelevant_mention
  confidence: low
  context: Mentioned in the context of content that can be inserted into Sora videos,
    not an AI company itself, but relevant to AI application output.
  name: Mark Cuban
  source: llm_enhanced
- category: irrelevant_mention
  confidence: low
  context: Mentioned as the platform co-founded by Mike Krieger, who is now at Anthropic.
  name: Instagram
  source: llm_enhanced
- category: ai_infrastructure
  confidence: medium
  context: Mentioned as Robots and Pencils is an 'AWS certified partner,' indicating
    infrastructure alignment.
  name: AWS
  source: llm_enhanced
- category: ai_model
  confidence: high
  context: Mentioned as another LLM the speaker could switch to, implying it is a
    competitor model to OpenAI's offerings.
  name: Gemini
  source: llm_enhanced
- category: ai_model
  confidence: high
  context: Mentioned as another LLM the speaker could switch to, implying it is a
    competitor model to OpenAI's offerings.
  name: Grok
  source: llm_enhanced
date: 2025-10-19 22:00:01 +0000
duration: 21
has_transcript: false
layout: episode
llm_enhanced: true
original_url: https://audio.listennotes.com/e/p/431853ff840f4ca4a9f3866806226ac3/
processing_date: 2025-10-20 01:11:09 +0000
quotes:
- length: 201
  relevance_score: 6
  text: And for this, we have to turn to some prompting strategies, five of which
    I'm going to share today, that I have found help me in the ways that I use LLMs
    to make them excel ahead of that average output
  topics: []
- length: 141
  relevance_score: 6
  text: Generative AI tends to produce the average of averages, seeking to minimize
    the delta between its output and the mean of human-generated work
  topics: []
- length: 213
  relevance_score: 6
  text: 'The last technique to get your LLM to be not average is an obvious one, a
    tried-and-true method: to the extent that you have an example of an output that
    you think is better than average, give the LLM that example'
  topics: []
- length: 195
  relevance_score: 5
  text: The simple notion here is that because AI has been trained across the entire
    corpus of everything that humans have output, almost by definition, it is optimized
    around average conventional wisdom
  topics: []
- length: 140
  relevance_score: 5
  text: The problem is that increasingly when it comes to production use cases and
    using AI for things that really matter, average isn't good enough
  topics: []
- length: 61
  relevance_score: 4
  text: Today on the AI Daily Brief, how to make your LLM not average
  topics: []
- length: 83
  relevance_score: 4
  text: What that does is that it ensures that the output of an LLM has a fairly high
    floor
  topics: []
- length: 187
  relevance_score: 4
  text: A lot of what gives us the feeling of AI and LLMs being in patterns is these
    common elements that come up way more in AI writing or AI output than they do
    in human output of the same type
  topics: []
- length: 120
  relevance_score: 4
  text: Another approach to breaking out of the averageness and sameness of standard
    AI outputs, we'll call the cliche burn down
  topics: []
- length: 81
  relevance_score: 4
  text: '" your output would instantly be significantly better than the generic LLM
    output'
  topics: []
- length: 99
  relevance_score: 3
  text: The AI Daily Brief is a daily podcast and video about the most important news
    and discussions in AI
  topics: []
- length: 286
  relevance_score: 3
  text: The whole idea, though, of unbounded, unlimited, and basically cost-free intelligence
    is that you can re-run a prompt over and over and over again, or for our purposes,
    you can run an actual process around it where the first output is just that, the
    first pass that then gets built upon
  topics: []
- length: 252
  relevance_score: 3
  text: Now, not everyone is an insane person like me with premium subscriptions to
    every single LLM, but even for those of you who are, for example, just using OpenAI
    models, there is a big breadth of different approaches that these different models
    represent
  topics: []
- length: 84
  relevance_score: 3
  text: Super Intelligent right now is growing 41% month over month when it comes
    to revenue
  topics:
  - revenue
- impact_reason: 'This introduces the central thesis of the episode: LLMs are inherently
    biased toward average output due to their training data, which is a critical concept
    for users aiming for high-quality, non-generic results.'
  relevance_score: 10
  source: llm_enhanced
  text: In my head, I've always called it AI's tyranny of the average.
  topic: AI limitations/Strategy
- impact_reason: A concise, powerful restatement of the core problem, framing it mathematically
    ('average of averages').
  relevance_score: 10
  source: llm_enhanced
  text: Generative AI tends to produce the average of averages, seeking to minimize
    the delta between its output and the mean of human-generated work.
  topic: AI limitations/Technical
- impact_reason: Perfectly describes the LLM's pathological tendency toward hedging
    and equivocation when faced with binary choices.
  relevance_score: 10
  source: llm_enhanced
  text: How many times, for example, have you asked an LLM something like, 'Should
    I do this or should I do that?' And instead of picking one and making an argument
    for it, instead, the LLM says, 'Well, if you value X, Y, or Z, you should do this,
    and if you value A, B, or C, you should do that.'
  topic: AI limitations/Technical
- impact_reason: Details a sophisticated two-step process (Steelman arguments, then
    commit) that leverages the LLM's reasoning power before forcing a decision, leading
    to better final choices.
  relevance_score: 10
  source: llm_enhanced
  text: I'll ask it to steelman the two or three arguments that we're discussing.
    In other words, make the strongest, most compelling argument it possibly can for
    that scenario or that option, and then after it has done that, after it has put
    itself in the position of having to make the best argument it possibly can for
    each of the different options, to then actually decide and commit to one.
  topic: Practical lessons/Technical
- impact_reason: A concise, powerful statement summarizing the shift from AI as an
    assistant (co-pilot) to AI as an executor (agent).
  relevance_score: 10
  source: llm_enhanced
  text: These agents don't just help with work; they finish it.
  topic: Predictions
- impact_reason: Provides the single most actionable, high-leverage prompt engineering
    tip for immediate quality improvement.
  relevance_score: 10
  source: llm_enhanced
  text: If you did nothing else on this list, except at the end of each first-pass
    output, say, 'What are the most commonly shaded this felt prey to, and how could
    you change it to avoid them?' your output would instantly be significantly better
    than the generic LLM output.
  topic: Technical/Strategy
- impact_reason: Provides a concrete, multi-stage prompt structure for implementing
    self-critique, combining generation, critique, revision, and justification.
  relevance_score: 10
  source: llm_enhanced
  text: In a single prompt, you could, for example, say, 'Draft a first version...
    then red team it and list the top five ways it's generic. Rewrite a V2 that fixes
    each issue, and then explain why you changed what you changed.'
  topic: Technical
- impact_reason: Provides a nuanced comparison between two distinct hypothetical model
    personalities/architectures (clinical/precise vs. strategic/fluid), illustrating
    that model choice must align with the desired output style.
  relevance_score: 10
  source: llm_enhanced
  text: O3 is much more clinical. It's much more likely to give you lists and charts
    and tables. There's a certain concession and precision of thought that O3 goes
    for that GPT-5 thinking doesn't have in the same way, which is not to say that
    O3 is better for all use cases.
  topic: Technical
- impact_reason: Demonstrates a sophisticated, cross-model critique workflow using
    context sharing (via links/history), maximizing the benefit of model heterogeneity
    within a single ecosystem.
  relevance_score: 10
  source: llm_enhanced
  text: I turned that whole thread into a link and shared it and flipped over to a
    new chat in the same app, toggled that new chat to the O3 model instead of the
    5-thinking model, asked it to review and basically make a set of critiques and
    changes, and argue for what it thought we—which is me and GPT-5 thinking together—were
    missing as part of the whole conversation.
  topic: Technical/Strategy
- impact_reason: 'Crucially upgrades few-shot prompting: don''t just show the example,
    explain the *deviation* from the norm that makes the example superior.'
  relevance_score: 10
  source: llm_enhanced
  text: However, the important thing that I think to add, which many people miss,
    is to actually take the time to explain why that example is better, and in particular,
    why the consensus or conventional wisdom that it floats is wrong or at least limited.
  topic: Technical/Strategy
- impact_reason: A powerful, real-world example of strategic deviation from generic
    advice based on unique business reality (high growth mandates front-loading key
    metrics).
  relevance_score: 10
  source: llm_enhanced
  text: Super Intelligent right now is growing 41% month over month when it comes
    to revenue. You better believe I'm not waiting till business slide 6 or whatever
    to show that. That is going on slide number one.
  topic: Business/Strategy
- impact_reason: 'Summarizes the core danger of relying on LLMs trained on aggregated
    web data: they produce ''correct'' but strategically suboptimal outputs that fail
    to account for unique, high-stakes context.'
  relevance_score: 10
  source: llm_enhanced
  text: This to me is a quintessential example of the LLM not doing anything wrong,
    but where its process of aggregating the collected and conventional wisdom of
    people who have built decks just makes for a generic product that is almost doomed
    to not do what the creator needs it to do.
  topic: Strategy/Safety (of output)
- impact_reason: This explains the technical root cause of the 'tyranny of the average'—training
    on the mean of human output.
  relevance_score: 9
  source: llm_enhanced
  text: The simple notion here is that because AI has been trained across the entire
    corpus of everything that humans have output, almost by definition, it is optimized
    around average conventional wisdom.
  topic: AI limitations/Technical
- impact_reason: Highlights the shift in user expectation from novelty/utility to
    high-stakes production use, where average output fails.
  relevance_score: 9
  source: llm_enhanced
  text: The problem is that increasingly when it comes to production use cases and
    using AI for things that really matter, average isn't good enough. We want more
    than average; we want unique, we want distinct, we want really high quality.
  topic: Business advice/Strategy
- impact_reason: Generalizes the observation from Sora (video) to all generative AI
    (images, text), emphasizing the universality of the issue.
  relevance_score: 9
  source: llm_enhanced
  text: Sora's sameness problem is an isolated one; it's present in almost all AI-generated
    content.
  topic: AI limitations/Predictions
- impact_reason: Uses a concrete historical example (Ghibli style prompting) to illustrate
    how popular styles quickly become saturated and then discarded due to uniformity.
  relevance_score: 9
  source: llm_enhanced
  text: This is the case with the Studio Ghibli moment that OpenAI's 4.0 model kicked
    off. After some initial novelty, everything eventually became Studio Ghibli, and
    then the excitement faded, and nobody Ghibli-fies their images anymore.
  topic: AI trends/Limitations
- impact_reason: Points to a significant, observable impact on professional communication,
    suggesting AI is homogenizing business language.
  relevance_score: 9
  source: llm_enhanced
  text: AI's sameness problem is perhaps most apparent in writing. Forget the em-dash;
    it seems like most business communication reads exactly the same these days since
    much of it was written via prompt.
  topic: AI impact/Business
- impact_reason: 'A cautionary prediction: overcoming the fundamental limitation of
    averaging might require architectural changes, not just better prompting.'
  relevance_score: 9
  source: llm_enhanced
  text: For AI-generated content to achieve its potential, it's going to have to increase
    its variety, and given the technology's fundamentals, that might be a tough problem
    to solve.
  topic: Predictions/AI limitations
- impact_reason: Provides a highly specific, humorous, and relatable example of an
    overused AI artifact ('telemetry') that instantly signals machine generation.
  relevance_score: 9
  source: llm_enhanced
  text: I literally don't go a day without ChatGPT using the word 'telemetry' at least
    two or three times in some strategic discussion or another, and I don't know that
    I've even once in my entire life heard an actual human being in the real world
    use the word 'telemetry.'
  topic: Practical lessons/AI limitations
- impact_reason: 'Connects the technical limitation (hedging) back to human nature
    (the necessity of commitment) and provides the solution: forcing commitment.'
  relevance_score: 9
  source: llm_enhanced
  text: Living life is about making choices in what you do and in what you communicate
    and write. And so something that I very frequently do is force the model to recognize
    that based on what we're discussing, there are divergent paths, and it needs to
    pick and argue for one.
  topic: Strategy/Practical lessons
- impact_reason: 'Prediction/Trend: Signals the shift from simple chatbots to workflow-completing
    AI agents that operate within existing user environments (like Notion).'
  relevance_score: 9
  source: llm_enhanced
  text: Chatbots are great, but they can only take you so far. I've recently been
    testing Notion's new AI agents, and they are a very different type of experience.
    These are agents that actually complete entire workflows for you in your style.
  topic: AI technology trends/Predictions
- impact_reason: 'Technical insight: Describes a novel approach to context handling
    in enterprise software development using thousands of specialized agents and long
    thinking times (''infinite context'').'
  relevance_score: 9
  source: llm_enhanced
  text: Blitzy uses thousands of specialized AI agents that think for hours to understand
    enterprise-scale code bases with millions of lines of code.
  topic: Technical insights/Model architectures
- impact_reason: 'Business/Productivity insight: Quantifies the potential automation
    level (80% autonomous) for complex engineering tasks, defining the new human role
    as the final 20% guide.'
  relevance_score: 9
  source: llm_enhanced
  text: Blitzy delivers 80%+ of the development work autonomously while providing
    a guide for the final 20% of human development work required to complete the sprint.
  topic: AI impact/Business
- impact_reason: 'Defines the core mechanism of the ''cliche burn down'' technique:
    forcing the model to recognize its own internalized patterns so they can be consciously
    overridden.'
  relevance_score: 9
  source: llm_enhanced
  text: The idea here is to make the model expose and then replace the template it
    wants to use.
  topic: Technical
- impact_reason: This is the philosophical underpinning for improving generic LLM
    output—meta-awareness of pattern recognition leads to higher quality output.
  relevance_score: 9
  source: llm_enhanced
  text: Basically, the thing to recognize here is that there is a lot of value in
    getting the AI to identify the patterns that it's building off of so that it can
    then more conscientiously avoid those patterns.
  topic: Technical/Strategy
- impact_reason: Emphasizes the economic shift enabled by LLMs (near-zero marginal
    cost for computation) which justifies iterative, multi-step prompting workflows
    (self-critique).
  relevance_score: 9
  source: llm_enhanced
  text: The whole idea, though, of unbounded, unlimited, and basically cost-free intelligence
    is that you can re-run a prompt over and over and over again, or for our purposes,
    you can run an actual process around it where the first output is just that, the
    first pass that then gets built upon.
  topic: Strategy/Technical
- impact_reason: Introduces the concept of context-specific critique, significantly
    refining the quality and relevance of the self-correction process.
  relevance_score: 9
  source: llm_enhanced
  text: You can even add an additional dimension where you give it a context lens
    through which to critique itself. So, for example, instead of just generically
    saying, 'List the top five ways it's generic,' you could say, 'List the top five
    ways it feels too generic for an undergraduate audience.'
  topic: Technical
- impact_reason: Suggests model diversity as a powerful critique mechanism, leveraging
    the different inherent biases and strengths of various LLMs.
  relevance_score: 9
  source: llm_enhanced
  text: Further, one additional element that you can add to that sort of self-critique
    is to have different models do the critiquing as well.
  topic: Technical
- impact_reason: Uses a concrete business example (pitch decks) to show how LLMs internalize
    and reproduce conventional wisdom, often to the detriment of novel or high-performing
    strategies.
  relevance_score: 9
  source: llm_enhanced
  text: A really bright, blinking example of this for me is around pitch decks. There
    are an infinite number of articles across the internet about the standard 10-slide
    pitch deck... decks that stand out very rarely follow that template.
  topic: Business/Strategy
- impact_reason: Acknowledges the baseline utility of LLMs (high floor for passable
    content), setting the stage for why going beyond 'passable' requires specific
    effort.
  relevance_score: 8
  source: llm_enhanced
  text: What that does is that it ensures that the output of an LLM has a fairly high
    floor. If it produces passable content, passable writing, passable imagery, based
    on how you prompted it, that's good, right? At least it gets you in the zone.
  topic: AI utility/Strategy
- impact_reason: Cites external validation (Alex Cantrowitz) for the core issue being
    discussed, lending credibility to the problem statement.
  relevance_score: 8
  source: llm_enhanced
  text: He called it the AI sameness problem.
  topic: AI limitations
- impact_reason: Provides a specific, relatable example of the sameness problem in
    visual AI, suggesting a lack of true stylistic diversity despite massive training
    data.
  relevance_score: 8
  source: llm_enhanced
  text: AI-generated images suffered from the sameness problem as well. There's a
    quality to these images that makes it possible to spot most from a distance. It's
    as if the same artist responds to every prompt, even though the models have ingested
    all the world's artwork.
  topic: AI limitations/Technical
- impact_reason: Highlights a significant technical breakthrough (physical simulation
    understanding) within Sora, despite the overall sameness critique.
  relevance_score: 8
  source: llm_enhanced
  text: The Sora videos are a breakthrough, demonstrating AI has some basic understanding
    of physics in a way that surprised even the most advanced researchers.
  topic: AI breakthroughs/Technical
- impact_reason: 'Defines the target for the negative style guide: identifying and
    eliminating statistically overrepresented linguistic artifacts.'
  relevance_score: 8
  source: llm_enhanced
  text: A lot of what gives us the feeling of AI and LLMs being in patterns is these
    common elements that come up way more in AI writing or AI output than they do
    in human output of the same type.
  topic: Practical lessons/Technical
- impact_reason: Provides a specific, actionable prompt strategy for achieving decisive
    output.
  relevance_score: 8
  source: llm_enhanced
  text: A very frequent prompt that I have is to force it to pick a single choice
    among many and argue vociferously why that is the best choice.
  topic: Practical lessons
- impact_reason: Demonstrates the massive productivity gains possible when AI agents
    are purpose-built to execute complex, multi-step workflows using proprietary data.
  relevance_score: 8
  source: llm_enhanced
  text: Notion's new AI agents completely expand the range of what Notion can do.
    They can now build documents from your entire company's knowledge base, organize
    scattered information into organized reports—basically do tasks that used to take
    days and get them complete in minutes.
  topic: AI impact/Business
- impact_reason: Provides a strong, quantifiable business metric (5X velocity increase)
    for advanced AI tooling in software development.
  relevance_score: 8
  source: llm_enhanced
  text: Global companies are achieving a 5X engineering velocity increase when incorporating
    Blitzy as their pre-IDE development tool, pairing it with their coding co-pilot.
  topic: Business advice/Predictions
- impact_reason: Introduces a novel, actionable technique ('cliche burn down') for
    improving the quality and originality of LLM outputs.
  relevance_score: 8
  source: llm_enhanced
  text: Another approach to breaking out of the averageness and sameness of standard
    AI outputs, we'll call the cliche burn down.
  topic: Technical/Strategy
- impact_reason: A critical observation about user behavior that limits the utility
    of powerful, iterative AI tools.
  relevance_score: 8
  source: llm_enhanced
  text: People, I think, are much too comfortable just using the first pass of whatever
    AI does.
  topic: Strategy
- impact_reason: Introduces the first actionable technique for overcoming averageness.
  relevance_score: 7
  source: llm_enhanced
  text: The first, let's call a negative style guide.
  topic: Practical lessons/Strategy
- impact_reason: 'Summarizes the immediate benefit of the technique: clearing out
    the most obvious pitfalls of generic output.'
  relevance_score: 7
  source: llm_enhanced
  text: In short, a negative style guide is one of the simplest but most effective
    ways to get at least the landmines of averageness that you've identified off of
    the table.
  topic: Practical lessons
- impact_reason: Introduces the second key technique focused on decision-making and
    commitment.
  relevance_score: 7
  source: llm_enhanced
  text: Next up is an approach I'll call forced divergence in choice.
  topic: Practical lessons/Strategy
- impact_reason: Uses the classic five-paragraph essay structure as an analogy for
    clear, committed communication, which LLMs often fail to replicate due to equivocation.
  relevance_score: 7
  source: llm_enhanced
  text: 'One of the things that makes writing strong is the simple clarity of what
    it''s trying to argue. You all remember, if you were of the right age, I''m sure,
    the five-paragraph essay: the first paragraph which has your thesis statement,
    and then three paragraphs to support them in the conclusion.'
  topic: Strategy
- impact_reason: 'Business insight: highlights the emerging need for structured planning
    and mapping of AI use cases before deployment (Agent Planning).'
  relevance_score: 7
  source: llm_enhanced
  text: Super Intelligent maps every AI use case across your company and helps you
    create an agent plan that you can actually execute.
  topic: Business advice
- impact_reason: Reiterates the value of in-context learning via high-quality examples
    (few-shot prompting).
  relevance_score: 7
  source: llm_enhanced
  text: 'The last technique to get your LLM to be not average is an obvious one, a
    tried-and-true method: to the extent that you have an example of an output that
    you think is better than average, give the LLM that example.'
  topic: Technical
- impact_reason: 'Business insight: emphasizes the importance of infrastructure modernization
    and long-term partnership for sustainable AI value creation.'
  relevance_score: 6
  source: llm_enhanced
  text: Robots and Pencils work side by side with organizations to turn AI ambition
    into real human impact. As an AWS certified partner, they modernize infrastructure,
    design cloud-native systems, and apply AI to create business value.
  topic: Business advice/Strategy
source: Unknown Source
summary: '## Podcast Summary: 5 Prompting Tricks to Make Your AI Less Average


  This 20-minute episode of the AI Daily Brief addresses the pervasive issue the host
  terms **"AI''s tyranny of the average,"** where Large Language Models (LLMs) default
  to conventional wisdom and generic output because they are trained on the mean of
  human-generated data. The goal of the episode is to provide actionable prompting
  strategies to elevate AI output from merely "passable" to "unique" and "high quality."


  The discussion is framed by an essay from technology writer Alex Cantrowitz, who
  highlighted the **"AI sameness problem,"** noting that generative content (like
  Sora videos or common business writing) exhibits a uniformity that requires deliberate
  prompting to break.


  The host then details five specific prompting techniques designed to overcome this
  averageness:


  1.  **Negative Style Guide:** Explicitly instructing the model on what *not* to
  do. This involves banning overused, hackneyed words (e.g., "telemetry," "leverage,"
  "synergy") and stylistic choices (e.g., avoiding titles with colons) that signal
  generic AI output.

  2.  **Forced Divergence in Choice:** Counteracting the LLM''s pathological unwillingness
  to commit to a single path. The host recommends forcing the model to pick one option
  and argue vociferously for it, often preceded by a "steelman" exercise where it
  first builds the strongest case for *all* competing options before committing. This
  mimics strong human decision-making.

  3.  **Cliche Burn Down:** Asking the model to first identify the most common analogies
  or turns of phrase (cliches) present in its initial draft for a given topic, and
  then explicitly instructing it to replace those with more original phrasing.

  4.  **Self-Critique (Iterative Refinement):** Moving beyond the first pass by building
  a multi-step process into the prompt. A powerful example is: Draft V1, **Red Team**
  it by listing the top five ways it''s generic, **Rewrite V2** fixing those issues,
  and then **Explain** the changes. This can be enhanced by using different models
  (e.g., GPT-5 thinking vs. GPT-4o) to critique each other''s output for added dimensionality.

  5.  **Exemplar Prompting with Rationale:** Providing the LLM with an example of
  superior, non-average output. Crucially, the user must explain *why* the example
  is better and specifically detail how it breaks from the conventional wisdom the
  model typically aggregates (e.g., placing a strong revenue growth metric on the
  first slide of a pitch deck, contrary to standard templates).


  ---


  ### Summary Analysis:


  | Category | Detail |

  | :--- | :--- |

  | **1. Focus Area** | Prompt Engineering strategies for Large Language Models (LLMs)
  to overcome generic output, specifically addressing the "AI sameness problem" in
  text, image, and video generation. |

  | **2. Key Technical Insights** | 1. LLMs are fundamentally optimized for the mean
  of human output, leading to predictable patterns. 2. Forcing commitment (Forced
  Divergence) is necessary because models naturally equivocate to cover all bases.
  3. Multi-model critique (using different model architectures within the same ecosystem)
  introduces necessary cognitive diversity. |

  | **3. Business/Investment Angle** | 1. Generic AI output is insufficient for high-stakes
  production use cases, necessitating advanced prompting skills for competitive advantage.
  2. Companies relying on AI for external communication (e.g., PR pitches) risk sounding
  uniform and inauthentic. 3. Investment in AI tooling must prioritize platforms that
  facilitate complex, multi-step refinement processes (like Blitzy or Notion AI agents).
  |

  | **4. Notable Companies/People** | **Alex Cantrowitz** (Technology Writer, author
  of the "AI sameness problem" essay); **Mike Krieger** (Instagram co-founder, Anthropic
  CPO, commenting on Sora''s lack of long-term variety); Sponsors: **Super Intelligent**,
  **Robots and Pencils**, **Notion**, **Blitzy**. |

  | **5. Future Implications** | The industry is moving toward a requirement for highly
  skilled prompt engineers or specialized agents capable of executing complex, multi-stage
  refinement workflows to extract true value beyond baseline performance. The "sameness"
  problem must be solved for AI content to achieve long-term relevance in social media
  and professional contexts. |

  | **6. Target Audience** | AI practitioners, prompt engineers, content creators,
  product managers, and technology professionals who use generative AI daily for production-level
  work and need to differentiate their output. |'
tags:
- artificial-intelligence
- generative-ai
- startup
- openai
- anthropic
title: 5 Prompting Tricks to Make Your AI Less Average
topics:
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 88
  prominence: 1.0
  topic: artificial intelligence
- keywords:
  - generative ai
  - genai
  - chatgpt
  - gpt
  - claude
  - text generation
  - image generation
  mentions: 14
  prominence: 1.0
  topic: generative ai
- keywords:
  - startup
  - entrepreneur
  - founder
  - venture
  mentions: 1
  prominence: 0.1
  topic: startup
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-10-20 01:11:09 UTC -->
