---
companies:
- category: unknown
  confidence: medium
  context: of How to Build the Future. Today, I'm joined by Michael Trull, co-founder
    and CEO of anisphere, the company beh
  name: Michael Trull
  position: 508
- category: unknown
  confidence: medium
  context: e in a while. That's kind of the tap form factor. And I think that if they
    game in the next six months to
  name: And I
  position: 4880
- category: tech
  confidence: high
  context: it to another human being, but you really have to spell it out for the
    computer. Because the language tha
  name: Spell
  position: 12478
- category: tech
  confidence: high
  context: of us worked on building actually a competitor to Google using neural networks
    to try and speed run buildi
  name: Google
  position: 16452
- category: unknown
  confidence: medium
  context: ul AI products where AI was really at the center. And GitHub Copilot was
    honestly the moment where that viscerally we
  name: And GitHub Copilot
  position: 16778
- category: tech
  confidence: high
  context: us really excited was seeing research come out of OpenAI and other places
    that showed there were these ver
  name: Openai
  position: 17164
- category: unknown
  confidence: medium
  context: very early. And we were doing things like forking Megatron LM or Microsoft
    DeepSpeed and kind of ripping out th
  name: Megatron LM
  position: 22570
- category: tech
  confidence: high
  context: we were doing things like forking Megatron LM or Microsoft DeepSpeed and
    kind of ripping out the internals a
  name: Microsoft
  position: 22585
- category: unknown
  confidence: medium
  context: we were doing things like forking Megatron LM or Microsoft DeepSpeed and
    kind of ripping out the internals and then, y
  name: Microsoft DeepSpeed
  position: 22585
- category: unknown
  confidence: medium
  context: uture of Copilot. It sounds extra pressing in the Sam Altman set in this
    chair maybe a year ago and talked abo
  name: Sam Altman
  position: 25857
- category: unknown
  confidence: medium
  context: getting better and better and better. The classic Peter Thielism is what
    do you believe that nobody else believes?
  name: Peter Thielism
  position: 26533
- category: unknown
  confidence: medium
  context: t more attention to it. Then there was a PaLM and Stable Diffusion. And
    then you start to get RLHF. You start to get
  name: Stable Diffusion
  position: 27472
- category: unknown
  confidence: medium
  context: it about the internal inside baseball of building GitHub Copilot, the first
    version. The whole building GitHub Cop
  name: GitHub Copilot
  position: 28994
- category: unknown
  confidence: medium
  context: of sent a tie-over team off to figure out. Was it Matt Friedman at the
    time? Yeah. That yeah. My understanding is
  name: Matt Friedman
  position: 29517
- category: unknown
  confidence: medium
  context: They had to go and change things in the mainline VS Code and expose different
    editor APIs to even just sho
  name: VS Code
  position: 30249
- category: unknown
  confidence: medium
  context: of VS Code. But the editor thing was non-obvious. So Cursor's out, you
    made a bunch of decisions that turned
  name: So Cursor
  position: 31084
- category: tech
  confidence: high
  context: s very focused on kind of like what we understand Apple to be very focused
    on dogfooding and usable demos
  name: Apple
  position: 35037
- category: ai_application
  confidence: high
  context: The company co-founded by Michael Trull that is behind the AI coding platform
    Cursor.
  name: anisphere
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: The AI coding platform developed by anisphere, focused on replacing traditional
    coding with higher-level description.
  name: Cursor
  source: llm_enhanced
- category: investment_accelerator
  confidence: high
  context: Mentioned as an accelerator/incubator where the speaker sees the first
    signs of change in smaller codebases.
  name: YC (Y Combinator)
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as the first useful AI product that made the founders realize
    the potential for building useful AI-centric companies.
  name: GitHub Copilot
  source: llm_enhanced
- category: big_tech
  confidence: medium
  context: Mentioned in the context of one of the co-founders building a competitor
    to Google using neural networks for search.
  name: Google
  source: llm_enhanced
- category: software_tooling
  confidence: medium
  context: Mentioned as an example of a tool (logs/monitoring) that future coding
    agents will need to interface with.
  name: DataDog
  source: llm_enhanced
- category: ai_research_institution
  confidence: high
  context: The co-founders of Cursor met here, and it is referenced as a place where
    academic AI work was being done.
  name: MIT
  source: llm_enhanced
- category: ai_company
  confidence: high
  context: Research coming out of this organization showed predictable natural laws
    regarding scaling data and compute for model improvement.
  name: OpenAI
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: Mentioned as an organization that has worked on the academic problem of
    3D model prediction.
  name: DeepMind
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: A CAD application mentioned as a target environment for the founders' initial
    3D autocomplete models.
  name: SolidWorks
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: A CAD application mentioned as a target environment for the founders' initial
    3D autocomplete models.
  name: Fusion 360
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: An infrastructure/framework the founders forked and modified for training
    large models.
  name: Megatron LM
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: An infrastructure/framework the founders forked and modified for training
    large models.
  name: Microsoft DeepSpeed
  source: llm_enhanced
- category: big_tech
  confidence: medium
  context: Mentioned via DeepSpeed, an infrastructure tool they developed.
  name: Microsoft
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: The first coding model whose training cost the founders calculated to justify
    investment in their CAD idea.
  name: Codex
  source: llm_enhanced
- category: person_associated_with_ai
  confidence: high
  context: Mentioned as someone who spoke about the necessity of betting on models
    getting smarter (associated with OpenAI).
  name: Sam Altman
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: A model launch mentioned that improved GPT-3 via fine-tuning on instructions.
  name: InstructGPT
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: A model launch mentioned that convinced many people to pay attention to
    AI.
  name: DALL-E
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: A model launch mentioned during the pivotal year of 2022.
  name: PaLM
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: A model launch mentioned during the pivotal year of 2022.
  name: Stable Diffusion
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: The predecessor model to GPT-3.5, mentioned in relation to training costs
    and initial impressions.
  name: GPT-3
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: A model mentioned that showed significant improvement via RLHF and instruction
    tuning.
  name: GPT-3.5
  source: llm_enhanced
- category: ai_tooling
  confidence: high
  context: The editor platform that GitHub Copilot was built upon, and which Cursor
    initially avoided building upon (before switching to basing on it).
  name: VS Code
  source: llm_enhanced
- category: technology_analogy
  confidence: medium
  context: Used as an analogy for the open-source technology base Cursor initially
    avoided, similar to how browsers use Chromium.
  name: Chromium
  source: llm_enhanced
- category: general_tech_reference
  confidence: medium
  context: Mentioned in the context of dogfooding and usable demos, implying a standard
    for product development quality that the speakers aimed for.
  name: Apple
  source: llm_enhanced
date: 2025-06-11 13:45:00 +0000
duration: 37
has_transcript: false
insights:
- actionable: false
  confidence: medium
  extracted: code. Welcome back to another episode of How to Build the Future. Today,
    I'm joined by Michael Trull, co-founder and CEO of anisphere, the company behind
    Cursor, the AI coding platform we all know and love. They recently hit a $9 billion
    valuation and are one of the fastest-growing startups of all time, reaching $100
    million ARR just 20 months after launching. Michael, thanks for joining us. Thank
    you for having me. Excited to be here. You've said the goal of Cursor
  text: the future of code. Welcome back to another episode of How to Build the Future.
    Today, I'm joined by Michael Trull, co-founder and CEO of anisphere, the company
    behind Cursor, the AI coding platform we all know and love. They recently hit
    a $9 billion valuation and are one of the fastest-growing startups of all time,
    reaching $100 million ARR just 20 months after launching. Michael, thanks for
    joining us. Thank you for having me. Excited to be here. You've said the goal
    of Cursor is to actually invent a new type of programming where you can just describe
    what you want and it gets built.
  type: prediction
- actionable: false
  confidence: medium
  extracted: code. Being able to run the code, being able to look at DataDog logs
    and interface with, with those tools that humans use. There are a lot of known
    devils that we will have to face, and then a lot of unknown devils that we will
    have to face. And, you know, the task of making coding agents superhuman. And
    then, you know, one thing I will note kind of harkening back to a last response
  text: the future of code. Being able to run the code, being able to look at DataDog
    logs and interface with, with those tools that humans use. There are a lot of
    known devils that we will have to face, and then a lot of unknown devils that
    we will have to face. And, you know, the task of making coding agents superhuman.
    And then, you know, one thing I will note kind of harkening back to a last response
    is that even if you had something you had talked to that was human level at coding,
    or faster or better than a human at coding, you know, sort of the skill of an
    entire engineering department, I think that the UI of just having a text box,
    asking for a change to the software is imprecise.
  type: prediction
- actionable: false
  confidence: medium
  extracted: Copilot. It sounds extra pressing in the Sam Altman set in this chair
    maybe a year ago and talked about how if you're betting against the models getting
    smarter, that's bad. You should always bet that the models are going to get a
    lot smarter. And you know, 12, 18, 24 months later, that's been only more and
    more true. And then it sounds like you had been taking that bet a full 12 months
    before even that was said. Yeah, we had a phrase back then, which was follow the
    line. And you wanted to always be following the line and planning for where the
    line was, I mean, kind of harkening back to the scaling laws of like, you know,
    these things are just going to keep getting better and better and better. The
    classic Peter Thielism
  text: the future of Copilot. It sounds extra pressing in the Sam Altman set in this
    chair maybe a year ago and talked about how if you're betting against the models
    getting smarter, that's bad. You should always bet that the models are going to
    get a lot smarter. And you know, 12, 18, 24 months later, that's been only more
    and more true. And then it sounds like you had been taking that bet a full 12
    months before even that was said. Yeah, we had a phrase back then, which was follow
    the line. And you wanted to always be following the line and planning for where
    the line was, I mean, kind of harkening back to the scaling laws of like, you
    know, these things are just going to keep getting better and better and better.
    The classic Peter Thielism is what do you believe that nobody else believes? And
    you believed this and you were so right, but that's what allowed you to actually
    go to where the puck was going to be.
  type: prediction
- actionable: false
  confidence: medium
  extracted: AI. So they thought immediately, can we just automate PRs intent a little
    before or it's time. And they worked on that for a bit and then decided that was
    impossible. And they tried all these other wacky product ideas until they just
    found the simple thing of autocomplete. But even after they got autocomplete to
    work, they needed to make changes at the editor level. They couldn't do it entirely
    as an extension. They had to go and change things in the mainline VS Code and
    expose different editor APIs to even just show that ghost text. Then there was
    some from my understanding that was actually kind of hard to do organizationally.
    If you were going to need to change the editor for something as simple as ghost
    text autocomplete, we knew we were going to have to do it a bunch. And so that
    was non-obvious and we got a lot of flack for that. And we actually initially
    started by building our own editor from scratch, obviously using lots of open-source
    technology, but not, you know, basing it off of VS Code, kind of like how browsers
    are based off of Chromium. It was a little bit more akin to building, you know,
    all the internal rendering of a browser from scratch. And we launched with that.
    And then we then we switched to basing it off of VS Code. But the editor thing
    was non-obvious. So Cursor's out, you made a bunch of decisions that turned out
    to be right. When did you know it was going to work? It took a little bit of time.
    If you'll remember, there's this initial year, roughly a year in the wilderness
    of, you know, working on something that was precursor to Cursor and the mechanical
    engineering side of things. And then, you know, there was an initial development
    period for Cursor that was fairly small before we released the first version to
    the public. I think that it was from lines of code to first public beta release,
    it was three months. But then there was this year of iterating in public at very
    small scale where we had did not have lightning in the model. And it was growing,
    but it was, you know, the numbers numbers were small. Dialing in the product at
    that point took maybe a year of getting all of the details right. Then it was
    only after that initial period of Cursor being out for nine months to a year of
    working on the underlying product, building out the team, also not just the product
    side of things, but also starting to get the first versions of custom models behind
    Cursor to power, you know, underneath Cursor. The things started to click. And
    then we're started to pick up. And then, since then, it's been, you know, we sort
    of have a tiger by the tail. And if we are to be successful, there's a lot of
    things that we need to continue to execute on in the future. I think one of the
    challenges we have and a lot of other companies in parallel spaces have
  text: the future of AI. So they thought immediately, can we just automate PRs intent
    a little before or it's time. And they worked on that for a bit and then decided
    that was impossible. And they tried all these other wacky product ideas until
    they just found the simple thing of autocomplete. But even after they got autocomplete
    to work, they needed to make changes at the editor level. They couldn't do it
    entirely as an extension. They had to go and change things in the mainline VS
    Code and expose different editor APIs to even just show that ghost text. Then
    there was some from my understanding that was actually kind of hard to do organizationally.
    If you were going to need to change the editor for something as simple as ghost
    text autocomplete, we knew we were going to have to do it a bunch. And so that
    was non-obvious and we got a lot of flack for that. And we actually initially
    started by building our own editor from scratch, obviously using lots of open-source
    technology, but not, you know, basing it off of VS Code, kind of like how browsers
    are based off of Chromium. It was a little bit more akin to building, you know,
    all the internal rendering of a browser from scratch. And we launched with that.
    And then we then we switched to basing it off of VS Code. But the editor thing
    was non-obvious. So Cursor's out, you made a bunch of decisions that turned out
    to be right. When did you know it was going to work? It took a little bit of time.
    If you'll remember, there's this initial year, roughly a year in the wilderness
    of, you know, working on something that was precursor to Cursor and the mechanical
    engineering side of things. And then, you know, there was an initial development
    period for Cursor that was fairly small before we released the first version to
    the public. I think that it was from lines of code to first public beta release,
    it was three months. But then there was this year of iterating in public at very
    small scale where we had did not have lightning in the model. And it was growing,
    but it was, you know, the numbers numbers were small. Dialing in the product at
    that point took maybe a year of getting all of the details right. Then it was
    only after that initial period of Cursor being out for nine months to a year of
    working on the underlying product, building out the team, also not just the product
    side of things, but also starting to get the first versions of custom models behind
    Cursor to power, you know, underneath Cursor. The things started to click. And
    then we're started to pick up. And then, since then, it's been, you know, we sort
    of have a tiger by the tail. And if we are to be successful, there's a lot of
    things that we need to continue to execute on in the future. I think one of the
    challenges we have and a lot of other companies in parallel spaces have is just
    the rate at which we need to build the company, I think, is really fast.
  type: prediction
layout: episode
llm_enhanced: true
original_url: https://anchor.fm/s/8c1524bc/podcast/play/103964360/https%3A%2F%2Fd3ctxlq1ktw2nl.cloudfront.net%2Fstaging%2F2025-5-11%2F401956275-44100-2-bbb605afb1dbd.mp3
processing_date: 2025-10-05 10:38:17 +0000
quotes:
- length: 141
  relevance_score: 6
  text: And honestly, also now there weren't that many people training 10 billion
    plus parameter scale large language models, machine learning models
  topics: []
- length: 142
  relevance_score: 4
  text: But yeah, training large language models in the order of tens of billions
    of parameters was not something a ton of people were doing back then
  topics: []
- length: 160
  relevance_score: 4
  text: And, you know, some of some of the experience of doing inference back then
    and training back then has definitely been immensely useful for the Cursor experience
  topics: []
- length: 155
  relevance_score: 3
  text: Because the language that you have to describe things to the computer is for
    normal programming, just for loops and if statements and variables and methods
  topics: []
- length: 157
  relevance_score: 3
  text: Another one of us worked on building actually a competitor to Google using
    neural networks to try and speed run building an amazing search engine for the
    web
  topics: []
- length: 158
  relevance_score: 3
  text: And we were doing things like forking Megatron LM or Microsoft DeepSpeed and
    kind of ripping out the internals and then, you know, deploying that for training
  topics: []
- impact_reason: This is the ultimate vision statement for the company, signaling
    a paradigm shift away from traditional coding towards a higher-level abstraction
    for building software.
  relevance_score: 10
  source: llm_enhanced
  text: For us, the end goal is to replace coding with something much better.
  topic: predictions
- impact_reason: 'Reiterates the core mission: moving from explicit coding instructions
    to intent-driven software creation.'
  relevance_score: 10
  source: llm_enhanced
  text: You've said the goal of Cursor is to actually invent a new type of programming
    where you can just describe what you want and it gets built.
  topic: strategy
- impact_reason: A crucial caution against over-reliance on black-box generation,
    especially in complex, long-lived professional codebases where deep understanding
    is necessary.
  relevance_score: 10
  source: llm_enhanced
  text: The whole idea of vibe coding or coding without really looking at the code
    and understanding it, it doesn't really work. There are lots of nth order effects.
  topic: safety/limitations
- impact_reason: Directly addresses context window size as a primary bottleneck for
    human-level performance on large codebases.
  relevance_score: 10
  source: llm_enhanced
  text: Is it a context window thing? It sort of makes sense that, well, once you
    get past about a million to two million tokens, only even in I feel like the last
    100 days did we get a usable two million token length? Is that naturally one of
    the places where once your codebase reaches a certain size, you know, you got
    to use RAG, it has incomplete context, and then it just can't do what a human
    coder could do?
  topic: technical
- impact_reason: Distinguishes between the technical capacity to hold context (ingestion)
    and the model's ability to effectively utilize that context (attention), both
    being critical hurdles.
  relevance_score: 10
  source: llm_enhanced
  text: I think that there are a bunch of bottlenecks to agents being human level.
    I think one is context window side of things... and then not just having a model
    that can physically ingest that into its weights, but also one that actually pays
    attention effectively to that context window, is tricky.
  topic: technical
- impact_reason: Identifies 'continual learning' and organizational context retention
    as a major, unsolved bottleneck beyond just code length.
  relevance_score: 10
  source: llm_enhanced
  text: It's not just a codebase thing there, it's also just a continual learning
    problem of, you know, knowing the context of the organization and things that
    have been tried in the past, and who your co-workers are, and that problem of
    having, you know, a model really continually learn something, kind of something
    that the field, I think, still doesn't really have a great solution to.
  topic: technical/limitations
- impact_reason: Argues that even perfect AI capability won't solve the interface
    problem; the text box UI is inherently imprecise for complex software control.
  relevance_score: 10
  source: llm_enhanced
  text: Even if you had something you had talked to that was human level at coding,
    or faster or better than a human at coding, you know, sort of the skill of an
    entire engineering department, I think that the UI of just having a text box,
    asking for a change to the software is imprecise.
  topic: strategy/technical
- impact_reason: Identifies 'taste'—the high-level judgment of what is valuable, useful,
    and well-designed—as the irreplaceable human skill.
  relevance_score: 10
  source: llm_enhanced
  text: What will be irreplaceable, or like sort of the essential pieces of being
    a software engineer in the future? What do you think that one thing that will
    be irreplaceable is taste, so just defining what, what do you actually want to
    build?
  topic: predictions
- impact_reason: 'A concise summary of the future role of the developer: focusing
    on the ''what'' (logic/intent) rather than the ''how'' (syntax/implementation).'
  relevance_score: 10
  source: llm_enhanced
  text: People need to become logic designers.
  topic: predictions
- impact_reason: 'Explains the feedback loop: product usage data (dislikes, pain points)
    is crucial for guiding the next generation of ML improvement, especially in complex
    tasks where models currently fail.'
  relevance_score: 10
  source: llm_enhanced
  text: And one way to continue caring for progress on the underlying machine learning
    is to get product data of what suggestions to people like what do they dislike,
    what are the hard pieces of human work that the AI still can't really access.
    And you get that after the pin of glass where the knowledge work happens.
  topic: Business
- impact_reason: A strong, long-term conviction statement about the revolutionary
    potential of AI in coding, justifying high risk by pointing to an extremely high
    ceiling for transformation.
  relevance_score: 10
  source: llm_enhanced
  text: I think if we were being really consistent with our beliefs in five years,
    all of coding was going to flow through these models and the active programming
    was going to entirely change. And there were going to be all these jumps you needed
    both at a product level and at a model level to get there. And the ceiling was
    just just so high.
  topic: Predictions
- impact_reason: This is a strong, long-term prediction about the fundamental transformation
    of software development driven by AI models, setting a high ambition level for
    the company.
  relevance_score: 10
  source: llm_enhanced
  text: if we were being really consistent with our beliefs in five years, all of
    coding was going to flow through these models and the active programming was going
    to entirely change.
  topic: predictions
- impact_reason: A core strategic belief in the accelerating capability of AI models,
    echoing common wisdom from major AI leaders (like Sam Altman), reinforcing the
    'follow the line' mentality.
  relevance_score: 10
  source: llm_enhanced
  text: if you're betting against the models getting smarter, that's bad. You should
    always bet that the models are going to get a lot smarter.
  topic: strategy
- impact_reason: Highlights the massive leverage gained from alignment techniques
    (Instruction Tuning, RLHF) over raw compute scaling in achieving breakthrough
    performance (GPT-3 to GPT-3.5/ChatGPT).
  relevance_score: 10
  source: llm_enhanced
  text: It was rumored that to go from GPT-3, which, you know, had existed for a while
    and didn't impress some people, but was certainly not the breakout moment at GPT
    was two at GPT was like a 1% increase in the training costs. Oh my gosh. It was,
    you know, from fine-tuning on instructions, RLHF, you know, some other details
    too.
  topic: technical
- impact_reason: 'Defines a crucial organizational structure challenge in the current
    AI landscape: bridging fundamental research (lab) with deployable products (software
    company).'
  relevance_score: 10
  source: llm_enhanced
  text: folks who bled across disciplines where we are this company that needs to
    be something in between a foundation model lab and a normal software company.
  topic: strategy
- impact_reason: 'Identifies the ideal profile for early-stage AI companies: individuals
    who combine technical depth (training models at scale) with business acumen (product/commercial
    mindset).'
  relevance_score: 10
  source: llm_enhanced
  text: we had fantastic people who were product-minded, commercially minded, but
    had actually trained models at scale.
  topic: business
- impact_reason: A direct observation on how generative AI tools are complicating
    traditional engineering evaluation and hiring processes.
  relevance_score: 10
  source: llm_enhanced
  text: simply because the AI tools are so great, it's making it harder at times to
    even figure out how do you evaluate great engineers?
  topic: safety/business
- impact_reason: A concrete, actionable policy for technical hiring in the age of
    AI, aiming to test foundational skills.
  relevance_score: 10
  source: llm_enhanced
  text: for interviewing, we actually still interview people without allowing them
    to use AI other than autocomplete for our first technical screens.
  topic: strategy
- impact_reason: A strong prediction about the immediate future impact of AI tools
    on developer productivity and building capacity.
  relevance_score: 9
  source: llm_enhanced
  text: I think that this is going to be a decade where just your ability to build
    will be so magnified.
  topic: predictions
- impact_reason: Provides a specific, medium-term timeline for achieving this major
    technological shift in software development.
  relevance_score: 9
  source: llm_enhanced
  text: We think that over the next five to 10 years, it will be possible to invent
    a new way to build software that's higher level and more productive.
  topic: predictions
- impact_reason: 'Details the iterative, market-driven strategy: dominate the current
    AI coding landscape while simultaneously building the successor paradigm.'
  relevance_score: 9
  source: llm_enhanced
  text: Our path to getting there is to, at any given point in time, always be the
    best way to code with AI and then evolve that process, evolve it away from normal
    programming to something that looks very different.
  topic: business
- impact_reason: Provides concrete usage metrics (40-50% AI-generated code) while
    emphasizing the current necessity of human review and verification.
  relevance_score: 9
  source: llm_enhanced
  text: On average, we see about people using having AI write 40%, 50% of the lines
    of code produced within Cursor, but it's still a process of reading everything
    that comes out of the AI.
  topic: technical
- impact_reason: 'Defines the next major product evolution: moving beyond code assistance
    to fundamentally changing the artifact being created/manipulated.'
  relevance_score: 9
  source: llm_enhanced
  text: An important chasm for us to cross is a product. We'll be getting to a place
    where we become less of a productivity tool that's helping you look at, read,
    write, understand code, and where the artifact changes.
  topic: strategy
- impact_reason: Offers two distinct, high-level conceptual frameworks for understanding
    LLMs in the context of software development.
  relevance_score: 9
  source: llm_enhanced
  text: One way in which you can view LLMs is there, you interface with them like
    a human, like a helper. Another way in which you can view LLMs is they're kind
    of an advance in compiler or interpreter technology.
  topic: technical
- impact_reason: Highlights the non-negotiable requirement for user control, even
    as automation increases—the need to edit the 'finest details' must remain.
  relevance_score: 9
  source: llm_enhanced
  text: It's going to be always helpful if we are a tool to help a human go from an
    idea in their head to something on the screen to give people control over the
    finest details.
  topic: safety/control
- impact_reason: Connects reduced attention on code syntax with the necessary evolution
    of the abstract representation of software logic (e.g., higher-level DSLs or specifications).
  relevance_score: 9
  source: llm_enhanced
  text: If we were to get to a place where you don't have to pay attention to the
    code as much, that written down version of the logic of the software is going
    to have to get higher level.
  topic: technical
- impact_reason: Highlights the necessity of AI agents developing 'embodiment' or
    the ability to interact with external execution environments (running code, checking
    logs) to be truly effective.
  relevance_score: 9
  source: llm_enhanced
  text: Computer using is kind of, is going to be important for the future of code.
    Being able to run the code, being able to look at DataDog logs and interface with,
    with those tools that humans use.
  topic: technical
- impact_reason: Explains that current aesthetic improvements are achieved via expensive,
    data-heavy RLHF/RLAIF, confirming it's a workaround rather than true intrinsic
    learning.
  relevance_score: 9
  source: llm_enhanced
  text: The way you teach these models to be better at something like aesthetics is
    not in the way you would a human. It is by, you know, basically collecting much
    data, doing RL on them. And that's how you've taught at that task. And that's
    a task that enough people care about that you can pay the cost to do all of that.
    But it's kind of a hack around the continual learning problem.
  topic: technical
- impact_reason: 'Articulates the current burden on programmers: bundling high-level
    design/taste with low-level ''human compilation'' (syntactic translation), which
    AI will remove.'
  relevance_score: 9
  source: llm_enhanced
  text: Right now, the active programming kind of bundles up you figuring out how
    exactly you want the thing to work, like what product you're really defining with
    the logic that you're writing, and the kind of high-level taste of the implementation
    details, of how that maps onto a physical computer. But then right now, a lot
    of programming is kind of this human compilation that you're doing, where you
    kind of know what you want, you could tell it to another human being, but you
    really have to spell it out for the computer.
  topic: strategy
- impact_reason: Predicts the automation of the translation layer between human intent
    and formal code syntax.
  relevance_score: 9
  source: llm_enhanced
  text: I think that more and more of that human compilation step will go away. And
    computers will be able to kind of fill in the gaps, fill in the details.
  topic: predictions
- impact_reason: Highlights the critical role of human judgment, intuition, and 'taste'
    in achieving mastery, distinguishing high-level performance from mere competence,
    even in an AI-augmented world.
  relevance_score: 9
  source: llm_enhanced
  text: Good people will help you hit this bar, but the truly great, the truly masterful,
    they hit a bar that you can't even see. And that requires taste.
  topic: Strategy
- impact_reason: Suggests AI tools will accelerate the creation of the *next generation*
    of foundational infrastructure (training frameworks, databases), breaking current
    engineering bottlenecks in AI research.
  relevance_score: 9
  source: llm_enhanced
  text: The next distributed training framework or the next database or the next visual
    design tool will just be way faster to build the next AI model, which if you talk
    to the labs, largely they're bottlenecked on engineering capacity.
  topic: AI Technology Trends
- impact_reason: Confirms the foundational belief in scaling laws as the primary driver
    of predictable progress in large models, justifying long-term investment.
  relevance_score: 9
  source: llm_enhanced
  text: The other thing that got us really excited was seeing research come out of
    OpenAI and other places that showed there were these very predictable natural
    laws that showed if you scaled up the data and you scaled up the compute that
    goes into these models, they were just getting better.
  topic: AI Technology Trends
- impact_reason: 'Outlines a strategic approach: building domain-specific products
    allows companies to adapt the user interface/experience as foundational models
    improve, while also necessitating specialized product data beyond raw model scaling.'
  relevance_score: 9
  source: llm_enhanced
  text: We were very interested in the shape of a company where you build the product
    for that area of knowledge work because that lets you do a couple of things. One,
    as the underlying tech matures, you can then evolve the form factor of what doing
    that thing looks like. And then two is even back then, it was clear, you were
    probably going to need more than just scaling up the size of language models to
    GPT-N.
  topic: Business
- impact_reason: 'Highlights a key limitation in applying standard LLMs to complex
    3D/physical simulation tasks: the model must internally simulate complex state/geometry,
    which is much harder than predicting text sequences.'
  relevance_score: 9
  source: llm_enhanced
  text: The problem is if you're going to do it entirely text-based, you're asking
    the model to do something really tricky, not just predict what the user's going
    to do next, but also in its mind's eye, simulate the geometry, because CAD kernels,
    like the software underlying these CAD applications, they're fairly complicated.
  topic: Technical
- impact_reason: 'A valuable lesson: early, commercially unsuccessful projects can
    provide critical, hard-won experience in infrastructure (training and inference
    at scale) that becomes essential later.'
  relevance_score: 9
  source: llm_enhanced
  text: Even though the kind of end product of the production models that we were
    working on at that time wasn't that useful, it was a great dry run of training
    models at scale.
  topic: Practical Lessons
- impact_reason: Identifies a strategic gap in the market (ambition/vision) rather
    than just execution, justifying a new entrant's approach.
  relevance_score: 9
  source: llm_enhanced
  text: It really didn't seem like the existing players in the space were aiming for
    a completely different type of coding. It didn't seem like they had that ambition,
    like they were really set up to execute on that too.
  topic: strategy
- impact_reason: Articulates a clear strategy based on the predictable improvement
    trajectory of foundational models (scaling laws), crucial for long-term AI investment.
  relevance_score: 9
  source: llm_enhanced
  text: We had a phrase back then, which was follow the line. And you wanted to always
    be following the line and planning for where the line was, I mean, kind of harkening
    back to the scaling laws of like, you know, these things are just going to keep
    getting better and better and better.
  topic: strategy
- impact_reason: 'A key product decision driven by future vision: choosing to build
    a full editor environment rather than integrating as a lightweight extension,
    suggesting deeper control over the workflow is necessary for radical change.'
  relevance_score: 9
  source: llm_enhanced
  text: One of the product decisions that we made early on that was non-obvious that
    came from being excited about a bit more of a radical future was not building
    an extension and was building an editor.
  topic: business
- impact_reason: 'A critical warning for AI product builders: demos can be misleading,
    and true product success requires solving reliability, speed, and intelligence,
    not just surface-level ''wow'' moments.'
  relevance_score: 9
  source: llm_enhanced
  text: one of the siren songs involved in building AI products is optimizing for
    the demo. We were really nervous about optimizing for the demo.
  topic: business
- impact_reason: Defines a highly specific and rigorous success metric ('paid power
    users' using the tool almost daily), prioritizing deep integration into professional
    workflow over vanity metrics like DAU/MAU.
  relevance_score: 9
  source: llm_enhanced
  text: The main top-line metric we looked at, we looked at revenue. We looked at
    paid power users measured by, are you using the AI four or five days a week out
    of seven days a week?
  topic: business
- impact_reason: 'Describes a unique organizational structure required for cutting-edge
    AI products: tightly coupling model development with product iteration, unlike
    traditional software companies.'
  relevance_score: 9
  source: llm_enhanced
  text: we're this company that needs to be something in between a foundation model
    lab and a normal software company. And the models and products have to work together
    under one roof.
  topic: strategy
- impact_reason: Reiterates the core conviction driving the company's focus on radical
    transformation in coding, not incremental improvement.
  relevance_score: 9
  source: llm_enhanced
  text: And then also just sitting down and thinking that if we were being really
    consistent with our beliefs in five years, all of coding was going to flow through
    these models and the active programming was going to entirely change.
  topic: strategy
- impact_reason: Highlights the exponential positive effect of high initial talent
    density on future recruiting and culture.
  relevance_score: 9
  source: llm_enhanced
  text: if you really nail the first 10 people to come into the company, they will
    both accelerate you in the future because when, you know, the end person comes
    in that's, you know, is thinking about working with you, comes in and hangs out
    with the team, they'll just be shocked by the talent density and then really excited
    to work there.
  topic: business
- impact_reason: Asserts the enduring value of testing raw coding ability as a proxy
    for fundamental engineering skill, separate from tool proficiency.
  relevance_score: 9
  source: llm_enhanced
  text: Programming without AI is still a really great time-boxed test for skill and
    intelligence.
  topic: strategy
- impact_reason: Identifies the current sweet spot for AI adoption and impact—smaller,
    agile projects—before tackling massive enterprise systems.
  relevance_score: 8
  source: llm_enhanced
  text: I think that in smaller code bases, with smaller groups of people working
    on a piece of software, that's where you feel the change the most.
  topic: strategy
- impact_reason: 'Clearly categorizes current AI coding interaction into two primary
    modes: Agent (delegation) and Co-pilot (tap/keyboard takeover).'
  relevance_score: 8
  source: llm_enhanced
  text: Right now, we're in this phase where AI is kind of operating as a helper for
    you. Right? So kind of like the main ways in which people are using AI to code,
    they're either delegating tasks to an AI, and they're saying, go do this thing
    for me... or they have an AI looking over their shoulder and taking over the keyboard
    every once in a while. That's kind of the tap form factor.
  topic: technical
- impact_reason: Points out the current lack of subjective, aesthetic judgment in
    LLMs, which requires visual feedback loops (seeing the output).
  relevance_score: 8
  source: llm_enhanced
  text: The models don't seem to have a really clear sense for aesthetics, for instance.
    And so the idea that maybe this human level designer needs to actually, you know,
    be able to, they need to be able to see, actually.
  topic: limitations
- impact_reason: This defines the enduring role of human expertise ('taste') even
    as low-level coding is automated. AI tools will remain assistants guided by human
    judgment.
  relevance_score: 8
  source: llm_enhanced
  text: But since we are a tool that's helping you make things happen, helping you
    build things that kind of taste for what is actually useful for what you want
    to build, I don't think we'll ever go away.
  topic: Strategy
- impact_reason: This redefines the future role of a programmer—shifting focus from
    syntax and implementation details to high-level system design and intent specification.
  relevance_score: 8
  source: llm_enhanced
  text: You've called it sort of, people need to become logic designers.
  topic: Strategy
- impact_reason: Predicts democratization of software creation, allowing specialized,
    internal tools (like the one needed by the biotech company) to be built affordably,
    increasing overall software density.
  relevance_score: 8
  source: llm_enhanced
  text: I think that one second-order effect too will be many more pieces of niche
    software will exist.
  topic: Predictions
- impact_reason: Pinpoints a specific product (Copilot) as the inflection point that
    signaled the transition from academic AI research to real-world, immediately useful
    applications.
  relevance_score: 8
  source: llm_enhanced
  text: GitHub Copilot was honestly the moment where that viscerally we really felt
    like now it was possible to make just really useful things with AI, and that we
    shouldn't go to work in a lab to work on these things, you know, an academic lab.
    Instead, it was time for this stuff to come out into the real world.
  topic: AI Technology Trends
- impact_reason: 'Provides a concrete reason for failure/pivot: the underlying science
    (model capability) and data availability were insufficient for the chosen domain
    (3D CAD) at that time.'
  relevance_score: 8
  source: llm_enhanced
  text: I think that the science back then wasn't yet ready for 3D. It's like the
    pre-trained models weren't that good at it. There wasn't a lot of data. There's
    orders of magnitude less data of CAD models than the internet thin code.
  topic: Technical
- impact_reason: 'Actionable advice on product discovery: deep immersion (''going
    undercover'') in the user''s environment is superior to relying solely on hundreds
    of user interviews for understanding workflow friction.'
  relevance_score: 8
  source: llm_enhanced
  text: I think it would have been better up front to actually just go work at a company
    that was employing mechanical engineers for three weeks. Just go undercover. Give
    a better sense for the just stulative. Just get a job as a draftsperson.
  topic: Business
- impact_reason: Provides a concrete, impressive metric demonstrating the massive
    scale of modern AI product deployment and the necessity of mastering inference
    infrastructure.
  relevance_score: 8
  source: llm_enhanced
  text: Now in Cursor, we do over half a billion model calls per day on our own inference.
  topic: Business
- impact_reason: Provides a surprising historical data point regarding the relatively
    low initial cost of training early, groundbreaking models like Codex, which influenced
    early investment decisions.
  relevance_score: 8
  source: llm_enhanced
  text: From my memory, it only cost about $90K or $100K by our calculations [to train
    Codex]. That really surprised surprise investors at the time...
  topic: Technical
- impact_reason: Illustrates the technical friction and organizational difficulty
    in deeply integrating AI features into existing software ecosystems (like VS Code
    extensions) when fundamental UI/UX changes are required.
  relevance_score: 8
  source: llm_enhanced
  text: If you were going to need to change the editor for something as simple as
    ghost text autocomplete, we knew we were going to have to do it a bunch. And so
    that was non-obvious and we got a lot of flack for that.
  topic: technical
- impact_reason: 'Strong advice on early hiring strategy: prioritize talent density
    and cultural fit (the ''immune system'') over speed in the initial phase, as the
    first hires dictate future velocity.'
  relevance_score: 8
  source: llm_enhanced
  text: if you want to go fast on the order of years, actually going slow on the order
    of, you know, for six months is super helpful. Because if you really nail the
    first 10 people to come into the company, they will both accelerate you in the
    future...
  topic: business
- impact_reason: Addresses the unique scaling pressure in frontier AI companies, where
    organizational growth must often exceed traditional software benchmarks to keep
    pace with technological change.
  relevance_score: 8
  source: llm_enhanced
  text: I think one of the challenges we have and a lot of other companies in parallel
    spaces have is just the rate at which we need to build the company, I think, is
    really fast. And I think rules of thumb around don't grow head count more than
    50% year over year, I earn lots to have to have to have to be broken, I think.
  topic: business
- impact_reason: 'Provides nuance on the ''build for yourself'' mantra: it worked
    here because the founders were the target ''power user,'' but warns against letting
    that bias lead to demo optimization.'
  relevance_score: 8
  source: llm_enhanced
  text: I think building for yourself doesn't work in a lot of spaces. For us, it
    did. And I think I was actually clarifying because one of the siren songs involved
    in building AI products is optimizing for the demo.
  topic: business
- impact_reason: Highlights the 'trough of disillusionment' period post-launch where
    initial excitement fades, and the hard, unglamorous work of achieving product-market
    fit through iteration (especially on speed/reliability) takes significant time.
  relevance_score: 8
  source: llm_enhanced
  text: It was growing, but it was, you know, the numbers numbers were small. Dialing
    in the product at that point took maybe a year of getting all of the details right.
  topic: business
- impact_reason: Describes the critical role early, high-caliber hires play in maintaining
    cultural and performance standards.
  relevance_score: 8
  source: llm_enhanced
  text: if someone comes in and they're not a great fit, these people act as an immune
    system against that, right? And they will be kind of keepers of holding the bar
    really high.
  topic: strategy
- impact_reason: Provides a specific hiring archetype recommendation for the very
    early stages of a high-tech startup.
  relevance_score: 8
  source: llm_enhanced
  text: generalist polymath is really, really great at sort of that first 10 people
    stage.
  topic: strategy
- impact_reason: A direct prediction on the immediate impact of advanced AI tools
    on software engineering productivity.
  relevance_score: 7
  source: llm_enhanced
  text: I think one is that professional devs will just get so much more productive.
  topic: Predictions
- impact_reason: Illustrates the high friction and cost barrier for non-software-native
    companies to acquire necessary digital tools, a barrier AI aims to remove.
  relevance_score: 7
  source: llm_enhanced
  text: It was crazy to think that this company for whom software was not their core
    competency, had to go out and do this crazy, laborious thing of hiring a real
    software engineering team and training them up and having them do internal product
    development.
  topic: Business
- impact_reason: Contextualizes the difficulty and rarity of large-scale model training
    in the early days (pre-2022/2023 boom), emphasizing the technical barrier they
    overcame.
  relevance_score: 7
  source: llm_enhanced
  text: training large language models in the order of tens of billions of parameters
    was not something a ton of people were doing back then.
  topic: Technical
- impact_reason: Details the hands-on, low-level engineering required for early large-scale
    ML infrastructure, involving deep modification of foundational frameworks.
  relevance_score: 7
  source: llm_enhanced
  text: We were doing things like forking Megatron LM or Microsoft DeepSpeed and kind
    of ripping out the internals and then, you know, deploying that for training.
  topic: Technical
- impact_reason: Shows that conviction in a market can be driven by a combination
    of personal passion *and* observed acceleration in external progress, coupled
    with a belief that current efforts are suboptimal.
  relevance_score: 7
  source: llm_enhanced
  text: The thing that drew us back into coding was our personal interest and the
    thing that gave us the confidence then to continue with it was one seeing the
    progress that others had made over the course of nine months or whatever it was.
    It felt like it was a little bit slower than it could have been.
  topic: Strategy
- impact_reason: Suggests a belief that the pace of AI development, even when fast,
    might still be bottlenecked by organizational or execution speed, implying room
    for faster players.
  relevance_score: 7
  source: llm_enhanced
  text: It felt like it was a little bit slower than it could have been [referring
    to the progress others made in 9 months].
  topic: predictions
- impact_reason: Identifies DALL-E as a key public inflection point that shifted broader
    industry and investor perception of generative AI capabilities.
  relevance_score: 7
  source: llm_enhanced
  text: DALL-E in the summer, I remember that was kind of the visceral moment that
    convinced a lot of people who weren't focused on the space to be to pay a bit
    more attention to it.
  topic: technical
- impact_reason: Describes the moment when network effects or product maturity lead
    to exponential growth, indicating successful execution after the initial hard
    slog.
  relevance_score: 7
  source: llm_enhanced
  text: And then we're started to pick up. And then, since then, it's been, you know,
    we sort of have a tiger by the tail.
  topic: business
- impact_reason: Shows consideration for candidates who may lack familiarity with
    new AI coding assistants, prioritizing fundamental skill over tool mastery during
    initial assessment.
  relevance_score: 7
  source: llm_enhanced
  text: we don't want to unfairly disadvantage them because these tools are so useful.
  topic: strategy
- impact_reason: Illustrates the competitive landscape perception when entering the
    AI coding assistant space, highlighting the perceived risk despite recognizing
    the massive potential.
  relevance_score: 6
  source: llm_enhanced
  text: We had a little bit of trepidation about going and working on that space [coding]
    because there were so many people already doing it. We thought Copilot was awesome
    and there were dozens of other companies working on it too at the time.
  topic: Business
source: Unknown Source
summary: '## Podcast Summary: Cursor CEO - Going Beyond Code, Superintelligent AI
  Agents And Why Taste Still Matters


  This 37-minute episode features Michael Trull, co-founder and CEO of Anisphere (the
  company behind the AI coding platform Cursor), discussing their ambitious goal to
  fundamentally reinvent software development by moving beyond traditional coding
  toward a higher level of abstraction driven by AI agents. Cursor has achieved remarkable
  success, hitting a $9 billion valuation and $100 million ARR in just 20 months.


  ### 1. Focus Area

  The discussion centers on the **Future of Software Development** driven by advanced
  AI. Key themes include:

  *   **AI Agents and Automation:** Evolving AI from a "helper" (like Copilot) to
  autonomous agents capable of handling complex, multi-step tasks.

  *   **Abstraction Layer:** The goal of replacing the labor of writing formal programming
  languages with intent-driven design—describing what you want the software to do
  and look like.

  *   **Technical Bottlenecks:** Challenges in achieving human-level or superhuman
  coding capabilities, specifically long context windows, continual learning, and
  multi-modality (running and testing code).

  *   **The Enduring Role of Human Input:** The necessity of "taste" and high-level
  logic design even when the implementation details are automated.


  ### 2. Key Technical Insights

  *   **Current AI Usage in Cursor:** Professional developers using Cursor currently
  have AI generate about 40-50% of the code, but the process still requires significant
  human review and understanding of the code (not yet "vibe coding").

  *   **Bottlenecks to Superhuman Agents:** Key technical hurdles include context
  window limitations (especially for massive codebases exceeding millions of tokens),
  the difficulty of enabling true continual learning within models, and the need for
  multi-modal interaction (e.g., interfacing with logs and running environments).

  *   **Agent Evolution Path:** The immediate next steps involve making the current
  "tap" (over-the-shoulder assistance) and "agent" (delegation) form factors an order
  of magnitude more useful before evolving the interface beyond text boxes entirely.


  ### 3. Business/Investment Angle

  *   **Rapid Growth & Market Validation:** Cursor’s achievement of $100M ARR in 20
  months validates the massive demand for tools that significantly magnify developer
  productivity.

  *   **Product Evolution Strategy:** Cursor’s path is to remain the best way to code
  *with* AI today, while simultaneously evolving that process away from traditional
  programming toward a new paradigm, capturing value at every stage.

  *   **Impact on Adjacent Industries:** Increased developer productivity will dramatically
  accelerate the creation of foundational tools (new frameworks, databases, design
  tools) and enable niche software creation for non-core tech companies (like the
  biotech example provided).


  ### 4. Notable Companies/People

  *   **Michael Trull (CEO, Cursor/Anisphere):** The central voice, outlining the
  vision for intent-driven software creation.

  *   **Co-founders (Swale, Arvid, Amman):** Mentioned as the team that met at MIT
  and shared the ambition to build something transformative.

  *   **GitHub Copilot:** Cited as the pivotal moment in 2021 that demonstrated the
  viability of shipping genuinely useful AI products outside of academic labs.

  *   **OpenAI/DeepMind:** Referenced for their research demonstrating predictable
  scaling laws in model performance.


  ### 5. Future Implications

  The industry is heading toward a future where the "human compilation" step—translating
  high-level intent into low-level code syntax—will largely disappear. Developers
  will transition into **logic designers**, focusing on defining *what* the software
  should achieve and ensuring the high-level "taste" or quality of the implementation.
  This shift will lead to unprecedented productivity gains and a proliferation of
  specialized software solutions across all industries.


  ### 6. Target Audience

  This episode is highly valuable for **AI/ML Engineers, Software Engineering Leaders,
  Venture Capitalists, and Product Managers** focused on developer tooling, infrastructure,
  and the long-term trajectory of AI in knowledge work.'
tags:
- artificial-intelligence
- ai-infrastructure
- startup
- generative-ai
- investment
- google
- openai
- microsoft
title: 'Cursor CEO: Going Beyond Code, Superintelligent AI Agents And Why Taste Still
  Matters'
topics:
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 111
  prominence: 1.0
  topic: artificial intelligence
- keywords:
  - gpu
  - tensor
  - training
  - inference
  - model deployment
  - vector database
  mentions: 19
  prominence: 1.0
  topic: ai infrastructure
- keywords:
  - startup
  - entrepreneur
  - founder
  - venture
  mentions: 11
  prominence: 1.0
  topic: startup
- keywords:
  - generative ai
  - genai
  - chatgpt
  - gpt
  - claude
  - text generation
  - image generation
  mentions: 8
  prominence: 0.8
  topic: generative ai
- keywords:
  - investment
  - funding
  - valuation
  - ipo
  - acquisition
  mentions: 1
  prominence: 0.1
  topic: investment
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-10-05 10:38:17 UTC -->
