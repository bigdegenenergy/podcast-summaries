---
companies:
- category: unknown
  confidence: medium
  context: ell doctors what your body hasn't yet discovered? Today I'm talking to
    Henry Accomal, CEO and co-founder of
  name: Today I
  position: 828
- category: unknown
  confidence: medium
  context: body hasn't yet discovered? Today I'm talking to Henry Accomal, CEO and
    co-founder of Canary Speech, a company t
  name: Henry Accomal
  position: 849
- category: unknown
  confidence: medium
  context: m talking to Henry Accomal, CEO and co-founder of Canary Speech, a company
    turning human voice into one of the mo
  name: Canary Speech
  position: 886
- category: unknown
  confidence: medium
  context: e years ago in a bagel shop. My business partner, Jeff Adams, and I sat
    down for what we thought would be an e
  name: Jeff Adams
  position: 2053
- category: unknown
  confidence: medium
  context: met 40 years earlier. 40 years ago, I was at the National Institutes of
    Health in Bethesda, Maryland, and Jeff was at
  name: National Institutes
  position: 2289
- category: unknown
  confidence: medium
  context: nalysis. Jeff, after leaving the NSA, worked with Ray Kurzweil to develop
    the first natural language processing
  name: Ray Kurzweil
  position: 2748
- category: unknown
  confidence: medium
  context: tools. He then went on and led the team to build Dragon Naturally Speaking,
    which is the most successful medical dictation p
  name: Dragon Naturally Speaking
  position: 2881
- category: tech
  confidence: high
  context: ical dictation platform ever built on the planet. Microsoft purchased Nuance
    about five years ago for 19 and
  name: Microsoft
  position: 2990
- category: tech
  confidence: high
  context: l. He did many other fundamental things. And when Amazon was looking for
    a team to build the Amazon Echo,
  name: Amazon
  position: 3228
- category: unknown
  confidence: medium
  context: d when Amazon was looking for a team to build the Amazon Echo, they simply
    bought the company Jeff was in. And
  name: Amazon Echo
  position: 3271
- category: unknown
  confidence: medium
  context: Echo, they simply bought the company Jeff was in. And Jeff led the team
    to build the Amazon Echo, which we k
  name: And Jeff
  position: 3328
- category: unknown
  confidence: medium
  context: man that spends his entire life doing for others. But I asked him, after
    a career as you have had, what's
  name: But I
  position: 3869
- category: unknown
  confidence: medium
  context: e to the analysis of human condition and disease. And I said, well, why
    don't we do that? And so it the t
  name: And I
  position: 4247
- category: unknown
  confidence: medium
  context: nervous system is making in all of it, you know. So I'm measuring how the
    central nervous system create
  name: So I
  position: 11460
- category: unknown
  confidence: medium
  context: ed, and what are the tonal ranges of those words? Like I can start out
    low and go up very high. So that ha
  name: Like I
  position: 12194
- category: unknown
  confidence: medium
  context: in a partnership with a clinical group, like the Harvard Beth Israel Deaconess
    Medical Center or the National Institutes in Japan and Tallaght
  name: Harvard Beth Israel Deaconess Medical Center
  position: 13963
- category: unknown
  confidence: medium
  context: al Center or the National Institutes in Japan and Tallaght Hospital in
    Ireland. And so different clinical teams that
  name: Tallaght Hospital
  position: 14048
- category: unknown
  confidence: medium
  context: tries. We're working in the UK, in the US, and in South America on different
    diseases, as well as Japan and Asia
  name: South America
  position: 19675
- category: unknown
  confidence: medium
  context: different diseases, as well as Japan and Asia and Saudi Arabia and Al-Bardabia
    and Arabic. So the work is ongoin
  name: Saudi Arabia
  position: 19742
- category: unknown
  confidence: medium
  context: ere and that can assess my level of stress today. Should I go to work or
    should not because I may be yelling
  name: Should I
  position: 22952
- category: unknown
  confidence: medium
  context: Wow, that's great. And it's available in like the App Store and you can
    download it. Yeah, we can download it
  name: App Store
  position: 23109
- category: tech
  confidence: high
  context: ly it's available. It's on every device, Android, Apple, Samsung devices,
    you know, pretty pretty ubiquit
  name: Apple
  position: 23743
- category: unknown
  confidence: medium
  context: amsung is doing the same thing. LG is doing this. Global Med is doing this
    with us. And then a number of hospi
  name: Global Med
  position: 24252
- category: unknown
  confidence: medium
  context: sons and other places. We have been approached by Homeland Security or
    even the airplane industry, you know, where th
  name: Homeland Security
  position: 27328
- category: unknown
  confidence: medium
  context: re very excited about the work we're doing in the Middle East community.
    We're down as I was in Guatemala last
  name: Middle East
  position: 28176
- category: unknown
  confidence: medium
  context: as in Guatemala last week. And we're deploying in South South America.
    The tool is wonderful because a lot of people ar
  name: South South America
  position: 28266
- category: unknown
  confidence: medium
  context: ours need to operate at the same standard that a Cleveland Clinic does
    or that a Beth Israel Deaconess Medical Cent
  name: Cleveland Clinic
  position: 30474
- category: unknown
  confidence: medium
  context: e standard that a Cleveland Clinic does or that a Beth Israel Deaconess
    Medical Center does. And the treats as we do. We, all of our, fr
  name: Beth Israel Deaconess Medical Center
  position: 30506
- category: unknown
  confidence: medium
  context: '''s all the way. We don''t even know why it''s true. So Canary Speech
    doesn''t even know that. The only person who knows'
  name: So Canary Speech
  position: 31547
- category: ai_application
  confidence: high
  context: The company being interviewed, which turns human voice into a diagnostic
    tool using AI to analyze vocal biomarkers for diseases like Parkinson's and Alzheimer's.
  name: Canary Speech
  source: llm_enhanced
- category: research_government
  confidence: high
  context: Jeff Adams worked here building mathematical models for decrypting messages,
    foundational work for speech and language analysis.
  name: NSA
  source: llm_enhanced
- category: research_institution
  confidence: high
  context: Henry Accomal's former workplace where he did research in a neurological
    research group.
  name: National Institutes of Health
  source: llm_enhanced
- category: ai_pioneer
  confidence: high
  context: Jeff Adams worked with him to develop the first natural language processing
    (NLP) and speech-to-text tools.
  name: Ray Kurzweil
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: The company that built Dragon Naturally Speaking (a medical dictation platform),
    which was purchased by Microsoft.
  name: Nuance
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Purchased Nuance for $19.5 billion. Implied involvement in AI/speech technology.
  name: Microsoft
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Bought the company Jeff Adams was in to build the Amazon Echo (Alexa).
  name: Amazon
  source: llm_enhanced
- category: ai_product
  confidence: high
  context: Product built by Jeff Adams' team, powered by AI/speech technology (Alexa).
  name: Amazon Echo
  source: llm_enhanced
- category: ai_product
  confidence: high
  context: The AI assistant powering the Amazon Echo.
  name: Alexa
  source: llm_enhanced
- category: research_institution
  confidence: high
  context: A clinical group Canary Speech partners with to gather patient audio and
    ground truth diagnoses for training algorithms.
  name: Harvard Beth Israel Deaconess Medical Center
  source: llm_enhanced
- category: research_institution
  confidence: high
  context: A clinical partner where Canary Speech published a paper on mild cognitive
    impairment using their voice analysis technology.
  name: National Institutes in Japan
  source: llm_enhanced
- category: research_institution
  confidence: high
  context: A clinical partner Canary Speech works with for diagnosing diseases.
  name: Tallaght Hospital in Ireland
  source: llm_enhanced
- category: ai_technology
  confidence: high
  context: Mentioned generally as a technology used previously to analyze *what* words
    were spoken, contrasting with Canary Speech's focus on *how* words are created.
  name: NLP (Natural Language Processing)
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: The medical dictation platform built by Jeff Adams.
  name: Dragon Naturally Speaking
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: Partnered with Canary Speech for rolling out their technology and mentioned
    as a provider of watches used for audio capture.
  name: Samsung
  source: llm_enhanced
- category: ai_infrastructure
  confidence: medium
  context: Mentioned as a partner rolling out Canary Speech technology.
  name: LG
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: Mentioned as a partner rolling out Canary Speech technology.
  name: Global Med
  source: llm_enhanced
- category: healthcare_organization
  confidence: high
  context: Mentioned as an example of a high-standard healthcare institution whose
    data security level Canary Speech aims to match.
  name: Cleveland Clinic
  source: llm_enhanced
- category: healthcare_organization
  confidence: high
  context: Mentioned as an example of a high-standard healthcare institution whose
    data security level Canary Speech aims to match.
  name: Beth Israel Deaconess Medical Center
  source: llm_enhanced
- category: government_agency
  confidence: medium
  context: Mentioned as an entity that approached Canary Speech regarding the application
    of their aggression monitoring model.
  name: Homeland Security
  source: llm_enhanced
date: 2025-10-12 21:11:51 +0000
duration: 49
has_transcript: false
insights:
- actionable: false
  confidence: medium
  extracted: early detection and mental health. It's a fascinating look at the intersection
    of AI, medicine, and humanity, and the reminder that innovation often begins with
    a simple conversation. Please let me know what you think in the comments. I'd
    love to hear your thoughts. And now you can enjoy the conversation. Welcome to
    an hour on innovation, Henry. Thank you for your time today. Well, thank you.
    It's a delight to be here with you. Yeah, sure. Okay, so before we jump into the
    conversation, can you tell a little bit about your background and how you started
    your company? Well, thank you. The company itself started seven, nine years ago
    in a bagel shop. My business partner, Jeff Adams, and I sat down for what we thought
    would be an extended lunch, ended up being about eight hours of time together.
    But the story goes back a number of years because Jeff and I met 40 years earlier.
    40 years ago, I was at the National Institutes of Health in Bethesda, Maryland,
    and Jeff was at the NSA. I was doing research in a neurological research group.
    Jeff was doing work for our country building mathematical models that would decrypt
    spine messages, something he'd still be there, to be honest, if he could be. But
    that work, that mathematical work that he was doing
  text: the future of early detection and mental health. It's a fascinating look at
    the intersection of AI, medicine, and humanity, and the reminder that innovation
    often begins with a simple conversation. Please let me know what you think in
    the comments. I'd love to hear your thoughts. And now you can enjoy the conversation.
    Welcome to an hour on innovation, Henry. Thank you for your time today. Well,
    thank you. It's a delight to be here with you. Yeah, sure. Okay, so before we
    jump into the conversation, can you tell a little bit about your background and
    how you started your company? Well, thank you. The company itself started seven,
    nine years ago in a bagel shop. My business partner, Jeff Adams, and I sat down
    for what we thought would be an extended lunch, ended up being about eight hours
    of time together. But the story goes back a number of years because Jeff and I
    met 40 years earlier. 40 years ago, I was at the National Institutes of Health
    in Bethesda, Maryland, and Jeff was at the NSA. I was doing research in a neurological
    research group. Jeff was doing work for our country building mathematical models
    that would decrypt spine messages, something he'd still be there, to be honest,
    if he could be. But that work, that mathematical work that he was doing is fundamental
    to and foundational to speech and language analysis.
  type: prediction
layout: episode
llm_enhanced: true
original_url: https://audio.listennotes.com/e/p/19e3263ee4f345fab83dfa1e4454226c/
processing_date: 2025-10-16 05:15:06 +0000
quotes:
- length: 84
  relevance_score: 4
  text: What had been done before was using speech-detached NLP, natural language
    processing
  topics: []
- length: 111
  relevance_score: 3
  text: I know you mentioned that you have, like, top-level security and whatever
    protocols you have to, you have to do
  topics: []
- length: 132
  relevance_score: 3
  text: There are certain credentials and certain responsibilities you have to take
    seriously if you want to be a good partner in healthcare
  topics: []
- impact_reason: This highlights the massive data density advantage of their approach
    (15M data points/min) compared to traditional NLP (110 data points/min) for diagnostics,
    suggesting a paradigm shift in data utilization for health monitoring.
  relevance_score: 10
  source: llm_enhanced
  text: All the diseases I mentioned, all of those health conditions I mentioned,
    every one of them, any one of them, or every one of them could be measured in
    the same 40 seconds. By looking at the central nervous system, we're looking at
    15 million data elements a minute where NLP is producing about 110 data elements
    a minute.
  topic: technical/AI trends
- impact_reason: This is the core, high-level value proposition of the technology—using
    voice as a leading, pre-symptomatic diagnostic indicator, which is highly impactful
    for early disease detection.
  relevance_score: 10
  source: llm_enhanced
  text: What if your voice could tell doctors what your body hasn't yet discovered?
  topic: predictions/business
- impact_reason: This is the fundamental technical pivot that differentiates their
    work from standard NLP/speech analysis. They focus on the motor function/neurological
    process rather than the semantic content.
  relevance_score: 10
  source: llm_enhanced
  text: We actually looked at not what people speak, but how the central nervous system
    creates language.
  topic: technical/strategy
- impact_reason: Directly contrasts their method with prior art (NLP focused on word
    content) and explains the underlying biological rationale for their success.
  relevance_score: 10
  source: llm_enhanced
  text: The previous work had been measuring what words were actually created. But
    it's not how it's created. It's created with the central nervous system. And the
    central nervous system is impacted by a whole range of different types of illnesses
    and diseases.
  topic: technical/strategy
- impact_reason: Suggests that the underlying neurological biomarkers they measure
    are universal across languages, offering massive scalability and reducing localization
    costs for global deployment.
  relevance_score: 10
  source: llm_enhanced
  text: If I build an algorithm for Alzheimer's disease in English and I go to Japan
    with it, I validate that model there, but the algorithm is very, very, very, very
    much the same.
  topic: strategy/scalability
- impact_reason: This is the core technical insight, defining the specific acoustic
    biomarkers (vibrational characteristics, speed changes, recovery) being analyzed,
    moving beyond simple speech content.
  relevance_score: 10
  source: llm_enhanced
  text: So we're measuring elements of the vibrational characteristics of the vocal
    cords, which relate to their actual speed of motion, but also how fast that speed
    is changing and how quickly that speed recovers. Those can tell us things about
    a disease state that are specific to and are identifiers, cues of a particular
    disease.
  topic: technical
- impact_reason: 'This is a crucial strategic insight: the biomarkers are physiological/neurological,
    not linguistic, allowing for cross-cultural/cross-language model transferability,
    a major advantage over language-dependent AI.'
  relevance_score: 10
  source: llm_enhanced
  text: However, the biomarkers that we're looking at, the vibrational characteristics
    of how languages form in the element of the vocal cords and how the central nervous
    system controls that, that's common across all populations.
  topic: strategy
- impact_reason: Demonstrates extreme efficiency and breadth of diagnostic capability
    (multiple conditions measured in 40 seconds), a major technological breakthrough
    in real-time analysis.
  relevance_score: 10
  source: llm_enhanced
  text: Forty seconds after we do it, milliseconds after a 40-second sample, they're
    getting a range of different things. All the diseases I mentioned, all of those
    health conditions I mentioned, every one of them, any one of them or every one
    of them could be measured in the same 40 seconds.
  topic: technical/breakthroughs
- impact_reason: Details specific, high-level security and compliance standards (ISO
    27001/42001) required for operating in sensitive healthcare environments, offering
    a blueprint for data governance.
  relevance_score: 10
  source: llm_enhanced
  text: The data that we capture is de-identified. The information that we have is
    processed, it flows to us in an encrypted file, is processing and returned in
    an encrypted file, functioning at a high trust level and functioning at both the
    ISO standards 27001 and 42001...
  topic: technical/safety
- impact_reason: Provides specific technical detail on the granularity and speed of
    their feature extraction (2548 features, 10ms interval), showcasing the complexity
    and real-time capability of the AI model.
  relevance_score: 9
  source: llm_enhanced
  text: We're looking at 2,548 features in speech, every 10 milliseconds, and we process
    that in real time, in conversational communication.
  topic: technical
- impact_reason: 'Clearly defines the company''s strategic role: early warning system
    for clinical decision support, framing their business model around proactive health
    intervention.'
  relevance_score: 9
  source: llm_enhanced
  text: Canary in the coal mine is the concept. We want to be an early warning sign.
    We want to provide information to clinical teams that can help them in the process
    of determining and diagnosing illness.
  topic: business/strategy
- impact_reason: Lists the specific, high-value medical targets for their diagnostic
    technology, emphasizing the focus on debilitating neurological conditions.
  relevance_score: 9
  source: llm_enhanced
  text: 'The most obvious ones are progressive neurological diseases: Huntington''s,
    Parkinson''s, MS, Alzheimer''s, myocognitive impairment, all of these progressive
    neurological diseases impact on our ability to speak.'
  topic: predictions/applications
- impact_reason: Uses vivid analogy to explain why their high-density data stream
    is superior for ML training compared to sparse, word-based data sets.
  relevance_score: 9
  source: llm_enhanced
  text: By looking at the central nervous system, we were looking at 15 million data
    elements a minute where NLP is producing about 110 data elements a minute. Machine
    learning wants a big data set, it laughs about 110 words. It doesn't care at all
    about that. But if you give it 15 million, it's like you're picking mud, you know,
    it's swinging around, it's enjoying itself.
  topic: technical/AI trends
- impact_reason: Provides the precise technical specifications for data collection
    (40 seconds yields 12-15M elements), which is crucial for understanding the scale
    of their ML input.
  relevance_score: 9
  source: llm_enhanced
  text: We look at 2,548 features in speech, every 10 milliseconds... We do that for
    40 seconds is a normal sample for us. About 12 to 15 million data elements are
    collected in that time.
  topic: technical
- impact_reason: Indicates advanced signal processing techniques (using derivatives)
    to capture the *rate of change* of the biomarkers, which is often more indicative
    of neurological decline than static measurements.
  relevance_score: 9
  source: llm_enhanced
  text: We look at, in every case we look at, first and second and third order derivatives
    of that because those reflect how they're changing over time.
  topic: technical
- impact_reason: Predicts the future integration of this technology into ubiquitous
    wearable devices (smartwatches) for continuous, passive monitoring and feedback
    loops.
  relevance_score: 9
  source: llm_enhanced
  text: You could actually use the SAMHson watch to capture the audio and give a response
    that could either go to your doctor or come back to you.
  topic: predictions/deployment
- impact_reason: 'Clearly outlines the ML pipeline: massive feature extraction followed
    by supervised learning against expert clinical ground truth to generate diagnostic
    algorithms.'
  relevance_score: 9
  source: llm_enhanced
  text: We then extract all these features, 12 to 15 million features. And we use
    machine learning to correlate those features, that feature set with the diagnosis
    and the labels, if you will, that the doctor and clinical team gave us. That correlation
    becomes an algorithm.
  topic: technical
- impact_reason: Provides concrete evidence supporting the cross-population claim,
    demonstrating the robustness and universality of their physiological AI models
    across different languages (English to Japanese).
  relevance_score: 9
  source: llm_enhanced
  text: So if I build an algorithm for Alzheimer's disease in English, and I go to
    Japan with it, I validate that model there, but the algorithm is very, very, very,
    very much the same. Because the Alzheimer's and the damage to the central nervous
    system and how language is impaired, even though it's Japanese versus English,
    we see that the algorithms are very close.
  topic: predictions/strategy
- impact_reason: Highlights the platform flexibility and ubiquity of data capture
    (omnichannel deployment), crucial for continuous monitoring and adoption.
  relevance_score: 9
  source: llm_enhanced
  text: So pretty much wherever you can capture audio and process that to the web...
    we're having right now, or over a telephone, or in a clinic in a smartphone, or
    at home using that app... we also capture audio using Samsung watches.
  topic: deployment
- impact_reason: Clearly defines the product's role as a Clinical Decision Support
    (CDS) tool, which is crucial for regulatory and adoption strategy in healthcare
    AI.
  relevance_score: 9
  source: llm_enhanced
  text: this is to help doctors diagnose the condition, right? It's not like providing
    treatment suggestions or anything like that. So our product is considered a clinical
    decision support tool in the space of things that doctors would have in their
    hands.
  topic: business/strategy
- impact_reason: 'Articulates the value proposition of AI in this context: not replacing
    human expertise, but providing objective validation for trained human intuition
    (pattern recognition).'
  relevance_score: 9
  source: llm_enhanced
  text: What we're doing is validating what they're hearing. And so they have for
    years been experts at picking up those cues. They've trained themselves to do
    that. And what we're doing is giving them an objective ability to do that that
    they just hold in their hands.
  topic: strategy/adoption
- impact_reason: Emphasizes the strategic decision to tackle the most difficult sector
    (healthcare) first, implying that success here validates the technology for all
    other sectors.
  relevance_score: 9
  source: llm_enhanced
  text: We're pretty focused right now on on the medical application area. It's the
    hardest area to be there. You know, the requirements are higher. The bar is higher.
    The data security requirements are the highest in the world.
  topic: strategy
- impact_reason: 'A concise summary of their privacy architecture: strict separation
    of identification data from analytical data, ensuring patient anonymity from the
    AI provider.'
  relevance_score: 9
  source: llm_enhanced
  text: The only person who knows who is related to the sample that we got is the
    doctor you're sitting with.
  topic: safety/privacy
- impact_reason: Highlights the pedigree of the team and their direct involvement
    in creating mainstream, successful voice AI products (Alexa), linking past success
    to current innovation.
  relevance_score: 8
  source: llm_enhanced
  text: And when Amazon was looking for a team to build the Amazon Echo, they simply
    bought the company Jeff was in. And Jeff led the team to build the Amazon Echo,
    which we know is Alexa.
  topic: business/history
- impact_reason: Provides a clear, accessible analogy for how complex motor functions
    underpin speech, justifying why analyzing these physical aspects can reveal neurological
    health issues.
  relevance_score: 8
  source: llm_enhanced
  text: The central nervous system is controlling the vocal cords, the power of our
    respiration, the rate of our respiration, the duration of our respiration, how
    we move our tongue, our cheeks, our mouth. All of those things are the orchestra
    of speech. And the central nervous system is the conductor.
  topic: technical/explanation
- impact_reason: Highlights the necessity of breaking established norms in the field
    (unlearning traditions) and the requirement for real-world, conversational data
    for effective biomarker detection.
  relevance_score: 8
  source: llm_enhanced
  text: We had to unlearn those things [traditions in speech pathology] and we learned
    that by experimentation and we realized that we needed conversational students
    where you and I could be on this call, I could be talking, you could be in the
    role of a clinician and at the same time, analyzing my speech. It didn't matter
    what I spoke about because my central nervous system is making in all of it.
  topic: strategy/technical
- impact_reason: Gives concrete examples of the low-level physical features being
    measured (vibrational characteristics, speed changes, recovery time) that serve
    as disease identifiers.
  relevance_score: 8
  source: llm_enhanced
  text: We're measuring elements of the vibrational characteristics of the vocal cords,
    which relate to their actual speed of motion, but also how fast that speed is
    changing and how quickly that speed recovers. Those can tell us things about a
    disease state that are specific to and are identifiers, cues of a particular disease.
  topic: technical
- impact_reason: Shows the breadth of mental and emotional states that their voice
    analysis can potentially quantify, extending beyond purely physical diseases.
  relevance_score: 8
  source: llm_enhanced
  text: We're monitoring things like depression and anxiety, but we're also monitoring
    levels of aggression in the room.
  topic: applications/predictions
- impact_reason: Defines the broad scope and current focus areas of the company's
    AI application across neurology, cognition, mental health, and pediatrics.
  relevance_score: 8
  source: llm_enhanced
  text: So today, broadly speaking, we're working in four areas. Progressive neurological
    diseases... and the cognitive area... and then in the behavioral health area...
    And the fourth area is childhood diseases...
  topic: business
- impact_reason: Signals a strategic shift from episodic clinical testing to continuous,
    remote patient monitoring, a major trend in digital health AI.
  relevance_score: 8
  source: llm_enhanced
  text: However, we are going home with patients now. So we're taking point-to-point
    care to a more continuous care monitoring system.
  topic: strategy
- impact_reason: A powerful summary of the technology's potential reach—making health
    monitoring passive and ambient, integrated into daily life.
  relevance_score: 8
  source: llm_enhanced
  text: Speech is ubiquitous, it's everywhere. And wherever it's occurring in a conversation
    with someone or if you're doing it by yourself in your home, Canary Speech could
    actually with your permission, Canary Speech could be measuring your health?
  topic: predictions
- impact_reason: Indicates significant validation and integration partnerships with
    major technology and healthcare infrastructure providers (Microsoft, Samsung,
    LG), signaling market traction.
  relevance_score: 8
  source: llm_enhanced
  text: Microsoft has partnered with us to roll this out with their healthcare systems
    that they offer and support in hospitals. Samsung is doing the same thing. LG
    is doing this. Global Med is doing this with us.
  topic: business
- impact_reason: 'Defines the precise regulatory/clinical role of the AI: it is a
    decision support tool, not an autonomous diagnostic system, drawing an analogy
    to established medical aids.'
  relevance_score: 8
  source: llm_enhanced
  text: So our product is considered a clinical decision support tool in the space
    of things that doctors would have in their hands. And another obvious clinical
    decision support tool is like a drug pressure club, you know, right?
  topic: strategy/regulation
- impact_reason: Highlights the product's ease of integration and non-intrusive nature,
    key selling points for clinical adoption against more complex diagnostic methods.
  relevance_score: 8
  source: llm_enhanced
  text: We're giving of the multitude of information, the array of information a doctor
    or clinician has, clinical team member has to make a diagnosis. We're one of those
    pieces. We just happen to be a very easy one. It's non-invasive. It's non-intrusive.
  topic: business/strategy
- impact_reason: Shows clear cross-industry applicability of the core technology (aggression/agitation
    detection) beyond the initial medical focus, indicating broader market potential.
  relevance_score: 8
  source: llm_enhanced
  text: We do with our aggression model which has its application in healthcare. It
    also has applications in places like, you know, dangerous environments like prisons
    and other places. We have been approached by Homeland Security or even the airplane
    industry...
  topic: business/predictions
- impact_reason: Highlights the role of AI in democratizing healthcare access, especially
    in remote or underserved areas where clinical resources are scarce.
  relevance_score: 8
  source: llm_enhanced
  text: Our tool offers to provide a, in a much richer amount of information for a
    clinical person to be able to make a decision about a patient. And that's important.
    Reaching individuals, regardless of where they are in the world.
  topic: predictions/social impact
- impact_reason: Offers a fascinating perspective on the potential for AI in interspecies
    communication, suggesting that complex language modeling is feasible across species,
    given enough data.
  relevance_score: 8
  source: llm_enhanced
  text: dogs have 200 plus words or 200 plus things it communicates through language,
    dog language if you will. Dolphins probably have more words than we do. And so,
    there's no question at all that one could build a model to recognize what the
    dog is communicating and translate that.
  topic: predictions/technical
- impact_reason: Establishes the deep, foundational credibility of the co-founder
    in the history of NLP and speech technology, lending weight to their novel approach.
  relevance_score: 7
  source: llm_enhanced
  text: Jeff, after leaving the NSA, worked with Ray Kurzweil to develop the first
    natural language processing tools, speech to text tools. He then went on and led
    the team to build Dragon Naturally Speaking, which is the most successful medical
    dictation platform ever built on the planet.
  topic: business/history
- impact_reason: Expands the scope of biomarkers beyond just the vocal cords to include
    respiratory mechanics (lungs) and specific acoustic phenomena (jitter/flutter),
    showing comprehensive analysis.
  relevance_score: 7
  source: llm_enhanced
  text: Additionally, we have our lungs contribute to it and the speed of our lungs,
    the power of our lungs... There are things like jitter that tie into jitter and
    flutter that tie into different elements of speech. These are the biomarkers we're
    looking at.
  topic: technical
- impact_reason: Shows the breadth of ongoing R&D and validation efforts, indicating
    a pipeline beyond the initially launched products.
  relevance_score: 7
  source: llm_enhanced
  text: 'We currently have 16 current clinical studies: PTSD, pulmonary tract infections,
    COPD, the autistic and ADHD, as well as some additional fine-tuning Parkinson''s
    and Alzheimer''s disease.'
  topic: business
- impact_reason: Clarifies the current B2B/B2G business model (controlled deployment
    via specific organizational partners) rather than a direct-to-consumer app, despite
    the technology's ubiquity.
  relevance_score: 7
  source: llm_enhanced
  text: We don't we don't sell it to the general public right now, but there are organizations
    and teams, veterans for instance, that are using it. We build a specific deployment
    of it unique to them.
  topic: business
- impact_reason: Provides the strong ethical and personal motivation behind the company's
    mission, connecting technology development to fundamental human rights and global
    equity.
  relevance_score: 7
  source: llm_enhanced
  text: My personal feelings about this is that, regardless of where a person by chance
    happened to be born in the world, they still should have good healthcare. They
    should have good food. They should have good education.
  topic: safety/ethics
- impact_reason: Indicates a strategic move toward platformization and ecosystem building
    by offering API access, potentially accelerating broader innovation using their
    core technology.
  relevance_score: 7
  source: llm_enhanced
  text: We are looking to try to create an open source resource so that people, if
    they want to use our capability, say, could just use our APIs and do whatever
    they want.
  topic: business/strategy
source: Unknown Source
summary: '## Podcast Episode Summary: The Future of Medicine! AI That Listens to Your
  Voice for Early Disease Detection | Henry O’Connell


  This 48-minute episode features Henry O’Connell, CEO and co-founder of **Canary
  Speech**, detailing their groundbreaking work in leveraging vocal biomarkers for
  early disease detection across neurological, cognitive, and behavioral health conditions.
  The core narrative centers on shifting the focus from *what* is said (Natural Language
  Processing/NLP) to *how* it is said, analyzing the underlying mechanics controlled
  by the central nervous system.


  ### 1. Focus Area

  The primary focus is the **application of advanced AI/Machine Learning to speech
  analysis for medical diagnostics**. Specifically, the discussion centers on extracting
  **2,548 distinct vocal biomarkers** every few milliseconds to identify subtle impairments
  caused by diseases like Parkinson''s, Alzheimer''s, depression, and autism, long
  before overt symptoms manifest.


  ### 2. Key Technical Insights

  *   **Central Nervous System (CNS) Focus:** Canary Speech analyzes the mechanics
  of speech production (vocal cord vibration, respiration power/rate, tongue/mouth
  movement) as a direct reflection of CNS health, rather than relying on NLP''s analysis
  of word choice (which yields far less data—110 data elements/min vs. Canary''s 15
  million data elements/min over 40 seconds).

  *   **High-Density Biomarker Extraction:** The technology captures 2,548 features
  every 10 milliseconds over a 40-second conversational sample, generating 12–15 million
  data points per test. This high density is crucial for training robust machine learning
  models.

  *   **Language Transcendent Algorithms:** Because the underlying mechanics of CNS
  control over speech are universal, algorithms trained for diseases like Alzheimer''s
  in one language (e.g., English) are highly transferable and require only validation,
  not complete retraining, for other languages (e.g., Japanese, Arabic).


  ### 3. Business/Investment Angle

  *   **Clinical Decision Support (CDS) Tool:** Canary Speech positions itself as
  a non-invasive, easy-to-use CDS tool, providing objective data to clinicians to
  aid in diagnosis, similar to a blood pressure cuff.

  *   **Ubiquitous Data Capture:** The technology is deployable across nearly any
  audio capture point—video conferences, phone calls, smartphones, and wearables (specifically
  mentioning Samsung watches)—facilitating continuous, passive monitoring.

  *   **Strategic Partnerships:** The company is scaling rapidly through partnerships
  with major tech and healthcare entities, including **Microsoft Healthcare Systems,
  Samsung, and LG**, indicating strong commercial validation and integration into
  existing infrastructure.


  ### 4. Notable Companies/People

  *   **Henry O’Connell (CEO/Co-founder):** The interviewee, driving the vision for
  meaningful application of speech technology.

  *   **Jeff Adams (Co-founder):** A speech technology pioneer with a foundational
  background at the NSA, who led the development of **Dragon Naturally Speaking**
  (Nuance) and the **Amazon Echo (Alexa)**. His expertise provided the mathematical
  foundation for the company.

  *   **Canary Speech:** The company focused on applying speech analysis to human
  condition and disease detection.

  *   **Clinical Partners:** Mentioned partners include **Harvard Beth Israel Deaconess
  Medical Center** and the **National Institutes in Japan**, providing the "ground
  truth" diagnoses necessary for model training.


  ### 5. Future Implications

  The conversation suggests a future where routine conversation, captured passively
  via ubiquitous devices (smartwatches, home systems), serves as a continuous health
  monitor. This moves healthcare from episodic testing to **continuous care monitoring**,
  enabling the detection of neurological and mental health decline at the earliest,
  pre-symptomatic stages. Furthermore, the technology is being adapted for patient
  safety monitoring in hospitals (tracking aggression levels) and for early detection
  in children (ADHD, autism).


  ### 6. Target Audience

  This episode is highly valuable for **AI/ML professionals, HealthTech investors,
  clinical researchers, and healthcare executives** interested in digital biomarkers,
  non-invasive diagnostics, and the commercialization path for deep-tech medical applications.'
tags:
- artificial-intelligence
- startup
- investment
- microsoft
- apple
title: The Future of Medicine! AI That Listens to Your Voice for Early Disease Detection
  | Henry O’Connell
topics:
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 42
  prominence: 1.0
  topic: artificial intelligence
- keywords:
  - startup
  - entrepreneur
  - founder
  - venture
  mentions: 1
  prominence: 0.1
  topic: startup
- keywords:
  - investment
  - funding
  - valuation
  - ipo
  - acquisition
  mentions: 1
  prominence: 0.1
  topic: investment
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-10-16 05:15:06 UTC -->
