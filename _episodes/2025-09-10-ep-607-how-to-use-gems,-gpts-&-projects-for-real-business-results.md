---
companies:
- category: unknown
  confidence: medium
  context: This is the Everyday AI Show, the everyday podcast where we simplify AI
    and br
  name: Everyday AI Show
  position: 12
- category: tech
  confidence: high
  context: ton of time by not knowing how to use things like Google's Gems, OpenAI's
    ChatGPTs, GPTs, and Claude's pro
  name: Google
  position: 575
- category: tech
  confidence: high
  context: not knowing how to use things like Google's Gems, OpenAI's ChatGPTs, GPTs,
    and Claude's projects and OpenA
  name: Openai
  position: 590
- category: unknown
  confidence: medium
  context: to be talking about that today and a lot more on Everyday AI. What's going
    on, y'all? My name's Jordan Wilson,
  name: Everyday AI
  position: 1214
- category: unknown
  confidence: medium
  context: on Everyday AI. What's going on, y'all? My name's Jordan Wilson, and welcome
    to Everyday AI. This is your daily l
  name: Jordan Wilson
  position: 1261
- category: unknown
  confidence: medium
  context: ake sure to check that out in today's newsletter. But I really want to
    talk about these recent changes to
  name: But I
  position: 2337
- category: unknown
  confidence: medium
  context: penAI, some updates to OpenAI's projects feature, Google Gems, and Claude's
    projects. Because if you are just g
  name: Google Gems
  position: 2461
- category: unknown
  confidence: medium
  context: Sometimes things work well. Sometimes they don't. And I want you all to
    see the realness because if you j
  name: And I
  position: 5198
- category: unknown
  confidence: medium
  context: re choosing to do this one audio only. All right. So I'm going to share
    my screen right now, and all I'm
  name: So I
  position: 5700
- category: unknown
  confidence: medium
  context: reen right now, and all I'm going to do, I have a Google Gem, a ChatGPT
    custom GPT, a GPT project, and a Claud
  name: Google Gem
  position: 5777
- category: unknown
  confidence: medium
  context: d I even name these the same. They're just called Everyday AI All Stats
    June 2025. All right. I'm going to put this prompt in.
  name: Everyday AI All Stats June
  position: 6211
- category: unknown
  confidence: medium
  context: All right. So now my Google Gem is often running. Now I am in my ChatGPT
    custom GPT, and I'm using the O3
  name: Now I
  position: 6374
- category: unknown
  confidence: medium
  context: s going to use Sonnet, but let's go ahead and use Claude Opus 4, which
    is their most powerful model. And I do h
  name: Claude Opus
  position: 6786
- category: unknown
  confidence: medium
  context: ail is info@youreverydayai.com, so you know, it's Google Workspace. So
    if I go in there, I have access to all my Wor
  name: Google Workspace
  position: 12041
- category: unknown
  confidence: medium
  context: 'access to all my Workspace apps, which is great: Google Drive, Google
    Docs, Gmail, Calendar, etc. It''s all in t'
  name: Google Drive
  position: 12136
- category: unknown
  confidence: medium
  context: 'my Workspace apps, which is great: Google Drive, Google Docs, Gmail, Calendar,
    etc. It''s all in there, which i'
  name: Google Docs
  position: 12150
- category: unknown
  confidence: medium
  context: to more. You have access to things like YouTube, YouTube Music, Google
    Flights, you know, just some things that
  name: YouTube Music
  position: 12599
- category: unknown
  confidence: medium
  context: ave access to things like YouTube, YouTube Music, Google Flights, you know,
    just some things that you don't have a
  name: Google Flights
  position: 12614
- category: unknown
  confidence: medium
  context: s to if you're using a Workspace plan. All right. So Google Gem, again,
    think of it like a personalized, customiz
  name: So Google Gem
  position: 12732
- category: unknown
  confidence: medium
  context: ogle Workspace apps. All right. Let's go to GPTs. So GPTs were just updated
    a couple of days ago, and this
  name: So GPTs
  position: 12904
- category: unknown
  confidence: medium
  context: d reason like Gemini 2.5 Pro or like, you know, a Claude Sonnet or a Claude
    Opus 4, we were still stuck using GPT
  name: Claude Sonnet
  position: 13566
- category: unknown
  confidence: medium
  context: e because there's it's a folder structure, right? Whereas GPTs and Gems,
    not really. So people think projects ar
  name: Whereas GPTs
  position: 14592
- category: unknown
  confidence: medium
  context: Canvas, but you can inside projects. You can use ChatGPT Canvas, and you
    can use Claude's Artifacts, which are ki
  name: ChatGPT Canvas
  position: 15753
- category: unknown
  confidence: medium
  context: but also having that memory across the projects. On Anthropic's project
    side, you have access to your Gmail. So
  name: On Anthropic
  position: 16100
- category: tech
  confidence: high
  context: t also having that memory across the projects. On Anthropic's project side,
    you have access to your Gmail. So
  name: Anthropic
  position: 16103
- category: unknown
  confidence: medium
  context: st the different integrations. So you have Gmail, Google Calendar, Google
    Drive, but then you have MCP, their Model
  name: Google Calendar
  position: 16215
- category: unknown
  confidence: medium
  context: endar, Google Drive, but then you have MCP, their Model Context Protocol.
    So this is something, again, a very underlooked
  name: Model Context Protocol
  position: 16275
- category: unknown
  confidence: medium
  context: veryone, David here, one of the product leads for Google Gemini. Check
    out VO3, our state-of-the-art AI video gen
  name: Google Gemini
  position: 16868
- category: unknown
  confidence: medium
  context: ideos with native audio generation. Try it with a Google AI Pro plan or
    get the highest access with the Ultra pla
  name: Google AI Pro
  position: 17063
- category: unknown
  confidence: medium
  context: ore, but can't really get traction to find ROI on Gen AI. Hey, this is
    Jordan Wilson, host of this very po
  name: Gen AI
  position: 17426
- category: tech
  confidence: high
  context: host of this very podcast. Companies like Adobe, Microsoft, and Nvidia
    have partnered with us because they t
  name: Microsoft
  position: 17511
- category: tech
  confidence: high
  context: ery podcast. Companies like Adobe, Microsoft, and Nvidia have partnered
    with us because they trust our exp
  name: Nvidia
  position: 17526
- category: unknown
  confidence: medium
  context: t can find the obvious things in all of my files. Then I'm asking for 10
    of the most impactful stats or tr
  name: Then I
  position: 19062
- category: unknown
  confidence: medium
  context: All right. So here's what I uploaded. I uploaded Google Search Console
    data for different terms that are bringing traffi
  name: Google Search Console
  position: 20600
- category: unknown
  confidence: medium
  context: erent actually three different kind of files from Google Analytics. So
    everything that's happening on the your every
  name: Google Analytics
  position: 20859
- category: unknown
  confidence: medium
  context: t has the content of all of those emails as well. So Claude couldn't handle
    it, but we have that as well. And
  name: So Claude
  position: 21680
- category: unknown
  confidence: medium
  context: because I've been looking at it for a long time. If I were to hire a consultant,
    it would take them for
  name: If I
  position: 22047
- category: unknown
  confidence: medium
  context: l 10. Good. And the creative ideas got me all 10. So Google on their Gems
    side passed the test. And the good
  name: So Google
  position: 26839
- category: tech
  confidence: high
  context: it thought. So actually, if you want to get super meta, probably what I'm
    going to do is I'm going to up
  name: Meta
  position: 27542
- category: unknown
  confidence: medium
  context: u don't really know how they're going to respond. Generative AI is generative.
    It's going to be different every s
  name: Generative AI
  position: 28372
- category: unknown
  confidence: medium
  context: igure it out." Right? "Figure it out." All right. So Gemini and their Gems,
    at least passed the test. All rig
  name: So Gemini
  position: 29492
- category: unknown
  confidence: medium
  context: nable to open any of the data files you uploaded. The Python environment
    that normally lets me read and analyz
  name: The Python
  position: 30505
- category: unknown
  confidence: medium
  context: ning empty results for every file access attempt. Because I cannot inspect
    the underlying numbers, I would ha
  name: Because I
  position: 30647
- category: unknown
  confidence: medium
  context: t work. So that's interesting here. A little bug. Like I said, these new
    updated GPTs have only been out f
  name: Like I
  position: 32805
- category: unknown
  confidence: medium
  context: AI is fun. Yeah. All right. So exact same thing. When I ran this last night
    in the projects, and it worke
  name: When I
  position: 34215
- category: unknown
  confidence: medium
  context: e go. All right. So Claude did a pretty good job. Although I'm going to
    have to go be the judge and see which
  name: Although I
  position: 37580
- category: unknown
  confidence: medium
  context: l. And hey, just comment what should you comment? Comment Gemini. All
  name: Comment Gemini
  position: 39397
- category: big_tech
  confidence: high
  context: Mentioned as the provider of Google Gems and Gemini models, and as a sponsor
    of the podcast.
  name: Google
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: A specific personalized/customized AI chatbot feature provided by Google,
    utilizing the Gemini model.
  name: Google's Gems
  source: llm_enhanced
- category: ai_company
  confidence: high
  context: The creator of ChatGPT, GPTs, and the underlying models (GPT-3.5, GPT-4,
    GPT-4o).
  name: OpenAI
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Customizable versions of ChatGPT created by users, now supporting newer
    models.
  name: OpenAI's ChatGPTs
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: A feature within ChatGPT, often associated with folder structure and advanced
    capabilities like Canvas mode and deep research.
  name: OpenAI's projects
  source: llm_enhanced
- category: ai_company
  confidence: high
  context: The AI chatbot/model family developed by Anthropic (mentioned via its projects
    and models like Sonnet and Opus 4).
  name: Claude
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: A feature within Claude, similar to ChatGPT projects, offering organization
    and access to integrations like Gmail and MCP.
  name: Claude's projects
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: The primary chatbot interface from OpenAI being compared against competitors.
  name: ChatGPT
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: Mentioned generally as one of the AI chatbots people use on the web.
  name: Copilot
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: Mentioned generally as one of the AI tools people use on the web.
  name: Mattermost
  source: llm_enhanced
- category: ai_company
  confidence: high
  context: The company behind Claude, mentioned in relation to its project features
    and models (Opus 4, Sonnet).
  name: Anthropic
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: The enterprise suite from Google, whose apps (Drive, Docs, Gmail, Calendar)
    integrate with Google Gems.
  name: Google Workspace
  source: llm_enhanced
- category: ai_model
  confidence: high
  context: The underlying model family used by Google Gems (specifically Gemini 2.5
    Pro mentioned).
  name: Gemini
  source: llm_enhanced
- category: ai_model
  confidence: high
  context: The specific, powerful model version used by the speaker for Google Gems.
  name: Gemini 2.5 Pro
  source: llm_enhanced
- category: ai_model
  confidence: medium
  context: Referred to as GPT-4o (or a similar high-end OpenAI model) used within
    ChatGPT custom GPTs.
  name: O3 model
  source: llm_enhanced
- category: ai_model
  confidence: medium
  context: Referred to as GPT-4o Pro (or a similar high-end OpenAI model) used within
    ChatGPT custom GPTs and projects.
  name: O3 Pro
  source: llm_enhanced
- category: ai_model
  confidence: high
  context: One of the models offered by Anthropic, mentioned for comparison.
  name: Claude Sonnet
  source: llm_enhanced
- category: ai_model
  confidence: high
  context: Anthropic's most powerful model mentioned, used by the speaker in the live
    demo.
  name: Claude Opus 4
  source: llm_enhanced
- category: personnel_mention
  confidence: high
  context: Mentioned as one of the product leads for Google Gemini, introducing a
    sponsor segment.
  name: David
  source: llm_enhanced
- category: ai_model
  confidence: high
  context: Mentioned as Google's state-of-the-art AI video generation model within
    the Gemini app.
  name: VO3
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Mentioned as the product lead's affiliation and the technology powering
    Google Gems, specifically referencing the Gemini 2.5 Pro model.
  name: Google Gemini
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Referenced via the Google AI Pro plan for accessing the VO3 video generation
    model.
  name: Google AI
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Mentioned as a company that partners with the podcast host for Gen AI education
    and strategy.
  name: Microsoft
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: Mentioned as a company that partners with the podcast host for Gen AI education
    and strategy.
  name: Nvidia
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: Mentioned as a company that partners with the podcast host for Gen AI education
    and strategy.
  name: Adobe
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: The podcast/company hosting the discussion, which uses various AI tools
    and analyzes its own data.
  name: Everyday AI
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Another large language model being tested, developed by Google AI (implied,
    as Gemini is Google's model family).
  name: Gemini 2.5
  source: llm_enhanced
date: 2025-09-10 13:00:00 +0000
duration: 49
has_transcript: false
insights:
- actionable: true
  confidence: medium
  extracted: be using these AI chatbots
  text: we should be using these AI chatbots.
  type: recommendation
layout: episode
llm_enhanced: true
original_url: https://pscrb.fm/rss/p/www.buzzsprout.com/2175779/episodes/17819880-ep-607-how-to-use-gems-gpts-projects-for-real-business-results.mp3
processing_date: 2025-10-04 18:39:32 +0000
quotes:
- length: 76
  relevance_score: 6
  text: You have to always stay up to date and take advantage of the biggest updates
  topics: []
- length: 188
  relevance_score: 5
  text: But one of the biggest problems is we aren't taking advantage of the context
    window, and then we're also not taking advantage of the true capabilities that
    these large language models have
  topics: []
- length: 200
  relevance_score: 5
  text: So whether you're looking for ChatGPT training for thousands or just need
    help building your front-end AI strategy, you can partner with us too, just like
    some of the biggest companies in the world do
  topics: []
- length: 260
  relevance_score: 4
  text: You probably think that you're saving yourself a lot of time whenever you
    go into your favorite AI chatbot, click that new chat button, spend some time
    getting it to respond just how you want it, sharing your files, and you get an
    output that you're happy with
  topics: []
- length: 102
  relevance_score: 4
  text: Just using these AI chatbots, whether you're using Gemini, Claude, ChatGPT,
    Copilot, Mattermost, right
  topics: []
- length: 117
  relevance_score: 4
  text: So when we talk about Google Gems, I would say one of the biggest differentiators
    is number one, it uses the Gemini 2
  topics: []
- length: 157
  relevance_score: 4
  text: Companies like Adobe, Microsoft, and Nvidia have partnered with us because
    they trust our expertise in educating the masses around generative AI to get ahead
  topics: []
- length: 175
  relevance_score: 4
  text: '" So I like that midway through it actually did some research on it looks
    like it went out and searched for "AI podcast market size growth 2025" and analyzed
    some things there'
  topics:
  - growth
  - market
- length: 138
  relevance_score: 3
  text: But maybe more importantly, we pull out the most important insights or things
    that we didn't even have time to get to from today's episode
  topics: []
- length: 223
  relevance_score: 3
  text: The problem is these AI systems that we use so much, and some of us have become
    reliant on almost for our day-to-day work and business, they change too quickly
    to actually establish those good routines and those good habits
  topics: []
- length: 50
  relevance_score: 3
  text: So you and your skill set, you have to do the same
  topics: []
- length: 270
  relevance_score: 3
  text: Whatever you're using, if you're using something on the web, I would say most
    people, they just go in and they click that new chat, which is actually dangerous
    because one of the biggest mistakes people make is overlooking things like context
    window, organization, right
  topics: []
- length: 32
  relevance_score: 3
  text: So here's what we're going to do
  topics: []
- length: 96
  relevance_score: 3
  text: '" Then I''m going to say, "10 of the biggest blind spots that I''m not aware
    of based on this data'
  topics: []
- length: 25
  relevance_score: 3
  text: So here's what I uploaded
  topics: []
- length: 47
  relevance_score: 3
  text: Hey, here's what's going right with our website
  topics: []
- length: 42
  relevance_score: 3
  text: Here's what's going right with the podcast
  topics: []
- length: 29
  relevance_score: 3
  text: 10 of the biggest blind spots
  topics: []
- length: 75
  relevance_score: 3
  text: Sometimes when you export something, you have to do a little bit of cleanup
  topics: []
- length: 112
  relevance_score: 3
  text: I just clicked export all on all of those and just dumped it in there and
    said, "Yo, here's what these files are
  topics: []
- length: 84
  relevance_score: 3
  text: So the problem is I wish that ChatGPT would change back some of their user
    interface
  topics: []
- impact_reason: This reveals a critical technical limitation in Anthropic's Claude
    projects (file count and size limits, specifically 30MB per file), contrasting
    it directly with the apparent higher capacity of Google Gems and OpenAI GPTs for
    large context uploads.
  relevance_score: 10
  source: llm_enhanced
  text: Unfortunately, Claude would only accept nine because it has a file limit.
    All right. So anything over 30 megabytes you cannot upload. So I had a spreadsheet
    that was like 60 megabits or no, it was like 42 megabytes or something like that,
    and Claude couldn't take it, whereas Google Gems and GPTs could.
  topic: technical/limitations
- impact_reason: 'This is a core strategic insight for maximizing LLM utility: leveraging
    custom contexts (Gems/GPTs) by pre-loading them with personal/organizational data
    (job description, meeting transcripts) to drastically improve output quality and
    save time on repetitive context-setting.'
  relevance_score: 10
  source: llm_enhanced
  text: Now think instead of go clicking new chat, now all of a sudden, if you just
    unload your brain, unload everything about your position, put your job description
    in there, who you are, who you work with, meeting transcripts, right? You can
    fit so much information in these Gems, GPTs, and projects that all that time that
    you would normally spend trying to get the most and explain things and feed all
    this data to a large language model, if you just set it up correctly and then
    use it every single time, think of not just how much time you're saving, but how
    much better the outputs are going to be.
  topic: Business/Strategy
- impact_reason: Directly links the quality of the Chain of Thought output to the
    quality of the input prompt/custom instructions. It emphasizes that poor CoT reveals
    poor prompting, a key lesson for prompt engineering.
  relevance_score: 10
  source: llm_enhanced
  text: But like I tell you all every time, you need to be reading this chain of thought.
    This tells you because we're using these either reasoning models or hybrid models...
    the quality of my prompt was very low. Right? The custom instructions were not
    very great. So when you don't spend a lot of time before you go and set these
    very powerful models in motion, you don't really know how they're going to respond.
  topic: Technical/Prompt Engineering
- impact_reason: 'Crucial advice for enterprise AI adoption: due to the generative
    and sometimes inconsistent nature of LLMs, rigorous, repeated testing (minimum
    five times) is necessary before trusting a process or writing it off.'
  relevance_score: 10
  source: llm_enhanced
  text: Generative AI is generative. Just because it doesn't work once doesn't mean
    it's broken. Right? This is why I encourage companies that I work with that hire
    us to, you know, don't just do something once and write it off. You need to be
    revisiting these things... you should at least be testing it minimum five times
    minimum, and you need something to measure.
  topic: Business/Adoption Strategy
- impact_reason: 'This sets up the central thesis: the common, default way of using
    chatbots (new chat) is often inefficient compared to using specialized tools like
    GPTs/Gems/Projects.'
  relevance_score: 9
  source: llm_enhanced
  text: You probably think that you're saving yourself a lot of time whenever you
    go into your favorite AI chatbot, click that new chat button, spend some time
    getting it to respond just how you want it, sharing your files, and you get an
    output that you're happy with. You saved yourself time, right? Maybe, or maybe
    you just wasted a ton of time by not knowing how to use things like Google's Gems,
    OpenAI's ChatGPTs, GPTs, and Claude's projects and OpenAI's projects.
  topic: strategy
- impact_reason: A crucial warning against complacency. AI efficiency is the new baseline,
    requiring continuous skill upgrading.
  relevance_score: 9
  source: llm_enhanced
  text: Is using an AI chatbot in this way faster than doing things manually? Absolutely.
    But the bar is continuing to rise. So you and your skill set, you have to do the
    same. You can't become complacent just because you're using AI.
  topic: strategy
- impact_reason: Positions the new specialized tools (Gems, GPTs, Projects) as the
    direct solution to the organizational and context-loss problems.
  relevance_score: 9
  source: llm_enhanced
  text: This is where using Google Gems, custom GPTs from ChatGPT, projects from ChatGPT,
    and projects from Claude can help erase this problem because the solution is literally
    right in front of us.
  topic: strategy
- impact_reason: 'Highlights the critical advantage of Google Gems: deep, native integration
    with the Google Workspace ecosystem.'
  relevance_score: 9
  source: llm_enhanced
  text: 'The other big advantage that you have using GPTs is you have all of their
    apps, integrations. So if you are using a Workspace account... if I go in there,
    I have access to all my Workspace apps, which is great: Google Drive, Google Docs,
    Gmail, Calendar, etc.'
  topic: business advice
- impact_reason: 'Reveals a significant, under-reported update from OpenAI: the ability
    to select different underlying models (like GPT-4o) within custom GPTs.'
  relevance_score: 9
  source: llm_enhanced
  text: OpenAI actually didn't really announce it at first. They updated some projects...
    but they enabled anyone to use any version of their model for GPTs. And this is
    why it's huge.
  topic: technology trends
- impact_reason: 'This diagnoses a key failure point for the initial adoption of OpenAI''s
    GPTs: the inability to leverage the latest, most capable models, which has now
    been rectified, signaling a potential resurgence in GPT adoption.'
  relevance_score: 9
  source: llm_enhanced
  text: One of the reasons I think is because you could never choose which model to
    use. So, you know, as we got these new models that can think and reason like Gemini
    2.5 Pro or like, you know, a Claude Sonnet or a Claude Opus 4, we were still stuck
    using GPTs, these non-recenting models until a couple of days ago.
  topic: business/predictions
- impact_reason: Highlighting 'Deep Research' within projects as a unique, brand-new
    capability suggests a competitive advantage for OpenAI's project structure over
    its rivals in terms of internal data analysis.
  relevance_score: 9
  source: llm_enhanced
  text: So that's a new update. You can actually in ChatGPT projects now, you can
    do deep research using just the information in the project. Brand new update,
    no one else has that.
  topic: technical/strategy
- impact_reason: 'This captures the core business pain point for many enterprises:
    moving past experimentation (tinkering) with LLMs to achieving measurable Return
    on Investment (ROI) in Generative AI.'
  relevance_score: 9
  source: llm_enhanced
  text: Are you still running in circles trying to figure out how to actually grow
    your business with AI? Maybe your company has been tinkering with large language
    models for a year or more, but can't really get traction to find ROI on Gen AI.
  topic: business advice
- impact_reason: This is a bold prediction about the democratization of high-level
    strategic analysis, suggesting that advanced LLM context loading could substitute
    for expensive, traditional consulting services.
  relevance_score: 9
  source: llm_enhanced
  text: So will this can like will this replace like hiring a big consultancy? Maybe,
    let's be honest, I couldn't afford to go hire a six-figure consultant. But I think
    right here, we have the making of it, right?
  topic: predictions/business
- impact_reason: This philosophical statement frames the personalized AI environment
    as an extension of the user's own cognitive capacity and institutional knowledge,
    making context loading a mandatory strategic step.
  relevance_score: 9
  source: llm_enhanced
  text: Why wouldn't I want to give it access to all of this information? This is
    my brain. This is my brain and then some. This is my brain and my computer's brain,
    right?
  topic: strategy
- impact_reason: A powerful metaphor summarizing the goal of building highly customized
    AI agents—creating an externalized, augmented version of one's own knowledge base
    and thought process.
  relevance_score: 9
  source: llm_enhanced
  text: This is my brain and my computer's brain, right?
  topic: Strategy
- impact_reason: Actionable advice on how to convert tacit, unstructured knowledge
    (like verbal thought processes) into structured input for AI tools, maximizing
    the value derived from personal expertise.
  relevance_score: 9
  source: llm_enhanced
  text: Even taking that unstructured data, your thought process, your domain expertise,
    talk it into a microphone, transcribe it, and dump it into Google Gems, ChatGPT,
    GPTs, or folders.
  topic: Practical Lessons
- impact_reason: Highlights the critical importance of inspecting the 'chain of thought'
    (CoT) or reasoning path provided by advanced models, especially when using reasoning
    or hybrid models.
  relevance_score: 9
  source: llm_enhanced
  text: I can go through here and see the chain of thought, see how it thought, see
    how it thought.
  topic: Technical/Model Usage
- impact_reason: A fundamental principle of Generative AI—its non-deterministic nature—and
    the corresponding necessity of using CoT analysis to iteratively refine inputs
    for consistency and quality.
  relevance_score: 9
  source: llm_enhanced
  text: Generative AI is generative. It's going to be different every single time.
    So by reading this chain of thought, it's going to tell me how I should improve
    my inputs to get a better output.
  topic: Technical/Model Limitations
- impact_reason: Highlights the rapid pace of change in the AI tooling landscape (GPTs,
    Gems, Projects) and suggests that established habits are already obsolete.
  relevance_score: 8
  source: llm_enhanced
  text: These things have changed so much in the last week or two. Whether you're
    a new person learning the basics of these AI chatbots or you're a seasoned vet
    using them for hours a day, there have been some under-the-radar changes to these
    projects, GPTs, and Gems that I think change how we should be using these AI chatbots.
  topic: technology trends
- impact_reason: 'A key challenge for AI adoption: the speed of platform evolution
    outpaces the user''s ability to form stable, efficient workflows.'
  relevance_score: 8
  source: llm_enhanced
  text: The problem is these AI systems that we use so much, and some of us have become
    reliant on almost for our day-to-day work and business, they change too quickly
    to actually establish those good routines and those good habits.
  topic: strategy
- impact_reason: 'Identifies two critical, often overlooked technical/organizational
    aspects of effective LLM usage: context management and chat history structure.'
  relevance_score: 8
  source: llm_enhanced
  text: One of the biggest mistakes people make is overlooking things like context
    window, organization, right?
  topic: technical
- impact_reason: Reinforces the idea that users are underutilizing LLMs by failing
    to leverage context memory and advanced features.
  relevance_score: 8
  source: llm_enhanced
  text: But one of the biggest problems is we aren't taking advantage of the context
    window, and then we're also not taking advantage of the true capabilities that
    these large language models have.
  topic: technical
- impact_reason: A strong, albeit time-sensitive, claim about the relative power of
    Gemini 2.5 Pro compared to competitors at the time of recording.
  relevance_score: 8
  source: llm_enhanced
  text: When we talk about Google Gems, I would say one of the biggest differentiators
    is number one, it uses the Gemini 2.5 Pro model, which until we get full benchmarks
    for O3 Pro, it's the best model in the world, right?
  topic: technical
- impact_reason: Provides a critical retrospective analysis on why the initial GPT
    Store concept struggled—lack of model choice stifled utility.
  relevance_score: 8
  source: llm_enhanced
  text: OpenAI kind of started this phase of the, you know, GPTs and we thought, oh,
    it's going to be like the app store, right, for AI. And it never really took off.
    One of the reasons I think is because you could never choose which model to use.
  topic: business advice
- impact_reason: The introduction of external API connections (Actions) within GPTs
    significantly enhances their functionality, turning them from isolated tools into
    integrated applications, a major step toward the 'AI App Store' vision.
  relevance_score: 8
  source: llm_enhanced
  text: Well, one big one is you can actually connect via kind of external APIs or
    actions, which is pretty unique in terms of ChatGPT, what it can do in GPTs.
  topic: technical/business
- impact_reason: This points out specific, powerful features (Canvas mode, Deep Research)
    available in ChatGPT Projects that are explicitly *not* available in custom GPTs
    or Google Gems, defining a key differentiator for the Project structure.
  relevance_score: 8
  source: llm_enhanced
  text: The big one in ChatGPT projects would be using things like Canvas mode, would
    be using things like deep research.
  topic: technical/strategy
- impact_reason: This is a direct product announcement (VO3) from Google Gemini, showcasing
    advancements in multimodal AI, specifically high-quality, short-form video generation
    with native audio.
  relevance_score: 8
  source: llm_enhanced
  text: Check out VO3, our state-of-the-art AI video generation model in the Gemini
    app, which lets you create high-quality eight-second videos with native audio
    generation.
  topic: AI technology trends
- impact_reason: This details a complex, multi-part prompt designed to rigorously
    test the models' ability to rely on provided context (RAG) versus external knowledge,
    a crucial test for enterprise use cases.
  relevance_score: 8
  source: llm_enhanced
  text: I said, 'Please carefully analyze my files for Everyday AI seen at your everydayai.com.
    Do not do additional research on the web when or sorry, I said, you can do additional
    research on the web when needed. Do not make anything up. Take your time. Be detailed.'
  topic: technical/strategy
- impact_reason: This highlights the critical importance of providing clear metadata
    or 'data dictionary' within the custom instructions, even when testing RAG capabilities,
    to ensure accurate interpretation of complex, uploaded datasets.
  relevance_score: 8
  source: llm_enhanced
  text: So notice, all I did when telling, oh, I actually didn't even tell what the
    data is. I probably should have done that. Oh, wait, hold up. Sorry, I'm getting
    distracted here in the customer instructions. Okay, this is good. We talked about
    the customer instructions. So in the customer instructions, I did tell them what
    each of these things are.
  topic: technical/strategy
- impact_reason: This provides actionable advice for general users on maximizing personalized
    AI utility by feeding it proprietary and external strategic context (competitors,
    brand voice, internal docs) beyond simple Q&A.
  relevance_score: 8
  source: llm_enhanced
  text: Well, you probably have access to a lot of data that you're not just thinking
    about. Right? So what what are your company docs? Can you put in what about industry
    white papers? What about information about your competitors? What about information
    about your brand voice?
  topic: business advice/strategy
- impact_reason: This emphasizes that the primary benefit of pre-loading context into
    personalized AI environments (Gems, GPTs, Projects) is not just efficiency, but
    a significant qualitative improvement in the quality of the AI's output.
  relevance_score: 8
  source: llm_enhanced
  text: Think of not just how much time you're saving, but how much better the outputs
    are going to be.
  topic: business advice
- impact_reason: Provides a timely insight into the competitive landscape and feature
    parity between major AI platforms (Google Gems vs. ChatGPT), specifically regarding
    access to the most advanced underlying models.
  relevance_score: 8
  source: llm_enhanced
  text: It looks like Google Gemini 2.5 Pro, which you can use the most powerful model
    in your Gem, which wasn't a huge advantage for Gems until a couple of days ago
    when ChatGPT allowed you to have the most powerful model.
  topic: Business/Technology Trends
- impact_reason: Documents a real-world, platform-specific bug/inconsistency in the
    deployment of new features (GPTs vs. direct chat uploads), highlighting the instability
    of rapidly evolving AI products.
  relevance_score: 8
  source: llm_enhanced
  text: I'm trying to see if it actually gave any ideas. So it says, 'You know, please
    reshare data in a way I can access... So what I'm actually going to do is I'm
    going to manually upload these in the body of the chat... It looks like it was
    able to open about half of those files when I shared them in the body of the chat,
    but when I uploaded them as files in the project knowledge, it didn't work. So
    that's interesting here. A little bug.'
  topic: Practical Lessons/Product Issues
- impact_reason: Expresses skepticism regarding speed versus depth of reasoning, suggesting
    that complex tasks require significant computational 'thinking time,' which rapid
    results might mask or skip.
  relevance_score: 8
  source: llm_enhanced
  text: I don't have a ton of faith in the fact that Claude went through all this
    in a couple of seconds. Maybe it'll still be good. But I would have even hoped
    even a large language model would spend multiple minutes on this thinking about
    it critically, trying to connect dots between the different data patterns, etc.
  topic: Technical/Model Performance
- impact_reason: This points to the model's ability to dynamically decide to use external
    search/retrieval augmentation (RAG) mid-process, a key feature for improving factual
    accuracy and depth.
  relevance_score: 8
  source: llm_enhanced
  text: In the middle of this, Claude went out and did some research, which is good
    to see.
  topic: technical/model behavior
- impact_reason: This documents real-world instability and inconsistency in a major
    model (ChatGPT/GPTs), which is crucial information for developers relying on API
    stability or feature reliability.
  relevance_score: 8
  source: llm_enhanced
  text: So we saw some failure issues for ChatGPT in certain instances on the second
    time I ran this because again, I ran it last night. It worked fine on the GPT
    side and the project side today. Not so much.
  topic: business/deployment issues
- impact_reason: This provides an initial, high-level confidence assessment based
    purely on the process/handling, suggesting that initial output quality or structure
    can be a strong predictor of overall utility.
  relevance_score: 8
  source: llm_enhanced
  text: I can't judge the accuracy of everything just yet, but it looks like Gemini
    off the bat and Gemini in the Gems, I might have the most confidence in before
    looking at everything, just looking at how it handled it.
  topic: strategy/model selection
- impact_reason: This reinforces the positive observation about Claude's self-awareness
    regarding knowledge gaps and its subsequent decision to use external tools, emphasizing
    the value of RAG integration.
  relevance_score: 8
  source: llm_enhanced
  text: I like that Claude halfway through said, 'You know, hold up. I got to actually
    go research some more because in order for me to, you know, find out this information,
    I'm not sure.'
  topic: model behavior/technical
- impact_reason: 'Actionable advice: Users must define their specific use case before
    diving into the features of custom AI tools.'
  relevance_score: 7
  source: llm_enhanced
  text: Okay, get your use case first. All right. So keep that in mind, we're going
    to be going through my use case, but this is going to be applicable on Wednesdays.
    It's going to be applicable to just about anyone. You just have to first think
    and say, okay, what's my use case for custom GPTs, for Gems, for projects, et
    cetera?
  topic: business advice
- impact_reason: Advocates for transparency in AI development and usage, showing the
    messy reality behind the polished results.
  relevance_score: 7
  source: llm_enhanced
  text: I know sometimes I ramble on a little bit, but generative AI is generative.
    Sometimes things work well. Sometimes they don't. And I want you all to see the
    realness because if you just see these polished finished products like everyone
    else does, you don't see sometimes where things go wrong or how long they take.
  topic: practical lessons
- impact_reason: 'Details the specific time-wasting loop: repeatedly setting tone/context
    and losing access to that context in standard chat sessions.'
  relevance_score: 7
  source: llm_enhanced
  text: You're spending that time to get it to respond exactly how you want to, and
    then you're sharing some files, right? But then where did that chat go? Maybe
    you go in and you search for it, but most people, I would say, are just wasting
    time.
  topic: business advice
- impact_reason: 'Provides a high-level categorization of the new tools based on their
    core function: persistent, instruction-based environments.'
  relevance_score: 7
  source: llm_enhanced
  text: 'I would separate these into one category: Is there GPTs/Gems? And your other
    category is projects. Okay? But ultimately, they kind of do the same thing. You
    give them a set of custom instructions, and you give them project files.'
  topic: technical
- impact_reason: This details Claude's unique integration strategy, specifically mentioning
    native access to Google Workspace apps within its projects and introducing the
    'Model Context Protocol' (MCP) as a web-based API equivalent.
  relevance_score: 7
  source: llm_enhanced
  text: On Anthropic's project side, you have access to your Gmail. So just the different
    integrations. So you have Gmail, Google Calendar, Google Drive, but then you have
    MCP, their Model Context Protocol.
  topic: technical/strategy
- impact_reason: 'This is a clear, actionable business promise: providing strategic
    guidance to move companies from aimless AI exploration to a defined path for Gen
    AI ROI.'
  relevance_score: 7
  source: llm_enhanced
  text: We'll help you stop running in those AI circles and help get your team ahead
    and build a straight path to ROI on Gen AI.
  topic: business advice
- impact_reason: This sets the stage for a high-stakes test of the models' context
    window and retrieval capabilities, using massive, real-world business datasets
    (Search Console, Analytics, Email history).
  relevance_score: 7
  source: llm_enhanced
  text: I uploaded hundreds of thousands of rows of data. A lot of data.
  topic: technical
- impact_reason: This links observed model failures directly to potential external
    factors like platform updates or service instability, a common operational headache
    for AI users.
  relevance_score: 7
  source: llm_enhanced
  text: ChatGPT's been having a lot of downtime the past couple of days. That might
    be it, or this could just be a bug because they did just update both their projects
    and their GPTs.
  topic: business/deployment issues
- impact_reason: This is a specific positive data point for Gemini 2.5's capability
    in data analysis, highlighting its ability to spot structural errors (mismatched
    columns).
  relevance_score: 7
  source: llm_enhanced
  text: It looked like it did a pretty good and a pretty thorough job. It identified
    some mismatched columns and it told me about this.
  topic: model performance/technical
- impact_reason: This provides a concrete example of the model executing a targeted,
    timely search query, demonstrating practical application of web browsing capabilities
    for current market data.
  relevance_score: 7
  source: llm_enhanced
  text: I like that midway through it actually did some research on it looks like
    it went out and searched for 'AI podcast market size growth 2025' and analyzed
    some things there.
  topic: technical/RAG application
- impact_reason: A nuanced insight into the feature disparity between personal and
    Workspace Google accounts regarding AI app access.
  relevance_score: 6
  source: llm_enhanced
  text: Actually, if you're using your personal Gmail, though, you have access to
    more. You have access to things like YouTube, YouTube Music, Google Flights, you
    know, just some things that you don't have access to if you're using a Workspace
    plan.
  topic: technical
- impact_reason: This sets up the conclusion of the comparison, framing the entire
    exercise as a practical guide for users deciding on the best LLM for their needs.
  relevance_score: 6
  source: llm_enhanced
  text: All right. So overall, y'all, as we start to wrap this thing up, I wanted
    to show you which one should you use?
  topic: strategy/model selection
source: Unknown Source
summary: '## Podcast Episode Summary: EP 607: How To Use Gems, GPTs & Projects for
  Real Business Results


  This episode of the Everyday AI Show focuses on a critical shift in how professionals
  should be utilizing generative AI tools—moving beyond the default "New Chat" button
  to leverage persistent, customized environments like Google Gems, OpenAI''s Custom
  GPTs, and the Projects feature in both ChatGPT and Claude. The host argues that
  failing to use these organizational tools leads to wasted time due to repeated context
  setting and poor organization.


  ### 1. Focus Area

  The primary focus is on **Practical AI Implementation and Workflow Optimization**
  across major LLM platforms (OpenAI, Google, Anthropic). The discussion centers on
  the strategic advantages of using **Customized AI Agents (Gems/GPTs)** and **Organized
  Workspaces (Projects)** to maintain context, leverage proprietary data, and achieve
  superior, repeatable business results.


  ### 2. Key Technical Insights

  *   **Model Selection in Custom Tools:** A significant recent update is that OpenAI
  now allows users to select the most powerful models (like GPT-4 Turbo) for their
  Custom GPTs, a feature previously restricted, making them far more capable than
  before.

  *   **Platform Feature Parity and Differentiation:** While Gems/GPTs and Projects
  share the core function of custom instructions and file access, Projects (in ChatGPT
  and Claude) often retain advanced features like **Canvas Mode** (ChatGPT) or **Artifacts**
  (Claude), and specialized research tools (like ChatGPT Projects'' **Deep Research**),
  which are often disabled in the simpler Gem/GPT format.

  *   **File Handling Limitations:** Claude has a notable limitation where uploaded
  files cannot exceed 30MB, which was a constraint encountered when trying to upload
  large datasets (like email history), whereas Google Gems and ChatGPT GPTs handled
  larger files.


  ### 3. Business/Investment Angle

  *   **ROI Through Context Persistence:** The central business argument is that setting
  up these persistent environments eliminates the time wasted repeatedly feeding context,
  brand voice, or proprietary data to the AI, leading to significant time savings
  and better output quality—a direct path to Gen AI ROI.

  *   **Democratizing Consultancy:** By loading extensive proprietary data (analytics,
  search console data, internal documents) into a custom agent, users can potentially
  generate high-level strategic insights that might otherwise require expensive, time-consuming
  external consultancy.

  *   **Competitive Advantage via Organization:** The ability to organize work within
  Projects (folder structure) prevents the chaos of unsearchable chats, ensuring that
  valuable AI interactions and derived knowledge are retained and accessible.


  ### 4. Notable Companies/People

  *   **OpenAI (ChatGPT/GPTs/Projects):** Highlighted for the recent, under-the-radar
  update allowing users to select advanced models for GPTs and the unique capabilities
  of ChatGPT Projects (Canvas, Deep Research).

  *   **Google (Gems/Gemini):** Noted for Gems utilizing the powerful Gemini 2.5 Pro
  model and deep integration with Google Workspace apps (Drive, Gmail, Calendar).

  *   **Anthropic (Claude Projects):** Mentioned for its Project feature supporting
  Artifacts and the **Model Context Protocol (MCP)**, which acts as a web-based API
  layer within projects.

  *   **Jordan Wilson (Host):** The host uses the podcast to provide a transparent,
  live demonstration of how the Everyday AI team uses these tools internally, sharing
  their own data and prompting strategy as a real-world case study.


  ### 5. Future Implications

  The conversation strongly suggests that the future of professional LLM usage is
  **agent-centric and persistent**. The industry is moving away from one-off queries
  toward building specialized, data-rich AI assistants that function as embedded team
  members. Staying current with feature rollouts (like model selection in GPTs) is
  crucial, as these updates fundamentally change the efficiency ceiling of existing
  workflows.


  ### 6. Target Audience

  This episode is most valuable for **AI Practitioners, Business Leaders, and Tech
  Professionals** who are already using LLMs daily but are struggling with efficiency,
  organization, or maximizing the depth of their AI outputs. It is specifically targeted
  at those ready to move beyond basic prompting to building scalable, customized AI
  solutions.


  ---

  ### Comprehensive Summary Narrative


  The episode addresses the common pitfall where users, despite using AI daily, are
  actually wasting time by defaulting to the "New Chat" function across platforms
  like ChatGPT, Gemini, and Claude. Host Jordan Wilson argues that the rapid evolution
  of AI tools necessitates adopting persistent, customized environments—**Gems, Custom
  GPTs, and Projects**—to save time and elevate output quality by pre-loading context
  and data.


  Wilson frames the discussion around a live, unedited demonstration where he inputs
  the exact same complex prompt into four identically configured agents (a Google
  Gem, a Custom GPT, a ChatGPT Project, and a Claude Project), all utilizing their
  respective platforms'' most powerful models (Gemini 2.5 Pro, GPT-4 Turbo, Claude
  Opus 4). The goal is to analyze 50 specific strategic insights derived from a massive
  dataset comprising Google Analytics, Search Console, podcast stats, and email history.


  The core of the episode is a comparison matrix detailing the pros and cons of these
  four persistent tools. **Gems** are praised for their Gemini 2.5 Pro power and Workspace
  integration. **Custom GPTs** are now significantly more powerful following the update
  allowing selection of the latest models and offering unique API/Action connectivity.
  **Projects** (from both OpenAI and Anthropic) are highlighted as superior organizational
  structures that retain the full feature set of the underlying models (e.g., Canvas,
  Artifacts, Deep Research), features often stripped from the simpler GPT/Gem format.
  A practical challenge noted was Claude''s restrictive 30MB'
tags:
- generative-ai
- artificial-intelligence
- ai-infrastructure
- google
- openai
- anthropic
- microsoft
- nvidia
title: 'EP 607: How To Use Gems, GPTs & Projects for Real Business Results'
topics:
- keywords:
  - generative ai
  - genai
  - chatgpt
  - gpt
  - claude
  - text generation
  - image generation
  mentions: 139
  prominence: 1.0
  topic: generative ai
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 133
  prominence: 1.0
  topic: artificial intelligence
- keywords:
  - gpu
  - tensor
  - training
  - inference
  - model deployment
  - vector database
  mentions: 1
  prominence: 0.1
  topic: ai infrastructure
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-10-04 18:39:32 UTC -->
