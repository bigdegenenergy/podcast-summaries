---
companies:
- category: unknown
  confidence: medium
  context: Welcome everyone to the AI in Business Podcast. I'm Matthew D'Mello, Editorial
    Director here at
  name: Business Podcast
  position: 30
- category: unknown
  confidence: medium
  context: lcome everyone to the AI in Business Podcast. I'm Matthew D'Mello, Editorial
    Director here at Emerge AI Resea
  name: Matthew D
  position: 52
- category: unknown
  confidence: medium
  context: the AI in Business Podcast. I'm Matthew D'Mello, Editorial Director here
    at Emerge AI Research. Today's guest is Chri
  name: Editorial Director
  position: 69
- category: unknown
  confidence: medium
  context: . I'm Matthew D'Mello, Editorial Director here at Emerge AI Research. Today's
    guest is Christo Siebritz, Senior Associ
  name: Emerge AI Research
  position: 96
- category: unknown
  confidence: medium
  context: ctor here at Emerge AI Research. Today's guest is Christo Siebritz, Senior
    Associate in General Counsel at ABV. Chri
  name: Christo Siebritz
  position: 133
- category: unknown
  confidence: medium
  context: e AI Research. Today's guest is Christo Siebritz, Senior Associate in General
    Counsel at ABV. Christo has over 20 ye
  name: Senior Associate
  position: 151
- category: unknown
  confidence: medium
  context: '''s guest is Christo Siebritz, Senior Associate in General Counsel at
    ABV. Christo has over 20 years of experience i'
  name: General Counsel
  position: 171
- category: unknown
  confidence: medium
  context: harmaceutical companies and currently leads ABV's AI Initiatives while
    providing strategic guidance on AI-related
  name: AI Initiatives
  position: 335
- category: unknown
  confidence: medium
  context: ecutive thought leaders, everyone from the CIO of Goldman Sachs to the
    head of AI at Raytheon and AI pioneers lik
  name: Goldman Sachs
  position: 1327
- category: unknown
  confidence: medium
  context: o the head of AI at Raytheon and AI pioneers like Yoshua Bengio. With nearly
    a million annual listeners, AI and B
  name: Yoshua Bengio
  position: 1392
- category: unknown
  confidence: medium
  context: eve you can help other leaders move the needle on AI ROI, visit emerj.com
    and fill out our Thought Leader
  name: AI ROI
  position: 1858
- category: unknown
  confidence: medium
  context: eedle on AI ROI, visit emerj.com and fill out our Thought Leader submission
    form. That's emerj.com and click on Be
  name: Thought Leader
  position: 1899
- category: unknown
  confidence: medium
  context: egard to what we've heard a lot in this series as Shadow AI, or in so many
    words, employees using open tools
  name: Shadow AI
  position: 2641
- category: unknown
  confidence: medium
  context: ernally? And if we do, what would that look like? And I'll sort of preface
    that by saying we probably wen
  name: And I
  position: 4137
- category: unknown
  confidence: medium
  context: What would that look like? I'll say it's my data. Can I rely on data in
    the cloud? Nobody else will acces
  name: Can I
  position: 4377
- category: unknown
  confidence: medium
  context: mes down for me to the build versus buy question. So I break it up into
    what is your most important data
  name: So I
  position: 5444
- category: unknown
  confidence: medium
  context: tractually we have the right provisions in place. That I think would solve
    for probably 80% of the data in
  name: That I
  position: 6063
- category: unknown
  confidence: medium
  context: People can take any form of that model they like. But I think at the end
    of the day, you're going to put
  name: But I
  position: 6545
- category: tech
  confidence: high
  context: nment. So we would make sure if we're speaking to OpenAI that we have an
    agreement that can protect our da
  name: Openai
  position: 8715
- category: tech
  confidence: high
  context: interrogate information and emails and the like. Microsoft Copilot comes
    into play because that connects you
  name: Microsoft
  position: 9864
- category: unknown
  confidence: medium
  context: interrogate information and emails and the like. Microsoft Copilot comes
    into play because that connects you between
  name: Microsoft Copilot
  position: 9864
- category: unknown
  confidence: medium
  context: e multiple tools trying to solve for the problem. Maybe I don't see a single
    solution that solves everythin
  name: Maybe I
  position: 10180
- category: tech
  confidence: high
  context: unique challenges with AI. And you know, you can Google us not too far
    into the past, but a lot of legal
  name: Google
  position: 10492
- category: unknown
  confidence: medium
  context: future maybe for where this is going inevitably? Because I think in maybe
    the headlines, they get that, you
  name: Because I
  position: 10948
- category: unknown
  confidence: medium
  context: say what it wasn't this, but let's say it was the Harvard Law Review, you
    know, says that hallucinations are way bigge
  name: Harvard Law Review
  position: 11122
- category: ai_research
  confidence: high
  context: The organization hosting the podcast and employing the interviewer (Matthew
    D'Mello). They research and feature executive thought leaders on AI.
  name: Emerge AI Research
  source: llm_enhanced
- category: big_tech_user
  confidence: high
  context: Mentioned as an organization whose CIO has been featured on the podcast,
    indicating their involvement in enterprise AI strategy.
  name: Goldman Sachs
  source: llm_enhanced
- category: big_tech_user
  confidence: high
  context: Mentioned as an organization whose Head of AI has been featured on the
    podcast, indicating their involvement in enterprise AI strategy.
  name: Raytheon
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: Mentioned as an AI pioneer featured on the podcast.
  name: Yoshua Bengio
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: A specific, widely used generative AI tool (OpenAI's product) frequently
    referenced as an example of an external, unsanctioned 'Shadow AI' tool.
  name: ChatGPT
  source: llm_enhanced
- category: ai_company
  confidence: high
  context: Mentioned explicitly as the developer of ChatGPT, and later in the context
    of securing agreements to protect proprietary data when using their services.
  name: OpenAI
  source: llm_enhanced
- category: ai_startup
  confidence: high
  context: Mentioned as a specific third-party legal AI solution being considered
    by the guest's organization.
  name: Harvey
  source: llm_enhanced
- category: ai_startup
  confidence: high
  context: Mentioned as a specific third-party legal AI solution being considered
    by the guest's organization.
  name: CoCounsel
  source: llm_enhanced
- category: ai_startup
  confidence: high
  context: Mentioned as a specific third-party legal AI solution being considered
    by the guest's organization.
  name: LegalOn
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Mentioned as a tool that connects files and data, suggesting its role in
    enterprise AI integration (likely leveraging OpenAI models).
  name: Microsoft Copilot
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as a tool that can knit together local/cloud data and as a third-party
    AI use case with a per-user cost.
  name: Copilot
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Referenced as a provider of big third-party tools where organizations spend
    significant amounts hoping for AI returns.
  name: Microsoft
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as a large third-party tool where organizations spend money hoping
    to get AI value.
  name: SAP
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as a large third-party tool where organizations spend money hoping
    to get AI value.
  name: Workday
  source: llm_enhanced
date: 2025-10-13 06:00:00 +0000
duration: 28
has_transcript: false
layout: episode
llm_enhanced: true
original_url: https://traffic.libsyn.com/secure/techemergence/Business_-_10.13.25_-_Christo_Siebrits.mp3?dest-id=151434
processing_date: 2025-10-13 18:39:50 +0000
quotes:
- length: 152
  relevance_score: 4
  text: But first, are you driving AI transformation at your organization, or maybe
    you're guiding critical decisions on AI investments, strategy, or deployment
  topics:
  - investment
- length: 65
  relevance_score: 3
  text: That's probably the biggest question and also the biggest barrier
  topics: []
- length: 142
  relevance_score: 3
  text: You have to figure out what would that look like, how do you satisfy everybody's
    requirements, what's the development cost of a tool like that
  topics: []
- length: 114
  relevance_score: 3
  text: So I break it up into what is your most important data, and where will you
    keep that, and then what about the rest
  topics: []
- length: 89
  relevance_score: 3
  text: So I would say where you have the biggest value, where AI can bring the biggest
    solutions
  topics: []
- length: 103
  relevance_score: 3
  text: Microsoft Copilot comes into play because that connects you between all your
    files and the data on file
  topics: []
- length: 238
  relevance_score: 3
  text: So me as a legal practitioner here at a big pharma company, one of the biggest
    questions that I get asked, we struggle with most is we've got all of these different
    repositories of data, older, much older, newer, different, much different
  topics: []
- length: 162
  relevance_score: 3
  text: But when it comes to actual data across the company, that's the real value
    of what we have, and this is the biggest asset we have, is all of the data that
    we have
  topics: []
- length: 24
  relevance_score: 3
  text: You have to pay per user
  topics: []
- impact_reason: Identifies data sharing comfort with external vendors as the primary
    organizational barrier to adopting third-party GenAI tools.
  relevance_score: 10
  source: llm_enhanced
  text: I would say firstly, it's how comfortable is your organization to embrace
    these external third-party tools? That's probably the biggest question and also
    the biggest barrier. Are we ready to share our data into third-party tools?
  topic: business
- impact_reason: 'Offers a crucial strategic framework for data classification: not
    all data requires the same security posture, leading to a hybrid approach for
    AI deployment.'
  relevance_score: 10
  source: llm_enhanced
  text: So I break it up into what is your most important data, and where will you
    keep that, and then what about the rest? I don't think it all fits into one bucket.
  topic: strategy
- impact_reason: 'Provides a clear business strategy: prioritize internal build investment
    for high-value/sensitive areas (like R&D) and use external ''buy'' solutions for
    general enterprise needs.'
  relevance_score: 10
  source: llm_enhanced
  text: I think at the end of the day, you're going to put your money into the development
    where it matters most, and you're going to try and to satisfy people's AI needs
    through third-party tools like ChatGPT and the like.
  topic: business
- impact_reason: 'Describes a key emerging technical/deployment pattern: ''data residency
    with vendor access'' or ''co-habitation environments,'' which mitigates data transfer
    risk.'
  relevance_score: 10
  source: llm_enhanced
  text: What we're seeing is third parties come into your environment and provide
    the solutions there, meaning we can keep our data where we like it, but we invite
    the third party into that environment and we can apply the solution there.
  topic: technical
- impact_reason: Directly addresses the heightened risk of LLM hallucinations in the
    legal domain, where factual accuracy is paramount, contrasting it with potentially
    lower-stakes applications.
  relevance_score: 10
  source: llm_enhanced
  text: Hallucinations tend to be much more dangerous in this space [legal].
  topic: safety
- impact_reason: Reiterates the absolute necessity of HITL mechanisms for high-stakes,
    regulated functions like legal work.
  relevance_score: 10
  source: llm_enhanced
  text: But from the legal perspective, there's nothing more important than human
    in the loop.
  topic: safety
- impact_reason: 'Provides a sophisticated definition of modern HITL: it cannot be
    simple post-processing review, as that negates AI efficiency gains. It must be
    integrated earlier.'
  relevance_score: 10
  source: llm_enhanced
  text: Human in the loop is becoming a new science because it's not just a human
    checking the work product at the end of a cycle because that's a little bit naive.
    I mean, we're processing terabytes of data. You can't put a human in the process
    without redoing all of that. Then the whole purpose of AI has been defeated.
  topic: technical
- impact_reason: 'Defines the goal of advanced HITL: strategic insertion points for
    validation only in the most critical decision junctures, rather than blanket oversight.'
  relevance_score: 10
  source: llm_enhanced
  text: So it's a question of where do you insert the human in the loop to ultimately
    get to a point that you feel that you can trust the data? It's not everywhere.
    It's just in the most critical spaces.
  topic: safety
- impact_reason: 'A powerful philosophical conclusion: trust in AI systems is derived
    not from the model''s inherent perfection, but from the organization''s deliberate,
    strategic placement of human oversight.'
  relevance_score: 10
  source: llm_enhanced
  text: It's not an AI or an AI system that gives us trust in the system. It's our
    ability to insert the human at the exact right juncture and then say, well, it's
    validated, and it's validated to the point where we have trust in it.
  topic: safety
- impact_reason: 'Pinpoints the critical enterprise challenge: unifying siloed, historical,
    and diverse data repositories. Notes the current limitation of tools like Copilot
    primarily addressing connected/local data, not deep enterprise integration.'
  relevance_score: 10
  source: llm_enhanced
  text: How do you bring all of them together? So we currently don't have a system
    that knits all of this together. Yes, through Copilot you can certainly knit together
    what's on your C drive or even what's in the cloud that's connected to you. But
    when it comes to actual data across the company, that's the real value of what
    we have...
  topic: technical/strategy
- impact_reason: 'Provides a clear heuristic for prioritizing HITL: external consumption
    (risk of litigation/reputational damage) over internal data integrity checks.'
  relevance_score: 10
  source: llm_enhanced
  text: human in the loop becomes critically important when you're interfacing with
    an output that will be viewed or consumed by a third party.
  topic: safety/strategy
- impact_reason: 'Provides a necessary taxonomy for understanding enterprise AI: it
    must be segmented based on the user (individual, developer, enterprise platform
    integration), as the value and cost structures differ significantly.'
  relevance_score: 10
  source: llm_enhanced
  text: AI is not one thing. It's different things depending on how it is deployed.
    For the individual, AI is ChatGPT... Then you have the developer... And then the
    last one is big third-party tools like Microsoft and SAP and Workday...
  topic: strategy
- impact_reason: 'Frames the core challenge of AI adoption as one of continuous portfolio
    management: establishing clear kill/continue criteria based on validated metrics.'
  relevance_score: 10
  source: llm_enhanced
  text: are we tracking the value and productivity of each tool we're deploying? And
    if so, how do we validate that? When do we heal off a tool? When do we cancel
    an initiative? When do we move on to the next thing?
  topic: strategy
- impact_reason: 'Highlights the core challenge facing legal/compliance teams: information
    overload and difficulty discerning valuable tools amidst rapid technological change
    (the ''signal from the noise'' problem).'
  relevance_score: 9
  source: llm_enhanced
  text: There's been a lot of confusion for legal and compliance teams around generative
    AI right now. Part of this is the speed of technology, but there's just, frankly,
    too many tools, and organizations are really struggling to get a signal here from
    the noise.
  topic: strategy
- impact_reason: Directly addresses the pervasive and critical issue of 'Shadow AI'
    adoption within enterprises, which drives the need for formal governance.
  relevance_score: 9
  source: llm_enhanced
  text: This is really with regard to what we've heard a lot in this series as Shadow
    AI, or in so many words, employees using open tools like ChatGPT unsanctioned
    or at least unobserved by their employer organization.
  topic: safety
- impact_reason: 'Specific guidance for regulated industries (Pharma): invest internal
    development (''build'') resources where the highest value (R&D, discovery) and
    sensitivity lie.'
  relevance_score: 9
  source: llm_enhanced
  text: Where you have the biggest value, where AI can bring the biggest solutions.
    So in our environment, that might be in the R&D environment or discovery and the
    R&D through the clinic and so forth. There you're probably going to invest in
    the build environment and you're going to secure that data in that environment.
  topic: business
- impact_reason: A strong statement on the rapid pace of AI evolution, cautioning
    against over-committing to current vendor solutions due to imminent obsolescence
    or change.
  relevance_score: 9
  source: llm_enhanced
  text: AI's capabilities are doubling every four to six months. So these tools offer
    maybe a time and a place right now, but it's going to look very different six
    months or a year from now.
  topic: predictions
- impact_reason: 'Advocates for a multi-tool strategy: a general-purpose LLM (internal
    or external) for interrogation, plus integrated tools like Copilot for data connectivity
    across internal files.'
  relevance_score: 9
  source: llm_enhanced
  text: I'm also saying you probably for our legal colleagues, you need to provide
    them with a ChatGPT option or an internal version of that so that they can interrogate
    information and emails and the like. Microsoft Copilot comes into play because
    that connects you between all your files and the data on file.
  topic: strategy
- impact_reason: 'Identifies the two critical levers for managing AI risk and driving
    adoption: Human-in-the-Loop (HITL) design and understanding the adoption trajectory.'
  relevance_score: 9
  source: llm_enhanced
  text: Human in the loop. And I think we're going to talk about that a little bit
    later. And I guess the other is the adoption curve.
  topic: safety
- impact_reason: Offers a counterpoint to the fear of hallucinations, suggesting that
    fine-tuning or isolating an LLM to a specific, controlled data environment significantly
    mitigates accuracy issues.
  relevance_score: 9
  source: llm_enhanced
  text: I think statistically, we're seeing that it's becoming less and less of a
    problem, especially if you can isolate your environment, your data environment.
    You could dedicate your large language model to a specific ecosystem, you could
    vastly reduce those kinds of problems.
  topic: technical
- impact_reason: A strong philosophical statement emphasizing that trust is an outcome
    of human intervention design, not an inherent feature of the AI system itself.
  relevance_score: 9
  source: llm_enhanced
  text: So it's not an AI or an AI system that gives us trust in the system. It's
    our ability to insert the human at the exact right juncture and then say, well,
    it's validated, and it's validated to the point where we have trust in it.
  topic: safety/strategy
- impact_reason: Raises crucial, complex data governance and IP issues that arise
    when aggregating data for AI use, especially concerning ownership and licensing.
  relevance_score: 9
  source: llm_enhanced
  text: What part of the data doesn't belong to us? And then if it doesn't belong
    to us, who owns it? Do we own it? Is it a licensed piece of data? Do we just have
    access to the data? Do we share the data?
  topic: safety/business
- impact_reason: A candid admission from a large organization about the difficulty
    of proving Return on Investment (ROI) for AI deployments, a major barrier to scaling.
  relevance_score: 9
  source: llm_enhanced
  text: We find it pretty challenging to be able to demonstrate the ROI in all of
    the situations or the use cases where we apply AI.
  topic: business
- impact_reason: 'Highlights the strategic uncertainty in AI adoption: spending large
    sums based on faith rather than proven use cases, especially when the application
    strategy itself is immature.'
  relevance_score: 9
  source: llm_enhanced
  text: I don't think we know really how and where exactly to apply the AI. And so
    it also breaks up into internal versus external because you have to make decisions
    around spending millions of dollars... on the belief or understanding or faith
    that it's going to have a certain outcome, which is currently unproven.
  topic: strategy/business
- impact_reason: 'Identifies a critical missing piece of enterprise infrastructure:
    a standardized tool for tracking AI/productivity ROI across diverse deployments.'
  relevance_score: 9
  source: llm_enhanced
  text: And we don't have a tool across big organizations such as ours that will track
    the ROI on that. It's just impossible to say.
  topic: business
- impact_reason: A powerful concluding thought acknowledging the current state of
    AI maturityâ€”we have the technology, but lack the mature deployment and termination
    strategies.
  relevance_score: 9
  source: llm_enhanced
  text: we don't have all the answers, even though AI is with us. We don't yet know
    how we are to deploy AI, and then more importantly, when should we stop?
  topic: strategy
- impact_reason: Elevates 'knowing when to stop' (or sunsetting initiatives) as a
    critical, underappreciated skill in the age of rapid technological deployment.
  relevance_score: 9
  source: llm_enhanced
  text: Right. And knowing when to stop is the key. Knowing when to stop is the key
    skill, maybe for so many disciplines across so many spaces.
  topic: strategy
- impact_reason: Articulates the tension between business demand for consumer-grade
    AI experiences (like ChatGPT) and the difficulty/cost of internal IT teams building
    equivalent solutions.
  relevance_score: 8
  source: llm_enhanced
  text: And that's where I see a lot of tension. Because we're expecting our internal
    development or our IT folks to come up with solutions that look and feel like
    the third-party apps that we see today, like ChatGPT. But that's no easy task.
  topic: strategy
- impact_reason: Draws a direct, relevant parallel between current GenAI data concerns
    and the historical 'watershed moment' experienced during the initial adoption
    of cloud computing.
  relevance_score: 8
  source: llm_enhanced
  text: I'll say it's my data. Can I rely on data in the cloud? Nobody else will access
    it, etc. So we sort of had a watershed moment between internal versus external
    versus how fast is all of this developing, and how do we get our arms around all
    of that?
  topic: strategy
- impact_reason: Contrasts the R&D strategy with general enterprise use, emphasizing
    the necessity of contractual safeguards (like enterprise agreements with OpenAI)
    even for 'buy' solutions.
  relevance_score: 8
  source: llm_enhanced
  text: And the opposite, I guess, is for the enterprise where people want to ask
    questions, they want to brainstorm and the like. That's where you might go for
    the buy solution, but also in a secure environment. So we would make sure if we're
    speaking to OpenAI that we have an agreement that can protect our data.
  topic: business
- impact_reason: A pragmatic assessment that the legal workflow requires a portfolio
    of specialized and general AI tools, rather than a single monolithic solution.
  relevance_score: 8
  source: llm_enhanced
  text: Maybe I don't see a single solution that solves everything for a lawyer in
    his or her day job.
  topic: strategy
- impact_reason: Identifies 'matter-centric workflows' as a key deliverable or 'fruit
    of the AI tree' when AI is deployed correctly in legal/enterprise settings.
  relevance_score: 8
  source: llm_enhanced
  text: what about matter-centric workflows? And those will start carrying the appearance
    and we'll start to see more of those as we're deploying AI correctly in these
    spaces.
  topic: business/predictions
- impact_reason: Defines the core value proposition of integrated AI tools (like Copilot)
    in connecting disparate data sources for actionable output.
  relevance_score: 8
  source: llm_enhanced
  text: Systems like Copilot that goes in and connects all of your data so that you
    can get a report in one place on what all of this means and perhaps how you respond
    to a question.
  topic: technical/business
- impact_reason: Differentiates the consequences of internal vs. external AI errors,
    prioritizing external risk mitigation as the most immediate challenge.
  relevance_score: 8
  source: llm_enhanced
  text: Internally, your data becomes corrupted if you get it wrong. I mean, there
    are downstream problems for that. But I suspect the immediate challenge with AI
    and the use of AI is how it is consumed outside of your environment by external
    third parties.
  topic: safety/strategy
- impact_reason: 'Raises a sophisticated point about productivity gains: the value
    is only realized if the freed-up time is strategically reinvested in the ''next-best''
    activity, not just wasted.'
  relevance_score: 8
  source: llm_enhanced
  text: Did the employee's productivity go up? How are we ensuring that the employee
    is redeploying that productivity to the right alternative second-best opportunity,
    or next-best opportunity, probably better we have saying that?
  topic: business/strategy
- impact_reason: A direct call to action for developing internal governance/measurement
    systems to manage the proliferation of AI tools.
  relevance_score: 8
  source: llm_enhanced
  text: we probably need some kind of a system that will help us track and then determine
    which ones are actually working.
  topic: business
- impact_reason: Highlights the strategic difficulty of vendor lock-in and the risk
    of selecting a single AI platform given the current velocity of the market.
  relevance_score: 7
  source: llm_enhanced
  text: I'm personally finding it difficult to convince the business to say, invest
    in one of them. So you're backing one horse. What does that look like?
  topic: strategy
source: Unknown Source
summary: '## Podcast Episode Summary: From Tool Sprawl to Defensible Value in AI for
  Legal - with Christo Siebrits of AbbVie


  This 27-minute episode features Christo Siebrits, Senior Associate in General Counsel
  at AbbVie, discussing the critical challenges and strategic approaches for legal
  and compliance teams adopting Generative AI, particularly within highly regulated
  environments like pharmaceuticals. The core narrative revolves around navigating
  the overwhelming landscape of AI tools ("tool sprawl"), managing data governance
  risks, and establishing measurable value (ROI) for AI investments.


  ### 1. Focus Area

  The discussion centers on **Generative AI adoption within Enterprise Legal Operations**,
  focusing specifically on:

  *   **Data Governance and Risk Management:** Balancing the use of internal vs. external
  (third-party) AI tools (e.g., ChatGPT, Copilot).

  *   **Workflow Implementation:** Strategies for deploying AI safely, including the
  necessity of "Human in the Loop" (HITL) frameworks.

  *   **Value Measurement:** The difficulty in demonstrating and defending the ROI
  of AI initiatives across diverse use cases.


  ### 2. Key Technical Insights

  *   **Data Segmentation Strategy (Build vs. Buy):** Organizations must segment data
  based on sensitivity. Highly sensitive data (e.g., R&D/discovery) necessitates **building**
  secure, internal solutions, while less sensitive enterprise querying and brainstorming
  can leverage **buying** secure, contracted third-party tools (like OpenAI with protective
  agreements).

  *   **Hybrid AI Deployment:** The future involves a layered approach: an internal/private
  LLM option for basic interrogation, integration with enterprise tools like Microsoft
  Copilot for file connectivity, and specialized third-party legal tools for contract
  navigation. No single tool is expected to solve the lawyer''s entire day.

  *   **Evolving HITL:** Human-in-the-Loop is evolving beyond simple post-check validation.
  It must become a "new science" of inserting human oversight at the most critical
  junctures (e.g., decision points, external sharing) to validate trust without defeating
  the efficiency gains of processing massive data volumes.


  ### 3. Business/Investment Angle

  *   **The Cloud Analogy:** The initial nervousness around sharing data with third-party
  AI mirrors the early adoption challenges faced with cloud computing, suggesting
  a necessary evolution in organizational comfort levels.

  *   **ROI Measurement Crisis:** Demonstrating defensible ROI for AI is extremely
  challenging. It is difficult to track productivity gains (re-deployment of time)
  or cost savings across disparate internal development projects versus subscription
  costs for third-party tools (e.g., $25/user/month across thousands of employees).

  *   **Knowing When to Stop:** A critical, underdeveloped skill is determining when
  to "heal off" or cancel an AI initiative because the value proposition is not being
  met, highlighting the need for better tracking systems.


  ### 4. Notable Companies/People

  *   **Christo Siebrits (AbbVie):** The expert providing the perspective from a highly
  regulated pharmaceutical environment, focusing on practical implementation and risk
  mitigation.

  *   **AbbVie (ABV):** The context for the discussion, representing a regulated industry
  where data security is paramount.

  *   **Mentioned Tools:** ChatGPT, Microsoft Copilot, Harvey, CoCounsel, LegalOn
  (representing the spectrum of general-purpose vs. specialized legal AI).

  *   **Clarivate:** The episode sponsor.


  ### 5. Future Implications

  The industry is moving toward a nuanced, hybrid model where data residency and trust
  dictate the deployment strategy. The immediate future requires legal leaders to
  become comfortable with uncertainty regarding ROI and to actively develop sophisticated,
  context-specific Human-in-the-Loop protocols, especially where outputs interface
  with external parties (patients, partners, regulators).


  ### 6. Target Audience

  This episode is highly valuable for **Enterprise Legal Technology Leaders, Chief
  Legal Officers (CLOs), Compliance Officers, and IT/Digital Transformation Executives**
  operating within highly regulated industries (Pharma, Finance) who are currently
  grappling with vendor selection, data security policies, and justifying AI spend.'
tags:
- artificial-intelligence
- generative-ai
- investment
- openai
- microsoft
- google
title: From Tool Sprawl to Defensible Value in AI for Legal - with Christo Siebrits
  of AbbVie
topics:
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 67
  prominence: 1.0
  topic: artificial intelligence
- keywords:
  - generative ai
  - genai
  - chatgpt
  - gpt
  - claude
  - text generation
  - image generation
  mentions: 18
  prominence: 1.0
  topic: generative ai
- keywords:
  - investment
  - funding
  - valuation
  - ipo
  - acquisition
  mentions: 3
  prominence: 0.3
  topic: investment
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-10-13 18:39:50 UTC -->
