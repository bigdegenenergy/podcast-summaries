---
actionable_items:
- action: potentially
  category: investigation
  full_context: 'you could potentially '
  priority: medium
companies:
- category: unknown
  confidence: medium
  context: Hello everybody and welcome to the CIM Marketing Podcast, and today we're
    starting the season with AI Ques
  name: CIM Marketing Podcast
  position: 35
- category: unknown
  confidence: medium
  context: Podcast, and today we're starting the season with AI Question Time. Delighted
    to say we're joined by two expert gues
  name: AI Question Time
  position: 99
- category: unknown
  confidence: medium
  context: lighted to say we're joined by two expert guests, Kerry Harrison, who was
    an AI trainer and AI consultant, and in
  name: Kerry Harrison
  position: 169
- category: unknown
  confidence: medium
  context: ultant, and in fact, founder of the world's first AI Gin. Hello Kerry,
    how are you? I'm good, thank you, v
  name: AI Gin
  position: 268
- category: unknown
  confidence: medium
  context: and in fact, founder of the world's first AI Gin. Hello Kerry, how are
    you? I'm good, thank you, very good. Exc
  name: Hello Kerry
  position: 276
- category: unknown
  confidence: medium
  context: eat to have you on the show. We're also joined by Duncan Smith, who is
    a fellow of the CIM and is a data protect
  name: Duncan Smith
  position: 406
- category: unknown
  confidence: medium
  context: 'r most: how do I get the most out of these tools? So I think it does make
    a huge difference. There''s a r'
  name: So I
  position: 1925
- category: unknown
  confidence: medium
  context: s a really great prompting methodology called the GCSE Prompting methodology,
    which I think came out of Microsoft,
  name: GCSE Prompting
  position: 2024
- category: tech
  confidence: high
  context: Prompting methodology, which I think came out of Microsoft, and it's really
    great, which talks about the imp
  name: Microsoft
  position: 2078
- category: unknown
  confidence: medium
  context: f. So you don't actually even have to go to them. And I wonder over time
    if maybe we'll have to think abo
  name: And I
  position: 3818
- category: unknown
  confidence: medium
  context: ulatory bodies. So in my instance, it's often the Information Commissioner's
    Office, and I don't recognize the quote. I know
  name: Information Commissioner
  position: 5223
- category: tech
  confidence: high
  context: are. And I've had it on a notebook I learned from Google where it's actually
    said, I can't answer that que
  name: Google
  position: 6649
- category: tech
  confidence: high
  context: don't use that on a regular basis. I tend to use OpenAI's tools. I haven't
    used Claude as much as I've us
  name: Openai
  position: 8585
- category: unknown
  confidence: medium
  context: ', at an unphobic, would come out slightly better. But I think the fact
    that it just can hallucinate is th'
  name: But I
  position: 9153
- category: unknown
  confidence: medium
  context: ily. And so I think it depends what you're doing. If I always just say
    if it's anything statistical or f
  name: If I
  position: 11680
- category: unknown
  confidence: medium
  context: and, you know, what happened with replicants and Philip K. Dick's writing
    and things? And immediately that
  name: Philip K
  position: 12860
- category: unknown
  confidence: medium
  context: single sentence but didn't look at it afterwards. Because I think one of
    the things is one of the biggest thi
  name: Because I
  position: 20791
- category: unknown
  confidence: medium
  context: manufacturing, there was always something called Hazard Analysis Critical
    Control Point. You know, the last thing you want is a blue elas
  name: Hazard Analysis Critical Control Point
  position: 21684
- category: tech
  confidence: high
  context: hat process do I put that? We call it pulling the domino. So if you set
    dominoes up in a room and somebody
  name: Domino
  position: 22246
- category: unknown
  confidence: medium
  context: lack of humanness, the spotting the replicant as Blade Runner would have
    us, that we're very good at doing it.
  name: Blade Runner
  position: 25116
- category: unknown
  confidence: medium
  context: eric, boring, vanilla, like everyone else output. Custom GPT is one of
    the great things is you can give it ins
  name: Custom GPT
  position: 31833
- category: unknown
  confidence: medium
  context: h AI. So this would be my byline would become not Ben Walker, but Ben Walker
    and AI, Ben Walker and my mate, t
  name: Ben Walker
  position: 39924
- category: tech
  confidence: high
  context: mark it as AI generated. So I'll say generated on Midjourney or generated
    with Google or whatever it might be.
  name: Midjourney
  position: 40535
- category: unknown
  confidence: medium
  context: hink, so important. Just get that out of the way. Do I think enough people
    have that conversation at the
  name: Do I
  position: 45402
- category: unknown
  confidence: medium
  context: ny training on ethics other than perhaps watching Hot Fuzz and realizing
    that was all about ethics, you know
  name: Hot Fuzz
  position: 54486
- category: unknown
  confidence: medium
  context: course, we all know that. It's a load of rubbish. Some FDs get it, some
    FDs don't probably. I think if you s
  name: Some FDs
  position: 55536
- category: unknown
  confidence: medium
  context: of the risks. We might, for example, what was it, Air Canada, I think?
    Air Canada is one of those stories that
  name: Air Canada
  position: 58314
- category: unknown
  confidence: medium
  context: changing is the likelihood part of the equation. Does AI increase the likelihood?
    Yes. At this point, most
  name: Does AI
  position: 60806
- category: Professional Organization/Media
  confidence: high
  context: The podcast is named the 'CIM Marketing Podcast' and the guest is a 'fellow
    of the CIM'. CIM likely stands for the Chartered Institute of Marketing.
  name: CIM
  source: llm_enhanced
- category: tech
  confidence: high
  context: Mentioned as the origin of the 'GCSE Prompting methodology'.
  name: Microsoft
  source: llm_enhanced
- category: tech
  confidence: high
  context: Frequently mentioned as the most common AI tool used by marketers for prompting
    and generating content. Criticized for hallucinations.
  name: ChatGPT
  source: llm_enhanced
- category: Government/Regulatory
  confidence: high
  context: Mentioned as a regulatory body whose guidance Duncan checks against when
    using ChatGPT for legal/regulatory issues.
  name: Information Commissioner's Office (ICO)
  source: llm_enhanced
- category: tech
  confidence: high
  context: 'Mentioned in two contexts: 1) A notebook learned from Google where the
    AI admitted it couldn''t answer a question. 2) When entering a search in Google,
    it automatically pings up an AI answer (Search Generative Experience/AI Overviews).'
  name: Google
  source: llm_enhanced
- category: tech
  confidence: high
  context: Mentioned as another AI model alongside ChatGPT that research suggests
    doesn't fare very well in reliability tests.
  name: Gemini
  source: llm_enhanced
- category: tech
  confidence: high
  context: The company behind ChatGPT. The speaker mentions tending to use 'OpenAI's
    tools' more often.
  name: OpenAI
  source: llm_enhanced
- category: tech
  confidence: high
  context: Mentioned as an alternative model to ChatGPT. Research suggests it might
    have come out slightly better than ChatGPT before GPT-5 regarding hallucination
    rates.
  name: Claude
  source: llm_enhanced
- category: Government/Regulatory
  confidence: high
  context: The Financial Conduct Authority. Mentioned as the regulatory body setting
    rules for finance advertising copy, which AI might fail to include.
  name: FCA
  source: llm_enhanced
- category: consulting/tech
  confidence: high
  context: Duncan Smith's data protection and compliance consultancy.
  name: iComply
  source: llm_enhanced
- category: Media/Literature
  confidence: low
  context: Mentioned as a source of inspiration (science fiction/replicants) suggested
    by AI for an article idea.
  name: Philip K. Dick's writing
  source: llm_enhanced
- category: Media/Entertainment
  confidence: medium
  context: Mentioned in a discussion about factual accuracy (replicants/movies), where
    the speaker's editor corrected a potential error regarding the source material.
  name: Westworld
  source: llm_enhanced
- category: Consulting/Methodology
  confidence: medium
  context: Mentioned in relation to his lateral thinking tools, which the speaker
    tried to apply to AI to encourage conceptual thought.
  name: Edward de Bono
  source: llm_enhanced
- category: tech
  confidence: high
  context: Mentioned as a specific tool used to generate images for a newsletter,
    which the speaker marks as AI-generated.
  name: Midjourney
  source: llm_enhanced
- category: tech/airline
  confidence: high
  context: Used as a case study where their chatbot mishandled a grieving customer,
    illustrating reputational and legal risk from unchecked AI output.
  name: Air Canada
  source: llm_enhanced
- category: retail
  confidence: high
  context: Mentioned as an example of a company that suffered a recent cyber attack,
    used to draw parallels regarding the need for preventative investment like training.
  name: Marks and Spencer
  source: llm_enhanced
- category: tech/customer service
  confidence: high
  context: Mentioned as the source of the 'Clarner effect,' where a company devolved
    too much customer service to a bot, leading to customer dissatisfaction and the
    need to bring human staff back.
  name: Clarner
  source: llm_enhanced
- category: tech/case study
  confidence: high
  context: Mentioned as a useful case study following the negative outcome experienced
    by Clarner.
  name: Gidges
  source: llm_enhanced
date: 2025-10-02 03:30:00 +0000
duration: 74
has_transcript: false
insights:
- actionable: true
  confidence: medium
  extracted: be training
  text: we should be training.
  type: recommendation
- actionable: true
  confidence: medium
  extracted: be talking to marketers about the reality check of we're not living in
    the world of enterprise million-pound budgets
  text: we should be talking to marketers about the reality check of we're not living
    in the world of enterprise million-pound budgets.
  type: recommendation
- actionable: true
  confidence: medium
  extracted: be watermarking content
  text: we should be watermarking content.
  type: recommendation
- actionable: true
  confidence: medium
  extracted: be thinking a bit deeper about this
  text: we should be thinking a bit deeper about this.
  type: recommendation
layout: episode
llm_enhanced: true
original_url: https://audio.listennotes.com/e/p/c656125e249340e99db5b9a5f8667aa7/
processing_date: 2025-10-06 04:11:35 +0000
quotes:
- length: 152
  relevance_score: 5
  text: Because I think one of the things is one of the biggest things that constantly
    plead in my course is, please don't copy and paste output and just use it
  topics: []
- length: 217
  relevance_score: 5
  text: It's the idea of where in a process from a marketer's perspective, if you
    start engaging with AI, if you start and really getting to grips with the tool,
    you have to think about how it fits into the marketing workflow
  topics:
  - market
- length: 237
  relevance_score: 5
  text: That's one of the, if you start introducing AI into things like customer service
    chatbots, the one thing that you have to do is almost like adding salt sugar in
    a recipe is you have to balance that up perhaps with more sentiment analysis
  topics: []
- length: 181
  relevance_score: 4
  text: And there is, from the homogenization, there is that sort of very philosophical
    thing that says, at some point in the not too distant future, AI is training itself
    on its own output
  topics: []
- length: 218
  relevance_score: 4
  text: What marketer has had any training on ethics other than perhaps watching Hot
    Fuzz and realizing that was all about ethics, you know, that, you know, that idea
    that's for the greater good, or is it, am I following rules
  topics:
  - market
- length: 114
  relevance_score: 4
  text: It's a hard ask to spend money on that kind of training because the return
    on investment is not immediate for sure
  topics:
  - investment
- length: 253
  relevance_score: 3
  text: So I think if you're staying in the free model and you move up to ChatGPT,
    the first level of paid, you just have more usage, so you don't run out, because
    it's really frustrating if you're doing work and then you run out of credits,
    or you have to wait
  topics: []
- length: 82
  relevance_score: 3
  text: One of the biggest stumbling blocks I've had to using AIs is for that exact
    reason
  topics: []
- length: 67
  relevance_score: 3
  text: If I took it into ChatGPT, for example, say, "Here's what we've got
  topics: []
- length: 71
  relevance_score: 3
  text: But the reality is it just ain't going to happen for most of the public
  topics: []
- length: 111
  relevance_score: 3
  text: So I think having those conversations, yes, it is a person or you have to
    take personal responsibility for that
  topics: []
- length: 154
  relevance_score: 3
  text: And I think the responsibility there is for the employer to recognize that
    you have to bring those people through, otherwise there is a thing in your body
  topics: []
- impact_reason: Provides an actionable, structured methodology (GCSE) for effective
    prompt engineering, highly valuable for practitioners.
  relevance_score: 10
  source: llm_enhanced
  text: There's a really great prompting methodology called the GCSE Prompting methodology,
    which I think came out of Microsoft, and it's really great, which talks about
    the importance of having a goal, some context, some sources—so giving it some
    kind of example—and then E, which is expectations, which is setting expectations
    of what you want them all to deliver for you.
  topic: Technology
- impact_reason: A significant prediction about the evolution of AI interaction moving
    from direct querying to autonomous task execution via agents.
  relevance_score: 10
  source: llm_enhanced
  text: I think in terms of websites, what will change will probably be the greater
    use of AI agents. So if you think about ChatGPT now, they've got an agent tool
    built into it. So you literally just set it a task, and off it will go, and it'll
    do its thing.
  topic: Technology/Industry Trends
- impact_reason: 'A critical strategic insight for web development and digital marketing:
    websites must be optimized for both human users and autonomous AI agents.'
  relevance_score: 10
  source: llm_enhanced
  text: As agents become more commonplace, we're going to have to think about how
    can we make our websites relevant, not just to people, but also how can we make
    sure that the agents that people send out on their behalf get the information
    that we want them to get? So I think they'll have to have this kind of hybrid
    dual purpose, which at the moment they don't really have.
  topic: Business/Technology
- impact_reason: 'Identifies the most dangerous aspect of hallucinations: presenting
    fabricated information with authoritative formatting (citations), posing significant
    legal/compliance risk.'
  relevance_score: 10
  source: llm_enhanced
  text: I think what's really challenging for anybody looking at the response is when
    it makes those things up, the fact that it puts it in a rotation block and cites
    the source... when it quotes a regulatory source and says the regulator says it's
    okay to do that, that is just plain dangerous.
  topic: Business/Compliance
- impact_reason: 'Offers a powerful, relatable analogy for the current state of AI
    productivity: the time spent verifying complex AI output often negates the time
    saved.'
  relevance_score: 10
  source: llm_enhanced
  text: A very mean analysis of that is it's a bit like having an untrained intern
    in the office and asking them to do a professional task... that very often if
    you're marking their homework, if you're checking their work, it is quicker and
    more reliable to do it from scratch yourself.
  topic: Business/Productivity
- impact_reason: Provides a concrete example (FCA regulations in finance advertising)
    illustrating mandatory human verification for compliance elements.
  relevance_score: 10
  source: llm_enhanced
  text: If you're in finance and you ask it to create the copy for a finance ad, but
    we know there are rules that the FCA puts around us as to what needs to be said,
    your APIs and things have to be in there. And if the ChatGPT or whatever doesn't
    put those in, somebody has to check them.
  topic: Compliance/Business
- impact_reason: 'Defines a clear boundary for AI utility: it struggles with high-level,
    lateral, conceptual creative tasks.'
  relevance_score: 10
  source: llm_enhanced
  text: I think it's important to know when not to use it. So, for example, I think
    for highly conceptual creative work, I just don't think you can do it, and believe
    me, I've tried everything.
  topic: technology/business
- impact_reason: 'Presents the winning formula for modern professional work: the synergy
    between deep human expertise and AI assistance.'
  relevance_score: 10
  source: llm_enhanced
  text: Leaning into your expertise in your field, I think is really important with
    AI. And that kind of combination of deep expertise, human expertise, and AI, I
    think is like a really brilliant combination.
  topic: technology/business
- impact_reason: A significant philosophical warning about the long-term feedback
    loop of AI training on its own output, leading to content decay (dullness/inaccuracy).
  relevance_score: 10
  source: llm_enhanced
  text: At some point in the not too distant future, AI is training itself on its
    own output. And of course, if we allow that to happen, then content is going to
    become pretty dull and early and inaccurate.
  topic: technology
- impact_reason: Introduces a specific, actionable framework ('AI Sandwich') for maximizing
    authentic AI output.
  relevance_score: 10
  source: llm_enhanced
  text: I have this methodology. It's called the AI sandwich, which I created at the
    beginning of 2024. And it's this idea that to get the best kind of content out
    of AI... we need a combination of a sort of three-part process of human, AI, and
    then human.
  topic: technology/business
- impact_reason: 'Pinpoints the core current limitation of AI: the inability to authentically
    replicate nuanced human values and empathy, which humans are adept at detecting.'
  relevance_score: 10
  source: llm_enhanced
  text: Machines are struggling with human values. And why is it that a human can
    recognize another? What is it in that text that goes, ah, thankfully, that's not
    AI?
  topic: Technology/AI Limitations
- impact_reason: 'Details the critical security features of enterprise AI versions:
    on-premise options and data isolation (''no-trained command'').'
  relevance_score: 10
  source: llm_enhanced
  text: The enterprise versions, the paid-for versions, will give you the possibility
    of on-premises. They'll certainly give you a ring fence around it, so you can
    have a no-trained command. So whatever you put in there doesn't go into the public
    training model.
  topic: Business/Security & Governance
- impact_reason: A stark, personal example of the risk associated with using free/standard
    LLMs for proprietary or pre-publication content.
  relevance_score: 10
  source: llm_enhanced
  text: If I'm using the standard off-the-shelf ChatGPT, I'm working on stuff that's
    not in the public domain... I don't do that, because I think I've just given you
    all of that information, which you're now going to disseminate to the world and
    her wife.
  topic: Business/Data Security
- impact_reason: 'Articulates the ''Shadow AI'' problem: banning official use drives
    adoption underground, making compliance impossible. Official adoption is a control
    mechanism.'
  relevance_score: 10
  source: llm_enhanced
  text: It also makes a very strong message that we do have a shadow AI, which is
    a huge problem in terms of compliance, which is if you don't implement AI, half
    the team have got it on their phone anyway, and they're using, of course, the
    free version to do what you would like them to do on the paid version.
  topic: Business/Strategy & Governance
- impact_reason: Establishes the critical 'Human-in-the-Loop' framework for AI usage,
    stressing individual accountability for outputs.
  relevance_score: 10
  source: llm_enhanced
  text: Human, AI, human, we've got to be the guardians. We've got to be in charge
    of what we're doing ourselves. It comes down to personal responsibility, I think.
  topic: Ethics/Process Control
- impact_reason: Directly links the failure to discuss AI usage to the risk of losing
    established client relationships.
  relevance_score: 10
  source: llm_enhanced
  text: I do think we have to have those awkward conversations with clients because
    the trust, I think, is such an important part of a relationship. And I think with
    AI, people, if you lose trust with your clients, long-standing clients, that could
    be super detrimental.
  topic: Business Strategy/Trust
- impact_reason: Reframes the AI discussion from a binary 'yes/no' to a nuanced conversation
    about the *degree* of AI contribution.
  relevance_score: 10
  source: llm_enhanced
  text: The discussions you have is around the extent to which you have used it and
    to the extent which it has contributed to your final output. So you're transparent
    about it and you're having a conversation about the gray areas in the middle that
    matter of degree.
  topic: Process/Transparency
- impact_reason: 'Forces a fundamental strategic question for clients: what is the
    core value proposition they are paying for—authenticity or efficacy?'
  relevance_score: 10
  source: llm_enhanced
  text: Do you attach the value to? Is it authentic content or is it content that
    does a job? If the content does the job and it was written by AI, do I have a
    problem?
  topic: Business Strategy/Value Proposition
- impact_reason: 'Presents a counter-argument to job loss fears: pure AI output lacks
    the necessary human elements (authenticity, brand voice) to be truly valuable.'
  relevance_score: 10
  source: llm_enhanced
  text: The machines are going to take our jobs... Because what I've heard today is
    that if you devolve your work to machines, it will pretty much be homogenous and
    inauthentic.
  topic: Future of Work/Strategy
- impact_reason: 'Summarizes the core risks associated with unmanaged AI content generation:
    factual errors and brand misalignment.'
  relevance_score: 10
  source: llm_enhanced
  text: There's a high risk of it [AI output]. It will be littered with hallucinations,
    slash errors, slash lies, or there's a great risk of it. And it will be, it risks
    being inauthentic for your brand.
  topic: Technology Risk
- impact_reason: Reiterates the essential 'Human-AI-Human' workflow as the mitigation
    strategy against AI risks.
  relevance_score: 10
  source: llm_enhanced
  text: The answer to this is human, AI, human, a human being the marketer at the
    end of the, at the start and the end of the process.
  topic: Process Control/Strategy
- impact_reason: This is a core warning about over-reliance on generative AI, highlighting
    the risks of homogeneity, inauthenticity, and factual errors (hallucinations)
    in marketing output.
  relevance_score: 10
  source: llm_enhanced
  text: if you devolve your work to machines, it will pretty much be homogenous and
    inauthentic. There's a high risk of it. It will be littered with hallucinations,
    slash errors, slash lies, or there's a great risk of it. And it will be, it risks
    being inauthentic for your brand.
  topic: Technology/Marketing
- impact_reason: A blunt prediction about job displacement in specific, data-heavy
    marketing functions where machines demonstrably outperform humans.
  relevance_score: 10
  source: llm_enhanced
  text: I think the writing's on the wall when it comes to anything that has large
    volumes of statistical data input analysis, programmatic marketing, those kind
    of things. I think some of the agencies that are involved in programmatic and
    some of the jobs that are currently done by people, the machine does it better.
  topic: Technology/Industry Trends
- impact_reason: A powerful, specific statistic indicating the current market premium
    placed on demonstrable AI proficiency, even over traditional experience.
  relevance_score: 10
  source: llm_enhanced
  text: 73% of employers would be, would hire someone with AI skills and less experience
    than hire someone with more experience without them.
  topic: Industry Trends/Career
- impact_reason: Uses a high-profile case study (Air Canada chatbot failure) to pivot
    the ROI discussion from productivity gains to risk mitigation costs.
  relevance_score: 10
  source: llm_enhanced
  text: We're training them to spot some of the risks. We might, for example, what
    was it, Air Canada, I think? Air Canada is one of those stories that everybody
    leaves... where their chatbot mishandled a grieving customer... That the reputational
    cost, the legal cost, that had we not trained somebody to think about that tool
    better, we could have avoided all of those costs that you haven't factored into
    buying the tool.
  topic: Risk Management/Case Study
- impact_reason: 'Provides a simple, powerful risk assessment framework for FDs: AI
    often increases the *likelihood* of negative outcomes (like bad advice) if human
    checks are omitted.'
  relevance_score: 10
  source: llm_enhanced
  text: Ask yourself the question now, is AI going to increase the likelihood of that
    or reduce the likelihood of that? And the answer is often it increases the likelihood
    of it unless we have this human check in the process.
  topic: Risk Management/Strategy
- impact_reason: This directly addresses the core risk equation of deploying AI in
    high-stakes environments, highlighting that AI often increases the *likelihood*
    of error without human oversight.
  relevance_score: 10
  source: llm_enhanced
  text: Is AI going to increase the likelihood of [giving bad advice] or reduce the
    likelihood of that? And the answer is often it increases the likelihood of it
    unless we have this human check in the process.
  topic: Technology/Risk Management
- impact_reason: A powerful real-world anecdote illustrating the failure of over-reliance
    on AI for complex, human-centric tasks, leading to necessary rehiring.
  relevance_score: 10
  source: llm_enhanced
  text: They got rid of 700 staff members and saying, 'Okay, AI is going to do our
    job for us. We've got an AI that can do the job of 700.'... And now in 2025, we're
    slowly bringing those people back in because it's not nuanced enough. It's not
    human enough.
  topic: Startups/Industry Trends
- impact_reason: A concise metaphor illustrating that prompt quality directly impacts
    the value and quality of the AI output, moving beyond 'vanilla' results.
  relevance_score: 9
  source: llm_enhanced
  text: The difference between a bog-standard AI Gin and an award-winning one.
  topic: Technology/Business
- impact_reason: Confirms the critical importance of prompting skills for maximizing
    AI utility, a key skill for tech professionals.
  relevance_score: 9
  source: llm_enhanced
  text: 'I think they really do have a big impact on the output. That''s one of the
    things I teach in all of my courses: prompting, and it''s actually one of the
    things that people ask for most: how do I get the most out of these tools?'
  topic: Technology/Startups
- impact_reason: Highlights the trade-off between speed (simple prompts) and value
    (detailed prompts), a core strategic decision in AI adoption.
  relevance_score: 9
  source: llm_enhanced
  text: I think if you just, obviously with these tools, one of the great things is
    you can just rock up and give it one-sentence prompt, and it will deliver something
    for you, but I think what we get with that is a very sort of vanilla, quite mediocre
    output, and actually taking the time for prompting makes that output much more
    valuable.
  topic: Business/Technology
- impact_reason: Directly addresses the core reliability issue (hallucinations) in
    LLMs, framing it starkly for business risk assessment.
  relevance_score: 9
  source: llm_enhanced
  text: One thing that ChatGPT, the most common tool, has been criticized, probably
    fairly, for is what IT people call hallucinations, which is what every other normal
    person on the planet calls errors. I call it lying.
  topic: Technology
- impact_reason: 'Reveals the inherent design flaw in current LLMs: they are trained
    to always provide an answer rather than admit uncertainty, making ''I don''t know''
    a sign of advanced reliability.'
  relevance_score: 9
  source: llm_enhanced
  text: I don't think it's capable of saying, that's a tough one, Duncan. You know,
    I don't know. Yeah, whenever they, whenever, so it's very, very rare. And I've
    had it on a notebook I learned from Google where it's actually said, I can't answer
    that question. I was so excited. Actually, that's impressive.
  topic: Technology
- impact_reason: 'Differentiates the level of required verification based on the output''s
    purpose: high-stakes (legal, finance) vs. low-stakes (ideation, starting points).'
  relevance_score: 9
  source: llm_enhanced
  text: I think that's as we go forward, that's something we really have to work harder.
    I think it also depends on the kind of what you're creating with it as well, though.
    So for me, because I work mainly in copying content, it's actually, you don't
    necessarily, the things that it's generating, you don't necessarily have to factor,
    because it might be some ideas or a starting point...
  topic: Business/Strategy
- impact_reason: 'Clear, actionable advice: fact-check anything involving data, statistics,
    or regulatory claims.'
  relevance_score: 9
  source: llm_enhanced
  text: If it's anything statistical or fact-tolerant, of course, it's bringing about
    like you say something from some papers somewhere, then yeah, you need to fact-check
    it...
  topic: Technology/Compliance
- impact_reason: 'Defines the most reliable and immediate value proposition of current
    generative AI: overcoming initial creative block and serving as an idea generator.'
  relevance_score: 9
  source: llm_enhanced
  text: It's the greatest, of course, as a course, isn't it? I think it's on an ideas
    listing tool. It can be very, very useful. It takes out that initial sort of,
    oh, that's initially brain fog. I've got to get in and try and find a load of
    examples to start me off. So fabulous springboard.
  topic: Business/Startups
- impact_reason: Emphasizes that the *possibility* of error, regardless of frequency,
    mandates constant vigilance (being 'on guard').
  relevance_score: 9
  source: llm_enhanced
  text: I think the fact that it just can hallucinate is the issue, isn't it? It's
    like whether it's 70% at the time or 10% at the time, it's just the fact that
    we have to be aware. So there's a possibility, and therefore we have to be on
    guard whenever we use that.
  topic: Compliance/Technology
- impact_reason: 'Poses the central economic and productivity question surrounding
    AI adoption: Does the time saved equal the time required for verification?'
  relevance_score: 9
  source: llm_enhanced
  text: Is actually the use of AI valuable to us when we make time savings, but then
    do we have to use that time saving to then check the output of everything that
    comes out?
  topic: Business/Productivity
- impact_reason: Connects AI content generation directly to regulatory risk in high-stakes
    marketing areas like sustainability claims.
  relevance_score: 9
  source: llm_enhanced
  text: If we're talking about sustainability, for example, say, let's write some
    podcasts or some content for that. Obviously, there's legislation and consumer
    protection legislation around those things. That means we have to check, as we
    always would, we would check the content to something that matters.
  topic: Compliance/Business
- impact_reason: A critical warning about the necessity of human oversight (editors/fact-checkers)
    when using AI-generated content to mitigate errors.
  relevance_score: 9
  source: llm_enhanced
  text: The danger I think is that you take that content as read and you run with
    it and you don't fact-check it. And that's why it's to have a copyright or an
    editor that really knows their stuff is vital.
  topic: technology/business
- impact_reason: 'A core strategic insight: successful AI integration requires understanding
    both human capability boundaries and technological constraints.'
  relevance_score: 9
  source: llm_enhanced
  text: I think it's about knowing one's own limits and the limits of the technology.
  topic: technology/business
- impact_reason: Cautionary advice against over-relying on AI as an omniscient solution,
    contrasting it with its practical utility as a focused tool.
  relevance_score: 9
  source: llm_enhanced
  text: If you treat it in that way [as 42, the life, the universe, and everything],
    you're going to come and start very quickly. If you use it within the limits of
    what it can do as an idea generation tool, as a springboard, it can be incredibly
    powerful...
  topic: technology
- impact_reason: Identifies 'homogenization' as a major risk in marketing if AI is
    used without human guidance, leading to generic output.
  relevance_score: 9
  source: llm_enhanced
  text: Another flaw that marketers have encountered very quickly is this idea of
    homogenization, that if you devolve your creative work to an AI, it will generate
    for you pretty much what it's going to generate for every other marketer in the
    world.
  topic: business/technology
- impact_reason: Connects AI overuse directly to the loss of crucial 'brand authenticity'
    that consumers seek.
  relevance_score: 9
  source: llm_enhanced
  text: We're not going to have that brand authenticity, which is what we all crave
    as marketers, if we do, as Duncan says, and not as Duncan recommends, as Duncan
    describes, and devolve this sort of process to an AI.
  topic: business
- impact_reason: Stresses the critical importance of pre-prompting preparation—the
    quality of the human input determines the quality of the AI output.
  relevance_score: 9
  source: llm_enhanced
  text: 'The prompting that we give it, the time that we take before we even touch
    the tools is really important: having an objective, knowing what the brand is,
    putting all this, any kind of research we''ve got into our prompting...'
  topic: technology
- impact_reason: 'Defines the crucial second ''human'' phase of the AI Sandwich: injecting
    proprietary knowledge and expertise post-generation.'
  relevance_score: 9
  source: llm_enhanced
  text: And then afterwards we've got the human again. And this is where we send,
    check it, we fact-check it, and we also add our own deep expertise of our brands,
    our objectives, our customers, of the world that we live in...
  topic: technology/business
- impact_reason: A direct, strong plea to professionals against lazy adoption; human
    contribution is mandatory for authenticity.
  relevance_score: 9
  source: llm_enhanced
  text: Please don't copy and paste output and just use it. Like, please add something
    of yourself into it because it's so important for that authenticity side of things.
  topic: technology/business
- impact_reason: Provides a powerful metaphor ('holding the tenth domino') for maintaining
    control over the final deployment stage of an automated workflow.
  relevance_score: 9
  source: llm_enhanced
  text: We call it pulling the domino. So if you set dominoes up in a room... What
    you really want is somebody to be holding the tenth domino and go, you shouldn't
    have kicked that first one off, should you? I hold the tenth domino, which means
    I decide when it's going to run and I put it in...
  topic: business/technology
- impact_reason: Predicts a future market dynamic where genuine creativity and effort
    will be a significant differentiator against generic AI output.
  relevance_score: 9
  source: llm_enhanced
  text: I also feel like if you can be creative and you can actually be bothered to
    do the hard work, you will also really stand out.
  topic: startups/business
- impact_reason: 'A concise statement on the fundamental current limitation of AI:
    inability to grasp nuanced human values.'
  relevance_score: 9
  source: llm_enhanced
  text: Machines are struggling with human values.
  topic: technology
- impact_reason: Highlights the bifurcation of AI-generated content into generic noise
    versus high-quality, creative output, emphasizing the value of genuine effort.
  relevance_score: 9
  source: llm_enhanced
  text: There'll be a real divide between the stuff that's very generic that we just
    kind of pass over, and then there'll be the stuff that's really beautiful. And
    I think that that's where we'll get the most from.
  topic: Technology/Content Quality
- impact_reason: 'A direct warning to brands: off-the-shelf AI language is becoming
    a recognizable liability that undermines authenticity.'
  relevance_score: 9
  source: llm_enhanced
  text: If your brand is about authenticity and being in touch with people, there
    has to be a sort of AI ease, hasn't there? Sort of a language of AI that has become
    a bit too easy to spot, certainly from the off-the-shelf AI.
  topic: Business/Branding
- impact_reason: Emphasizes that effective AI customization requires deep introspection
    and deconstruction of one's own expert workflow.
  relevance_score: 9
  source: llm_enhanced
  text: I think it's just about breaking down your own processes. So I've created
    custom GPTs, for example, that write LinkedIn posts for me. And in order to do
    that, I had to almost go back to my, like, when I write LinkedIn posts, what do
    I do? What process do I move through?
  topic: Startups/Productivity
- impact_reason: Clearly contrasts poor prompting with expert prompting, highlighting
    the necessity of providing context, tone, and examples.
  relevance_score: 9
  source: llm_enhanced
  text: 'The difference between turning it with a one-sentence problem: ''Write me
    a blog on'' versus ''Write me a blog on, you know, here''s my information. These
    are the kind of, this is the tone of voice that I''d like you to adopt. Here''s
    some examples of tone or style that I''d like you to follow.'''
  topic: Technology/Prompt Engineering
- impact_reason: Highlights Custom GPTs (or similar features like Claude Projects)
    as the key mechanism for moving beyond generic output to proprietary, valuable
    results.
  relevance_score: 9
  source: llm_enhanced
  text: Custom GPT is one of the great things is you can give it instructions, you
    can give it knowledge. So what it's generating is not what everyone else is generating.
  topic: Technology/Customization
- impact_reason: 'Provides a crucial reality check for consultants and trainers: most
    organizations will use COTS (Commercial Off-The-Shelf) public models, not bespoke
    enterprise solutions.'
  relevance_score: 9
  source: llm_enhanced
  text: The reality check is for the vast majority of people that you and I train,
    it's just not going to happen. We're going to be taking commercial off-the-shelf
    software. We're going to be looking at the, what we can literally access straight
    from the web.
  topic: Startups/Adoption Reality
- impact_reason: Summarizes the gap between ideal, secure AI infrastructure and the
    practical, accessible solutions available to the majority of the market.
  relevance_score: 9
  source: llm_enhanced
  text: There is, there is technically, theoretically a solution where you have a
    sort of locked-up enterprise solution which addresses all of the issues we've
    talked about this morning. But the reality is it just ain't going to happen for
    most of the public.
  topic: Technology/Implementation Gap
- impact_reason: 'Defines the immediate, accessible reality for most professionals:
    leveraging paid, public-facing LLMs rather than building proprietary infrastructure.'
  relevance_score: 9
  source: llm_enhanced
  text: We're going to be taking commercial off-the-shelf software. We're going to
    be looking at the, what we can literally access straight from the web. So it's
    going to be ChatGPT, and I'm probably going to pay for the this version I can
    get to get the most attractive model out of it.
  topic: Technology Adoption
- impact_reason: A strong statement on the regulatory lag concerning AI and intellectual
    property.
  relevance_score: 9
  source: llm_enhanced
  text: We're way, way, way behind in terms of copyright legislation. It's a can that's
    being kicked down the road at the moment very definitely.
  topic: Industry Trends/Legislation
- impact_reason: Connects AI utility directly to the emerging necessity for content
    traceability and authenticity markers.
  relevance_score: 9
  source: llm_enhanced
  text: AI is going to be a very valuable tool for content creation. But it does segue
    into this issue about transparency and provenance and whether we should be watermarking
    content.
  topic: Technology/Ethics
- impact_reason: Provides concrete evidence (EU legislation) supporting the trend
    toward mandatory content provenance tracking.
  relevance_score: 9
  source: llm_enhanced
  text: There is legislation coming forward. Already we see legislation coming forward.
    It's already in EU co-supractors that says in terms of the provenance of content,
    it's so important that the rest of us understand where it came from.
  topic: Legislation/Future Trends
- impact_reason: A clear, actionable example of maintaining audience trust through
    proactive disclosure of AI usage.
  relevance_score: 9
  source: llm_enhanced
  text: I always mark it [AI-generated images] as AI generated... I just never want
    that to be a thing. I want people to come into my newsletter and trust what they
    see as what they see.
  topic: Client Trust/Transparency
- impact_reason: 'Proposes the most effective point for transparency: embedding the
    AI discussion directly into the initial project brief.'
  relevance_score: 9
  source: llm_enhanced
  text: We sort of reached the side of actually putting it in the brief, you know,
    having the conversation with the client at brief stage and saying, 'Where are
    we going to use AI for this?'
  topic: Business Process
- impact_reason: Highlights the unreliability and potential injustice of current AI
    detection tools, even when human work is original.
  relevance_score: 9
  source: llm_enhanced
  text: People are starting to run your content through AI checkers. And so it, and
    I'm sure they read it and go, 'Well, it's come up as 90% AI in your thinking.'
    'No, I definitely wrote that.'
  topic: Technology Limitations/Risk
- impact_reason: 'Defines the ethical failure in localization: using AI output without
    native human verification is a disservice to the client.'
  relevance_score: 9
  source: llm_enhanced
  text: If you've used the machine language learning tools and not checked yourself
    as that native Spanish speaker or native English speaker, then you are short-changing
    the client.
  topic: Ethics/Quality Control
- impact_reason: Uses the failure of the creator (OpenAI) to build a reliable detector
    as evidence that detection tools are fundamentally untrustworthy.
  relevance_score: 9
  source: llm_enhanced
  text: If OpenAI can't make a detection tool that's reliable enough of them to run
    it, then I just thought, well, who can?
  topic: Technology Limitations
- impact_reason: 'Actionable advice for junior professionals: proactive mastery of
    AI tools is essential for career survival and growth, regardless of job security
    fears.'
  relevance_score: 9
  source: llm_enhanced
  text: I think such a difficult question. I feel like for young people or people
    in their early stage of their career, it's just really a good idea to just get
    on top of AI and just to see how it can help you.
  topic: Startups/Career
- impact_reason: A critical observation on the structural impact of AI on entry-level
    roles and the potential erosion of traditional apprenticeship/training pipelines.
  relevance_score: 9
  source: llm_enhanced
  text: I'm not sure whether the young people today will have those opportunities
    [deep training opportunities]... If a lot of the more basic roles are a bit, are
    able to happen with AI, whether or not we'll need as many juniors.
  topic: Business/Workforce
- impact_reason: 'Highlights the long-term strategic challenge for organizations:
    balancing immediate AI efficiency gains with the necessity of maintaining institutional
    knowledge transfer.'
  relevance_score: 9
  source: llm_enhanced
  text: How can we make sure that we are developing expertise alongside developing
    our AI? Because at some point when the older people like me leave the profession,
    then who's going to train up the people below?
  topic: Strategy/Workforce
- impact_reason: 'Defines the new role of the marketer: shifting from execution to
    strategic control and mastery of the AI toolset.'
  relevance_score: 9
  source: llm_enhanced
  text: The marketer has to retrain, rethink. So we need to be understanding what
    the tool does and then how do I use the tool? So I need to be the person that's
    controlling the tool.
  topic: Career/Technology
- impact_reason: Frames the talent pipeline as the central strategic risk for companies
    adopting AI, moving beyond immediate efficiency gains.
  relevance_score: 9
  source: llm_enhanced
  text: The real risk is thinking, how do we maintain a flow of marketers new to the
    profession going through and becoming valuable enough to survive the cut?
  topic: Business/Strategy
- impact_reason: A strong call to action for employers regarding the necessity of
    formal ethics training in the age of AI, especially for new hires.
  relevance_score: 9
  source: llm_enhanced
  text: I think nurturing employers have a real responsibility here to think about
    nurturing those people with the training that they can give on ethics.
  topic: Business/Ethics
- impact_reason: Articulates the difficulty of justifying investment in junior roles
    (who bring 'ethereal' skills like ethics) to finance departments focused purely
    on immediate cost centers.
  relevance_score: 9
  source: llm_enhanced
  text: Marketing already has an issue that it's seen as a cost center... This makes
    it even more challenging, doesn't it? That if you're saying to the FD... 'we are
    going to continue to bring young people into the fresh and lower ladder'... but
    they are bringing a whole bunch of ethereal things like ethics and morals and
    critical thinking into the business...
  topic: Business/Finance
- impact_reason: 'A sophisticated breakdown of risk factors: AI changes the *likelihood*
    variable in the risk equation, making human oversight crucial.'
  relevance_score: 9
  source: llm_enhanced
  text: The severity hasn't changed. We still gave bad advice. The human gave bad
    advice, the machine gave bad advice. So that hasn't changed. So the only factor
    that's changing is the likelihood part of the equation. Does AI increase the likelihood?
    Yes.
  topic: Risk Management/Technology
- impact_reason: Connects the risk-based argument directly to securing budget and
    buy-in from finance for human oversight roles.
  relevance_score: 9
  source: llm_enhanced
  text: If we make that case, then suddenly the argument for human checkers, humans
    in the loop, becomes a lot more powerful when we're talking to finance departments.
  topic: Strategy/Business
- impact_reason: 'A direct recommendation for employers: tolerate inefficiency at
    the entry level to preserve the talent pipeline necessary for future senior roles.'
  relevance_score: 9
  source: llm_enhanced
  text: In order for organizations to protect their pipeline... they're going to have
    to tolerate the fact that at their entry level, sometimes the task could be done
    by machines and it just let human beings do them.
  topic: Strategy/Talent Management
- impact_reason: Provides a clear, actionable framework (Severity x Likelihood) for
    assessing AI deployment risk, emphasizing that AI primarily impacts the 'likelihood'
    variable.
  relevance_score: 9
  source: llm_enhanced
  text: So from a really simple risk equation, which your FD will get eaten instantly,
    is there's the severity and likelihood. The severity hasn't changed. We still
    gave bad advice. The human gave bad advice, the machine gave bad advice. So that
    hasn't changed. So the only factor that's changing is the likelihood part of the
    equation. Does AI increase the likelihood? Yes.
  topic: Business/Risk Management
- impact_reason: 'Offers a direct business response to increased AI risk: increased
    investment in human training and risk management processes, framed within the
    Return on Investment (ROI) discussion.'
  relevance_score: 9
  source: llm_enhanced
  text: We see our risk going up. I think we need to start training people a little
    more. We need to start feeding in more money into this process. So we can use
    AI, but we manage that risk process in the ROI.
  topic: Business/Strategy
- impact_reason: 'A concise summary of the dual nature of AI adoption: massive scaling
    benefits coupled with inherent risk amplification.'
  relevance_score: 9
  source: llm_enhanced
  text: It helps us rapidly scale, Kerry. It increases our ability to do things at
    volume. But it also increases risk.
  topic: Technology/Business
- impact_reason: Introduces a named concept ('Clarner effect') for the phenomenon
    of brand damage resulting from excessive automation in customer interaction.
  relevance_score: 9
  source: llm_enhanced
  text: I read some recent news called it the Clarner effect. And I just thought it
    was quite interesting. They devolved too much of the customer service to a bot
    or any AI, and into the customer's effect, really.
  topic: Industry Trends/Customer Experience
- impact_reason: Provides anecdotal evidence of the model's tendency to fabricate
    information when challenged, emphasizing the need for human oversight.
  relevance_score: 8
  source: llm_enhanced
  text: I have a folder now on ChatGPT, which is all the time I've had an argument
    with it... And ultimately it says, you got me. It's a very polite liar. It is.
  topic: Technology
- impact_reason: A strong cautionary statement emphasizing the severe professional
    liability associated with trusting unverified AI output in regulated fields.
  relevance_score: 8
  source: llm_enhanced
  text: I would have been fired 20 years ago if I did, if I'd ever did that in my
    profession.
  topic: Business/Compliance
- impact_reason: Provides context on the scale of the hallucination problem and notes
    that model iteration (like GPT-5) is actively addressing this core weakness.
  relevance_score: 8
  source: llm_enhanced
  text: Some of that suggests that they can hallucinate up to 75%, but I think that's
    getting lit. I think the ChatGPT 5, one of the things that they celebrated in
    the release of that was the lowering of hallucination rates.
  topic: Technology/Industry Trends
- impact_reason: Reinforces the necessity of the 'Human in the Loop' (HITL) for quality
    control, even when the AI provides a creative spark.
  relevance_score: 8
  source: llm_enhanced
  text: It's a great surfacing tool for ideas. And, you know, as you said, if there
    are stats that my editor called me out on what your brinner actually did was he
    in Westworld or was he in? And yeah, and the editor caught me out on that. That
    was a human in the loop that said, huh, Duncan, you've made a mistake there.
  topic: Technology/Business
- impact_reason: A sharp, practical warning about basic data compliance errors, relevant
    to anyone handling customer data, especially in marketing.
  relevance_score: 8
  source: llm_enhanced
  text: Don't put everybody's email in the two box, say nothing else. [Regarding a
    data breach lesson]
  topic: Compliance
- impact_reason: 'A crucial methodological warning for tech professionals: anecdotal
    evidence about model performance (OpenAI vs. Claude) must be weighed against scientific
    research.'
  relevance_score: 8
  source: llm_enhanced
  text: I tend to use OpenAI's tools. I haven't used Claude as much as I've used ChatGPT.
    So I think you need to be careful about personal experience versus something which
    is rigorous, peer-reviewed, scientific research.
  topic: Technology
- impact_reason: 'Highlights the primary immediate value of generative AI: overcoming
    initial creative inertia and serving as a ''springboard'' for ideas.'
  relevance_score: 8
  source: llm_enhanced
  text: It takes out that initial sort of, oh, that's initially brain fog. I've got
    to get in and try and find a load of examples to start me off. So fabulous springboard.
  topic: technology/startups
- impact_reason: 'Actionable advice: revert to traditional methods (pen and paper)
    for tasks where AI''s generative nature is a hindrance, saving wasted time.'
  relevance_score: 8
  source: llm_enhanced
  text: I have to be aware that it's a generative tool. And so now I just don't go
    that I just sit down with a notepad and a pen, which I've done for the last 20
    years of any kind of conceptual work, because I know that there's no point in
    going.
  topic: technology/startups
- impact_reason: 'Emphasizes the need for task-specific assessment: use AI where speed
    and volume (like 100 ideas quickly) are superior to human capability.'
  relevance_score: 8
  source: llm_enhanced
  text: It's super helpful for us to know where it can work. So yeah, and I think
    in terms of our own limitations, I guess, the certain things that I can do better,
    you know, it's very good. You can get 100 ideas from it in a matter of seconds,
    stop content ideas, for example.
  topic: technology/business
- impact_reason: 'Reinforces the safety net: ensuring a human is the final gatekeeper
    before deployment.'
  relevance_score: 8
  source: llm_enhanced
  text: If you hold that in your mind and can human, AI, human, you know that the
    last person before anything goes out there, the last thing in the process is a
    human and not a machine.
  topic: technology
- impact_reason: Suggests drawing process and safety lessons from high-reliability
    organizations (HROs) to structure AI workflows.
  relevance_score: 8
  source: llm_enhanced
  text: That's so we can learn a lot from hazardous environments like hospital theatres,
    you know, commercial airlines. We can learn how those people keep us safe and
    take a little bit of that learning and put it into our workflows.
  topic: business
- impact_reason: 'A concerning observation about the current state of AI adoption:
    a perceived increase in ''blind'' or uncritical use.'
  relevance_score: 8
  source: llm_enhanced
  text: My anecdotal impression is that there's been a lot of a lot more blind around
    now than there was two years ago.
  topic: technology
- impact_reason: 'Forecasts market segmentation based on content quality: mass generic
    content vs. high-value, human-crafted ''beautiful'' content.'
  relevance_score: 8
  source: llm_enhanced
  text: And I think it will be like a real divide between the stuff that's very generic
    that we just kind of pass over, and then there'll be the stuff that's really beautiful.
  topic: business
- impact_reason: Highlights the inherent human ability to detect inauthenticity or
    lack of empathy in machine-generated communication.
  relevance_score: 8
  source: llm_enhanced
  text: Why is it that a human can recognize another? What is it in that text that
    goes, ah, thankfully, that's not AI? We're very capable of spotting that.
  topic: technology
- impact_reason: 'Specific example of where lack of empathy fails: customer service
    interactions, leading to user frustration.'
  relevance_score: 8
  source: llm_enhanced
  text: We might, we might test its emotional empathy and we go, that's not written
    by a human. And so when we get responses back from customer complaints, for example,
    and we read it and we go, oh, that is so written by a bot.
  topic: business/technology
- impact_reason: 'Provides a clear business case for AI adoption: high-volume content
    needs, coupled with necessary editorial staffing.'
  relevance_score: 8
  source: llm_enhanced
  text: If I've got a task where volume of content is important to me or the organization,
    of course, I'm going to use AI to generate a lot of that content. And I'm going
    to have a team of editors who are looking at that content specifically.
  topic: business
- impact_reason: Uses a strong cultural reference ('Blade Runner') to illustrate the
    human capability to spot inauthentic, non-empathetic AI communication.
  relevance_score: 8
  source: llm_enhanced
  text: That insincerity, that lack of empathy, that lack of humanness, the spotting
    the replicant as Blade Runner would have us, that we're very good at doing it.
  topic: Technology/User Experience
- impact_reason: Provides actionable, specific advice on prompt engineering to avoid
    generic AI markers (like specific punctuation or formatting).
  relevance_score: 8
  source: llm_enhanced
  text: Tell your persona to never use em-dash, to never have five bullet points at
    the end that says this is what—they are so AI, you know, we can do that.
  topic: Technology/Prompt Engineering
- impact_reason: 'Introduces a novel, cross-platform prompt refinement technique:
    using one LLM to critique and improve the output/prompt structure of another.'
  relevance_score: 8
  source: llm_enhanced
  text: Somebody advised me the other day to, when you're talking about prompts and
    improving prompts... to take the prompt from one engine and put it in another.
    So you write a prompt and it comes back and then you say, 'Oh, Claude, could you
    take a look at these prompts that have come out of chat? Can you improve those?'
  topic: Technology/Tool Utilization
- impact_reason: 'Sets realistic expectations for paid tiers: they primarily solve
    usage frustration and enable customization, not fundamental model flaws like hallucinations.'
  relevance_score: 8
  source: llm_enhanced
  text: I don't think it's necessary we're going to, like, cut hallucinations or necessarily
    get over some of the issues that we've been talking about, but you're definitely
    avoid the frustration of useless, and you can definitely customize it, which can
    be, again, very helpful in helping us to get something that's not a very, like,
    a really generic, boring, vanilla, like everyone else output.
  topic: Technology/AI Limitations
- impact_reason: Identifies compliance/safety concerns as a major bottleneck slowing
    down organizational AI adoption.
  relevance_score: 8
  source: llm_enhanced
  text: One of the ways we can move forward faster is to think about the compliance
    issue, if it's being blocked. So somebody's saying, 'Well, we're just going to
    go slowly because we're not sure if it's safe yet.'
  topic: Business/Compliance
- impact_reason: Directly links investment in enterprise software to the mitigation
    of significant legal and confidentiality risks.
  relevance_score: 8
  source: llm_enhanced
  text: There's also those kind of enterprise risks which can be mitigated by buying
    the enterprise version.
  topic: Business/Risk Management
- impact_reason: 'A clear strategic recommendation: embrace the inevitable use of
    AI by providing sanctioned, secure tools.'
  relevance_score: 8
  source: llm_enhanced
  text: So better to embrace it, we think, probably worthwhile getting an enterprise
    version.
  topic: Business/Strategy
- impact_reason: Reinforces the previous point, grounding the discussion in the financial
    reality for most marketers and small/mid-sized businesses.
  relevance_score: 8
  source: llm_enhanced
  text: We're not living in the world of enterprise million-pound budgets.
  topic: Business/Budgeting
- impact_reason: Highlights the tiered access problem, where security and customization
    benefits are disproportionately available to large enterprises, leaving SMBs exposed.
  relevance_score: 8
  source: llm_enhanced
  text: If you're a small business, I work a lot with small businesses, and I'm an
    independent consultant that I can't access the enterprise version. So it's also,
    I think, knowing, I think if you get to teams, you get a certain level, don't
    you, but not anywhere near the enterprise service.
  topic: Startups/Access Inequality
- impact_reason: Illustrates the spectrum of client comfort levels regarding AI usage
    and the necessity of explicit consent.
  relevance_score: 8
  source: llm_enhanced
  text: I always say to them, are you happy for me to use AI with this? And some are
    just like, yeah, put everything in, I don't care.
  topic: Business/Client Relations
- impact_reason: 'Actionable advice for service providers: AI usage must be negotiated,
    not assumed.'
  relevance_score: 8
  source: llm_enhanced
  text: I would always have a conversation and say, what, where are you happy for
    me to use it? Where are you not?
  topic: Business/Client Relations
- impact_reason: Suggests that proactive transparency relieves client anxiety and
    awkwardness, benefiting both parties.
  relevance_score: 8
  source: llm_enhanced
  text: I should imagine that clients are probably quite relieved that that conversation's
    happening because it's probably awkward for them as well to go, 'Oh, have they
    used AI or haven't they used AI?'
  topic: Client Relations
- impact_reason: Identifies native cultural nuance and specific colloquialisms as
    a key differentiator that current AI struggles to replicate reliably.
  relevance_score: 8
  source: llm_enhanced
  text: If you can add, depending upon your audience, the colloquialisms that you
    can add as perhaps an English speaker or as a native speaker in a particular language,
    that is something which you can genuinely put into articles.
  topic: Content Quality/AI Weakness
- impact_reason: Uses a memorable, cautionary anecdote to illustrate the severe risks
    of relying on unverified AI for localization.
  relevance_score: 8
  source: llm_enhanced
  text: Just Google mistakes that AI makes in localization, and you're very soon find
    the Spanish one and the diarrhea pills. It's just, you know, cause light will
    never forget that one.
  topic: Technology Risk/Localization
- impact_reason: Provides concrete, interview-ready language for candidates to demonstrate
    modern AI literacy and strategic awareness.
  relevance_score: 8
  source: llm_enhanced
  text: What's really important is the human in the loop sandwich,' or 'What's really
    important is the ability to critically think the output.'
  topic: Career/Technology
- impact_reason: Illustrates how ethical awareness translates into practical, critical
    scrutiny of underlying data systems and potential bias, even in non-AI tools.
  relevance_score: 8
  source: llm_enhanced
  text: If you suddenly see a CRM system that is not binning people because they don't
    come from the right postcode, you go, 'What is second? That looks a little biased.'
    That's a marketer who is looking at a CRM tool and actually thinking there's some
    really important things here that I need to be thinking about.
  topic: Ethics/Technology
- impact_reason: 'Provides the most straightforward, finance-friendly metric for justifying
    AI tool implementation: direct time-saving ROI.'
  relevance_score: 8
  source: llm_enhanced
  text: If you're implementing any tools and you want to get someone to side with
    you from that point of view, I guess it would be looking at how long did this
    job take us before, how long does it take us now, and what's the cost of that?
    I guess that's an easy measurement in terms of ROI.
  topic: Business/ROI
- impact_reason: 'Identifies the true, hard-to-measure value proposition of AI adoption:
    unlocking higher-value strategic work.'
  relevance_score: 8
  source: llm_enhanced
  text: If we use AI tools and we free up more time for those people, what's the value
    of the strategic or creative thinking that they now get to do that maybe they
    didn't have time to do before? And that's obviously a lot more difficult to attach
    to an ROI label to.
  topic: Strategy/ROI
- impact_reason: Draws a parallel between the difficulty of funding preventative cybersecurity
    measures and the difficulty of funding preventative AI ethics/training—both are
    easily deferred until a crisis occurs.
  relevance_score: 8
  source: llm_enhanced
  text: Cyber security is one of those things that can be easily, I'm not saying M&S
    did this for the record, but cyber security projects are things that can easily
    be put off... Because unless there's a media threat, or you can see something
    going wrong, it's just a big cost center...
  topic: Risk Management/Business
- impact_reason: 'Actionable advice for making the business case for preventative
    spending: leverage negative case studies to illustrate future risk.'
  relevance_score: 8
  source: llm_enhanced
  text: If you can then say, 'Look at Air Canada, look at M&S.' You can use case studies
    of where things have gone wrong. It's much easier to make a medium-term and long-term
    case, isn't it?
  topic: Strategy/Communication
- impact_reason: Suggests AI might not destroy the total number of jobs but will radically
    restructure the composition, eliminating low-level tasks.
  relevance_score: 8
  source: llm_enhanced
  text: The totality of the jobs, probably similar and maybe even greater. But the
    simple truth is that those right at the bottom rung, if you're taking the task
    that those people do, in a lot of cases, they can be done by machines.
  topic: Workforce/Trends
- impact_reason: Provides a strategic argument for maintaining human oversight, specifically
    linking it to securing budget approval from finance departments based on risk
    mitigation.
  relevance_score: 8
  source: llm_enhanced
  text: And if we make that case, then suddenly the argument for human checkers, humans
    in the loop, becomes a lot more powerful when we're talking to finance departments.
  topic: Business/Strategy
- impact_reason: 'Offers a specific, actionable mitigation strategy: balancing AI
    deployment with enhanced human feedback mechanisms like sentiment analysis.'
  relevance_score: 8
  source: llm_enhanced
  text: If you start introducing AI into things like customer service chatbots, the
    one thing that you have to do is almost like adding salt sugar in a recipe is
    you have to balance that up perhaps with more sentiment analysis.
  topic: Technology/Actionable Advice
- impact_reason: 'A fundamental cautionary principle for technology implementation:
    technology deployment must be paired with proactive harm assessment.'
  relevance_score: 8
  source: llm_enhanced
  text: Introducing that technology means you also need to be thinking about any harm
    that comes out of that.
  topic: Technology/Ethics
- impact_reason: 'Signals the importance of a critical, often overlooked, aspect of
    modern tech scaling: sustainability and environmental cost.'
  relevance_score: 8
  source: llm_enhanced
  text: We can't conclude this conversation without talking about the big elephant
    in the room, which is the environmental impact of AI.
  topic: Technology/Industry Trends
- impact_reason: Captures the rapid, almost sudden, industry shift and obsession surrounding
    AI adoption in marketing.
  relevance_score: 7
  source: llm_enhanced
  text: We're going to learn many lessons today about how to use AI in marketing,
    which I think has become something of an obsession for marketers. It was not there,
    and then suddenly it was there.
  topic: Industry Trends
- impact_reason: Describes the walled-garden nature of current proprietary LLMs, contrasting
    it with the potential for future agent-based systems.
  relevance_score: 7
  source: llm_enhanced
  text: You ask a question to ChatGPT, and your answer is then bound, limited by ChatGPT.
  topic: Technology
- impact_reason: Warns about the inherent bias of LLMs to always suggest improvements,
    even when the output is adequate, complicating iterative refinement.
  relevance_score: 7
  source: llm_enhanced
  text: The only thing is, I think, again, going back to the thing we talked about
    earlier, because you, it's never going to say no, it will always find an improvement.
    No, no, no. Because you can also ask the model to find problems with its own answer,
    so you can do that as well, but it never says, 'Oh, there's no problem here.'
  topic: Technology/AI Limitations
- impact_reason: Further details the cross-pollination technique, suggesting that
    revealing the source model can influence the critique provided by the second model.
  relevance_score: 7
  source: llm_enhanced
  text: I always make sure that I tell the other one where it came from. Yeah, so
    just guess what it is. So it's like, 'Okay, it came from ChatGPT, come on, Claude,
    what can you do?'
  topic: Technology/Prompt Engineering
- impact_reason: 'Provides a pragmatic reason for paying for premium AI services:
    avoiding frustrating usage caps rather than necessarily achieving massive quality
    leaps.'
  relevance_score: 7
  source: llm_enhanced
  text: I think the reason to upgrade would be more around usage limits. So I think
    if you're staying in the free model and you move up to ChatGPT, the first level
    of paid, you just have more usage, so you don't run out.
  topic: Business/Tool Adoption
- impact_reason: Draws a historical parallel between the initial resistance/control
    of mobile phones and the current management of personal AI use.
  relevance_score: 7
  source: llm_enhanced
  text: I remember the days when mobile phones first came out, you weren't allowed
    to have a mobile phone at your desk in theory. So everyone put it in the pocket
    or the handbag, and nobody knew. The same as now happening.
  topic: Business/Change Management
- impact_reason: Highlights the necessary friction point—legal/compliance review—when
    customizing AI models with sensitive corporate data.
  relevance_score: 7
  source: llm_enhanced
  text: Legal, can you check those before we just upload everything into, you know,
    just to get that persona right?
  topic: Compliance/Data Security
- impact_reason: A provocative suggestion for future content attribution, emphasizing
    the need for clear disclosure.
  relevance_score: 7
  source: llm_enhanced
  text: My byline would become not Ben Walker, but Ben Walker and AI, Ben Walker and
    my mate, the AI engine.
  topic: Ethics/Transparency
- impact_reason: A humorous but pointed critique of the current lack of formal ethics
    training within the marketing profession.
  relevance_score: 7
  source: llm_enhanced
  text: What marketer has had any training on ethics other than perhaps watching Hot
    Fuzz...
  topic: Ethics
- impact_reason: A cautionary note on the current unreliability of AI detection tools,
    relevant to academic integrity and content verification.
  relevance_score: 7
  source: llm_enhanced
  text: History is littered with examples of people being accused of plagiarism when
    they're not plagiarists. So even the tool, the detection tools aren't, aren't
    up to scratch.
  topic: Technology/Validation
- impact_reason: Highlights the strategic cost of ignoring early negative feedback
    when deploying new technology—missing the chance to course-correct.
  relevance_score: 7
  source: llm_enhanced
  text: Clarner obviously didn't, and that's, you know, as a consequence of which
    they missed, they missed that golden opportunity to listen to the customer and
    go, 'I think we got this wrong.'
  topic: Business/Strategy
- impact_reason: Serves as a prompt for risk assessment by defining the 'worst-case
    scenario' in a professional context.
  relevance_score: 7
  source: llm_enhanced
  text: What's the worst thing that could happen? Oh, well, we tell a client some
    incorrect information and they lose a massive case or whatever.
  topic: Risk Management
- impact_reason: A philosophical observation on the potential future state of autonomous
    AI iteration, raising concerns about human oversight.
  relevance_score: 6
  source: llm_enhanced
  text: It does sound like the sort of start of the prologue of well, but Harris's
    novel, you know, where these AIs end up prompting each other, and there are no
    humans in the loop.
  topic: Technology/Future Trends
source: Unknown Source
summary: '## Comprehensive Summary of CIM Marketing Podcast: AI Question Time


  This episode of the CIM Marketing Podcast, titled "AI Question Time," featured experts
  **Kerry Harrison** (AI Trainer/Consultant and founder of the world''s first AI Gin)
  and **Duncan Smith** (Data Protection and Compliance Expert and founder of iComply)
  discussing the practical application, limitations, and strategic integration of
  Generative AI in marketing.


  ### 1. Main Narrative Arc and Key Discussion Points


  The conversation moved from the fundamentals of effective AI interaction (prompting)
  to the critical risks associated with AI output (hallucinations/errors), and finally
  settled on strategic frameworks for maintaining quality and authenticity in AI-assisted
  workflows. The central tension explored was balancing the efficiency gains of AI
  against the dangers of mediocrity and inaccuracy.


  ### 2. Major Topics, Themes, and Subject Areas Covered


  *   **Prompt Engineering:** The significant impact of prompt quality on output.

  *   **AI Reliability and Hallucinations:** The problem of AI "lying" or generating
  inaccurate, fabricated information, especially concerning legal and regulatory matters.

  *   **Website Evolution:** How the rise of AI agents will necessitate websites having
  a "hybrid dual purpose" to serve both human users and automated agents.

  *   **Homogenization Risk:** The danger of creative content becoming dull and generic
  if AI output is used without significant human refinement.

  *   **Strategic Integration:** Developing workflows that leverage AI strengths while
  mitigating its weaknesses.


  ### 3. Technical Concepts, Methodologies, or Frameworks Discussed


  *   **GCSE Prompting Methodology:** A structured approach to prompting involving
  **G**oal, **C**ontext, **S**ources (examples), and **E**xpectations.

  *   **AI Agents:** Tools within platforms like ChatGPT that can execute multi-step
  tasks autonomously (e.g., visiting websites on the user''s behalf).

  *   **Hallucination Rate:** The frequency with which LLMs generate false information,
  with anecdotal mention of research suggesting high rates, though newer models (like
  GPT-5) claim improvements.

  *   **The AI Sandwich (Human-AI-Human):** Kerry Harrison''s proposed methodology
  for ensuring authentic, high-quality output by sandwiching the AI generation step
  between rigorous human input (prompting) and critical human refinement (editing/fact-checking).

  *   **HACCP (Hazard Analysis Critical Control Point):** An analogy drawn from the
  food industry to emphasize the need for critical control points (checks) in marketing
  workflows to prevent high-risk errors from reaching the public.


  ### 4. Business Implications and Strategic Insights


  *   **Value Proposition:** AI is excellent for high-volume, low-risk tasks (e.g.,
  generating 100 content ideas quickly) where it outperforms human speed.

  *   **Risk Management:** For content involving legal, regulatory (e.g., FCA compliance),
  or factual data, the time saved by AI is often negated by the necessary verification
  time, sometimes making starting from scratch quicker and safer.

  *   **Competitive Advantage:** In an environment where many marketers default to
  generic AI output, those who invest the hard work in human creativity and strategic
  refinement will stand out significantly.

  *   **Workflow Adaptation:** Marketers must actively map where AI fits into their
  existing workflows, identifying the "Human in the Loop" checkpoints (the "tenth
  domino holder") responsible for final sign-off.


  ### 5. Key Personalities, Experts, or Thought Leaders Mentioned


  *   **Kerry Harrison:** Emphasized the "AI Sandwich" and the value of human expertise
  in refining AI output.

  *   **Duncan Smith:** Focused heavily on the compliance and regulatory dangers of
  AI hallucinations, sharing personal anecdotes of challenging ChatGPT on fabricated
  regulatory quotes.

  *   **Edward de Bono:** Mentioned in the context of lateral thinking tools, highlighting
  areas where AI currently struggles with truly conceptual work.


  ### 6. Predictions, Trends, or Future-Looking Statements


  *   AI agents will become more commonplace, forcing website designers to optimize
  content for automated retrieval, not just human browsing.

  *   There is a philosophical concern that if AI trains predominantly on its own
  output, content will become increasingly dull, inauthentic, and inaccurate.

  *   A clear divide will emerge between generic, AI-generated content and highly
  creative, human-validated work.


  ### 7. Practical Applications and Real-World Examples


  *   **Idea Generation:** AI is a "fabulous springboard" for overcoming initial creative
  blocks (e.g., suggesting a science fiction angle for an article).

  *   **High-Risk Content:** Examples cited where AI output requires rigorous checking
  include sustainability claims (consumer protection laws) and financial advertising
  copy (FCA regulations requiring specific disclosures).

  *   **Personalized Training:** Experts are training specific personas on their LLMs
  (e.g., Duncan training his to stop making things up when challenged).


  ### 8. Controversies, Challenges, or Problems Highlighted


  *   **Hallucinations as Lying:** Duncan Smith strongly criticized the polite nature
  of AI admitting errors after fabricating regulatory quotes, calling it dangerous
  for professionals.

  *   **Homogenization:** The risk that relying on AI for creative tasks leads to
  content that lacks brand authenticity and sounds the same as competitors.

  *   **Conceptual Work Limitations:** AI struggles significantly with highly conceptual,
  lateral thinking, or "off the wall" creative tasks, wasting time if marketers try
  to force it into that role.


  ### 9. Solutions, Recommendations, or Actionable Advice Provided


  1.  **Adopt the GCSE Prompting Method:** Structure prompts with Goal, Context, Sources,
  and Expectations for higher quality initial output.

  2.  **Implement the AI Sandwich (Human-AI-Human):'
tags:
- artificial-intelligence
- generative-ai
- ai-infrastructure
- startup
- investment
- microsoft
- google
- openai
title: 'Artificial Intelligence for marketers: Your top questions answered by the
  experts'
topics:
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 222
  prominence: 1.0
  topic: artificial intelligence
- keywords:
  - generative ai
  - genai
  - chatgpt
  - gpt
  - claude
  - text generation
  - image generation
  mentions: 53
  prominence: 1.0
  topic: generative ai
- keywords:
  - gpu
  - tensor
  - training
  - inference
  - model deployment
  - vector database
  mentions: 15
  prominence: 1.0
  topic: ai infrastructure
- keywords:
  - startup
  - entrepreneur
  - founder
  - venture
  mentions: 3
  prominence: 0.3
  topic: startup
- keywords:
  - investment
  - funding
  - valuation
  - ipo
  - acquisition
  mentions: 1
  prominence: 0.1
  topic: investment
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-10-06 04:11:35 UTC -->
