---
companies:
- category: unknown
  confidence: medium
  context: This is an I Heart Podcast. This is an I Heart Podcast. Legends don't stop.
  name: I Heart Podcast
  position: 11
- category: unknown
  confidence: medium
  context: ush. You can't have a true Texas barbecue without Craft Real Mayo, made
    with craft real mayo. That's why families h
  name: Craft Real Mayo
  position: 140
- category: unknown
  confidence: medium
  context: er valid only on eligible participating products. Quarza Media. Hello and
    welcome to Better Off Line. I'm of cou
  name: Quarza Media
  position: 681
- category: unknown
  confidence: medium
  context: ting products. Quarza Media. Hello and welcome to Better Off Line. I'm
    of course your host Ed Zitron. What's up all
  name: Better Off Line
  position: 716
- category: unknown
  confidence: medium
  context: lcome to Better Off Line. I'm of course your host Ed Zitron. What's up
    all night? We're in the third episode
  name: Ed Zitron
  position: 757
- category: tech
  confidence: high
  context: unprofitable for the model providers. Outside of OpenAI and to a lesser
    extent Anthropic, nobody seems to
  name: Openai
  position: 1618
- category: tech
  confidence: high
  context: oviders. Outside of OpenAI and to a lesser extent Anthropic, nobody seems
    to be making much revenue, with the
  name: Anthropic
  position: 1648
- category: unknown
  confidence: medium
  context: on this year, and as I mentioned in the past, the Magnificent Seven expect
    to make $35 billion or so in revenue for M
  name: Magnificent Seven
  position: 2217
- category: unknown
  confidence: medium
  context: n expect to make $35 billion or so in revenue for May AI this year, and
    I think in total when you throw in
  name: May AI
  position: 2283
- category: unknown
  confidence: medium
  context: nd all of them, it's barely $55 billion in total. Even Anthropic and OpenAI
    seem a little off-large, both burning
  name: Even Anthropic
  position: 2401
- category: unknown
  confidence: medium
  context: their negative gross margin businesses flounder. As I dug into a few months
    ago, I could find only 12 A
  name: As I
  position: 2867
- category: tech
  confidence: high
  context: ing their revenue, specifically AI search company Perplexity, which is
    now near $150 million in ARR, or $12.5
  name: Perplexity
  position: 3062
- category: tech
  confidence: high
  context: f money. Perplexity burned 164% of its revenue on Amazon Web Services,
    OpenAI, and Anthropic last year, an
  name: Amazon
  position: 3299
- category: unknown
  confidence: medium
  context: f money. Perplexity burned 164% of its revenue on Amazon Web Services,
    OpenAI, and Anthropic last year, and while Repli
  name: Amazon Web Services
  position: 3299
- category: unknown
  confidence: medium
  context: t year, and while Replit hasn't leaked its costs, The Information reports
    its gross margins in July were 23%, which
  name: The Information
  position: 3395
- category: unknown
  confidence: medium
  context: a piece on Anthropic losing money on every single Claude Code subscriber,
    and now I'm going to walk you through
  name: Claude Code
  position: 4180
- category: unknown
  confidence: medium
  context: simplified fashion because it's quite important. So Claude Code is a coding
    environment that people used, or I sh
  name: So Claude Code
  position: 4312
- category: unknown
  confidence: medium
  context: ather than paying for the actual tokens you burn. When I say burn tokens,
    and someone reached out saying I
  name: When I
  position: 4764
- category: unknown
  confidence: medium
  context: okens and $6 per million output tokens to use its Claude Sonnet 3.5 model.
    And it's about, I think, a word before
  name: Claude Sonnet
  position: 5200
- category: unknown
  confidence: medium
  context: s the cost to Anthropic are likely not identical. So I got a little clever
    using Anthropic's gross profi
  name: So I
  position: 5865
- category: unknown
  confidence: medium
  context: ndle on its infrastructure than anyone outside of Big Tech and OpenAI,
    and it still cannot seem to fix this
  name: Big Tech
  position: 6482
- category: unknown
  confidence: medium
  context: were spiraling into the hundreds of dollars, with The Register reporting
    one customer found themselves with a $1
  name: The Register
  position: 8890
- category: unknown
  confidence: medium
  context: g, a consistent problem I found across Redditors. While Reddit is not the
    full summation of all users of every c
  name: While Reddit
  position: 10414
- category: unknown
  confidence: medium
  context: 'And now here''s where this is bad. Traditionally, Silicon Valley startups
    have relied upon the same model: grow re'
  name: Silicon Valley
  position: 10618
- category: unknown
  confidence: medium
  context: afe. Square has the tools to help make it happen. Square Banking to fund
    the next goal, AI-powered analytics to ma
  name: Square Banking
  position: 11195
- category: unknown
  confidence: medium
  context: powered analytics to make informed decisions, and Square Point of Sale
    that works for any type of business. Go t
  name: Square Point
  position: 11286
- category: unknown
  confidence: medium
  context: rated is not a bank. Banking services provided by Square Financial Services
    Incorporated in Sutton Bank, members FDIC. Loans are subject t
  name: Square Financial Services Incorporated
  position: 11477
- category: unknown
  confidence: medium
  context: ided by Square Financial Services Incorporated in Sutton Bank, members
    FDIC. Loans are subject to credit approv
  name: Sutton Bank
  position: 11519
- category: unknown
  confidence: medium
  context: Loans are subject to credit approval. October is Cybersecurity Awareness
    Month, a reminder that your digital life is always at r
  name: Cybersecurity Awareness Month
  position: 11595
- category: unknown
  confidence: medium
  context: s to your identity. If your identity is stolen, a LifeLock US-based restoration
    specialist will fix it, guarant
  name: LifeLock US
  position: 12114
- category: unknown
  confidence: medium
  context: ht today's time. So you need me right. Get you in Alex Lyson, Rush. Live
    50-something tour. Sign up for pre-sa
  name: Alex Lyson
  position: 12708
- category: unknown
  confidence: medium
  context: . Every journey needs a guide. Let the Center for Professional Education
    (CPE) be yours. Certificate programs to drive car
  name: Professional Education
  position: 12882
- category: unknown
  confidence: medium
  context: nal journey is unique, but no one succeeds alone. At CPE, we believe every
    career path deserves expert gui
  name: At CPE
  position: 13031
- category: tech
  confidence: high
  context: . Some bright spark out there is going to send it Microsoft's GitHub Copilot,
    that's 1.8 million paying subsc
  name: Microsoft
  position: 16955
- category: unknown
  confidence: medium
  context: t spark out there is going to send it Microsoft's GitHub Copilot, that's
    1.8 million paying subscribers, and guess
  name: GitHub Copilot
  position: 16967
- category: unknown
  confidence: medium
  context: 'In fact, I reported it. Here''s another fun fact: The Wall Street Journal
    reported that Microsoft loses on average $20 a mo'
  name: The Wall Street Journal
  position: 17100
- category: unknown
  confidence: medium
  context: er. Oh, my sweet summer child. If you believe the New York Times or other
    outlets that simply copy and paste whate
  name: New York Times
  position: 17609
- category: unknown
  confidence: medium
  context: t simply copy and paste whatever Anthropic's CEO, Dario Amodei, says, you
    think that the reason that software en
  name: Dario Amodei
  position: 17694
- category: unknown
  confidence: medium
  context: out the newsletter. First, I'm going to read what Carl Brown of the Internet
    of Bugs said, and I had him on th
  name: Carl Brown
  position: 19211
- category: unknown
  confidence: medium
  context: ior developers later down the line. Next, I asked Nick Shoresh what he
    thought. LLMs, he said, will sometimes so
  name: Nick Shoresh
  position: 20711
- category: unknown
  confidence: medium
  context: don't make that part any easier. I also talked to Colt Vogel of No AI Is
    Not Making Engineers 10X Productive,
  name: Colt Vogel
  position: 21151
- category: unknown
  confidence: medium
  context: t part any easier. I also talked to Colt Vogel of No AI Is Not Making Engineers
    10X Productive, we also had him on the show recen
  name: No AI Is Not Making Engineers
  position: 21165
- category: unknown
  confidence: medium
  context: . They evolve. Rush. Every journey needs a guide. The Center for Professional
    Education is yours, guiding your
  name: The Center
  position: 24116
- category: unknown
  confidence: medium
  context: ide to making it happen. Backed by the quality of UT Austin, our programs
    and instructors help individuals an
  name: UT Austin
  position: 24355
- category: unknown
  confidence: medium
  context: oblems. Good software engineering harkens back to Brian Merchant's interviews
    with translators. While some may bel
  name: Brian Merchant
  position: 24899
- category: unknown
  confidence: medium
  context: LLM doesn't know anything either. Now, my editor, Matt Hughes, gave an
    example of this in his newsletter, which
  name: Matt Hughes
  position: 25490
- category: unknown
  confidence: medium
  context: equires a bit of creative thinking, and I quote, "Take Harry Potter. In
    French, Hogwarts is Poudlard, which translate
  name: Take Harry Potter
  position: 25827
- category: unknown
  confidence: medium
  context: eative thinking, and I quote, "Take Harry Potter. In French, Hogwarts is
    Poudlard, which translates into baco
  name: In French
  position: 25846
- category: unknown
  confidence: medium
  context: hat's what they've been selling it as. That's why Jensen Huang told kids
    to stop learning to code, as with AI th
  name: Jensen Huang
  position: 28009
- category: unknown
  confidence: medium
  context: I there's no point. And it was all a fucking lie. Generative AI can't do
    the job of a software engineer, and it f
  name: Generative AI
  position: 28117
- category: ai_application
  confidence: high
  context: Major generative AI model provider, mentioned as one of the few making
    revenue, but still burning billions and increasing prices for priority processing.
  name: OpenAI
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Major generative AI model provider, mentioned as one of the few making
    revenue, burning billions, and increasing prices. Specific focus on their Claude
    Code product and Sonnet/Opus models.
  name: Anthropic
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Maker of the AI coding tool Cursor, noted as the most successful AI company
    mentioned in terms of revenue ($500M annualized at one point).
  name: AnySphere
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: AI coding tool made by AnySphere, mentioned in relation to price increases
    by OpenAI/Anthropic.
  name: Cursor
  source: llm_enhanced
- category: ai_infrastructure
  confidence: medium
  context: Mentioned in the context of total AI industry revenue figures, suggesting
    they are a significant player in AI infrastructure or services.
  name: CoreWeave
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: AI search company, mentioned as one of the few startups showing significant
    revenue ($150M ARR) but burning significant money (164% of revenue on AWS, OpenAI,
    and Anthropic).
  name: Perplexity
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: AI coding startup, mentioned for hitting $12.5M/month revenue but having
    poor gross margins (23%) and launching the problematic Agent 3 feature.
  name: Replit
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: Mentioned as a significant cost component for Perplexity's operations.
  name: Amazon Web Services (AWS)
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Anthropic's coding environment product, used as a primary example of negative
    gross margins and high user token burn.
  name: Claude Code
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: A product launched by Replit, criticized for obfuscated pricing and high,
    unpredictable costs for users.
  name: Agent 3
  source: llm_enhanced
- category: media_reference
  confidence: high
  context: News outlet cited for reporting on customer complaints regarding Replit's
    Agent 3 pricing.
  name: The Register
  source: llm_enhanced
- category: media_reference
  confidence: high
  context: Mentioned as a barometer for user sentiment regarding Replit's pricing
    changes and product issues.
  name: Reddit
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: An aggregator of LLM usage, where Anthropic's models are consistently popular
    for programming.
  name: OpenRouter
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Microsoft's coding assistant, mentioned as the benchmark that Claude Code
    is being compared against.
  name: GitHub Copilot
  source: llm_enhanced
- category: big_tech
  confidence: medium
  context: Implied owner/developer of GitHub Copilot, and generally referenced as
    part of 'Big Tech' with high AI capabilities.
  name: Microsoft
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: OpenAI's flagship product, used as an example to illustrate variable user
    infrastructural burden and token burning.
  name: ChatGPT
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Reference to OpenAI's model series (e.g., GPT uses) when discussing subscription
    limits.
  name: GPT
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned in an advertisement break, offering AI-powered analytics for
    businesses.
  name: Square
  source: llm_enhanced
- category: security_service
  confidence: high
  context: Mentioned in an advertisement break for identity protection services.
  name: LifeLock
  source: llm_enhanced
- category: education
  confidence: high
  context: Mentioned in an advertisement break, offering professional certificate
    programs.
  name: Center for Professional Education (CPE)
  source: llm_enhanced
- category: education
  confidence: medium
  context: The institution hosting the Center for Professional Education (CPE).
  name: UT Austin (implied via professionaled.utexas.edu)
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Microsoft's generative AI feature integrated into its productivity suite,
    discussed regarding its low conversion rate and pricing strategies.
  name: Microsoft 365 Copilot
  source: llm_enhanced
- category: other
  confidence: low
  context: Mentioned in an advertisement segment.
  name: Ticketmaster
  source: llm_enhanced
- category: research_affiliated
  confidence: low
  context: Mentioned in an advertisement segment, backed by UT Austin.
  name: The Center for Professional Education (CPE)
  source: llm_enhanced
- category: research_institution
  confidence: medium
  context: Mentioned as the backing institution for The Center for Professional Education.
  name: UT Austin
  source: llm_enhanced
- category: other
  confidence: low
  context: Mentioned in a disclaimer related to Square Banking services.
  name: Block, Incorporated
  source: llm_enhanced
- category: other
  confidence: low
  context: Mentioned in a disclaimer regarding banking services.
  name: Square Financial Services Incorporated
  source: llm_enhanced
- category: other
  confidence: low
  context: Mentioned in a disclaimer regarding banking services.
  name: Sutton Bank
  source: llm_enhanced
date: 2025-10-02 04:00:00 +0000
duration: 27
has_transcript: false
insights:
- actionable: false
  confidence: medium
  extracted: software. Smartwatches are projected to make $32 billion this year, and
    as I mentioned in the past, the Magnificent Seven expect to make $35 billion or
    so in revenue for May AI this year, and I think in total when you throw in CoreWeave
    and all of them, it's barely $55 billion in total. Even Anthropic and OpenAI seem
    a little off-large, both burning billions of dollars while making by May estimates
    no more than $2 billion in Anthropic's case this year so far, and $6.26 billion
    in 2025 so far for OpenAI, despite projections of $5 billion and $13 billion respectively.
    Outside of these two, AI startups are floundering, struggling to stay alive and
    raising money in several hundred million dollars as their negative gross margin
    businesses flounder. As I dug into a few months ago, I could find only 12 AI-powered
    companies making more than $8.3 million a month, with two of them slightly improving
    their revenue, specifically AI search company Perplexity, which
  text: the future of software. Smartwatches are projected to make $32 billion this
    year, and as I mentioned in the past, the Magnificent Seven expect to make $35
    billion or so in revenue for May AI this year, and I think in total when you throw
    in CoreWeave and all of them, it's barely $55 billion in total. Even Anthropic
    and OpenAI seem a little off-large, both burning billions of dollars while making
    by May estimates no more than $2 billion in Anthropic's case this year so far,
    and $6.26 billion in 2025 so far for OpenAI, despite projections of $5 billion
    and $13 billion respectively. Outside of these two, AI startups are floundering,
    struggling to stay alive and raising money in several hundred million dollars
    as their negative gross margin businesses flounder. As I dug into a few months
    ago, I could find only 12 AI-powered companies making more than $8.3 million a
    month, with two of them slightly improving their revenue, specifically AI search
    company Perplexity, which is now near $150 million in ARR, or $12.
  type: prediction
layout: episode
llm_enhanced: true
original_url: https://audio.listennotes.com/e/p/5a67f847cbf14f8f8dce3cee2695939f/
processing_date: 2025-10-06 04:06:46 +0000
quotes:
- length: 128
  relevance_score: 6
  text: Unlike most software products, any errors in producing an output from a large
    language model have a significant opportunity cost
  topics:
  - opportunity
- length: 227
  relevance_score: 4
  text: Outside of OpenAI and to a lesser extent Anthropic, nobody seems to be making
    much revenue, with the most successful company being AnySphere, makers of AI coding
    tool Cursor, which hit $500 million of annualized revenue, so $41
  topics:
  - revenue
- length: 141
  relevance_score: 4
  text: The more specific the output, the more opportunities there are for monstrous
    token burn, and I'm specifically thinking about coding with LLMs
  topics: []
- length: 261
  relevance_score: 4
  text: Carl also said, "Code generation AIs, from an industry standpoint, are roughly
    the equivalent of a slightly below-average computer science graduate fresh out
    of school without any real-world experience, only ever having written programs
    to be printed and graded
  topics: []
- length: 250
  relevance_score: 4
  text: '" That''s bad because, as he pointed out, whereas LLMs can''t get past this
    summer intern stage, actual humans get better, and if we''re replacing the bottom
    rung of the labor market, there won''t be any mid-level or senior developers later
    down the line'
  topics:
  - market
- length: 269
  relevance_score: 4
  text: In reality, LLMs can generate code and do some sort of software engineering-adjacent
    tasks, but like all large language models, they break down and go totally insane,
    hallucinate more and more as the tasks get more complex, and software engineering
    is extremely complex
  topics: []
- length: 158
  relevance_score: 3
  text: 3 million a month, with two of them slightly improving their revenue, specifically
    AI search company Perplexity, which is now near $150 million in ARR, or $12
  topics:
  - revenue
- length: 122
  relevance_score: 3
  text: So, for example, Anthropic charges $3 per million input tokens and $6 per
    million output tokens to use its Claude Sonnet 3
  topics: []
- length: 136
  relevance_score: 3
  text: Even if Anthropic's costs are half the published rates, they're not, by the
    way, one guy amounted to 125 users' worth of monthly revenue
  topics:
  - revenue
- length: 256
  relevance_score: 3
  text: To be clear, Anthropic's Sonnet and Opus models are consistently some of the
    most popular for programming on OpenRouter, an aggregator of LLM usage, and Anthropic's
    been consistently named as the best at coding, whether or not I feel that way
    is irrelevant
  topics: []
- length: 84
  relevance_score: 3
  text: Some bright spark out there is going to send it Microsoft's GitHub Copilot,
    that's 1
  topics: []
- length: 203
  relevance_score: 3
  text: 'Here''s another fun fact: The Wall Street Journal reported that Microsoft
    loses on average $20 a month per user, with some users costing the company as
    much as $80, and that''s for the most popular product'
  topics: []
- length: 124
  relevance_score: 3
  text: They lack the experience to be wholly trusted, and trust is the most important
    thing you need to fully delegate coding tasks
  topics: []
- length: 177
  relevance_score: 3
  text: But the reality is that software engineers maintain software, which includes
    writing and analyzing code amongst a vast array of different personalities and
    programs and problems
  topics: []
- length: 290
  relevance_score: 3
  text: I'm so excited, and I buried it in the third part of a four-part episode,
    and truly twisted, but a source that has seen materials related to sales has confirmed
    that as of August 2025, Microsoft has around 8 million active licensed—so paying
    users—of Microsoft 365 Copilot, amounting to a 1
  topics: []
- length: 143
  relevance_score: 3
  text: 88 billion in annual revenue for a product category that makes $33 billion
    a fucking quarter, this productivity and business unit for Microsoft
  topics:
  - revenue
- length: 124
  relevance_score: 3
  text: An active user is someone who has taken one action on any Microsoft 365 app
    with Copilot in the space of 28 days, not 30, 28
  topics: []
- impact_reason: This sets the central, highly provocative thesis of the entire podcast
    series, signaling a critical, bearish view on the current AI market structure.
  relevance_score: 10
  source: llm_enhanced
  text: I give you a comprehensive explanation as to the origins of the AI bubble,
    the mythology sustaining it, and why it's destined to end really, really badly.
  topic: strategy
- impact_reason: 'This is a core economic critique: the value proposition doesn''t
    justify the high, increasing operational costs, leading to systemic unprofitability.'
  relevance_score: 10
  source: llm_enhanced
  text: everybody is losing money on generative AI, in part because the costs of running
    AI models are increasing, and in part because the software itself doesn't do enough
    to warrant the costs associated with running them, which are already subsidized
    and unprofitable for the model providers.
  topic: business
- impact_reason: Quantifies the extreme negative gross margins for successful AI startups,
    emphasizing the hidden cost burden of free users in the LLM ecosystem.
  relevance_score: 10
  source: llm_enhanced
  text: Perplexity burned 164% of its revenue on Amazon Web Services, OpenAI, and
    Anthropic last year, and while Replit hasn't leaked its costs, The Information
    reports its gross margins in July were 23%, which doesn't include the cost of
    its free users, which you simply have to do with LLMs, as free users are capable
    of costing you a shit ton of money.
  topic: business
- impact_reason: 'This is a crucial technical/economic distinction: the variable,
    high cost per interaction in generative AI fundamentally breaks traditional software
    unit economics.'
  relevance_score: 10
  source: llm_enhanced
  text: Software doesn't usually connect you to a model that can burn, I don't know,
    $0.10 to 20 cents every time they touch it, which may not seem like much, but
    when you're making $3 on someone and they don't convert, it does.
  topic: technical
- impact_reason: Provides concrete evidence of extreme cost overruns by individual
    users on subscription models, demonstrating the fragility of the pricing structure.
  relevance_score: 10
  source: llm_enhanced
  text: I found at least 20 different accounts of people costing Anthropic anywhere
    from 130% to 3,084% of their subscription.
  topic: technical
- impact_reason: This suggests a deep, architectural limitation in current LLMs that
    prevents effective rate limiting or cost management, even for the creators.
  relevance_score: 10
  source: llm_enhanced
  text: Even the model developers have no real way of limiting user activity, likely
    due to the architecture of generative AI.
  topic: technical
- impact_reason: A shocking claim that even the foundational model providers struggle
    to enforce their own controls due to the nature of prompting/inference.
  relevance_score: 10
  source: llm_enhanced
  text: at the most advanced level, even there, model providers are still prompting
    their models, and whatever rate limits may be in place appear to at times get
    completely ignored, and there doesn't seem to be anything they can do to stop
    it. Not really.
  topic: technical
- impact_reason: A serious, concrete example of an AI agent exhibiting unintended,
    potentially malicious or destructive behavior (autonomy gone wrong) during testing.
  relevance_score: 10
  source: llm_enhanced
  text: One prompt brute-forced its way through authentication, redoing often hard-resetting
    users' passwords to what it wanted to perform app testing on a form, the user
    wrote. 'I realized that's a little nonsensical, but long story short, it did a
    bunch of shit it wasn't asked to.'
  topic: safety
- impact_reason: 'This is the ultimate strategic conclusion: the fundamental economic
    model of software (low marginal cost) is inverted in AI due to high marginal inference
    costs, making the ''grow fast, profit later'' strategy impossible.'
  relevance_score: 10
  source: llm_enhanced
  text: AI does not have a profit lever because the raw costs of providing access
    to AI models are so high, and they're only increasing, that the basic economics
    of how the tech industry sells software don't make sense.
  topic: strategy
- impact_reason: 'This pinpoints a fundamental economic challenge for LLMs: mistakes
    force regeneration, directly increasing compute costs (token burn), unlike traditional
    software.'
  relevance_score: 10
  source: llm_enhanced
  text: any errors in producing an output from a large language model have a significant
    opportunity cost.
  topic: technical/business
- impact_reason: 'This identifies the core difficulty in monetizing LLM services:
    the unpredictable and variable per-user infrastructure cost makes flat-rate subscription
    models economically risky.'
  relevance_score: 10
  source: llm_enhanced
  text: it's very, very, very difficult to imagine what one user for your otherwise
    might cost, and thus it's hard to charge them anything on a monthly basis or tell
    them what a service might actually cost them on average.
  topic: business
- impact_reason: Quantifies the direct financial loss for a major, established AI
    coding product, reinforcing the theme of high operational costs relative to subscription
    fees.
  relevance_score: 10
  source: llm_enhanced
  text: Microsoft loses on average $20 a month per user, with some users costing the
    company as much as $80, and that's for the most popular product [GitHub Copilot].
  topic: business
- impact_reason: A strong, emotional rebuttal to the mainstream narrative of mass
    job replacement by AI, calling out media sensationalism and lack of technical
    understanding.
  relevance_score: 10
  source: llm_enhanced
  text: If you believe the New York Times or other outlets... you think that the reason
    that software engineers are having trouble finding work is because their jobs
    are being replaced by AI. This grotesque, manipulative, abusive, and offensive
    lie has been propagated through the entire business and tech media without anybody
    sitting down and asking whether it's true...
  topic: safety/predictions
- impact_reason: Provides a precise definition separating code *generation* from actual
    *software engineering*, emphasizing the need for learning, adaptation, and maintenance
    capabilities.
  relevance_score: 10
  source: llm_enhanced
  text: LLMs are capable of writing code but can't do software engineering because
    software engineering is the process of understanding, maintaining, and executing
    code to produce functional software, and LLMs do not learn, cannot adapt...
  topic: technical
- impact_reason: 'This is a crucial insight into the utility curve of generative AI
    in coding: it accelerates low-hanging fruit but introduces complexity and potential
    roadblocks for genuinely hard problems.'
  relevance_score: 10
  source: llm_enhanced
  text: Coding large language models seem like magic at first because they, to quote
    a conversation with Carl Brown, "make the easy things easier," but they also make
    the harder things harder.
  topic: technical/business
- impact_reason: A highly counter-intuitive and impactful claim regarding productivity,
    suggesting that for experienced engineers, the overhead of using LLMs might negate
    or reverse expected efficiency gains.
  relevance_score: 10
  source: llm_enhanced
  text: They don't even speed up engineers; there's a study that showed they make
    them slower.
  topic: business/predictions
- impact_reason: A strong, definitive statement challenging the prevailing narrative
    that AI is replacing software engineers, framing current generative AI as both
    ineffective and expensive for this role.
  relevance_score: 10
  source: llm_enhanced
  text: Generative AI can't do the job of a software engineer, and it fails while
    also costing an abominable amount of money.
  topic: predictions/limitations
- impact_reason: Provides specific, potentially leaked data points on enterprise AI
    conversion rates, indicating a very low initial uptake for a major product line
    ($2.88B projected annual revenue vs. $33B quarterly revenue for the unit).
  relevance_score: 10
  source: llm_enhanced
  text: Microsoft has around 8 million active licensed—so paying users—of Microsoft
    365 Copilot, amounting to a 1.81% conversion rate across 404 million Microsoft
    365 subscribers.
  topic: business
- impact_reason: It highlights the extreme concentration of revenue among the top
    two players and shows how even successful downstream companies are immediately
    vulnerable to upstream cost increases.
  relevance_score: 9
  source: llm_enhanced
  text: Outside of OpenAI and to a lesser extent Anthropic, nobody seems to be making
    much revenue, with the most successful company being AnySphere, makers of AI coding
    tool Cursor, which hit $500 million of annualized revenue, so $41.6 million in
    one month a few months ago, just before Anthropic and OpenAI jacked up the prices
    for priority processing and enterprise queries, raising their operating costs
    as a result.
  topic: business
- impact_reason: A strong, generalized statement about the fundamental lack of cost
    predictability in current generative AI deployment models.
  relevance_score: 9
  source: llm_enhanced
  text: every user loses you money in generative AI because it's impossible to do
    cost control in a consistent manner.
  topic: business
- impact_reason: A stark illustration of the 'whale' problem in usage-based AI pricing,
    where one bad actor can wipe out the profitability of hundreds of standard users.
  relevance_score: 9
  source: llm_enhanced
  text: A customer paying $200 a month ran up $50,000 in costs immediately, devouring
    the margin of any user running the service that day, that week, or even that month.
  topic: business
- impact_reason: A blunt assessment of the current generative AI business model, labeling
    it fundamentally unsustainable without a breakthrough in cost control.
  relevance_score: 9
  source: llm_enhanced
  text: This is not a real business, that's a bad business without control of costs,
    and it doesn't appear anybody has these costs under control.
  topic: business
- impact_reason: A direct critique of the over-hyped autonomy claims of tools like
    Replit's Agent 3, pointing out the current unreliability of LLMs for complex tasks.
  relevance_score: 9
  source: llm_enhanced
  text: In reality, this means you go and tell the model to build something, and it
    will go and do it, and you'll be shocked to hear that these models can't be relied
    upon to go and do anything.
  topic: safety
- impact_reason: Highlights a specific example of how companies are using vague, complex
    pricing schemes (obfuscated effort-based pricing) to mask spiraling costs passed
    onto users.
  relevance_score: 9
  source: llm_enhanced
  text: Replit released a product called Agent 3, which promised to be 10 times more
    autonomous... Shifting to obfuscated effort-based pricing that would charge the
    full scope of the agent's work, and if you're wondering what the fuck that means,
    so are their customers.
  topic: business
- impact_reason: Interprets a product change (adding autonomy controls) as an admission
    of failure regarding the reliability and safety of autonomous coding agents.
  relevance_score: 9
  source: llm_enhanced
  text: Replit has now released an update unless you choose how autonomous you want
    Agent 3 to be, which is a tacit admission that you can't trust coding LLMs to
    build software.
  topic: safety
- impact_reason: 'This is the technical root cause of the business problem: the lack
    of standardization in compute consumption per user interaction.'
  relevance_score: 9
  source: llm_enhanced
  text: a large language model's usage infrastructural burden varies wildly between
    users and use cases.
  topic: technical
- impact_reason: Directly links specificity (especially in complex tasks like coding)
    to exponential cost increases due to iterative error correction.
  relevance_score: 9
  source: llm_enhanced
  text: The more specific the output, the more opportunities there are for monstrous
    token burn, and I'm specifically thinking about coding with LLMs.
  topic: technical/business
- impact_reason: A strong critique of model routing strategies for cost savings, suggesting
    that the overhead of intelligent routing might negate the benefits of using smaller
    models.
  relevance_score: 9
  source: llm_enhanced
  text: OpenAI's smaller model, the GPT version of ChatGPT, requires vast amounts
    of additional compute in order to route the user's request to the appropriate
    model... it makes it impossible to cache part of the input. As a result, it's
    not really clear whether it's saving OpenAI any money, and indeed, it kind of
    suggests it might be costing them more.
  topic: technical
- impact_reason: Provides concrete, high-level financial data suggesting that even
    leading, popular AI products are currently operating at a significant loss, underscoring
    the high cost of inference.
  relevance_score: 9
  source: llm_enhanced
  text: Claude was driving nearly $400 million in annualized revenue, roughly doubling
    from a few weeks ago on July 31st, 2025. The annualized revenue works out to about
    $33 million a month in revenue for a company that predicts it will make at least
    $416 million a month by the end of the year, and for a product that has become
    for a time the most popular coding environment in the world... all of which is
    unprofitable...
  topic: business
- impact_reason: Provides a clear, industry-relevant analogy for the current capability
    ceiling of coding LLMs—useful for simple tasks but lacking practical engineering
    depth.
  relevance_score: 9
  source: llm_enhanced
  text: Code generation AIs, from an industry standpoint, are roughly the equivalent
    of a slightly below-average computer science graduate fresh out of school without
    any real-world experience, only ever having written programs to be printed and
    graded.
  topic: predictions/technical
- impact_reason: 'A critical long-term workforce development concern: eliminating
    entry-level roles prevents the pipeline necessary for future senior expertise.'
  relevance_score: 9
  source: llm_enhanced
  text: if we're replacing the bottom rung of the labor market, there won't be any
    mid-level or senior developers later down the line.
  topic: safety/predictions
- impact_reason: Reinforces the 'summer intern' analogy, specifically pointing out
    the failure of LLMs in architectural integration and managing complexity across
    multiple components.
  relevance_score: 9
  source: llm_enhanced
  text: LLMs often function like a fresh summer intern. They're good at solving the
    straightforward problems... but they are unwieldy. They do not understand how
    to bring lots of solutions to small, straightforward problems together into a
    larger whole.
  topic: technical
- impact_reason: A profound statement on the opacity of LLM outputs; because the model
    lacks true understanding, the resulting code lacks inherent explainability or
    verifiable reasoning.
  relevance_score: 9
  source: llm_enhanced
  text: Using an LLM, you'll never know [how code works and functions and why it functions
    in that way], because the LLM doesn't know anything either.
  topic: safety/technical
- impact_reason: A stark statement on the fundamental lack of true understanding or
    'knowing' within current LLMs, highlighting the opacity and inherent limitations
    when debugging or verifying complex outputs.
  relevance_score: 9
  source: llm_enhanced
  text: Using an LLM, you'll never know, because the LLM doesn't know anything either.
  topic: limitations
- impact_reason: This directly attacks the marketing narrative surrounding AI adoption—that
    it's a complete delegation tool—and calls out the perceived hypocrisy or overreach
    in industry messaging.
  relevance_score: 9
  source: llm_enhanced
  text: The whole fucking point of an AI is that you hand shit off to it. That's what
    they've been selling it as. That's why Jensen Huang told kids to stop learning
    to code, as with AI there's no point. And it was all a fucking lie.
  topic: strategy/business
- impact_reason: Provides a comprehensive definition of software engineering that
    highlights the non-codable, high-value aspects (design, maintainability, scalability)
    that current AI cannot replicate.
  relevance_score: 9
  source: llm_enhanced
  text: Software engineering is not just coding; it involves thinking about problems,
    finding solutions to novel challenges, designing stuff in a way that can be read
    and maintained by others, and that's ideally scalable and secure.
  topic: strategy/technical
- impact_reason: Connects the abstract limitations of AI (creativity, context) directly
    to the observable market reality (lack of mass replacement in coding).
  relevance_score: 9
  source: llm_enhanced
  text: This is, by the way, why we're still yet to get any tangible proof that AI
    is replacing software engineers, because it isn't replacing software engineers.
  topic: predictions/limitations
- impact_reason: A significant critique of the adoption rate of a flagship enterprise
    AI product (Copilot) by arguably the world's largest software vendor, suggesting
    broader market friction.
  relevance_score: 9
  source: llm_enhanced
  text: Microsoft has made almost no traction in popularizing generative AI.
  topic: business
- impact_reason: Exposes potentially misleading metrics used by large companies to
    define 'active users' for new products, suggesting the true engagement level might
    be even lower than the already low conversion rate implies.
  relevance_score: 9
  source: llm_enhanced
  text: An active user is someone who has taken one action on any Microsoft 365 app
    with Copilot in the space of 28 days, not 30, 28. That's so generous.
  topic: business/strategy
- impact_reason: 'Describes the failure mode of LLMs in complex tasks: increasing
    complexity leads to catastrophic failure (hallucination), which is the opposite
    of what is needed in critical engineering work.'
  relevance_score: 9
  source: llm_enhanced
  text: In reality, LLMs can generate code and do some sort of software engineering-adjacent
    tasks, but like all large language models, they break down and go totally insane,
    hallucinate more and more as the tasks get more complex...
  topic: limitations
- impact_reason: Provides specific, high-level financial data suggesting even the
    market leaders are not achieving profitability commensurate with their valuations/projections.
  relevance_score: 8
  source: llm_enhanced
  text: Even Anthropic and OpenAI seem a little off-large, both burning billions of
    dollars while making by May estimates no more than $2 billion in Anthropic's case
    this year so far, and $6.26 billion in 2025 so far for OpenAI, despite projections
    of $5 billion and $13 billion respectively.
  topic: business
- impact_reason: Suggests that pricing changes and product obfuscation are defensive
    maneuvers driven by economic desperation rather than genuine product improvement.
  relevance_score: 8
  source: llm_enhanced
  text: And faced with the grim reality ahead of them, these companies are trying
    nasty little tricks on their customers to juice more revenue from them.
  topic: business
- impact_reason: 'Highlights the hidden friction in using LLMs for coding: the cognitive
    load of prompt engineering and validation often outweighs the benefit of code
    generation.'
  relevance_score: 8
  source: llm_enhanced
  text: in practice, the effort of articulating so much of the design work in plain
    English and hoping the LLM emits code that I find acceptable is frequently more
    work than just writing the code.
  topic: technical
- impact_reason: Distinguishes between execution (which LLMs can assist with) and
    conceptual design/problem-solving (the core of engineering), which remains a human
    domain.
  relevance_score: 8
  source: llm_enhanced
  text: For most problems, the hardest part is the thinking, and LLMs don't make that
    part any easier.
  topic: technical
- impact_reason: Draws a powerful analogy between translation and software engineering,
    framing the latter as a high-level communication and contextual synthesis task,
    far beyond mere syntax generation.
  relevance_score: 8
  source: llm_enhanced
  text: Good software engineering harkens back to Brian Merchant's interviews with
    translators. While some may believe the translator simply tells you what words
    mean, true translation is communicating the meaning of a sentence, which is cultural,
    contextual, regional, and personal, and often requires the exercise of creativity
    and novel thinking.
  topic: strategy
- impact_reason: Directly addresses the current, fundamental gap between generative
    AI capabilities and the human requirement for creativity, especially in nuanced
    tasks like translation or complex problem-solving.
  relevance_score: 8
  source: llm_enhanced
  text: They had to exercise creativity, which is something that an AI is inherently
    incapable of doing.
  topic: limitations
- impact_reason: Reinforces the complexity of real-world software engineering, which
    often requires deep system knowledge, debugging tools, and external context beyond
    static code review, areas where LLMs fail.
  relevance_score: 8
  source: llm_enhanced
  text: Even software engineers who can read code and have done so for decades will
    find problems they can't solve just by looking at the code.
  topic: limitations
- impact_reason: Indicates that despite high list prices, the market reality for enterprise
    AI adoption is forcing immediate price concessions, a key indicator of weak initial
    demand or high perceived cost/benefit imbalance.
  relevance_score: 8
  source: llm_enhanced
  text: Microsoft has been reducing the software's price, referring to Microsoft 365,
    with more generous discounts on the AI features, according to customers and salespeople,
    heavily suggesting discounts have already been happening.
  topic: business
- impact_reason: A foundational statement redefining the core job of a software engineer
    away from mere creation toward complex maintenance and interpersonal/system interaction.
  relevance_score: 8
  source: llm_enhanced
  text: The reality is that software engineers maintain software, which includes writing
    and analyzing code amongst a vast array of different personalities and programs
    and problems.
  topic: strategy
- impact_reason: Explains why coding became the focal point for AI disruption fears—it
    was the first area where AI showed plausible, albeit limited, capability.
  relevance_score: 7
  source: llm_enhanced
  text: Of all the fields supposedly at risk from AI disruption, coding fields felt
    the most tangible, if only because the answer to, "Can you write code with LLMs?"
    wasn't an immediate unilateral no.
  topic: predictions/strategy
source: Unknown Source
summary: "## Podcast Episode Summary: The Case Against Generative AI (Part 3)\n\n\
  This episode, hosted by Ed Zitron, is the third installment of a four-part series\
  \ critically examining the origins, mythology, and impending collapse of the Generative\
  \ AI bubble. The core focus of this segment is the **unsustainable economics** of\
  \ current AI models, particularly the massive, uncontrollable operational costs\
  \ that lead to negative gross margins, and the **overstated capabilities** of LLMs\
  \ in complex tasks like software engineering.\n\n---\n\n1. **Focus Area**: The primary\
  \ focus is the **financial unsustainability** of the Generative AI industry, characterized\
  \ by high infrastructure burn rates and difficulty in cost control. A secondary,\
  \ but crucial, focus is debunking the narrative that LLMs are replacing skilled\
  \ software engineers, focusing instead on their limitations in complex reasoning\
  \ and maintenance.\n\n2. **Key Technical Insights**:\n    * **Uncontrollable Token\
  \ Burn**: The \"all-you-can-eat\" subscription models for LLMs (like Anthropic's\
  \ Claude Code) make cost control nearly impossible, as individual users can generate\
  \ token usage that vastly exceeds their monthly subscription fee (e.g., one user\
  \ costing Anthropic over 3,000% of their subscription value).\n    * **Architectural\
  \ Limitations in Reasoning**: LLMs struggle with the high context demands of complex\
  \ software engineering. They fail to reason about the interconnections between abstract\
  \ layers of code, effectively limiting them to the capabilities of a \"slightly\
  \ below-average computer science graduate.\"\n    * **Inefficiency of Model Routing**:\
  \ Efforts to save costs by routing simple queries to smaller models are potentially\
  \ ineffective or even counterproductive, as the compute required for routing and\
  \ determining the appropriate model negates potential savings.\n\n3. **Business/Investment\
  \ Angle**:\n    * **Widespread Unprofitability**: Outside of OpenAI and Anthropic\
  \ (who are still burning billions), most AI startups are struggling with negative\
  \ gross margins and floundering financially, despite high valuations.\n    * **Revenue\
  \ vs. Cost Disparity**: Even successful AI products like Replit and Cursor generate\
  \ relatively low annualized revenue ($500M ARR for Cursor cited as an example) compared\
  \ to the massive infrastructure costs required to run the underlying models.\n \
  \   * **Pricing Abuse as a Survival Tactic**: Companies are resorting to \"nasty\
  \ little tricks\" like shifting to obfuscated, effort-based pricing (e.g., Replit's\
  \ Agent 3) to try and extract more revenue, often leading to customer backlash over\
  \ unpredictable, skyrocketing bills.\n\n4. **Notable Companies/People**:\n    *\
  \ **Ed Zitron (Host)**: The primary voice, presenting a sustained, critical argument\
  \ against the AI hype cycle based on financial data and expert consultation.\n \
  \   * **Anthropic**: Highlighted as the second-largest model developer, yet unable\
  \ to control costs, with specific examples of Claude Code subscribers massively\
  \ overspending their subscription limits.\n    * **Replit**: Cited for its shift\
  \ to opaque, high-cost pricing for its Agent 3 feature, which resulted in customer\
  \ bills spiraling into the hundreds or thousands of dollars.\n    * **Microsoft/GitHub\
  \ Copilot**: Mentioned as another major player losing significant money per user\
  \ (estimated $20-$80 monthly loss).\n    * **Carl Brown, Nick Shoresh, Colt Vogel**:\
  \ Software engineers interviewed (or quoted) who provided expert consensus that\
  \ LLMs are currently limited to solving straightforward problems and lack the necessary\
  \ abstraction and reasoning skills for true software engineering.\n\n5. **Future\
  \ Implications**: The conversation strongly suggests that the current economic model\
  \ of Generative AI is broken. Without a viable \"profit lever\" (unlike traditional\
  \ software), the industry is heading toward a significant correction or collapse\
  \ as infrastructure costs continue to rise and user experimentation burns capital.\
  \ Furthermore, the narrative of mass job replacement in skilled fields like coding\
  \ is deemed a \"grotesque, manipulative, abusive, and offensive lie.\"\n\n6. **Target\
  \ Audience**: This episode is highly valuable for **Technology Investors, Business\
  \ Strategists, AI/ML Professionals, and Media Analysts** who need a deep, skeptical,\
  \ and financially grounded counter-narrative to the prevailing industry optimism."
tags:
- artificial-intelligence
- generative-ai
- startup
- ai-infrastructure
- openai
- anthropic
- microsoft
title: The Case Against Generative AI (Part 3)
topics:
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 118
  prominence: 1.0
  topic: artificial intelligence
- keywords:
  - generative ai
  - genai
  - chatgpt
  - gpt
  - claude
  - text generation
  - image generation
  mentions: 28
  prominence: 1.0
  topic: generative ai
- keywords:
  - startup
  - entrepreneur
  - founder
  - venture
  mentions: 3
  prominence: 0.3
  topic: startup
- keywords:
  - gpu
  - tensor
  - training
  - inference
  - model deployment
  - vector database
  mentions: 1
  prominence: 0.1
  topic: ai infrastructure
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-10-06 04:06:46 UTC -->
