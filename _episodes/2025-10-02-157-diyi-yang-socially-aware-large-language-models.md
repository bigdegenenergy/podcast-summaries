---
companies:
- category: unknown
  confidence: medium
  context: Welcome back to the Stanford Psychology Podcast. I'm Souda Karajah, a pre-doctoral
    fellow at Stan
  name: Stanford Psychology Podcast
  position: 20
- category: unknown
  confidence: medium
  context: come back to the Stanford Psychology Podcast. I'm Souda Karajah, a pre-doctoral
    fellow at Stanford University. I'
  name: Souda Karajah
  position: 53
- category: unknown
  confidence: medium
  context: cast. I'm Souda Karajah, a pre-doctoral fellow at Stanford University.
    I'm excited to be joining the show as one of you
  name: Stanford University
  position: 93
- category: unknown
  confidence: medium
  context: today, I'm so happy to share my conversation with Professor D. Young, whose
    research I've long admired and who
  name: Professor D
  position: 245
- category: unknown
  confidence: medium
  context: tment at Stanford University, affiliated with the Stanford Natural Language
    Processing Group, Stanford Human Computer Interaction Group, Stanf
  name: Stanford Natural Language Processing Group
  position: 509
- category: unknown
  confidence: medium
  context: h the Stanford Natural Language Processing Group, Stanford Human Computer
    Interaction Group, Stanford AI Lab, and Stanford Human Center, Art
  name: Stanford Human Computer Interaction Group
  position: 553
- category: unknown
  confidence: medium
  context: Group, Stanford Human Computer Interaction Group, Stanford AI Lab, and
    Stanford Human Center, Art Schilling-Telgent
  name: Stanford AI Lab
  position: 596
- category: unknown
  confidence: medium
  context: Computer Interaction Group, Stanford AI Lab, and Stanford Human Center,
    Art Schilling-Telgent Center. She is also leadin
  name: Stanford Human Center
  position: 617
- category: unknown
  confidence: medium
  context: roup, Stanford AI Lab, and Stanford Human Center, Art Schilling-Telgent
    Center. She is also leading the Social an
  name: Art Schilling
  position: 640
- category: unknown
  confidence: medium
  context: AI Lab, and Stanford Human Center, Art Schilling-Telgent Center. She is
    also leading the Social and Language Tech
  name: Telgent Center
  position: 654
- category: unknown
  confidence: medium
  context: elgent Center. She is also leading the Social and Language Technologies
    Lab, where they study socially aware natural lang
  name: Language Technologies
  position: 705
- category: unknown
  confidence: medium
  context: elgent Center. She is also leading the Social and Language Technologies
    Lab, where they study socially aware natural language
  name: Language Technologies Lab
  position: 705
- category: unknown
  confidence: medium
  context: pproach to research, along with her recent paper, Social Skill Training
    with Large Language Models, which introduces a ne
  name: Social Skill Training
  position: 1193
- category: unknown
  confidence: medium
  context: with her recent paper, Social Skill Training with Large Language Models,
    which introduces a new framework that supports m
  name: Large Language Models
  position: 1220
- category: unknown
  confidence: medium
  context: raining in computer science and machine learning. When I moved to the US,
    I got very fascinated by differe
  name: When I
  position: 3987
- category: unknown
  confidence: medium
  context: lly got excited about all these kinds of factors. And I realized that language
    or language technology is
  name: And I
  position: 4454
- category: unknown
  confidence: medium
  context: a large language model training framework called AI Partner AI Mentor that
    makes social skills training more accessible
  name: AI Partner AI Mentor
  position: 7795
- category: unknown
  confidence: medium
  context: as quite a challenging one when I first got here. So I always want to learn
    all sorts of social skills.
  name: So I
  position: 8262
- category: unknown
  confidence: medium
  context: I think you mentioned our framework. It's called AI Partner and AI Mentor.
    I use it as more like a conceptual
  name: AI Partner
  position: 9961
- category: unknown
  confidence: medium
  context: ntioned our framework. It's called AI Partner and AI Mentor. I use it as
    more like a conceptual framework to
  name: AI Mentor
  position: 9976
- category: unknown
  confidence: medium
  context: on. Then you can actually talk to the AI Partner. This AI Partner there
    might be a roleplay of your roommate. And t
  name: This AI Partner
  position: 10216
- category: unknown
  confidence: medium
  context: ou can practice different types of conversations. And AI Mentor is tailored
    in a way that we will bring in or bui
  name: And AI Mentor
  position: 10574
- category: unknown
  confidence: medium
  context: main expertise into specific models so that those AI Mentors can actually
    give you very realistic feedback. So
  name: AI Mentors
  position: 10692
- category: unknown
  confidence: medium
  context: to a group of people, then you can have multiple AI Partners there. You
    can even have different AI Mentors. So
  name: AI Partners
  position: 11016
- category: unknown
  confidence: medium
  context: framework, which is super exciting to hear about. Here I want to stop talking
    about this framework, but be
  name: Here I
  position: 32261
- category: ai_research_institution
  confidence: high
  context: The host and professor are affiliated with Stanford, which houses several
    AI/ML research groups.
  name: Stanford University
  source: llm_enhanced
- category: ai_research_group
  confidence: high
  context: A research group at Stanford where the professor is affiliated, focusing
    on NLP.
  name: Stanford Natural Language Processing Group
  source: llm_enhanced
- category: ai_research_group
  confidence: high
  context: A research group at Stanford where the professor is affiliated, focusing
    on HCI.
  name: Stanford Human Computer Interaction Group
  source: llm_enhanced
- category: ai_research_institution
  confidence: high
  context: A research lab at Stanford where the professor is affiliated, focusing
    on AI.
  name: Stanford AI Lab
  source: llm_enhanced
- category: ai_research_institution
  confidence: medium
  context: A center at Stanford the professor is affiliated with, implying a focus
    on human-centered technology/AI.
  name: Stanford Human Center, Art Schilling-Telgent Center
  source: llm_enhanced
- category: ai_research_group
  confidence: high
  context: The lab led by the professor, focusing on socially aware NLP and language
    technologies.
  name: Social and Language Technologies Lab
  source: llm_enhanced
- category: ai_technology_focus
  confidence: high
  context: Mentioned repeatedly as the core technology being researched and applied
    (e.g., AI Partner, AI Mentor). While not a specific company, it represents the
    core technology area.
  name: Large Language Models (LLMs)
  source: llm_enhanced
- category: ai_application_framework
  confidence: high
  context: A conceptual framework/agent built using LLMs for role-playing social scenarios.
  name: AI Partner
  source: llm_enhanced
- category: ai_application_framework
  confidence: high
  context: A conceptual framework/agent built using LLMs to provide coaching and feedback
    during social skills training.
  name: AI Mentor
  source: llm_enhanced
- category: ai_application_system
  confidence: high
  context: A specific system built using the AI Partner/AI Mentor framework to help
    people practice difficult conversations (conflict resolution).
  name: Rehearsal
  source: llm_enhanced
- category: ai_research_institution_collaboration
  confidence: high
  context: The speaker mentions working with the medical school here at Stanford to
    look at how students in their therapy training classes use the CARE system.
  name: Stanford
  source: llm_enhanced
- category: ai_application_startup_project
  confidence: high
  context: A system built by the speaker's team where novice counselors practice with
    AI patients and receive feedback from an AI Mentor.
  name: CARE
  source: llm_enhanced
date: 2025-10-02 19:00:00 +0000
duration: 43
has_transcript: false
insights:
- actionable: false
  confidence: medium
  extracted: this type of human-AI collaboration, particularly in the fields traditionally
    focused on human interaction like therapy, education, or like any system like
    this? Yeah, I think this
  text: the future of this type of human-AI collaboration, particularly in the fields
    traditionally focused on human interaction like therapy, education, or like any
    system like this? Yeah, I think this is a great question.
  type: prediction
layout: episode
llm_enhanced: true
original_url: https://audio.listennotes.com/e/p/f4621f8c3cec4d7b9255441cd78d4fb0/
processing_date: 2025-10-06 03:51:24 +0000
quotes:
- length: 292
  relevance_score: 4
  text: Her research goal is to better understand human communication and social context
    and build socially aware language technologies via methods of MLP, deep learning
    and machine learning, as well as theories in social sciences and linguistics to
    support human-human and human-computer interaction
  topics: []
- length: 274
  relevance_score: 4
  text: In today's episode, we discussed her interdisciplinary approach to research,
    along with her recent paper, Social Skill Training with Large Language Models,
    which introduces a new framework that supports making social skills trainings
    more available, accessible, and inviting
  topics: []
- length: 77
  relevance_score: 4
  text: Before that, I did a lot of training in computer science and machine learning
  topics: []
- impact_reason: A powerful, concise summary emphasizing the pervasive human element
    in the entire AI lifecycle, reinforcing the need for human-centric design.
  relevance_score: 10
  source: llm_enhanced
  text: The data comes from humans, the model is produced by humans, the choices to
    build architecture are made by humans, and even the end product is for humans.
  topic: strategy
- impact_reason: A stark warning about the risks of ignoring human factors, specifically
    mentioning misalignment, trust erosion, and psychological impact—key concerns
    in modern AI deployment.
  relevance_score: 10
  source: llm_enhanced
  text: If we do not pay attention to those human-centric aspects, I think the consequences
    could be huge and really consequential in many ways. For example, our systems
    may not be aligned with human behavior. And in addition to the system themselves,
    when it comes to people, you imagine a lot of issues around the trust, or psychological
    impact of how AI systems may influence our behavior, all of those are very important
    today.
  topic: safety
- impact_reason: 'Identifies a major current limitation in LLM simulation: the tendency
    to caricature or amplify traits, which undermines the realism needed for effective
    social skills training.'
  relevance_score: 10
  source: llm_enhanced
  text: The first challenge even before we get to these nuances or social awareness
    is actually to make sure the technology would work well in the first place. Despite
    the fact that large language models are very powerful in doing role play, etc.,
    their simulation, like if you're going to use LLMs to simulate your roommate or
    simulate a typical learning partner, that process may not be very realistic because
    models tend to create a caricature and they tend to amplify a lot of the attributes
    if you tell them, okay, here is a specific person.
  topic: limitations
- impact_reason: Describes an advanced technique (self-critique/self-improvement)
    used within the model to ensure contextual appropriateness and alignment with
    domain knowledge during generation, crucial for high-stakes applications.
  relevance_score: 10
  source: llm_enhanced
  text: we actually develop some techniques such as self-critique and self-improvement.
    Like, is this a reasonable response to use here that is aligned with all the domain
    knowledge, is it appropriate, etc., etc.
  topic: technical
- impact_reason: 'Poses the core evaluation dilemma for human-centric AI: how to quantify
    subjective, fuzzy human qualities when they are used as performance metrics for
    the model.'
  relevance_score: 10
  source: llm_enhanced
  text: how do you plan to evaluate these human qualities like having a personality,
    understanding emotions or showing empathy and expertise? Are they measured using
    the same standards we would use for a person?
  topic: safety/evaluation
- impact_reason: 'Provides a crucial empirical finding: interactive practice (skill
    application) is vastly more effective for performance improvement than rote knowledge
    acquisition (''book smart vs. street smart'').'
  relevance_score: 10
  source: llm_enhanced
  text: We saw that people's knowledge about conflict resolution actually didn't change
    at all. However, if you let them do an interactive conflict resolution, people
    who practiced with our systems actually did much better compared to people who
    haven't used the system.
  topic: business/practical lessons
- impact_reason: Provides a concrete example of applying LLMs/AI for high-stakes professional
    training (counseling), integrating simulation (AI patient) and guidance (AI mentor).
  relevance_score: 10
  source: llm_enhanced
  text: We built a system called CARE where novice counselors can actually practice
    with different types of AI patients. We created those AI patients based on the
    learning materials that counselors need to learn in their training. And we also
    built an AI Mentor so that when they practice, they can also get feedback along
    the way.
  topic: technical/business
- impact_reason: 'Raises a significant ethical/social concern regarding AI training
    tools: the risk of users becoming overly dependent on the simulation, leading
    to poor real-world performance.'
  relevance_score: 10
  source: llm_enhanced
  text: the second kind of social technical challenge is more about this kind of scenarios
    that people may practice and then they may develop some kind of reliance there...
    we worry that one of the issues is this kind of over-reliance.
  topic: safety/ethics
- impact_reason: Lists specific, known LLM weaknesses (caricatures, bias, hallucination)
    as they apply directly to the challenge of building socially accurate AI agents.
  relevance_score: 10
  source: llm_enhanced
  text: researchers found that large language models tend to produce caricatures when
    it comes to social simulation, or there may be cultural biases, or they might
    hallucinate when it comes to specific domains that they don't have a really good
    knowledge of.
  topic: technical/safety
- impact_reason: 'Crucial advice for aspiring researchers/builders in this field:
    success requires true interdisciplinary fluency (computational methods + social
    science).'
  relevance_score: 10
  source: llm_enhanced
  text: I think this is a great direction, and when I think about the skills, I feel
    like I would encourage people to have a more open mind, understand the mindset
    about the space. It does not only require social science or social insights, it
    also requires some kind of computational methods.
  topic: strategy/business
- impact_reason: A powerful concluding philosophical statement emphasizing that the
    purpose of advanced technology, especially social AI, must be humanistic improvement,
    not just technical novelty.
  relevance_score: 10
  source: llm_enhanced
  text: the goal of how we build technology is not for the purpose of building technology.
    The goal is to think about how technology would help us, help more with human
    touch, help us with developing better and more meaningful interactions with each
    other.
  topic: strategy/safety
- impact_reason: This clearly defines 'socially aware language technology,' shifting
    the focus of NLP beyond mere syntax/semantics to include social context, which
    is crucial for advanced, human-aligned AI.
  relevance_score: 9
  source: llm_enhanced
  text: Basically, it's about the study and the development of language technologies
    from a social perspective. The goal here is that we want to enable today's AI
    systems to better understand and respond to social signals expressed in language
    and also the broader physical and social environment.
  topic: strategy
- impact_reason: 'Highlights the desired capability of future AI: processing meaning
    and implication like humans, moving beyond literal interpretation by incorporating
    cultural and emotional context.'
  relevance_score: 9
  source: llm_enhanced
  text: You can imagine that the socially aware systems can recognize social factors,
    such as social factors, cultural, emotion, perspectives, etc. And more importantly,
    they can help us produce or process implications and meanings behind the language
    in the same way humans do.
  topic: predictions
- impact_reason: Explicitly links NLP development to societal impact (positive and
    negative), emphasizing the ethical and consequential dimension of the technology.
  relevance_score: 9
  source: llm_enhanced
  text: The last dimension is what I call implication or social implication. It refers
    to the broader impact of the NLP system on society, including understanding both
    the positive and negative effects.
  topic: safety
- impact_reason: 'Identifies a novel, high-potential application for LLMs: interactive,
    personalized training for social skills, leveraging their conversational strengths
    beyond traditional tasks like coding or math.'
  relevance_score: 9
  source: llm_enhanced
  text: I really want to see can they really also do well with social skills. When
    large language models get popular and the performance get very impressive, I realize
    if we use them well, it's a great way to help enable very interactive training
    because one of the big advantages of large language models is that you can have
    conversations with these AI systems and you can do a lot of chit-chat. We can
    even roleplay different characters there with large language models.
  topic: predictions
- impact_reason: Details the 'AI Partner/AI Mentor' framework (APAM), a specific architectural
    approach for interactive, coached learning using two distinct LLM agents.
  relevance_score: 9
  source: llm_enhanced
  text: It's called AI Partner and AI Mentor. Think about you want to learn conflict
    resolution. Then you can actually talk to the AI Partner. This AI Partner there
    might be a roleplay of your roommate. And then you practice different types of
    topics with this AI Partner there. And then the entire conversation is going to
    be coached by this AI Mentor.
  topic: technical
- impact_reason: 'Highlights a critical limitation in LLM simulation: the tendency
    to oversimplify or exaggerate personality traits, making realistic individual
    simulation difficult.'
  relevance_score: 9
  source: llm_enhanced
  text: models tend to create a caricature and they tend to amplify a lot of the attributes
    if you tell them, okay, here is a specific person.
  topic: limitations
- impact_reason: 'Presents a practical workaround for the caricature problem: focusing
    simulation on skill templates rather than specific individuals, which is more
    scalable and reliable for training.'
  relevance_score: 9
  source: llm_enhanced
  text: Instead of doing the simulation of a specific individual, we try to create
    a typical template for interacting on that specific skill.
  topic: technical/strategy
- impact_reason: Emphasizes the necessity of grounding AI development in established
    human science theories to ensure feedback and interactions are meaningful and
    scientifically sound, moving beyond purely data-driven approaches.
  relevance_score: 9
  source: llm_enhanced
  text: we actually use a lot of theories from those different research fields [communication,
    psychology, psychotherapy] try to see whether we could let them into the development
    process so that a lot of the feedback is actually very grounded to users.
  topic: strategy
- impact_reason: Confirms the difficulty in operationalizing subjective social skills,
    suggesting that current benchmarks are inadequate for evaluating empathy or nuanced
    social performance.
  relevance_score: 9
  source: llm_enhanced
  text: a lot of those social aspects are actually very fuzzy and not well-defined.
    We don't even know how to operationalize them. So the evaluation will become something
    that's quite tricky and open-ended.
  topic: evaluation
- impact_reason: 'Identifies a secondary, high-value user group: expert supervisors/trainers,
    positioning the AI as a force multiplier for those providing mentorship (''Helping
    the Helper'').'
  relevance_score: 9
  source: llm_enhanced
  text: we want to also help people who are providing feedback to others to help their
    job to some extent. Imagine at those moments, this kind of AI Mentor would be
    a great help to the people who are already helping others.
  topic: business/strategy
- impact_reason: 'Offers a memorable, actionable insight for educators and trainers:
    performance hinges on applied, interactive skill, not just conceptual understanding.'
  relevance_score: 9
  source: llm_enhanced
  text: This was very, very surprising to us. But then later we realized that this
    is the difference between being book smart versus being street smart.
  topic: practical lessons
- impact_reason: Highlights a core limitation of knowledge-based systems (like early
    AI) and emphasizes the importance of interactive, contextual application—a key
    goal for advanced AI simulation.
  relevance_score: 9
  source: llm_enhanced
  text: this is the difference between being book smart versus being street smart.
    Like it's more about how you use the knowledge in an interactive context rather
    than remembering the concepts or knowledge.
  topic: strategy/limitations
- impact_reason: 'Identifies a common current limitation in generative AI simulation:
    lack of naturalness or ''stiffness'' in interaction, despite underlying LLM power.'
  relevance_score: 9
  source: llm_enhanced
  text: Some of our participants when they use our systems share that, oh, sometimes
    the conversation feels like they are very stiff.
  topic: technical/limitations
- impact_reason: Direct advice on managing user expectations for AI simulation tools,
    stressing transparency about the gap between practice and reality.
  relevance_score: 9
  source: llm_enhanced
  text: this simulation to real-world difference. And I think it's very important
    to point out these two things so that from a social perspective people won't develop
    too high or too unrealistic expectations of the system.
  topic: safety/strategy
- impact_reason: 'Outlines a clear technical roadmap/challenge for improving social
    AI: moving beyond text to incorporate multimodal inputs (audio, visual cues) essential
    for social skills.'
  relevance_score: 9
  source: llm_enhanced
  text: so far the system admission is actually text-based... Bringing additional
    modalities such as image or audio, so that'll be some of the technical challenges
    I perceive here.
  topic: technical
- impact_reason: Articulates the value proposition of 'socially aware AI'—it leads
    directly to more capable and useful general-purpose systems.
  relevance_score: 9
  source: llm_enhanced
  text: If you bring in more cultural context, make AI systems more aware of people's
    emotions, intentions, perspectives, empathy, a lot of the social implications,
    then I think that we definitely could make systems more capable of doing daily
    tasks...
  topic: technical/predictions
- impact_reason: 'Provides a philosophical framework for AI integration: AI should
    act as an intermediary or support structure, not a replacement.'
  relevance_score: 9
  source: llm_enhanced
  text: I think I would argue that we want to make AI systems, socially aware AI systems,
    more like a support system, more like a bridge for human-human interaction and
    human-computer interaction.
  topic: strategy
- impact_reason: 'Highlights a specific, high-leverage application in education: using
    AI to coach educators on interpersonal skills, thereby improving student outcomes.'
  relevance_score: 9
  source: llm_enhanced
  text: If teachers could be facilitated with the AI Mentor in terms of how to talk
    to kids better, then we definitely use this kind of technology as a way to improve
    the student and teacher relationships.
  topic: business/predictions
- impact_reason: Provides a structured, three-dimensional framework (Social Factors,
    Social Interactions, Social Implication) for analyzing and building socially aware
    systems, offering a clear research roadmap.
  relevance_score: 8
  source: llm_enhanced
  text: There are three dimensions I often use when I think about socially aware language
    technologies. So the first one is what we call social factors. If you think about
    the language communication between people for a specific message, it's not only
    just about the content, it's also about who is a speaker, who is a receiver, what's
    their social relation, and what the context, gathered by what type of social norms,
    culture, and ideology, and for what type of community goals.
  topic: strategy
- impact_reason: 'Strong business/research advice: prioritize problems based on real-world
    impact in critical domains (like education/healthcare) rather than purely technical
    novelty.'
  relevance_score: 8
  source: llm_enhanced
  text: I think one side we really want to make sure the problems we are going to
    work on matter in diverse real-world domains. When we think about K-12 education
    or even in healthcare, I think taking real-world impact into the first place to
    think about what the problems to work on is quite important.
  topic: business advice
- impact_reason: Articulates a critical barrier to human skill development (psychological
    risk in practice) that AI systems are uniquely positioned to solve by providing
    a safe simulation environment.
  relevance_score: 8
  source: llm_enhanced
  text: Practicing them is actually psychologically unsafe. So if you think about,
    oh, I want to negotiate or do this conflict resolution about this topic with my
    roommate, with my boss, I think a lot of times people don't feel like they can
    easily open up.
  topic: business advice
- impact_reason: 'Suggests a method for grounding LLM feedback: specializing mentor
    models with domain expertise to ensure feedback is realistic and actionable, addressing
    the generalist nature of base LLMs.'
  relevance_score: 8
  source: llm_enhanced
  text: AI Mentor is tailored in a way that we will bring in or build domain expertise
    into specific models so that those AI Mentors can actually give you very realistic
    feedback.
  topic: technical
- impact_reason: 'Acknowledges a major, unsolved challenge in advanced AI interaction:
    reliably integrating complex cultural dynamics and nuanced social awareness into
    current frameworks.'
  relevance_score: 8
  source: llm_enhanced
  text: In terms of a lot of the cultural dynamics, a lot of the social awareness,
    we haven't figured out a great way to integrate them into this space. I think
    that itself is an open question.
  topic: limitations/safety
- impact_reason: 'Details a practical, necessary evaluation method: relying on human
    expert judgment (human-in-the-loop) when objective metrics fail for complex social
    simulations.'
  relevance_score: 8
  source: llm_enhanced
  text: For many of the evaluations here, we actually sometimes work with human experts.
    We ask, is this a simulation that looks or sounds like it is difficult to you?
    Is this a good reflection of the client you had in your interaction?
  topic: evaluation
- impact_reason: Highlights the current modality limitation of text/voice-based AI—it
    misses crucial non-verbal communication cues essential for mastering social skills,
    pointing toward future needs in VR/3D environments.
  relevance_score: 8
  source: llm_enhanced
  text: It's also about how you behave, your emotion, your posture, like how you do
    eye contact, a lot of those. So I think it will be very, very cool to think about
    how to make social skill training in a physical world or a 3D space.
  topic: predictions/limitations
- impact_reason: Shows the integration of specific, established pedagogical frameworks
    (like interest-based negotiation) directly into the AI's training logic, making
    the learning process structured.
  relevance_score: 8
  source: llm_enhanced
  text: We actually leverage this theory called interest-based negotiation from conflict
    resolution. And so we basically try to introduce a lot of these pedagogical skills
    into the process so that people actually could learn from this.
  topic: technical/strategy
- impact_reason: Provides concrete evidence of success in teaching complex, soft skills
    (empathy, reflection) using the AI training system (CARE).
  relevance_score: 8
  source: llm_enhanced
  text: We found that the system helped them learn critical skills such as empathy,
    reflection, session management, etc.
  topic: practical lessons
- impact_reason: 'A crucial cautionary note for researchers and investors: early-stage
    AI applications, especially in sensitive domains, should be framed as ongoing
    research rather than proven success.'
  relevance_score: 8
  source: llm_enhanced
  text: I won't use the word success at this moment because it's still a very, very
    new and exciting direction.
  topic: strategy/safety
- impact_reason: 'Defines the ultimate strategic goal for socially aware AI: improving
    interactions on both axes (machine interaction and human interaction).'
  relevance_score: 8
  source: llm_enhanced
  text: I think eventually we want to make socially aware AI to hopefully help with
    both human-computer interaction and human-human interaction.
  topic: predictions/strategy
- impact_reason: Identifies social skill training as a key, immediate application
    for improving human-human relationships via AI.
  relevance_score: 8
  source: llm_enhanced
  text: I would argue that the topic we just talked about on social skill training
    is actually a great area where we are thinking about how socially aware systems
    could be used to help people learn better so that people could have better conversations
    or more positive conversations with others.
  topic: predictions/business
- impact_reason: Reinforces the necessity of cross-disciplinary expertise, suggesting
    a 'double major' level of exposure is beneficial for cutting-edge work in human-centered
    AI.
  relevance_score: 8
  source: llm_enhanced
  text: I do believe people may want to kind of typically be both majors to get exposure
    to this kind of thing.
  topic: strategy
- impact_reason: 'Highlights a crucial methodology for building effective human-centric
    AI: grounding development through iterative collaboration and feedback from domain
    experts (senior supervisors, novice users).'
  relevance_score: 7
  source: llm_enhanced
  text: we actually first work with domain users. So we talk to senior supervisors,
    we talk to novice counselors, we try to w[...]
  topic: practical lessons
- impact_reason: 'Defines the strategic niche for this AI application: serving as
    a foundational training tool for novices, rather than attempting to replace expert
    human training entirely.'
  relevance_score: 7
  source: llm_enhanced
  text: We imagine that it's especially for novices, for beginners, for people who
    don't know the field very well, they can actually use this kind of AI Partner
    and AI Mentor in the starting stage.
  topic: strategy
- impact_reason: 'States a core philosophical alignment for AI development: augmentation
    and empowerment over replacement.'
  relevance_score: 7
  source: llm_enhanced
  text: We want to build a system that can empower humans. This is like our true belief.
  topic: strategy
source: Unknown Source
summary: '## Podcast Episode Summary: 157 - Diyi Yang: Socially Aware Large Language
  Models


  This episode features Professor Diyi Yang discussing her research at the intersection
  of Computer Science, NLP, and Social Sciences, focusing on developing **Socially
  Aware Language Technologies**. The core narrative revolves around moving AI beyond
  mere technical accuracy to understanding and responding to the complex social signals
  inherent in human communication.


  ---


  ### 1. Focus Area

  The primary focus is **Socially Aware Natural Language Processing (NLP)**, defined
  by three dimensions: **Social Factors** (speaker/receiver relations, context, norms),
  **Social Interactions** (governing norms of communication), and **Social Implication**
  (the broader societal impact of NLP systems). A major application discussed is using
  LLMs for **Social Skill Training**, specifically through the **AI Partner AI Mentor
  (APAM)** framework.


  ### 2. Key Technical Insights

  *   **APAM Framework for Training:** The introduction of the **AI Partner** (role-playing
  conversational agent) and **AI Mentor** (domain-expert coach providing feedback)
  framework to make social skills training (like conflict resolution) accessible and
  psychologically safe.

  *   **Addressing Simulation Realism:** To overcome LLMs creating caricatures, the
  approach involves collaborating with domain experts to build **typical interaction
  templates** rather than simulating specific individuals, incorporating nuanced social
  behaviors directly into the simulation design.

  *   **Self-Critique for Contextual Assessment:** Techniques like **self-critique
  and self-improvement** are used during generation, where the AI Partner assesses
  its own responses against domain knowledge and appropriateness before outputting
  them, enhancing realism.


  ### 3. Business/Investment Angle

  *   **Transformative Training Market:** LLMs offer a scalable, interactive, and
  personalized solution to training skills that are traditionally time-consuming and
  expensive (e.g., conflict resolution, counseling).

  *   **Empowering Human Experts:** The technology is positioned not as a replacement
  but as a **collaborator** ("Helping the Helper"), significantly aiding senior supervisors
  and instructors by providing personalized, scalable initial feedback to novices.

  *   **Shift from "Book Smart" to "Street Smart":** Demonstrated success in improving
  interactive performance (conflict resolution) without changing underlying knowledge
  suggests a high market value for systems that bridge theoretical knowledge with
  practical application.


  ### 4. Notable Companies/People

  *   **Professor Diyi Yang (Stanford):** The central expert, leading the Social and
  Language Technologies Lab, focusing on human-centric NLP.

  *   **Souda Karajah (Stanford):** The host and interviewer, highlighting the importance
  of human elements in AI development.

  *   **Rehearsal System:** A specific implementation of the APAM framework used to
  teach conflict resolution skills, leveraging interest-based negotiation theory.

  *   **CARE System:** A system developed to help novice counselors practice empathy
  and reflection with AI patients, coached by an AI Mentor.


  ### 5. Future Implications

  The industry is moving toward **human-centric AI** where social and cultural awareness
  is integrated into model development and evaluation. Future work aims to incorporate
  deeper cultural dynamics into the APAM framework. There is also a suggestion to
  expand training into **physical or 3D spaces** to incorporate non-verbal cues (posture,
  eye contact) crucial for complete social skill mastery.


  ### 6. Target Audience

  **AI/ML Researchers** focusing on alignment, safety, and human-AI interaction; **EdTech
  Developers** looking to integrate advanced personalized training solutions; and
  **Organizational Development/HR Professionals** interested in scalable soft-skills
  training methodologies.'
tags:
- artificial-intelligence
- ai-infrastructure
- investment
- generative-ai
title: '157 - Diyi Yang: Socially Aware Large Language Models'
topics:
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 129
  prominence: 1.0
  topic: artificial intelligence
- keywords:
  - gpu
  - tensor
  - training
  - inference
  - model deployment
  - vector database
  mentions: 20
  prominence: 1.0
  topic: ai infrastructure
- keywords:
  - investment
  - funding
  - valuation
  - ipo
  - acquisition
  mentions: 6
  prominence: 0.6
  topic: investment
- keywords:
  - generative ai
  - genai
  - chatgpt
  - gpt
  - claude
  - text generation
  - image generation
  mentions: 2
  prominence: 0.2
  topic: generative ai
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-10-06 03:51:24 UTC -->
