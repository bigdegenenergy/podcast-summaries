---
companies:
- category: unknown
  confidence: medium
  context: This is the Everyday AI Show, the everyday podcast where we simplify AI
    and br
  name: Everyday AI Show
  position: 12
- category: tech
  confidence: high
  context: o-Banana. After some not so subtle hints from the Google team over the
    last two weeks, it was finally rele
  name: Google
  position: 412
- category: unknown
  confidence: medium
  context: h they just kept it as Nano-Banana, is Gemini 2.5 Flash Image. So on today's
    show, we're going to be going over
  name: Flash Image
  position: 572
- category: unknown
  confidence: medium
  context: and live demos for this impressive new model from Google Gemini. All right,
    it's time to go bananas. I told mysel
  name: Google Gemini
  position: 866
- category: unknown
  confidence: medium
  context: there. Welcome. What's going on, y'all? My name's Jordan Wilson. Welcome
    to Everyday AI. If you're new here, we d
  name: Jordan Wilson
  position: 1035
- category: unknown
  confidence: medium
  context: ng on, y'all? My name's Jordan Wilson. Welcome to Everyday AI. If you're
    new here, we do this thing every singl
  name: Everyday AI
  position: 1061
- category: tech
  confidence: high
  context: u're new here, we do this thing every single day, Monday through Friday.
    It's unedited, unscripted. I like
  name: Monday
  position: 1129
- category: unknown
  confidence: medium
  context: t are coming at us faster than bananas in the old Donkey Kong game. Another
    one. All right. So if you haven't a
  name: Donkey Kong
  position: 1437
- category: tech
  confidence: high
  context: tools. And for the most part, we kind of stick to OpenAI, Google, Microsoft,
    and Anthropic for the most pa
  name: Openai
  position: 2703
- category: tech
  confidence: high
  context: he most part, we kind of stick to OpenAI, Google, Microsoft, and Anthropic
    for the most part, right? Because
  name: Microsoft
  position: 2719
- category: tech
  confidence: high
  context: e kind of stick to OpenAI, Google, Microsoft, and Anthropic for the most
    part, right? Because I don't want to
  name: Anthropic
  position: 2734
- category: unknown
  confidence: medium
  context: icrosoft, and Anthropic for the most part, right? Because I don't want
    to go down too many rabbit holes. So a
  name: Because I
  position: 2770
- category: unknown
  confidence: medium
  context: n watch it on our YouTube channel, LinkedIn, etc. So I'm going to do my
    best for our podcast audience, b
  name: So I
  position: 3176
- category: unknown
  confidence: medium
  context: t is new. So pretty good write-up, actually, from Google DeepMind on the
    new release. Google actually does a much b
  name: Google DeepMind
  position: 3420
- category: unknown
  confidence: medium
  context: ana model was being tested by early evaluators on LM Arena. So if you don't
    know what LM Arena is, it's wher
  name: LM Arena
  position: 3786
- category: unknown
  confidence: medium
  context: ltimodal model at its core, and that's important. So Google actually has
    other image models, right? They have
  name: So Google
  position: 5060
- category: unknown
  confidence: medium
  context: thful. Nano-Banana is just fun to say. All right. So Nano-Banana, the other
    big thing is it maintains chara
  name: So Nano
  position: 6108
- category: unknown
  confidence: medium
  context: for all users, plus developers via the API inside Google AI Studio, as
    well as obviously in the front-end Gemini and
  name: Google AI Studio
  position: 6863
- category: unknown
  confidence: medium
  context: ight? That's the problem. I really did love GPT-4 Image Gen, but just because,
    I guess, you know, they're hav
  name: Image Gen
  position: 8119
- category: unknown
  confidence: medium
  context: bit from my background, right? So I've been using Adobe Photoshop, let
    me do the math here, for more than 20 years,
  name: Adobe Photoshop
  position: 9545
- category: unknown
  confidence: medium
  context: ivation and marketing agency for Nike and Jordan. And I literally, I'm
    thinking of it right now, so many
  name: And I
  position: 10264
- category: unknown
  confidence: medium
  context: eason, I don't always get the Google stuff early. Sometimes I do. But yeah,
    so I unfortunately didn't get Nano-
  name: Sometimes I
  position: 13426
- category: tech
  confidence: high
  context: ge model and not so—not inside of a platform like Midjourney or a, you
    know, Stable Diffusion, right? So that'
  name: Midjourney
  position: 14310
- category: unknown
  confidence: medium
  context: 'ide of a platform like Midjourney or a, you know, Stable Diffusion, right?
    So that''s the power: is just being able t'
  name: Stable Diffusion
  position: 14337
- category: unknown
  confidence: medium
  context: ng, all right, like I was mentioning, here is the LM Arena Elo scores.
    And I don't know the last time I saw some
  name: LM Arena Elo
  position: 14811
- category: unknown
  confidence: medium
  context: ext highest variant, but that is where Gemini 2.5 Flash Image Preview,
    aka Nano-Banana, came in over the next highest.
  name: Flash Image Preview
  position: 14967
- category: unknown
  confidence: medium
  context: verall performance on LM Arena, visual quality on Gen AI Bench, text-to-image,
    text rendering, pretty much Gemin
  name: Gen AI Bench
  position: 16225
- category: unknown
  confidence: medium
  context: more but can't really get traction to find ROI on Gen AI? Hey, this is
    Jordan Wilson, host of this very po
  name: Gen AI
  position: 17835
- category: tech
  confidence: high
  context: ery podcast. Companies like Adobe, Microsoft, and Nvidia have partnered
    with us because they trust our exp
  name: Nvidia
  position: 17935
- category: unknown
  confidence: medium
  context: o I shared on LinkedIn or something when I got to Nvidia GTC this past
    year. So, just a selfie picture of me i
  name: Nvidia GTC
  position: 18915
- category: unknown
  confidence: medium
  context: try this one out yet while I go check on Google's AI Studio. That's just
    not working, just not working right
  name: AI Studio
  position: 22910
- category: unknown
  confidence: medium
  context: e are. There we go. I thought it made sense since Logan Killpatrick from
    Google helped seemingly lead a lot of this,
  name: Logan Killpatrick
  position: 23974
- category: unknown
  confidence: medium
  context: g to be thinking for a while, do I want to do it? Do I want to hire someone
    else? Or will Nano-Banana be
  name: Do I
  position: 24319
- category: unknown
  confidence: medium
  context: do it itself? Let's see. So, pretty simple here. All I'm doing again—you
    can upload multiple photos, you
  name: All I
  position: 24438
- category: unknown
  confidence: medium
  context: ', put it on mugs, etc." Right? So, nothing crazy. But I am saying, "Make
    sure it''s 3D. Make sure it''s rea'
  name: But I
  position: 26613
- category: unknown
  confidence: medium
  context: holding up my kind of water bottle I got here, my Chicago Bears one. That's
    a ridiculously big Chicago Bears logo
  name: Chicago Bears
  position: 28108
- category: unknown
  confidence: medium
  context: t looks screen printed, though. So, that's why in Google Gemini I asked
    for it to be kind of stitched. All right. S
  name: Google Gemini I
  position: 28313
- category: unknown
  confidence: medium
  context: I did it in Gemini. I did it in Google AI Studio. And Gemini's done, y'all.
    That took—again, so fast, so fast.
  name: And Gemini
  position: 30047
- category: unknown
  confidence: medium
  context: ', right? Because I was talking about, you know, a Boston Consulting Group
    study, it pulled BCG''s. It pulled Snowflake''s log'
  name: Boston Consulting Group
  position: 33850
- category: tech
  confidence: high
  context: onsulting Group study, it pulled BCG's. It pulled Snowflake's logo. It
    put the actual stacks that I use, alth
  name: Snowflake
  position: 33908
- category: unknown
  confidence: medium
  context: on it at the top. It says, "Debunking the 95% of AI Pilot Failure Myth."
    It put the episode number. Says, "Why the study
  name: AI Pilot Failure Myth
  position: 34777
- category: big_tech
  confidence: high
  context: The company that released the new Gemini 2.5 Flash Image model (codenamed
    Nano-Banana). They are heavily involved in developing and deploying large language
    models and image generation technology.
  name: Google
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: The specific product/model family from Google being discussed, focusing
    on the new Gemini 2.5 Flash Image model.
  name: Google Gemini
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Mentioned as the source of a good write-up on the new model release, indicating
    their role in fundamental AI research at Google.
  name: Google DeepMind
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as a primary competitor whose GPT-4 Image Gen model is being
    compared against the new Google model. Also mentioned generally as one of the
    core companies they focus on.
  name: OpenAI
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Mentioned generally as one of the core companies they focus on regarding
    AI updates.
  name: Microsoft
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned generally as one of the core companies they focus on regarding
    AI updates. Also mentioned in the context of their Claude 4 model.
  name: Anthropic
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: A major software company whose stock was affected by the announcement,
    as their products (like Photoshop) are seen as being challenged by the new image
    generation capabilities.
  name: Adobe
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Google's previous image model, mentioned for comparison against Gemini
    2.5 Flash Image, noting it is still a top-rated model.
  name: Imagen 2
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: OpenAI's image generation model, used as a benchmark for comparison regarding
    speed and character consistency.
  name: GPT-4 Image Gen
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: Mentioned as a competitor to Gemini 2.5 Pro in the text-based LLM space.
  name: GPT-5
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: Mentioned as a competitor to Gemini in the text-based LLM space.
  name: Claude 4
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as an existing platform for image generation, contrasting with
    the integrated LLM approach of Gemini.
  name: Midjourney
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: Mentioned as an existing platform for image generation, contrasting with
    the integrated LLM approach of Gemini.
  name: Stable Diffusion
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: A platform used for blind, side-by-side comparison testing of AI models
    (using Elo scores) where Nano-Banana was first tested.
  name: LM Arena
  source: llm_enhanced
- category: ai_research
  confidence: medium
  context: A benchmark suite used to evaluate the visual quality of AI models.
  name: Gen AI Bench
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Google's large language model, benchmarked closely against GPT-5.
  name: Gemini 2.5 Pro
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: The specific model preview being tested for image editing capabilities
    in Google AI Studio and Google Gemini.
  name: Gemini 2.5 Flash Image
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: A free platform/tool provided by Google for interacting with and testing
    Gemini models.
  name: Google AI Studio
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as a point of comparison for image generation quality against
    the new model (Nano-Banana).
  name: GPT-4o Image
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: A company that has partnered with the podcast host's organization and whose
    GTC conference was mentioned.
  name: Nvidia
  source: llm_enhanced
- category: ai_event
  confidence: high
  context: The conference where the speaker obtained the source photo for testing.
  name: Nvidia GTC
  source: llm_enhanced
- category: ai_personnel
  confidence: high
  context: Mentioned as someone from Google who seemingly led developer relations/product
    management related to the new model.
  name: Logan Killpatrick
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: The name given to the new, high-performing image edit/generation model
    being tested.
  name: Nano-Banana
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Google's multimodal AI model, used for image generation and editing tasks.
  name: Gemini
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: Mentioned in reference to a study about AI pilots failing (MIT study).
    Likely referring to MIT CSAIL or related research groups.
  name: MIT
  source: llm_enhanced
- category: ai_media
  confidence: high
  context: The name of the speaker's podcast, which focuses on AI topics.
  name: Everyday AI
  source: llm_enhanced
date: 2025-08-27 16:00:00 +0000
duration: 48
has_transcript: false
layout: episode
llm_enhanced: true
original_url: https://pscrb.fm/rss/p/www.buzzsprout.com/2175779/episodes/17742745-ep-598-nano-banana-real-use-cases-for-google-s-new-gemini-2-5-flash-image.mp3
processing_date: 2025-10-04 20:06:25 +0000
quotes:
- length: 77
  relevance_score: 5
  text: So the biggest one, it's a multimodal model at its core, and that's important
  topics: []
- length: 201
  relevance_score: 5
  text: So, whether you're looking for ChatGPT training for thousands or just need
    help building your front-end AI strategy, you can partner with us too, just like
    some of the biggest companies in the world do
  topics: []
- length: 108
  relevance_score: 4
  text: And for the most part, we kind of stick to OpenAI, Google, Microsoft, and
    Anthropic for the most part, right
  topics: []
- length: 201
  relevance_score: 4
  text: So a lot of advanced features, but I think one of them is—well, it is a multimodal
    large language model at its core, which is extremely important when it comes to
    working and iterating with Nano-Banana
  topics: []
- length: 49
  relevance_score: 4
  text: It is a multimodal input-output powerhouse, right
  topics: []
- length: 157
  relevance_score: 4
  text: Companies like Adobe, Microsoft, and Nvidia have partnered with us because
    they trust our expertise in educating the masses around generative AI to get ahead
  topics: []
- length: 63
  relevance_score: 3
  text: I like to say it's the realest thing in artificial intelligence
  topics: []
- length: 296
  relevance_score: 3
  text: I got extremely impressive results when you iterate with it a little bit,
    but that's the—like I said—that's the—you might look at that as a con, but that's
    actually a pro of using a multimodal by default model like Google Gemini and not
    using like, you know, Imagen 2 for nothing against Imagen 2
  topics: []
- length: 206
  relevance_score: 3
  text: But it's so much different working with an image editing and image creating
    model inside of a large language model and not so—not inside of a platform like
    Midjourney or a, you know, Stable Diffusion, right
  topics: []
- length: 98
  relevance_score: 3
  text: So, not great output on that side from Google AI Studio, but at least it worked
    on the second time
  topics: []
- length: 77
  relevance_score: 3
  text: So, you can see so far, you know, a lot of times you have to reiterate, right
  topics: []
- impact_reason: Provides a crucial technical/community insight into how cutting-edge
    models are secretly benchmarked and validated before public release using the
    Elo scoring system.
  relevance_score: 10
  source: llm_enhanced
  text: Nano-Banana model was being tested by early evaluators on LM Arena. If you
    don't know what LM Arena is, it's where you get put in a prompt, and you get a
    side-by-side output. You don't know what they are. You vote for the winner, and
    that gets what it's called an Elo score.
  topic: technical/benchmarking
- impact_reason: 'Identifies the fundamental architectural advantage: being multimodal
    at its core, which enables deeper reasoning.'
  relevance_score: 10
  source: llm_enhanced
  text: So the biggest one, it's a multimodal model at its core, and that's important.
  topic: technical/architecture
- impact_reason: Illustrates the practical benefit of its world knowledge integration—understanding
    implied physics and context across sequential generations.
  relevance_score: 10
  source: llm_enhanced
  text: It has a better understanding of the world and physics, and if you're making
    a series of images, you don't have to explain a new scenario. You could say, 'Hey,
    put this basketball on Mars,' and players are probably going to start floating
    around, right? Because they're like, 'Oh, okay, well, gravity is gone.'
  topic: capability/multimodality
- impact_reason: Identifies character consistency as a major technical hurdle overcome,
    critical for narrative and branding applications.
  relevance_score: 10
  source: llm_enhanced
  text: Nano-Banana, the other big thing is it maintains character consistency, which
    is huge.
  topic: breakthrough/technical
- impact_reason: Provides a direct, high-stakes business prediction regarding the
    competitive threat posed to established creative software giants like Adobe.
  relevance_score: 10
  source: llm_enhanced
  text: Adobe, I think in this one, they have no choice. A lot of people are calling
    this a Photoshop killer. I won't go that far, but if Adobe doesn't do something,
    they're going to run into some problems.
  topic: business impact/predictions
- impact_reason: Crucial competitive pricing and speed comparison against the market
    leader (OpenAI), indicating a significant shift in API economics.
  relevance_score: 10
  source: llm_enhanced
  text: And then on the developer side, so if you're using this on the API side, it
    is extremely cheap. It is about 3.9 cents, so let's just say 4 cents per image.
    I believe that's like a quarter of the price of OpenAI's GPT-4 Image, and also
    way faster.
  topic: business/pricing/performance
- impact_reason: Provides a powerful, personal anecdote contrasting decades of professional
    manual effort with the speed of the new AI tool, emphasizing the productivity
    leap.
  relevance_score: 10
  source: llm_enhanced
  text: I've been using Adobe Photoshop, let me do the math here, for more than 20
    years... doing one of these things, right? Removing someone from a photo, changing
    something in Photoshop, right? Takes seconds now.
  topic: productivity/impact
- impact_reason: 'A major strategic insight: AI image generation democratizes creation,
    breaking down barriers for non-creatives and expanding the user base significantly.'
  relevance_score: 10
  source: llm_enhanced
  text: 'I do think the cap now is your imagination. And I do want to hit a pause
    here and say this: this is not just for creatives. I think this changes the way
    that non-creative people can actually create, and that is huge.'
  topic: strategy/democratization
- impact_reason: 'This is a core insight into the paradigm shift: integrating image
    generation/editing directly into an LLM interface allows for natural language
    instruction and iterative refinement, bypassing the complex, rigid prompting required
    by dedicated diffusion models.'
  relevance_score: 10
  source: llm_enhanced
  text: 'It''s so much different working with an image editing and image creating
    model inside of a large language model and not so—not inside of a platform like
    Midjourney or a, you know, Stable Diffusion, right? So that''s the power: is just
    being able to talk to the model with natural language and not having to speak,
    you know, prompt, you know, with these, you know, S-ref codes and, you know, all
    these, you know, adjectives throwing out of, you know, 1970s paintings.'
  topic: technical/model_architecture
- impact_reason: Provides concrete, quantitative evidence (170 Elo points lead) demonstrating
    a massive, unprecedented performance gap for Gemini 2.5 Flash in the image editing
    category, signaling a major breakthrough.
  relevance_score: 10
  source: llm_enhanced
  text: I don't know the last time I saw something come in at like 170 points above
    the next highest variant, but that is where Gemini 2.5 Flash Image Preview, aka
    Nano-Banana, came in over the next highest. And this is for image edit.
  topic: technical/benchmarks
- impact_reason: Demonstrates AI's capability for inpainting/outpainting and context
    completion—extending an existing image based on a text description.
  relevance_score: 10
  source: llm_enhanced
  text: I'm going to say, 'Make this a full-body shot of me walking around in downtown
    Chicago.' All right, I love typing live. All right, downtown Chicago. There we
    go. So, this photo is from like the shoulders up. I'm in front of a green screen.
    The rest of my body is obviously not showing. So, let's see how Nano-Banana in
    Gemini and in Google AI Studio handle this.
  topic: technical/image generation
- impact_reason: Showcases the powerful capability of multimodal models to synthesize
    long-form text (a transcript) into structured visual summaries (infographics),
    a major productivity leap.
  relevance_score: 10
  source: llm_enhanced
  text: Here's one other capability that I really like, and I think a lot of people
    could find some use for. All right, I'm just going to let it run because it might
    take a second, but all I'm doing here is I have a prompt, and I said at the very
    top of this—All right, I'll just read it out here. I said, 'This is text from
    my website, which mainly contains the transcript of a podcast episode of Everyday
    AI. Please create one detailed infographic or a series of images that accurately
    displays the main takeaway messages from the transcript. Be specific.'
  topic: technical/multimodality
- impact_reason: Demonstrates advanced visual grounding and retrieval capabilities—the
    model correctly identified and rendered specific, proprietary logos mentioned
    only in the input text.
  relevance_score: 10
  source: llm_enhanced
  text: It pulled logos, right? Because I was talking about, you know, a Boston Consulting
    Group study, it pulled BCG's. It pulled Snowflake's logo.
  topic: technical/multimodality
- impact_reason: 'Highlights the core challenge for the general audience: information
    overload and the gap between new releases and practical application.'
  relevance_score: 9
  source: llm_enhanced
  text: I think one of the hardest things when it comes to AI is number one, there
    are like 50 new things today, but number two, it's like, okay, how do we actually
    use this, right? The everyday business leaders like you and me.
  topic: business strategy
- impact_reason: Pinpoints the key capability (editing/manipulation) that drove the
    model's viral success, differentiating it from pure generation models.
  relevance_score: 9
  source: llm_enhanced
  text: So when people saw it and how good it was specifically at editing and manipulating
    images, it rightfully so kind of took over the AI internet.
  topic: breakthrough/capability
- impact_reason: A strong, definitive statement about the model's current performance
    superiority based on early testing metrics.
  relevance_score: 9
  source: llm_enhanced
  text: So it is the benchmark leader, and it's not even close.
  topic: breakthrough/performance
- impact_reason: Highlights a key operational limitation (speed/scaling) of a competitor,
    which Gemini 2.5 Flash Image appears to solve.
  relevance_score: 9
  source: llm_enhanced
  text: I really did love GPT-4 Image Gen, but just because, I guess, you know, they're
    having scaling issues, right? So I can sometimes take 30 seconds, 60 seconds,
    multiple minutes to generate an image in GPT-4 Image Gen.
  topic: performance/comparison
- impact_reason: Addresses the critical topic of AI safety and provenance (watermarking/fingerprinting)
    inherent in powerful generative models, signaling future ethical discussions.
  relevance_score: 9
  source: llm_enhanced
  text: Also, it is important to know that all outputs include AI watermarks and SynthID
    fingerprints. We'll save that for another day, another episode, because I think
    as powerful—and I'm not just talking about Nano-Banana here, I'm just saying this
    genre of AI image generating—as exciting and powerful as it is, it also can have
    a pretty dark side.
  topic: safety/ethics
- impact_reason: Lists specific, high-value editing capabilities that directly challenge
    professional workflows.
  relevance_score: 9
  source: llm_enhanced
  text: Precise object control. So being able to instantly remove people from photos,
    delete clothing stains, blur backgrounds, change poses, add color to black and
    white images using simple text commands.
  topic: capability/use case
- impact_reason: 'Defines the new multimodal workflow: LLMs for strategy/text, image
    models for creation, solidifying the concept of integrated AI workflows.'
  relevance_score: 9
  source: llm_enhanced
  text: You can strategize now with large language models like Gemini, like GPT-5,
    like Claude 4, but then you can use something like Nano-Banana and you can actually
    create things. It is a multimodal input-output powerhouse, right?
  topic: strategy/workflow
- impact_reason: Provides a concrete, high-ROI business use case (video B-roll replacement)
    that saves significant time and money for executives/small businesses.
  relevance_score: 9
  source: llm_enhanced
  text: So let's say you're the CEO of a small company, and you know, you have an
    older, you know, kind of corporate video, and it's kind of boring, and you want
    to update some of the shots. Okay, well, take a picture of yourself with your
    camera, load that into Nano-Banana. Nano-Banana, you know, go into different scenes,
    and there you go. You have new B-roll. You don't have to go out and spend 30,
    50,000 dollars and many hours hiring an expensive production crew just if you
    want to update, you know, the old training video.
  topic: business use case/cost savings
- impact_reason: 'Offers a balanced strategic view on technological disruption: destruction
    of old models alongside the creation of new platform opportunities.'
  relevance_score: 9
  source: llm_enhanced
  text: The whole 'this kills'—I think—well, 'kills,' but also creates so many opportunities.
    It's going to kill some current, you know, startups and apps out there, but it's
    also going to create so many opportunities of what you can build on top of this
    software.
  topic: strategy/disruption
- impact_reason: 'Highlights a key capability of advanced generative models: complex,
    sequential editing (multi-step editing), which is crucial for professional design
    workflows beyond simple single-shot generation.'
  relevance_score: 9
  source: llm_enhanced
  text: 'So some other things aside from character consistency: multi-step editing.
    So you can start with an empty room, then paint the walls blue, add a bookshelf,
    place a couch, etc. Great for interior, exterior design, you know, scene setting,
    etc., etc.'
  topic: technical/use_cases
- impact_reason: 'A classic observation about disruptive technology: it destroys existing
    business models while simultaneously creating new markets and opportunities for
    innovation built on the new foundation.'
  relevance_score: 9
  source: llm_enhanced
  text: The whole "this kills"—I think—well, "kills," but also creates so many opportunities.
    It's going to kill some current, you know, startups and apps out there, but it's
    also going to create so many opportunities of what you can build on top of this
    software.
  topic: business/strategy
- impact_reason: Contrasts the tight competition in traditional LLM text tasks (2-5
    points difference) with the overwhelming dominance (170 points) seen in the new
    multimodal image editing task, emphasizing the significance of the multimodal
    leap.
  relevance_score: 9
  source: llm_enhanced
  text: So, you have Gemini 2.5 Pro with a two-point lead over GPT-5, right? So pretty,
    pretty much tied, you know, there, one A and one B, which is normal. So, you know,
    two, five points, pretty big. 20 points, you're like, "Oh my gosh." 170, that
    means it is the category. There's no competition.
  topic: technical/benchmarks
- impact_reason: Reiterates the extreme performance lead in image editing, suggesting
    that multimodal integration within Gemini is currently setting a new, dominant
    standard in that specific domain.
  relevance_score: 9
  source: llm_enhanced
  text: But on the image edit side, I mean, absolutely bonkers. It is 170 points above
    the second-place model in flux one context. I don't remember the last time a model
    came in that much higher in an established category. It tells you how freaking
    good it is.
  topic: technical/benchmarks
- impact_reason: 'Provides a nuanced view on model usage: while one-shot results might
    be lacking, the true power (and advantage over single-purpose models) emerges
    through iterative, conversational refinement.'
  relevance_score: 9
  source: llm_enhanced
  text: I don't—at least for me personally yet—I haven't gotten a lot of impressive
    kind of one-shot results, right? I got extremely impressive results when you iterate
    with it a little bit, but that's the—like I said—that's the—you might look at
    that as a con, but that's actually a pro of using a multimodal by default model
    like Google Gemini...
  topic: technical/model_usage
- impact_reason: Directly compares the fidelity of identity preservation between Nano-Banana
    and a leading competitor (GPT-4o Image), suggesting superior character consistency
    in the former for personal images.
  relevance_score: 9
  source: llm_enhanced
  text: If if I did this in GPT-4o Image, it would not really look like me, right?
    I don't know last year's audience if if you watched, is this look like me? I'd
    say it pretty much does, right? So again, we have the watermark. We have a photo.
    It took the same hoodie, different pose, right, but got me looking just like me.
  topic: technical/comparison
- impact_reason: Poses a direct business/hiring question regarding the economic viability
    of using advanced AI (Nano-Banana) for creative tasks like podcast cover redesign
    versus hiring human professionals.
  relevance_score: 9
  source: llm_enhanced
  text: I'm going to be thinking for a while, do I want to do it? Do I want to hire
    someone else? Or will Nano-Banana be good enough to do it itself?
  topic: business/ROI
- impact_reason: 'Showcases a powerful marketing/merchandising application: realistic
    3D product mockups generated from a simple logo and text prompt.'
  relevance_score: 9
  source: llm_enhanced
  text: So, now what I'm doing is I'm essentially going to drop my Everyday AI logo
    in here, and I'm saying, 'Put this on a bunch of mockups, you know, t-shirts,
    put it on mugs, etc.' Right? So, nothing crazy. But I am saying, 'Make sure it's
    3D. Make sure it's realistic,' right? And put it on actual people, right?
  topic: business/practical application
- impact_reason: A direct, real-time comparison highlighting significant speed differences
    between competing AI platforms for the same task.
  relevance_score: 9
  source: llm_enhanced
  text: It's already done on Google Gemini in the 10 seconds where I was copying and
    pasting the prompt and going over to Google AI Studio. It's already done in Google
    Gemini.
  topic: technical/platform comparison
- impact_reason: Directly positions generative AI as a massive time-saver and potential
    replacement for traditional, complex creative software workflows.
  relevance_score: 9
  source: llm_enhanced
  text: So, this is where you can see how you can save a ton of time doing something
    that you might normally have to do in Adobe Photoshop, right? with a simple text
    prompt.
  topic: business/impact
- impact_reason: Another direct competitive comparison, suggesting that for specific
    tasks (like complex lighting changes while maintaining subject identity), one
    model currently outperforms another.
  relevance_score: 9
  source: llm_enhanced
  text: Google's AI Studio did a much better job converting that one to nighttime
    again, just taking a photo of myself kind of from the four arms or from my elbow
    up. Looks pretty much like me, not 100%, but much better than GPT-4o Image would
    do.
  topic: technical/platform comparison
- impact_reason: Emphasizes the need for human verification ('check for accuracy')
    even when the visual output is 'really, really good,' touching on the hallucination/factual
    risk in AI-generated summaries.
  relevance_score: 9
  source: llm_enhanced
  text: Okay, this is pretty good. So, I'll have to go through and check for accuracy,
    but this is really, really good. So, what it did is it kind of created—it looks
    like it kind of took four main takeaways, and it really deconstructed the entire—this
    is so good.
  topic: safety/accuracy
- impact_reason: Shows the model successfully extracted the core, nuanced argument
    of the podcast (debunking a specific study) and structured it visually.
  relevance_score: 9
  source: llm_enhanced
  text: 'Debunking the 95% of AI Pilot Failure Myth. It put the episode number. Says,
    ''Why the study is flawed: five major red flags.'''
  topic: technical/understanding
- impact_reason: Introduces the highly anticipated, codenamed AI model that generated
    significant viral buzz, setting the stage for the discussion.
  relevance_score: 8
  source: llm_enhanced
  text: Nano-Banana is no longer a mystery. If you follow AI at all, you've probably
    seen the very viral images making their rounds of some mystery AI image model
    called Nano-Banana.
  topic: technology trend
- impact_reason: Offers concrete evidence of the market's immediate reaction to the
    model's announcement, quantifying the perceived threat.
  relevance_score: 8
  source: llm_enhanced
  text: Adobe's stock actually took a pretty big hit yesterday when Nano-Banana was
    announced, believe it or not. That something called Nano-Banana, you know, I don't
    know how much market cap it took off Adobe, but it was a couple billion.
  topic: business impact
- impact_reason: Highlights the model's ability to handle sequential, stateful editing
    commands, which is critical for complex design tasks.
  relevance_score: 8
  source: llm_enhanced
  text: Multi-step editing. So you can start with an empty room, then paint the walls
    blue, add a bookshelf, place a couch, etc. Great for interior, exterior design,
    you know, scene setting, etc., etc.
  topic: capability/technical
- impact_reason: 'Offers practical reassurance and advice for the AI community: even
    experts struggle to find optimal workflows for brand-new technology, normalizing
    the learning curve for cutting-edge tools.'
  relevance_score: 8
  source: llm_enhanced
  text: So, a lot of times, I'm also—hey, when this is putting AI at work on Wednesdays—when
    something is brand new like this, I don't even necessarily know the best way yet,
    and unless you were developing the product at Google, most people don't. So, you
    know, if sometimes you feel like you're behind, don't worry, y'all. I do this
    every single day, and I'm still learning like everyone else.
  topic: strategy/practical_lessons
- impact_reason: 'Demonstrates advanced constraint adherence in prompting: maintaining
    specific item details (the hoodie logo) while applying stylistic changes (shot
    on iPhone) and generating multiple variations.'
  relevance_score: 8
  source: llm_enhanced
  text: So, I'm going to say, "Give me five professional headshot options, but still
    in this exact hoodie. Don't add anything new on the hoodie that's not already
    there." Make this—I'm going to say, "Make this appear it's shot on an iPhone."
  topic: use_cases/prompting
- impact_reason: Reveals a limitation (slight logo distortion) during complex multi-object
    insertion, providing a realistic view of current model failure modes even when
    core instructions (adding people in same clothes) are met.
  relevance_score: 8
  source: llm_enhanced
  text: All right. So, there we go. It added two team members. It looked—it distorted
    the logo in the hoodies slightly, but it just added kind of two more people in
    the same clothing like I told it to, and in Chicago.
  topic: technical/limitations
- impact_reason: 'Illustrates a common, practical use case for generative AI (image
    redesign) and frames the decision point for users: use AI or hire a human expert.'
  relevance_score: 8
  source: llm_enhanced
  text: I'm going to upload that image and then essentially have it redesign my podcast
    art, right? So, I'm going to be thinking for a while, do I want to do it? Do I
    want to hire someone else? Or will Nano-Banana be good enough to do it itself?
  topic: business/practical application
- impact_reason: Highlights the importance of fine-grained control over texture and
    rendering style (screen printed vs. stitched), which requires advanced prompting.
  relevance_score: 8
  source: llm_enhanced
  text: So, just iterating on the prompt. Let's see what Google AI Studio did. Google
    AI Studio did a pretty good job here... The logo just looks screen printed, though.
    So, that's why in Google Gemini I asked for it to be kind of stitched.
  topic: technical/prompt engineering
- impact_reason: 'A key strategic takeaway for any AI user: success relies on iteration
    and refinement of inputs, not just the first attempt.'
  relevance_score: 8
  source: llm_enhanced
  text: So, you can see so far, you know, a lot of times you have to reiterate, right?
    You're not going to be knocked out of the park with your first—depending on what
    you're doing, right?
  topic: strategy/workflow
- impact_reason: Touches upon the concept of 'character consistency' in generative
    models, even when the subject is a real person, and the model's tendency to alter
    physical attributes.
  relevance_score: 8
  source: llm_enhanced
  text: It made me like six foot two, which I'm here for... I'm looking for this consistency,
    right? It's weird to say character consistency when it's myself.
  topic: technical/consistency
- impact_reason: 'Sets a realistic benchmark for AI-generated design work: high quality,
    comparable to entry-level professional output, but still prone to minor errors
    (like incorrect letters).'
  relevance_score: 8
  source: llm_enhanced
  text: It looks like a professionally designed. Maybe not the highest-end designer,
    but this looks like something you might get with a junior designer if the letters
    were all correct.
  topic: business/predictions
- impact_reason: Officially reveals the true name of the model, linking the viral
    codename to the official Google product.
  relevance_score: 7
  source: llm_enhanced
  text: The real name, although I kind of wish they just kept it as Nano-Banana, is
    Gemini 2.5 Flash Image.
  topic: technology trend
- impact_reason: Provides specific, actionable details on the initial pricing and
    usage tiers, relevant for early adopters and developers.
  relevance_score: 7
  source: llm_enhanced
  text: For the most part, it's free. So right now, free users get 100 daily edits
    inside Google AI Studio, and then paid users get a thousand.
  topic: business/availability
- impact_reason: Details an advanced creative feature (texture/style transfer) with
    practical examples, showing deep creative flexibility.
  relevance_score: 7
  source: llm_enhanced
  text: Style transfers. So you can apply textures from one image to create something
    new. So, as an example, you could use a butterfly wing pattern for clothing or
    flower petals to redesign rain boots.
  topic: capability/creative
- impact_reason: Emphasizes the practical, high-value business application (professional
    headshots) enabled by the ease of natural language interaction.
  relevance_score: 7
  source: llm_enhanced
  text: So, this is what you can do. You just use natural language. You don't have
    to go in, you know, speak prompt to it. So, these are photos that in theory I
    could use as, you know, professional headshots if I wanted to, you know, update
    my LinkedIn photo.
  topic: business/use_cases
- impact_reason: Highlights the necessity of explicit instruction ('must make the
    layout design very different') when initial iterative attempts fail to produce
    the desired level of change, showing how to push the model past initial conservative
    outputs.
  relevance_score: 7
  source: llm_enhanced
  text: I'm going to say, "You must make the layout design very different." All right.
    So, I'm going to do a follow-up prompt here, see if we can get anything, because
    essentially when I ran this the first time, it worked great. Gave me some cool
    layouts.
  topic: technical/prompting
- impact_reason: Provides real-time feedback on the current state and reliability
    of specific Google AI tools (AI Studio), which is valuable for early adopters
    tracking platform stability.
  relevance_score: 7
  source: llm_enhanced
  text: Google AI Studio for whatever reason is being absolutely bonkers. At least
    it worked this time, but it didn't really change anything.
  topic: technical/platform feedback
- impact_reason: Demonstrates the importance of strong, prescriptive prompting when
    initial results are unsatisfactory, highlighting the iterative nature of prompt
    engineering.
  relevance_score: 7
  source: llm_enhanced
  text: I'm going to say, 'You must make the layout design very different.'
  topic: technical/prompt engineering
- impact_reason: Addresses the current state of visual realism in AI generation—good
    enough for casual viewing, but detectable upon close inspection.
  relevance_score: 7
  source: llm_enhanced
  text: The photos look fairly okay. They look obviously AI generated, ask, if these
    were on social media and small, you wouldn't be able to tell. I can tell.
  topic: predictions/limitations
- impact_reason: Specific example of visual fidelity failure (text rendering within
    logos) despite overall successful concept execution.
  relevance_score: 7
  source: llm_enhanced
  text: I was talking about, you know, a Boston Consulting Group study, it pulled
    BCG's. It pulled Snowflake's logo. It put the actual stacks that I use, although
    there's a couple of letters that maybe don't look like our 100% correct...
  topic: technical/limitations
- impact_reason: Reinforces the theme that AI output often requires iteration and
    persistence, even with advanced tools.
  relevance_score: 6
  source: llm_enhanced
  text: Not great output on that side from Google AI Studio, but at least it worked
    on the second time.
  topic: strategy/workflow
- impact_reason: Signals a shift from niche testing to broader, more accessible applications
    of the AI tools being demonstrated.
  relevance_score: 6
  source: llm_enhanced
  text: Here's one that I think just about everyone might be able to take advantage
    of. Again, I'm trying to find some general use cases that will be helpful for
    you all.
  topic: business/general application
- impact_reason: Illustrates the model's ability to handle high levels of ambiguity
    and abstraction when asked to summarize complex content without explicit step-by-step
    instructions.
  relevance_score: 6
  source: llm_enhanced
  text: I kind of left it up to Nano-Banana to just be like, 'Yo, okay, interesting.'
  topic: technical/model capability
source: Unknown Source
summary: '## Podcast Episode Summary: EP 598: Nano Banana! Real Use Cases for Google’s
  New Gemini 2.5 Flash Image


  This episode of the Everyday AI Show focuses entirely on the recent, highly anticipated
  release of Google''s new image generation and editing model, officially named **Gemini
  2.5 Flash Image**, but affectionately nicknamed **"Nano-Banana"** due to its codename
  during early testing on LM Arena. The host, Jordan Wilson, details the model''s
  capabilities, showcases live demos (despite some initial technical hiccups), and
  outlines practical use cases for everyday professionals.


  ### 1. Focus Area

  The primary focus is the **launch and practical application of Google''s Gemini
  2.5 Flash Image model**. The discussion centers on its superior performance in image
  editing and generation, its multimodal nature, and how it compares to existing market
  leaders like OpenAI''s GPT-4 Image Gen and Google''s own Imagen 2. The segment "AI
  at Work on Wednesdays" is dedicated to demonstrating its use for tasks like professional
  headshot creation and iterative design changes.


  ### 2. Key Technical Insights

  *   **Multimodal Core & Natural Language Understanding:** Gemini 2.5 Flash Image
  is fundamentally a multimodal LLM, allowing for much more intuitive, natural language
  interaction and iteration compared to previous image models. It demonstrates a strong
  understanding of physics and context (e.g., understanding gravity changes on Mars).

  *   **Industry-Leading Image Editing Performance:** The model achieved unprecedented
  Elo scores on LM Arena for image editing, scoring **170 points higher** than the
  next closest competitor, indicating a massive leap in human preference for its editing
  capabilities.

  *   **Character Consistency and Iterative Editing:** A major technical advantage
  is its ability to maintain character consistency across multiple generated images
  and support complex, multi-step editing workflows (e.g., painting walls, adding
  furniture) using simple text commands.


  ### 3. Business/Investment Angle

  *   **Disruption to Creative Software:** The model''s ability to perform complex
  edits (like removing people or changing lighting/composition) in seconds, tasks
  that previously took hours in tools like Photoshop, signals significant disruption.
  The host notes that Adobe’s stock took a hit upon the announcement.

  *   **Cost and Speed Advantage:** The API pricing for developers is cited as extremely
  cheap (around 4 cents per image), estimated to be a quarter of the cost of OpenAI''s
  GPT-4 Image generation, coupled with significantly faster output speeds.

  *   **Democratization of Creation:** The model breaks down barriers for non-creative
  professionals, allowing business leaders to execute on creative strategy by generating
  high-quality visuals without needing specialized design skills.


  ### 4. Notable Companies/People

  *   **Google DeepMind:** The developer of the Gemini 2.5 Flash Image model.

  *   **LM Arena:** The platform where the model was secretly tested under the "Nano-Banana"
  codename and achieved benchmark dominance.

  *   **Adobe:** Mentioned as a company whose traditional market share is threatened
  by this new capability.

  *   **Logan Killpatrick (Google):** Mentioned as a key figure from Google involved
  in the product''s development and developer relations.


  ### 5. Future Implications

  The conversation suggests the industry is moving rapidly toward **truly multimodal,
  context-aware AI systems** where text, image, and potentially video generation/editing
  are seamlessly integrated within a single LLM interface. The focus shifts from simple
  text-to-image generation to complex, iterative *editing* and *manipulation* driven
  by natural conversation. The host also briefly touches on the need for future discussions
  regarding watermarking and SynthID fingerprints due to the potential "dark side"
  of such powerful generation tools.


  ### 6. Target Audience

  This episode is highly valuable for **AI Professionals, Product Managers, Marketing/Creative
  Directors, and Business Leaders** who need to stay current on cutting-edge AI releases
  and understand how new models can immediately impact workflow efficiency, cost structures,
  and creative output within their organizations.'
tags:
- artificial-intelligence
- generative-ai
- ai-infrastructure
- startup
- google
- openai
- microsoft
- anthropic
title: 'EP 598: Nano Banana! Real Use cases for Google’s new Gemini 2.5 Flash Image'
topics:
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 125
  prominence: 1.0
  topic: artificial intelligence
- keywords:
  - generative ai
  - genai
  - chatgpt
  - gpt
  - claude
  - text generation
  - image generation
  mentions: 12
  prominence: 1.0
  topic: generative ai
- keywords:
  - gpu
  - tensor
  - training
  - inference
  - model deployment
  - vector database
  mentions: 2
  prominence: 0.2
  topic: ai infrastructure
- keywords:
  - startup
  - entrepreneur
  - founder
  - venture
  mentions: 1
  prominence: 0.1
  topic: startup
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-10-04 20:06:25 UTC -->
