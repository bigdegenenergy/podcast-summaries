---
companies:
- category: unknown
  confidence: medium
  context: in our daily lives. I co-founded a company called Physical Intelligence.
    I was trying to solve this problem. And in parti
  name: Physical Intelligence
  position: 962
- category: unknown
  confidence: medium
  context: what we did is we started simple. We started with Kenna Robot Fold, a single
    size, single branch shirt, and Kenna Ro
  name: Kenna Robot Fold
  position: 5958
- category: unknown
  confidence: medium
  context: bot Fold, a single size, single branch shirt, and Kenna Robot dynamically
    flattened one shirt, again, single br
  name: Kenna Robot
  position: 6016
- category: unknown
  confidence: medium
  context: hael is going to continue messing with the robot. So Michael unfolds one
    side and the robot reacts. Michael go
  name: So Michael
  position: 14754
- category: unknown
  confidence: medium
  context: data. And we collected robot data in homes across San Francisco here and
    also collected data in diverse mock kitc
  name: San Francisco
  position: 18972
- category: unknown
  confidence: medium
  context: ll as web data and high-level instructional data. And I should point out
    here that the mobile manipulatio
  name: And I
  position: 19603
- category: tech
  confidence: high
  context: we have the diffusion head, we'll be stopping the gradient from the randomly
    initialized diffusion head to p
  name: Gradient
  position: 21694
- category: unknown
  confidence: medium
  context: pill and eventually put the sponge into the sink. So I was able to do this
    for the bedroom. So Laura ask
  name: So I
  position: 23008
- category: unknown
  confidence: medium
  context: e sink. So I was able to do this for the bedroom. So Laura asked it, in
    this case, just clean the bedroom. A
  name: So Laura
  position: 23050
- category: unknown
  confidence: medium
  context: tidying the blanket or the comforter of the bed. APPLAUSE YC's next batch
    is now taking applications. Gotta st
  name: APPLAUSE YC
  position: 23300
- category: unknown
  confidence: medium
  context: hat's not in the basket." Right after I had put a Kit Kat into the basket
    and the robot says, "Sure, let me
  name: Kit Kat
  position: 30155
- category: unknown
  confidence: medium
  context: he open roles on the PI.website as well. Awesome. APPLAUSE I'd be happy
    to take some questions. Let's start on
  name: APPLAUSE I
  position: 32470
- category: tech
  confidence: high
  context: mple, also in your experiments, or it's also what OpenAI and then for other
    start doing right now with the
  name: Openai
  position: 38673
- category: unknown
  confidence: medium
  context: successfully. Thank you. Hi, Chelsea. My name is Charo Thomas. First off,
    really appreciate the talk. It was re
  name: Charo Thomas
  position: 40049
- category: tech
  confidence: high
  context: fascinating and been a big fan of your work since meta learning. When you
    think about how software and h
  name: Meta
  position: 40166
- category: ai_startup
  confidence: high
  context: The company co-founded by the speaker, focused on developing a general-purpose
    foundation model for robotics to enable robots to perform any task in any environment.
  name: Physical Intelligence
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: A specific, simplified task (folding a single shirt) used as an initial
    benchmark and training step for the robot policy.
  name: Kenna Robot Fold
  source: llm_enhanced
- category: ai_model/software
  confidence: high
  context: An open-source, 3-billion parameter vision-language model used as the base
    for pre-training the robot control policy.
  name: Polyjama
  source: llm_enhanced
- category: investment_accelerator
  confidence: high
  context: Mentioned as an accelerator whose next batch is taking applications.
  name: YC (Y Combinator)
  source: llm_enhanced
- category: ai_technology_type
  confidence: high
  context: Used to generate synthetic data and hypothetical prompts to augment robot
    training data.
  name: Language Models
  source: llm_enhanced
- category: ai_technology_type
  confidence: high
  context: The backbone model whose inherent knowledge is preserved during the fine-tuning
    process to improve language following.
  name: Vision-Language Models (VLM)
  source: llm_enhanced
- category: ai_technology_type
  confidence: high
  context: Existing foundation models that were evaluated and found to struggle with
    visual understanding for robotics tasks.
  name: Frontier Models
  source: llm_enhanced
- category: ai_application/startup
  confidence: high
  context: The organization presenting the research, focused on physical intelligence
    for robots, and currently hiring.
  name: Physical Intelligence (PI)
  source: llm_enhanced
- category: big_tech/ai_developer
  confidence: high
  context: Mentioned in the context of large language models (LLMs) where larger model
    sizes generally lead to better accuracy.
  name: OpenAI
  source: llm_enhanced
- category: big_tech/ai_research
  confidence: medium
  context: Referenced indirectly when the questioner states they have been a 'big
    fan of your work since meta learning,' strongly suggesting a connection to Meta
    AI research.
  name: Meta
  source: llm_enhanced
date: 2025-07-22 14:00:00 +0000
duration: 45
has_transcript: false
insights:
- actionable: true
  confidence: medium
  extracted: have in years to come
  text: we should have in years to come.
  type: recommendation
- actionable: true
  confidence: medium
  extracted: be doing control in end-effector space rather than in joint space of
    the robot
  text: we should be doing control in end-effector space rather than in joint space
    of the robot.
  type: recommendation
- actionable: true
  confidence: medium
  extracted: collect diverse data
  text: we should collect diverse data.
  type: recommendation
layout: episode
llm_enhanced: true
original_url: https://anchor.fm/s/8c1524bc/podcast/play/105822070/https%3A%2F%2Fd3ctxlq1ktw2nl.cloudfront.net%2Fstaging%2F2025-6-22%2F404323267-44100-2-4d7b34710d58e.mp3
processing_date: 2025-10-05 00:24:33 +0000
quotes:
- length: 118
  relevance_score: 5
  text: So the first thing is you mentioned that in post-training, the most important
    part is to have high-quality action data
  topics: []
- length: 65
  relevance_score: 4
  text: Kind of we were pre-training and fine-tuning only on laundry data
  topics: []
- length: 242
  relevance_score: 4
  text: So we compared this pre-training and post-training recipe to not using any
    pre-training and only training on the curated data set versus no post-training
    where you're training on all of the data rather than fine-tuning on the curated
    data set
  topics: []
- length: 87
  relevance_score: 4
  text: You can actually leverage pre-training across multiple robots and across multiple
    tasks
  topics: []
- length: 192
  relevance_score: 4
  text: Now you might also wonder, maybe some existing foundation models can serve
    as a high-level planner for robots and do the sort of high-level reasoning without
    actually training a separate model
  topics: []
- length: 130
  relevance_score: 4
  text: And then also thinking about large-scale machine learning infrastructure,
    training large models, and justing large amounts of data
  topics: []
- length: 174
  relevance_score: 4
  text: When you think about how software and hardware are going to continue to evolve,
    what are the biggest opportunities for builders today for your vision of physical
    intelligence
  topics: []
- length: 79
  relevance_score: 3
  text: You have to do all of that from scratch if you want to solve a robotics problem
  topics: []
- length: 209
  relevance_score: 3
  text: And essentially, this is the problem of trying to develop these sorts of foundation
    models and bring this sort of intelligence into the physical world rather than
    the digital world where they largely are today
  topics: []
- length: 119
  relevance_score: 3
  text: And so one possible conclusion would be that perhaps scale is the most important
    ingredient for developing these models
  topics: []
- length: 196
  relevance_score: 3
  text: But it's really, really hard because you have to deal with the variability
    in the clothes and the way in which they might be positioned and crumpled and
    be able to handle all those sorts of things
  topics: []
- length: 59
  relevance_score: 3
  text: And you have to be able to recover from even small mistakes
  topics: []
- length: 222
  relevance_score: 3
  text: So I think what we're seeing right now is that in general larger model sizes
    lead to better accuracy, for example, also in your experiments, or it's also what
    OpenAI and then for other start doing right now with their LLMs
  topics: []
- impact_reason: 'This is the core thesis of the work: moving from specialized robots
    to general-purpose foundation models for robotics, mirroring LLM success.'
  relevance_score: 10
  source: llm_enhanced
  text: we're trying to develop a general-purpose model that can enable any robot
    to do any task in any environment.
  topic: predictions
- impact_reason: Directly draws the analogy between foundation models in NLP/Vision
    and the potential for foundation models in robotics, suggesting a paradigm shift.
  relevance_score: 10
  source: llm_enhanced
  text: we think that this sort of generalist model may work better and be easier
    to use than purpose-built models, just like we've seen in the development of foundation
    models for language and other applications.
  topic: strategy
- impact_reason: 'The key breakthrough: applying the pre-train/fine-tune paradigm
    (standard in NLP/Vision) to robotics, using a high-quality, task-specific dataset
    for the final tuning stage.'
  relevance_score: 10
  source: llm_enhanced
  text: we found one thing that really seemed to make a difference in the robot's
    ability to do the task. And this was actually to take some inspiration from the
    world of language modeling to actually, instead of just training a policy on all
    of our data, we pre-trained on all the data and then fine-tuned on a highly uncurated,
    consistent, high-quality set of demonstration data.
  topic: technical
- impact_reason: Direct evidence of zero-shot generalization to novel object categories
    (V-neck shirts) based on learned underlying principles, a key goal in robust AI.
  relevance_score: 10
  source: llm_enhanced
  text: And then as I mentioned, it also is able to handle unseen clothing items.
    So here's an example of a shirt with a V-neck that is able to fold even though
    the post-trained data set didn't have, well, this shirt was completely held out.
    And the post-trained data set didn't have any V-necks as input in the data set.
  topic: AI/ML Application (Robotics)
- impact_reason: Provides quantitative validation for a specific, highly effective
    training methodology (Pre-training + Curated Post-training) over simpler alternatives,
    offering direct business/engineering advice.
  relevance_score: 10
  source: llm_enhanced
  text: We compared this pre-training and post-training recipe to not using any pre-training
    and only training on the curated data set versus no post-training where you're
    training on all of the data rather than fine-tuning on the curated data set. And
    we evaluated these models in terms of their progress on the task... And we see
    that the pre-training and post-training recipe is able to get far higher performance
    than omitting pre-training and omitting post-training.
  topic: Business/Technical Strategy (Training)
- impact_reason: 'This is the core argument for foundation models in robotics: knowledge
    transfer and task generalization without retraining from scratch, significantly
    lowering the barrier to deploying new skills.'
  relevance_score: 10
  source: llm_enhanced
  text: nothing in this recipe is specific to laundry. And so we took the same recipe
    and fine-tuned on other tasks. So here the task is to kind of clean up a table.
    And the robot is also able to successfully do this task... This is pointing at
    this kind of the benefit of foundation models that I alluded to before, which
    is that to do these different tasks, you don't have to start completely from scratch.
    You can actually leverage pre-training across multiple robots and across multiple
    tasks.
  topic: AI/ML Trends (Foundation Models)
- impact_reason: 'Powerful demonstration of the leverage provided by foundation models:
    a tiny fraction of task-specific data can unlock new capabilities when combined
    with a massive, diverse general foundation.'
  relevance_score: 10
  source: llm_enhanced
  text: mobile manipulation data of tidying bedrooms and kitchens only accounted for
    2.4% of the overall pre-training mix. And so the lesson here is that you were
    basically able to spin up a new task and actually an entirely new robot... without
    redoing all of the data collection. We're able to build upon everything that had
    been done before.
  topic: AI/ML Trends (Foundation Models)
- impact_reason: 'A key technical insight: the initialization strategy of the final
    action head can catastrophically interfere with the frozen, powerful backbone
    (VLM). This explains a failure mode and leads to a specific solution.'
  relevance_score: 10
  source: llm_enhanced
  text: what we did is with this pi-zero architecture, this action head that's using
    diffusion is randomly initialized. And this ends up actually deteriorating the
    pre-trained knowledge that's present in the vision-language model. And we found
    that if we can prevent this deterioration, we might be able to get better language
    following.
  topic: Technical Insight (Model Architecture)
- impact_reason: Describes a novel, effective technique (gradient stopping/freezing
    on the action head) to preserve the VLM's inherent capabilities while training
    the new output layer, leading to massive performance gains in language following
    (80% vs 20%).
  relevance_score: 10
  source: llm_enhanced
  text: we're going to be predicting tokenized actions. And then when we have the
    diffusion head, we'll be stopping the gradient from the randomly initialized diffusion
    head to prevent it from deteriorating the language-following abilities of the
    VLM backbone.
  topic: Technical Breakthrough
- impact_reason: 'The ultimate proof point: successful deployment in completely novel,
    real-world, unstructured environments (unseen homes), validating the entire data
    diversity and training strategy.'
  relevance_score: 10
  source: llm_enhanced
  text: We rented three AirBnBs that we had never been to before... The robot's able
    to succeed, even though it's never been to here before. There's different countertops,
    different furniture, different objects, and so forth.
  topic: AI/ML Application (Deployment Success)
- impact_reason: 'Highlights a novel and scalable method for data augmentation: using
    LLMs to generate synthetic, diverse language prompts conditioned on existing robot
    action sequences, overcoming the data collection bottleneck for language grounding.'
  relevance_score: 10
  source: llm_enhanced
  text: And so what we did is we kind of took all of our existing robot data and we
    can actually generate synthetic data for the existing robot data. And particularly
    we can use language models to relabel and generate hypothetical human prompts
    for the scenarios that the robots are in.
  topic: technical/training/business advice
- impact_reason: Crucial demonstration of real-time, situated reasoning and correction
    based on dynamic user input, moving beyond pre-scripted plans.
  relevance_score: 10
  source: llm_enhanced
  text: And then lastly, it's able to handle interjections and situated corrections.
    So in this case, the robot is kind of getting items for a user. The user interjects
    and says, "Get me something sweet that's not in the basket." Right after I had
    put a Kit Kat into the basket and the robot says, "Sure, let me get you some Skittles,"
    and reasons through kind of basic reasoning of how to fulfill the user's request
    and is able to respond to those kinds of corrections situated in the world that
    the robot is at.
  topic: breakthroughs/safety/predictions
- impact_reason: Directly compares specialized VLA systems against general frontier
    LLMs for robotics tasks, concluding that general models lack the necessary visual
    grounding for physical interaction.
  relevance_score: 10
  source: llm_enhanced
  text: And we found that in blue, the performance at following instructions and making
    progress on the task was substantially lower than the performance of our system
    which is shown in green. And in general, we found that these frontier models generally
    struggle with visual understanding as it pertains to robotics, which makes sense
    because in general, these models aren't really targeting many physical applications
    and have very little data in the physical world.
  topic: limitations/technical/strategy
- impact_reason: Describes a specific, promising architectural approach for improving
    VLA performance by predicting intermediate visual states (subgoals) rather than
    just the final action.
  relevance_score: 10
  source: llm_enhanced
  text: instead of only predicting the next action, you predict the intermediate subgoal
    image, like what should happen in the future in order to accomplish the task,
    and then predict an action from there.
  topic: technical
- impact_reason: 'Highlights a critical limitation/failure mode of world models: hallucination
    when evaluated on suboptimal or out-of-distribution actions, posing a significant
    safety/reliability challenge.'
  relevance_score: 10
  source: llm_enhanced
  text: the world model will hallucinate a video of completing the task successfully,
    even if the actions that you provided as input didn't, weren't actually going
    to successfully lead to a good outcome.
  topic: safety/limitations
- impact_reason: Highlights the massive fragmentation and high barrier to entry in
    robotics due to application-specific solutions, setting up the need for a general-purpose
    approach.
  relevance_score: 9
  source: llm_enhanced
  text: if you want to truly solve a robotics application, you essentially need to
    build an entire company around that application. You need to build a different
    company for logistics, for wet lab automation, for robots in kitchens, for surgical
    robots, and so on.
  topic: business
- impact_reason: 'A crucial strategic insight for AI development: scale is important,
    but data quality, diversity, and task relevance (solving the problem) are paramount,
    especially in embodied AI.'
  relevance_score: 9
  source: llm_enhanced
  text: the lesson here is that scale is necessary for developing these models that
    can generalize in open-world conditions, but they're subordinate to actually solving
    the problem. So you need scale, but it's not sufficient for the entire problem.
  topic: strategy
- impact_reason: Sets a high bar for success in general-purpose robotics, emphasizing
    the difficulty of long-horizon, dexterous manipulation tasks in unstructured environments.
  relevance_score: 9
  source: llm_enhanced
  text: to unload a dryer and fold laundry. And to date, I think this is the most
    impressive thing that I've seen a robot do in the physical world.
  topic: predictions
- impact_reason: Shows the transition from smaller, task-specific models (100-300M)
    to leveraging much larger, general-purpose foundation models (3B parameters) in
    robotics, mirroring the trend in other AI fields.
  relevance_score: 9
  source: llm_enhanced
  text: We took an open-source vision-language model, a 3-billion parameter model
    called Polyjama. Previously, we were using, previous reviews, we're all with like
    100 to 300 million parameters that we're iterating on.
  topic: technical
- impact_reason: Demonstrates the immediate, tangible benefit of transferring knowledge
    from a larger, general robot foundation model (pre-trained on diverse robot data)
    to a specific task (laundry).
  relevance_score: 9
  source: llm_enhanced
  text: When we did this, we actually saw the robot continue to actually get better
    when we just plugged in that new pre-trained model. In the left video, it's able
    to do five items in nine minutes, which was faster than the 12 minutes we had
    before.
  topic: technical
- impact_reason: 'Highlights a crucial advantage of modern, vision-based neural policies
    over traditional, pre-scripted robotic control: inherent robustness and reactivity
    to dynamic changes in the environment.'
  relevance_score: 9
  source: llm_enhanced
  text: because this policy is a neural network and it's taking as input the current
    image, it's able to handle interruptions.
  topic: Technical Insight/AI Advantage
- impact_reason: 'A critical finding: simply dumping all available data (even diverse
    data) is suboptimal for complex tasks; strategic curation (post-training) combined
    with broad pre-training is superior.'
  relevance_score: 9
  source: llm_enhanced
  text: We were able to independently develop post-training and pre-training and decouple
    the problem. And then eventually get the best of both. We found that training
    on all the data doesn't work for complex tasks. And this sort of pre-training
    and post-training on curated data, these two far better performance.
  topic: Technical Strategy/Best Practices
- impact_reason: Directly applies lessons from computer vision/NLP regarding data
    diversity to solve the robotics generalization problem, emphasizing scale and
    variety over single-environment optimization.
  relevance_score: 9
  source: llm_enhanced
  text: The lesson we've learned from machine learning in other places is that we
    should collect diverse data. And so we started by collecting data of tidying bedrooms
    and kitchens in many different environments... And in total, we had more than
    100 unique rooms represented in the data set.
  topic: Strategy/Data Collection
- impact_reason: 'Pinpoints a common failure mode when integrating vision and language
    models: the model defaults to visual priors or learned behaviors over explicit,
    potentially conflicting, language commands.'
  relevance_score: 9
  source: llm_enhanced
  text: naively these models can ignore language instructions. So we actually, in
    this case, asked it to pick up the cutting board and it chose to pick up the plate
    instead.
  topic: AI/ML Limitations (VLM)
- impact_reason: Quantifies the success of closing the generalization gap. Diverse
    data collection, not just more data from the target environment, is the key to
    achieving parity with in-domain performance.
  relevance_score: 9
  source: llm_enhanced
  text: We find that if we actually increase the amount of homes, the amount of locations
    that are represented in the data, the performance increases, which is great. And
    it actually gets to the same level of performance as if we train on data from
    that target environment. And so it means we're actually mostly closing the generalization
    gap.
  topic: Technical/Strategy Validation
- impact_reason: 'Summarizes the major achievement: achieving generalization across
    unseen environments through diverse pre-training, a crucial step toward real-world
    deployment.'
  relevance_score: 9
  source: llm_enhanced
  text: The takeaway here is that with diverse data, robots can follow a variety of
    instructions in environments that the robot has never been in before, which is
    a big step up from a lot of robotic scenarios where they're trained in the scenarios
    that they are being tested.
  topic: breakthroughs/strategy
- impact_reason: 'Frames the next major research direction: extending the LLM paradigm
    of open-ended prompting to physical control and robotics.'
  relevance_score: 9
  source: llm_enhanced
  text: And so just like we prompt language models, can we allow robots to respond
    to open-ended prompts and open-ended interjections?
  topic: AI technology trends/predictions
- impact_reason: Describes the core architectural solution (Hierarchical VLA) for
    handling complex, open-ended language instructions by decomposing them into manageable
    sub-tasks.
  relevance_score: 9
  source: llm_enhanced
  text: We're actually leveraging hierarchical vision-language action models. We're
    going to have a high-level policy break down the prompt into intermediate verbal
    responses and intermediate atomic language commands.
  topic: technical/model architectures
- impact_reason: Shows the model's ability to handle complex constraints (veganism,
    exclusion of specific ingredients) within the planning process, indicating advanced
    semantic understanding.
  relevance_score: 9
  source: llm_enhanced
  text: I can also follow more complicated prompts like, "Hi robot, can you make me
    a vegan sandwich? I don't like pickles though."
  topic: breakthroughs/technical
- impact_reason: 'Provides a nuanced view on data: large-scale real-world data is
    essential but insufficient alone for achieving robust physical intelligence, implying
    architectural or algorithmic breakthroughs are also needed.'
  relevance_score: 9
  source: llm_enhanced
  text: We also saw that large-scale data in the real world is really helpful for
    developing these things. And we found that, and I think that it's necessary, but
    not sufficient for physical intelligence.
  topic: strategy/technical
- impact_reason: Advocates for the integration of Reinforcement Learning (RL) in post-training
    to leverage online data, suggesting RL is key to surpassing the performance ceiling
    of pure imitation learning.
  relevance_score: 9
  source: llm_enhanced
  text: I think that online data from the robots, which reinforcement learning allows
    you to use, can allow robots to have a much higher success rate and also be faster
    than if they're just trained with imitation learning.
  topic: technical/training
- impact_reason: 'Details a critical failure mode of World Models: hallucination when
    evaluating suboptimal actions, posing a significant challenge for using them reliably
    for planning or safety checks.'
  relevance_score: 9
  source: llm_enhanced
  text: You might try to, on demonstration data of successful data of completing the
    task, and then evaluate it on to try to actually use it to evaluate actions that
    are not optimally completing the task. And then the world model will hallucinate
    a video of completing the task successfully, even if the actions that you provided
    as input didn't, weren't actually going to successfully lead to a good outcome.
  topic: limitations/safety
- impact_reason: Suggests a viable path for integrating world models (predictive simulation)
    directly into VLA systems, moving beyond simple next-action prediction.
  relevance_score: 9
  source: llm_enhanced
  text: there's actually fairly natural ways to incorporate world model objectives
    into vision-language action models.
  topic: technical
- impact_reason: Emphasizes the crucial, often overlooked, engineering challenge of
    real-time, low-latency inference infrastructure directly on physical hardware
    (robots) for successful deployment.
  relevance_score: 9
  source: llm_enhanced
  text: thinking about fast inference and infrastructure for that's actually going
    to be on the robot is a big part of what our software team does.
  topic: business/deployment
- impact_reason: 'Provides practical insight into the difficulty of designing effective
    Retrieval-Augmented Generation (RAG) or retrieval-based systems: defining the
    boundary between model computation and external knowledge retrieval.'
  relevance_score: 9
  source: llm_enhanced
  text: in my experience working on retrieval-based systems is that it actually is
    a little bit tricky to first figure out what should be offloaded versus actually
    done by the model.
  topic: technical/strategy
- impact_reason: Identifies a key failure mode in retrieval systems where the model
    fails to condition properly on external information, a common challenge in RAG
    architectures.
  relevance_score: 9
  source: llm_enhanced
  text: sometimes the model will ignore the retrieved content and try to generate
    something itself.
  topic: technical/limitations
- impact_reason: 'Identifies a major, underserved engineering opportunity in the physical
    intelligence space: creating robust, optimized, and potentially open-source infrastructure
    specifically for running complex AI models on robots.'
  relevance_score: 9
  source: llm_enhanced
  text: thinking about better ways of having infrastructure on the robot side. I think
    that there isn't a lot of like, there's some open-source code for that sort of
    thing, but there's a lot of opportunities to make robot infrastructure better.
  topic: business/opportunity
- impact_reason: Explains the limitation of current large-scale robotics datasets
    (lack of behavioral diversity) compared to the requirements for general intelligence.
  relevance_score: 8
  source: llm_enhanced
  text: we might look at data from industrial automation. And you get tons and tons
    of data of robots doing tasks over and over again, like this. But the sort of
    data isn't going to allow robots to go into disaster zones or to make a sandwich
    or to bag groceries.
  topic: technical
- impact_reason: Articulates the embodiment gap and the challenge of learning complex
    motor skills from passive observation data (like YouTube videos).
  relevance_score: 8
  source: llm_enhanced
  text: we don't learn how to write by watching other people write. And we don't become
    expert tennis players by watching Wimbledon. And so even though there's a massive
    scale of data here, it's very challenging to use.
  topic: safety
- impact_reason: Details the specific challenges of real-world variability (clutter,
    deformation) that current AI/robotics systems must overcome, contrasting with
    clean simulation environments.
  relevance_score: 8
  source: llm_enhanced
  text: It's really hard. It's an incredibly difficult problem. You can see that it's
    not perfect. Here it is making some miscrops, making some mistakes. But it's really,
    really hard because you have to deal with the variability in the clothes and the
    way in which they might be positioned and crumpled and be able to handle all those
    sorts of things.
  topic: technical
- impact_reason: Provides a comprehensive list of common architectural/training hypotheses
    (memory, control space, calibration, data conditioning) that researchers often
    test when facing hard problems.
  relevance_score: 8
  source: llm_enhanced
  text: We thought that maybe the robot needs memory, needs history in some way. Maybe
    we need to just train our models for longer. Maybe we should be doing control
    in end-effector space rather than in joint space of the robot. Maybe our encoders,
    we knew that there were calibration issues. Maybe we need to condition the model
    on more information about the data. Maybe we need to introduce interventions in
    data collection. A lot of these things we also tried. We had around two to three
    months of failure, where nothing was really working at addressing this task.
  topic: technical
- impact_reason: 'Provides a high-level technical overview of a modern embodied AI
    architecture: VLM backbone + diffusion/flow matching for multi-step, continuous
    action prediction.'
  relevance_score: 8
  source: llm_enhanced
  text: This model takes the input images from the robot, also a language command,
    and then has a head, a diffusion head that's going to attend to all the internal
    values of the vision-language model. With the joint angles, predict a chunk of
    50 actions into the future. So about one second of action steps.
  topic: technical
- impact_reason: Provides evidence of generalization to novel objects and complex,
    non-obvious manipulation strategies learned implicitly by the foundation model.
  relevance_score: 8
  source: llm_enhanced
  text: Here's a pair of shorts that the robot hasn't seen before. And this is kind
    of a tricky scenario where to flatten it, it actually kind of needs to reach under
    the bottom of the shorts. And it's able to do that.
  topic: predictions
- impact_reason: Identifies the critical challenge of Sim-to-Real and environment
    shift in robotics, setting the stage for the subsequent discussion on data diversity.
  relevance_score: 8
  source: llm_enhanced
  text: One limitation I'd like to point out is that these robots inevitably, in this
    case, were trained in the environments that they were tested. And so this means
    that in principle, you could use these methods to collect a lot of data in one
    environment and then deploy them in one environment. But ultimately, there's going
    to be things that change about an environment.
  topic: AI/ML Limitations (Generalization)
- impact_reason: Provides a sober assessment of current limitations. Even with major
    breakthroughs, reliability is not yet perfect (80% success), highlighting the
    remaining engineering challenge for real-world deployment.
  relevance_score: 8
  source: llm_enhanced
  text: Now, I should also mention that those failure modes, like the success rate
    was around 80%. There's lots of room for improvement.
  topic: AI/ML Limitations/Future Work
- impact_reason: 'Identifies the current primary bottleneck in robotics generalization:
    moving beyond data collection to improving the robustness and success rate of
    execution, even when generalization is achieved.'
  relevance_score: 8
  source: llm_enhanced
  text: And so just that the bottlenecks at this point for this sort of task lie not
    in collecting more diverse data, but in actually getting higher reliability and
    higher performance.
  topic: strategy/limitations
- impact_reason: Illustrates the difficulty of handling objects with challenging physical
    properties (thinness, low friction/adhesion) even when the general task (putting
    dishes in the sink) is understood.
  relevance_score: 8
  source: llm_enhanced
  text: Here we opted to put the dishes in the sink and it successfully is able to
    put a number of the dishes in the sink, but it struggles to pick up the cutting
    board in this particular case, because it's very thin and it's flush against the
    surface of the countertop.
  topic: limitations/technical
- impact_reason: A humorous but critical example of visual misclassification and poor
    affordance understanding, showing that object recognition alone is insufficient
    for safe/correct action selection.
  relevance_score: 8
  source: llm_enhanced
  text: And in the last case, probably my favorite case is told to put the spatula
    into a drawer and it decides that the oven looks a lot like a drawer.
  topic: limitations/safety
- impact_reason: Demonstrates successful language grounding and task planning, showing
    the robot can verbally articulate its plan before execution.
  relevance_score: 8
  source: llm_enhanced
  text: And as a result of this, we're able to actually allow robots to follow a variety
    of different prompts. So on the left we ask, "Hi robot, can you make me a ham
    and cheese sandwich?" The robot says, "Sure, I'll start with the bread and add
    ham and cheese next."
  topic: breakthroughs/predictions
- impact_reason: 'Offers a business/funding perspective: the field is reaching an
    inflection point where tangible results are emerging, leading to increased investor
    excitement after a long period of slow progress.'
  relevance_score: 8
  source: llm_enhanced
  text: I think that there's actually a lot of excitement around this sort of technology
    because I think things are actually starting to work. I started working on this
    technology more than 10 years ago at this point, and things really weren't working
    then.
  topic: business/predictions
- impact_reason: Describes a promising architectural integration of World Models (predicting
    future states/subgoal images) within the VLA framework, suggesting a path toward
    better planning.
  relevance_score: 8
  source: llm_enhanced
  text: We've done some work where, instead of only predicting the next action, you
    predict the intermediate subgoal image, like what should happen in the future
    in order to accomplish the task, and then predict an action from there. And we've
    seen some kind of signs of life that that seems to be quite promising.
  topic: technical/model architectures
- impact_reason: Points to the complexity and unique structure of real-world robotics
    data (multimodality) that standard ML pipelines must adapt to, contrasting it
    with typical text/image datasets.
  relevance_score: 8
  source: llm_enhanced
  text: The data that we have is different from a lot of typical data sets, because
    it's very multimodal in nature. It's videos, actions, language segments, and various
    other components as well.
  topic: technical/data
- impact_reason: Stresses that retrieval alone is insufficient; the core model must
    possess the necessary reasoning capacity to interpret and utilize the retrieved
    context effectively.
  relevance_score: 8
  source: llm_enhanced
  text: even the model part of it will need to have some degree of intelligence in
    order to like actually make use of the retrieved information and so forth.
  topic: technical/strategy
- impact_reason: 'Quantifies the operational requirement for robotics AI: achieving
    a specific, high frequency of action execution, which directly translates to latency
    requirements for inference.'
  relevance_score: 8
  source: llm_enhanced
  text: we have a real-time system that these actually be hitting a certain frequency
    to actually execute action successfully.
  topic: deployment
- impact_reason: 'Reiterates the core difficulty in hybrid AI systems: defining the
    optimal split of responsibility between the learned model and external knowledge
    sources.'
  relevance_score: 8
  source: llm_enhanced
  text: it ends up being quite tricky to figure out what the division of labor is
    [in retrieval systems].
  topic: technical
- impact_reason: 'Provides a practical, incremental development lesson: simplify the
    task domain before scaling complexity, a key strategy in building complex AI systems.'
  relevance_score: 7
  source: llm_enhanced
  text: We started simple. We started with Kenna Robot Fold, a single size, single
    branch shirt, and Kenna Robot dynamically flattened one shirt, again, single brand,
    single size. And if you start simple, this makes the problem quite a bit easier.
  topic: business
- impact_reason: Offers concrete technical specifications (model size, control frequency)
    for an early, successful imitation learning policy in robotics.
  relevance_score: 7
  source: llm_enhanced
  text: We had around 100 million parameters, mapping from images, from the robot's
    cameras, to target joint positions on the robot arms. And we do this source of
    control at 50 hertz on the robot.
  topic: technical
- impact_reason: Illustrates the gap between initial capability (signs of life) and
    real-world utility (speed/patience), emphasizing the need for efficiency improvements
    beyond mere success rate.
  relevance_score: 7
  source: llm_enhanced
  text: We had some initial signs of life in late June of last year. And so in this
    case, the robot was able to kind of make progress on flattening the shirt. It's
    also then able to fold the shirt decently well from that initial state, still
    not perfect. And as you can see, it takes quite a while to do this. So this is
    a video that was sped up A-Dex. So not something that you might have the patience
    for a robot to do.
  topic: predictions
- impact_reason: Highlights the significant time investment (months) required to move
    from initial failure to a functional, albeit slow, demonstration, grounding expectations
    for robotics timelines.
  relevance_score: 7
  source: llm_enhanced
  text: This was in September of 2024, so multiple months after our initial tests.
    Now, this is far from perfect. It takes 20 minutes to fold five items of clothes.
  topic: business
- impact_reason: Emphasizes the iterative nature of AI development, where data curation
    strategy itself becomes a critical lever for performance improvement (speed/efficiency).
  relevance_score: 7
  source: llm_enhanced
  text: We continue to iterate on this recipe. We selected and worked on our curation
    strategy for curating a higher-quality set of demonstration data. We got it from
    20 minutes down to 12 minutes for these five items.
  topic: business
- impact_reason: Provides a concrete, relatable example of current robotic failure
    modes (physical interaction errors, getting stuck), highlighting the gap between
    high-level instruction following and low-level physical competence.
  relevance_score: 7
  source: llm_enhanced
  text: Here the robot needs to put the clothes in the laundry basket. It drives over
    the shirt and then it gets stuck and it's not able to lift it up.
  topic: limitations/practical lessons
- impact_reason: Offers a nuanced, application-dependent strategic view on the large
    model vs. retrieval trade-off, suggesting no universal answer.
  relevance_score: 7
  source: llm_enhanced
  text: I think it's probably going to depend on the application and the use case
    in terms of how best to like, whether that might make sense [offloading knowledge].
  topic: strategy
- impact_reason: Provides a balanced outlook on world modeling—acknowledging significant
    hurdles while affirming its potential integration pathway with Vision-Language
    Action models.
  relevance_score: 7
  source: llm_enhanced
  text: there's various challenges [with world modeling], but there's also ways to
    integrate it into the VLA paradigm.
  topic: technical/predictions
- impact_reason: 'Broadly outlines the dual infrastructure needs for advanced AI:
    model training scale and efficient data handling/ingestion.'
  relevance_score: 6
  source: llm_enhanced
  text: thinking about large-scale machine learning infrastructure, training large
    models, and justing large amounts of data.
  topic: business/infrastructure
source: Unknown Source
summary: '## Podcast Episode Summary: Chelsea Finn: Building Robots That Can Do Anything


  This 44-minute podcast episode features Chelsea Finn discussing the critical challenge
  of moving robotics from highly specialized, application-specific solutions to developing
  **general-purpose foundation models for physical intelligence**. The core narrative
  traces the journey of her work, particularly at her company **Physical Intelligence**,
  in creating models that enable robots to perform diverse, long-horizon tasks in
  novel environments, drawing strong parallels to the success of large language models
  (LLMs).


  ### 1. Focus Area

  The primary focus is on **General-Purpose Robotics** using **Foundation Models**.
  Key themes include overcoming the traditional robotics bottleneck (requiring a new
  company/stack for every task), the role of **scale vs. diversity** in training data,
  and developing robust **pre-training and fine-tuning recipes** for real-world deployment
  across different hardware and environments.


  ### 2. Key Technical Insights

  *   **Decoupling Pre-training and Fine-tuning:** The most significant breakthrough
  for complex tasks like laundry folding was adopting a two-stage approach: extensive
  pre-training on all available robot data, followed by fine-tuning on a highly **uncurated,
  consistent, high-quality demonstration dataset** specific to the target task. This
  recipe drastically outperformed training solely on curated data or using only uncurated
  data.

  *   **Leveraging Vision-Language Models (VLMs) for Language Following:** To improve
  generalization and adherence to open-ended prompts (e.g., "clean the bedroom"),
  the team integrated larger, pre-trained VLMs (like Polyjama). Crucially, they prevented
  the randomly initialized diffusion action head from deteriorating the VLM backbone''s
  knowledge by **stopping the gradient flow** to that head, leading to an 80% language-following
  rate compared to 20% previously.

  *   **Diversity Over Specificity in Pre-training:** For generalization to unseen
  environments (e.g., testing in new AirBnBs), the model benefited significantly from
  diverse pre-training data. Mobile manipulation data (tidying kitchens/bedrooms)
  accounted for only about 2.4% of the total pre-training mixture, yet excluding static
  manipulation and web data reduced novel environment performance by over 20%, demonstrating
  that broad, diverse exposure is key to closing the generalization gap.


  ### 3. Business/Investment Angle

  *   **Market Shift from Custom to Generalist:** The current robotics landscape requires
  building an entire company (hardware, software, primitives) for every application.
  The foundation model approach promises to **lower the barrier to entry** by allowing
  a single model to serve multiple applications, mirroring the LLM ecosystem.

  *   **Data Strategy is Paramount:** Investment must focus not just on collecting
  massive scale (which can be repetitive, like industrial data) but on **diverse,
  high-quality, embodied data**. The success of the laundry folding task hinged on
  finding the right *recipe* for curating demonstration data, not just collecting
  more of it.

  *   **Hardware Agnosticism Potential:** The ability to fine-tune a pre-trained model
  on data from an entirely new robot platform (even without full knowledge of its
  control representation) suggests a path toward **faster deployment across heterogeneous
  hardware fleets**.


  ### 4. Notable Companies/People

  *   **Chelsea Finn:** Speaker, co-founder of Physical Intelligence, driving the
  research agenda for general-purpose physical intelligence.

  *   **Physical Intelligence:** The company focused on developing these general-purpose
  foundation models for robotics.

  *   **Polyjama:** Mentioned as the 3-billion parameter open-source Vision-Language
  Model used as the backbone for action prediction in later experiments.


  ### 5. Future Implications

  The industry is moving toward **embodied foundation models** that can handle long-horizon,
  dexterous tasks (like folding laundry) and generalize across novel objects and environments
  (like cleaning unknown homes). The immediate bottleneck is shifting from data collection
  diversity to achieving **higher reliability and performance** (currently around
  80% success rates in novel settings). This approach promises to unlock widespread,
  useful robotic applications beyond controlled industrial settings.


  ### 6. Target Audience

  This episode is highly valuable for **AI/ML Researchers, Robotics Engineers, Venture
  Capitalists focused on Deep Tech/Robotics, and Product Leaders** aiming to deploy
  intelligent physical systems. It requires a foundational understanding of machine
  learning concepts like imitation learning, foundation models, and fine-tuning.'
tags:
- artificial-intelligence
- ai-infrastructure
- investment
- openai
- meta
title: 'Chelsea Finn: Building Robots That Can Do Anything'
topics:
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 109
  prominence: 1.0
  topic: artificial intelligence
- keywords:
  - gpu
  - tensor
  - training
  - inference
  - model deployment
  - vector database
  mentions: 45
  prominence: 1.0
  topic: ai infrastructure
- keywords:
  - investment
  - funding
  - valuation
  - ipo
  - acquisition
  mentions: 1
  prominence: 0.1
  topic: investment
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-10-05 00:24:33 UTC -->
