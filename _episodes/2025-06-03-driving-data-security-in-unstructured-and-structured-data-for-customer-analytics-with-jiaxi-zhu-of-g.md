---
companies:
- category: unknown
  confidence: medium
  context: Welcome everyone to the AI and Business Podcast. I'm Matthew Damello, Editorial
    Director here at
  name: Business Podcast
  position: 31
- category: unknown
  confidence: medium
  context: come everyone to the AI and Business Podcast. I'm Matthew Damello, Editorial
    Director here at Emerge AI Research. T
  name: Matthew Damello
  position: 53
- category: unknown
  confidence: medium
  context: the AI and Business Podcast. I'm Matthew Damello, Editorial Director here
    at Emerge AI Research. Today's guest is Josh
  name: Editorial Director
  position: 70
- category: unknown
  confidence: medium
  context: . I'm Matthew Damello, Editorial Director here at Emerge AI Research. Today's
    guest is Joshi Zhu, head of analytics an
  name: Emerge AI Research
  position: 97
- category: unknown
  confidence: medium
  context: ctor here at Emerge AI Research. Today's guest is Joshi Zhu, head of analytics
    and insights at Google. Joshi
  name: Joshi Zhu
  position: 134
- category: tech
  confidence: high
  context: t is Joshi Zhu, head of analytics and insights at Google. Joshi joins us
    on today's show to discuss how la
  name: Google
  position: 179
- category: unknown
  confidence: medium
  context: lity issues and inconsistencies in customer data? So I would say that any
    challenges that we have with d
  name: So I
  position: 1884
- category: tech
  confidence: high
  context: ago when you had imagery and data and, you know, Facebook was just in its
    infancy. But now we're seeing tha
  name: Facebook
  position: 3917
- category: unknown
  confidence: medium
  context: rs, dates, trends, and so on and so forth, right? But I would say more
    recently, there is a broader focus
  name: But I
  position: 4462
- category: unknown
  confidence: medium
  context: ta and store it needs to align with the use case. What I mean by that is,
    for example, if you're using tha
  name: What I
  position: 6145
- category: unknown
  confidence: medium
  context: e information embedded in this specific document. And I know there have
    been historical industry, I would
  name: And I
  position: 9789
- category: unknown
  confidence: medium
  context: as well. So one example was in, I think in 2017, Hacker News, one of the
    credit bureaus, 147 million people's
  name: Hacker News
  position: 10079
- category: unknown
  confidence: medium
  context: things, but I know the big headline there is the EU AI Act is going into
    effect. We're recording this in Jan
  name: EU AI Act
  position: 12571
- category: unknown
  confidence: medium
  context: federated government, more than we might say the United States is, at least
    at this point, for how much attentio
  name: United States
  position: 12975
- category: tech
  confidence: high
  context: And they're really showing themselves to be very adept at wielding these
    technologies in a way that lean
  name: Adept
  position: 20222
- category: unknown
  confidence: medium
  context: box problem as we, as we call it in the industry. So Josh, I think that
    just means we have to have you back
  name: So Josh
  position: 21026
- category: unknown
  confidence: medium
  context: ecutive thought leaders, everyone from the CIO of Goldman Sachs to the
    head of AI at Raytheon and AI
  name: Goldman Sachs
  position: 22693
- category: big_tech
  confidence: high
  context: The guest, Joshi Zhu, is the Head of Analytics and Insights at Google.
    The discussion centers on how Google approaches data protection, analytics, and
    navigating AI/data challenges within a large enterprise context.
  name: Google
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: The podcast host's organization, where the host is the Editorial Director.
  name: Emerge AI Research
  source: llm_enhanced
- category: big_tech
  confidence: medium
  context: Mentioned historically in the context of data collection infancy, 20 years
    ago, relative to current data volumes.
  name: Facebook
  source: llm_enhanced
- category: media/platform
  confidence: high
  context: Mentioned in reference to a historical data incident involving a credit
    bureau leak in 2017.
  name: Hacker News
  source: llm_enhanced
- category: ai_user_enterprise
  confidence: medium
  context: Mentioned as an organization whose CIO is a featured thought leader, implying
    significant AI strategy/investment.
  name: Goldman Sachs
  source: llm_enhanced
- category: ai_user_enterprise
  confidence: medium
  context: Mentioned as an organization whose head of AI is a featured thought leader,
    implying significant AI strategy/investment.
  name: Raytheon
  source: llm_enhanced
- category: media_or_podcast
  confidence: high
  context: The host entity seeking guests for future episodes on AI transformation.
  name: The AI and Business Podcast
  source: llm_enhanced
date: 2025-06-03 07:27:00 +0000
duration: 26
has_transcript: false
insights:
- actionable: true
  confidence: medium
  extracted: anonymize that or remove it when we use it
  text: we should anonymize that or remove it when we use it.
  type: recommendation
layout: episode
llm_enhanced: true
original_url: https://traffic.libsyn.com/secure/techemergence/Business_-_6.3.25_-_Jiaxi_Zhu.mp3?dest-id=151434
processing_date: 2025-10-05 13:02:53 +0000
quotes:
- length: 140
  relevance_score: 4
  text: Are you driving AI transformation at your organization or maybe you're guiding
    critical decisions on AI investments, strategy, or deployment
  topics:
  - investment
- length: 58
  relevance_score: 3
  text: And that was actually one of the biggest challenges we had
  topics: []
- impact_reason: 'A crucial insight: despite new data volumes and types, the fundamental
    problems (like lineage and quality) are legacy issues that still dominate 80%
    of the effort.'
  relevance_score: 10
  source: llm_enhanced
  text: I would say that any challenges that we have with data is some of that is
    new because as you see, the data has grown so much and different born rights as
    well. But a lot of the, I would say, 80% of the problem that we see are still
    all problems from, you know, from probably decades ago.
  topic: strategy
- impact_reason: Identifies the major shift in analytics focus from structured (numbers)
    to unstructured data (text, audio) for deeper customer understanding.
  relevance_score: 10
  source: llm_enhanced
  text: But I would say more recently, there is a broader focus on leveraging unstructured
    data sources to draw insights. So a few examples is like culture and scripts.
    So there's lots of text that teams look at to try to draw insights about, for
    example, what customers think...
  topic: AI/ML trends
- impact_reason: Illustrates the 'needle in a haystack' problem for PII in unstructured
    data, where blanket protection is inefficient and restrictive.
  relevance_score: 10
  source: llm_enhanced
  text: But if it's, let's say a video or a voice recording that may be embedded in
    that large block of body of text and it's very hard for you to catalog that and
    say this entire block of text, does it ever contain PII data? And maybe part of
    the text does, part of that does not. So it's a, it's a much nuanced situation.
  topic: safety
- impact_reason: 'Crucial AI application: NLP models are presented as the necessary
    tool for granular PII discovery and classification within complex text blocks.'
  relevance_score: 10
  source: llm_enhanced
  text: But I would say one of the things that I would say is very important is to
    leverage things like natural language processing models to really understand what's
    in the text and identifying all of those sensitive pieces and keywords within
    the text and then so that we can properly classify those unstructured data sources.
  topic: AI/ML trends
- impact_reason: 'A critical warning: Attackers will use the same advanced AI/NLP
    tools that defenders use to *extract* sensitive data at scale.'
  relevance_score: 10
  source: llm_enhanced
  text: But at the same time, there's more technologically advanced ways of, I would
    say, data access that's unintended, right? So one example is this, as you mentioned,
    with the advent of the AI systems and all of these advanced ways of reading those
    documents, I would say cyber criminals could leverage some of the AI systems and
    massive, you know, and just feed the documents into those systems where them to
    extract these pieces of information.
  topic: AI/ML trends
- impact_reason: 'Defines a crucial framework for AI governance: balancing business
    gain against regulatory risk, a core challenge for enterprise AI adoption.'
  relevance_score: 10
  source: llm_enhanced
  text: We essentially had to work through all these use cases one by one to understand,
    first of all, what is the business upside of implementing this use case from a
    business standpoint, and number two, what is the risk of implementing this use
    case? Essentially, we wanted to do a trade-off between the gain that we get from
    a business standpoint, but then also the regulatory risk that this use case exposes
    us to.
  topic: business/strategy
- impact_reason: Crucially defines 'high-quality data' for AI beyond mere accuracy,
    emphasizing the necessity of contextual analysis to root out bias in unstructured
    data like transcripts.
  relevance_score: 10
  source: llm_enhanced
  text: By high quality, I mean not only just accurate, but also free of biases and
    potential embedded discrimination, for example. And with the rise of unstructured
    data, this is even more important because let's say a large block of trends, call
    transcripts, you know, it's words, but you do need to do that contextual analysis
    to see if there is any embedded biases...
  topic: safety/technical
- impact_reason: 'Articulates the third major challenge: modernizing data governance
    and access controls to account for autonomous AI systems accessing data, moving
    beyond traditional role-based controls.'
  relevance_score: 10
  source: llm_enhanced
  text: The last challenge that's on top of my mind is, you know, going back to this
    data governance piece. You know, you have a lot of data and unstructured data.
    How do you make sure that all of this data is properly labeled and properly stored
    and at the same time with the right level of access controls? Because previously
    you had access controls based on, let's say, the team or department or what type
    of user, but now you also have the AI system in the mix because some of this data
    may end up feeding into an AI application.
  topic: technical/governance
- impact_reason: 'Provides a holistic, organizational takeaway: AI success is fundamentally
    dependent on organizational structure and the alignment of strategy with risk
    tolerance.'
  relevance_score: 10
  source: llm_enhanced
  text: And finally, AI success requires more than just the right tools. It demands
    the right structure from analytics teams to executive leadership. Aligning strategy
    with data risk tolerance is critical for building secure, scalable systems.
  topic: strategy/business
- impact_reason: 'Highlights the core challenge in modern data management: the convergence
    of diverse data types necessitates stronger, more comprehensive security architecture.'
  relevance_score: 9
  source: llm_enhanced
  text: As organizations expand their data footprints, the lines between operational
    data, consumer behavioral signals, and third-party information continue to blur,
    making robust security frameworks more essential than ever.
  topic: strategy
- impact_reason: Directly names data lineage as a persistent, major challenge, which
    is foundational for governance and trust in analytics.
  relevance_score: 9
  source: llm_enhanced
  text: We had lots of issues with data lineage. And that was actually one of the
    biggest challenges we had.
  topic: technical
- impact_reason: 'Provides a clear definition of the metadata and governance gap:
    collection is easy, documentation (lineage, ownership, meaning) is hard.'
  relevance_score: 9
  source: llm_enhanced
  text: So just data formats and what data mean is a very challenging issue for a
    lot of organizations given that, you know, in many cases, organizations collect
    data. They are very diligent about collecting that. But it's a different story
    when it comes to documenting what all of this data is and where they got it from,
    who owns this, who has access rights to this data, and what is that data, translate
    into across different systems?
  topic: business
- impact_reason: 'Actionable advice: A data dictionary/catalog is the prerequisite
    for both security and effective analytics leverage.'
  relevance_score: 9
  source: llm_enhanced
  text: So I would say one of the first steps for us is really to develop a comprehensive
    data dictionary and catalog to both understand, you know, what we have so that
    we can better protect it, but also so that we know this is all of the data assets
    that we have that we can leverage for our analytics.
  topic: business
- impact_reason: Directly contrasts the security ease of structured data versus the
    complexity of unstructured data, setting up the need for advanced techniques.
  relevance_score: 9
  source: llm_enhanced
  text: Structured data is relatively easy to secure because you know exactly what
    goes in, the format is pretty as well. But for unstructured data, it's very challenging
    and we do need some advanced approaches for that.
  topic: safety
- impact_reason: Highlights the need for computer vision/image recognition (OCR +
    analysis) specifically for scanned documents, which often contain high-risk PII.
  relevance_score: 9
  source: llm_enhanced
  text: Now in those cases [document scans], given that it's a document scan, we can
    just say, you know, this scan that we'll have, we know that we know or may not
    know it that contains sensitive data. So in those cases, image recognition techniques
    will have to be used to understand what's the information embedded in this specific
    document.
  topic: AI/ML trends
- impact_reason: 'Points to the risk of data inference: even partial data extraction
    via AI can reveal enough sensitive context to be dangerous, even without direct
    access to the source file.'
  relevance_score: 9
  source: llm_enhanced
  text: Right. And that's unstructured data. You don't have a direct connection. You
    didn't get the document. You didn't get the resume, but knowing even the keywords
    of that resume, and that makes a much murkier space.
  topic: safety
- impact_reason: Provides actionable, strategic advice for organizations navigating
    new AI regulations (like the EU AI Act) by recommending a risk-based prioritization
    of existing AI use cases.
  relevance_score: 9
  source: llm_enhanced
  text: I would say the first step is really understanding all of the use cases that
    you currently have with those advanced AI systems and prioritizing use cases that
    are less sensitive or less impacted by the regulations.
  topic: strategy/business
- impact_reason: Offers a practical, phased implementation roadmap for AI projects
    under regulatory uncertainty, prioritizing high-impact, low-risk applications
    first.
  relevance_score: 9
  source: llm_enhanced
  text: So in some cases, in those cases, we would come up with a roadmap in terms
    of a phased implementation for all of these analytics use cases, starting with
    the ones that we had at least had the most business impact but the least regulatory
    risk.
  topic: strategy
- impact_reason: Strong strategic advice urging proactive compliance and foresight,
    suggesting that customer expectations often outpace formal regulation in the AI
    space.
  relevance_score: 9
  source: llm_enhanced
  text: No, you need to be proactive about what they're going to write legislation,
    what they're going to write regulations on in the next few years because customer
    expectations are far, far more advanced than where the regulations are right now.
  topic: strategy/predictions
- impact_reason: Identifies Ethical AI Principles, focusing on social justice and
    equity, as a primary challenge driving current and future AI legislation.
  relevance_score: 9
  source: llm_enhanced
  text: So one is ethical AI principles. So as you see in the US, I think there's
    already legislation underway to regulate AI and its downstream impact on, for
    example, social justice, equity, and so on and so forth.
  topic: safety/ethics
- impact_reason: Highlights the critical concept of context-dependent bias, especially
    relevant for global AI deployment and localization efforts.
  relevance_score: 9
  source: llm_enhanced
  text: '...something that''s biased in one cultural or geographical context may not
    be biased in another and vice versa.'
  topic: safety/ethics
- impact_reason: Pinpoints Transparency and Explainability (XAI) as the second major
    challenge, directly linking it to consumer trust in AI systems.
  relevance_score: 9
  source: llm_enhanced
  text: I would say the second challenge is transparency and explainability. So there
    is, I would say, growing concern, especially across consumers and I would say
    day-to-day users of AI systems about trust and transparency in the AI responses.
  topic: safety/ethics
- impact_reason: A direct warning about the necessity of updating security protocols
    to manage data access by autonomous AI agents.
  relevance_score: 9
  source: llm_enhanced
  text: Updating those access controls to these emerging technologies that could potentially
    access data on them by themselves is also a very critical step to take in preparation
    of these developments.
  topic: safety/governance
- impact_reason: 'A key summary takeaway: AI forces a redefinition of data security
    to explicitly include risks associated with unstructured data used in AI models.'
  relevance_score: 9
  source: llm_enhanced
  text: First, data security isn't just about firewalls and access controls. Protecting
    customer data today means understanding the unique risks tied to both structured
    and unstructured sources, particularly when scaling AI-powered insights.
  topic: governance/business
- impact_reason: 'Strategic guidance: Metadata strategy for unstructured data must
    be dictated by the intended analytical purpose (e.g., individual profiling vs.
    aggregate sentiment).'
  relevance_score: 8
  source: llm_enhanced
  text: But I think the way you document that data and store it needs to align with
    the use case.
  topic: strategy
- impact_reason: 'Clarifies the trade-off in unstructured data governance: aggregate
    analysis requires pattern recognition (NLP features), while individual analysis
    requires PII linkage.'
  relevance_score: 8
  source: llm_enhanced
  text: But if you are using this data more just to get an overall sentiment of your,
    of the body of customers you have, let's say, to improve customer satisfaction,
    then there's less of a need to tie that to a specific customer. But it's more
    about making sure that you're able to understand some of the nuanced patterns
    within the data.
  topic: technical
- impact_reason: Uses a major historical breach (Equifax-related context) to underscore
    the real-world danger of unprotected PII hidden in unstructured document scans.
  relevance_score: 8
  source: llm_enhanced
  text: One example was in, I think in 2017, Hacker News, one of the credit bureaus,
    147 million people's data was, I think one of the reasons was it was not properly
    protected because a lot of that was in the document scans that people weren't
    fully aware that they contained that this data.
  topic: safety
- impact_reason: Signals the immediate relevance of major upcoming regulation (EU
    AI Act) impacting data and AI strategy.
  relevance_score: 8
  source: llm_enhanced
  text: I know we're running headlong into kind of the regulatory side of things,
    but I know the big headline there is the EU AI Act is going into effect.
  topic: safety/regulation
- impact_reason: Highlights a common, yet privacy-concerning, use case of AI with
    unstructured personal data, immediately setting the stage for regulatory and privacy
    discussions.
  relevance_score: 8
  source: llm_enhanced
  text: I sometimes use AI tools to ask them to read my personal documents, right?
    Like my resume and try to extract some of the keywords out there. Right. And that's
    unstructured data. You don't have a direct connection. You didn't get the document.
    You didn't get the resume, but knowing even the keywords of that resume, and that
    makes a much murkier space.
  topic: safety/privacy
- impact_reason: Introduces the concept of a 'stage-gate process' contingent on evolving
    regulations, emphasizing the need for agility and re-evaluation in AI deployment.
  relevance_score: 8
  source: llm_enhanced
  text: But before we further consider them for development or rolling out, I would
    say there would be a stage-gate process where these use cases are revealed when,
    for example, the rules are finally being published or amended, and let's see whether
    they still make the cut based on this updated regulatory information.
  topic: strategy/regulation
- impact_reason: 'A key strategic insight: staying ahead of AI governance requires
    monitoring both regulatory trends and cutting-edge academic research.'
  relevance_score: 8
  source: llm_enhanced
  text: One of the things is really potentially just getting ahead of those trends.
    I would say by understanding where the regulatory wind is blowing and then also
    understanding where the research is currently in academia that potentially could
    help address some of these issues.
  topic: strategy
- impact_reason: Emphasizes the importance of collaboration with academia on Explainable
    AI (XAI) research to build user trust without compromising proprietary model details.
  relevance_score: 8
  source: llm_enhanced
  text: I think providing, you know, there is growing research actually in this area,
    which is what they call explainable AI or XAI? So working with academia on this
    is actually really important so that the AI system developers and organizations
    that leverage AI and develop strategies to, you know, be as transparent as they
    can to build that user trust...
  topic: technical/strategy
- impact_reason: 'Identifies the inherent tension in XAI: balancing the need for transparency
    with the need to protect sensitive model training data and intellectual property.'
  relevance_score: 8
  source: llm_enhanced
  text: '...but also make sure that you don''t reveal too much about, I would say,
    for example, the sensitive information that goes into developing the AI systems.'
  topic: safety/technical
- impact_reason: Points to a specific, high-leverage application of GenAI within academic/information
    sectors, noting its impact on controlling misinformation.
  relevance_score: 8
  source: llm_enhanced
  text: The academic publishing houses are getting a hold of natural language processing
    technologies, generative AI. And that is really changing the game as far as hallucinations,
    misinformation goes.
  topic: predictions/technology
- impact_reason: Identifies localization and dialect-specific bias mitigation as a
    major future discipline and set of use cases for AI development.
  relevance_score: 8
  source: llm_enhanced
  text: Even from there, you mentioned a lot about localization, just in terms of
    bias, in terms of really understanding what that means from region to region,
    dialect to dialect. I think that that's going to be a huge set of use cases, a
    huge discipline to develop going forward.
  topic: safety/predictions
- impact_reason: Reiterates the industry consensus that the burden of solving the
    'black box problem' (explainability) rests on the developers and deployers of
    AI.
  relevance_score: 8
  source: llm_enhanced
  text: And the onus is going to be on those wielding them to really clarify that
    black box problem as we, as we call it in the industry.
  topic: safety/ethics
- impact_reason: Elevates Zero Trust and Metadata Governance as essential, non-negotiable
    components for maintaining agility alongside compliance in the AI era.
  relevance_score: 8
  source: llm_enhanced
  text: Second, zero trust isn't a buzzword. It's a mindset. Joshy emphasized how
    adopting a zero-trust approach combined with metadata governance helps organizations
    remain agile without compromising compliance or customer trust.
  topic: governance/strategy
- impact_reason: 'Illustrates the low-tech, high-volume threat vector: manual extraction
    by outsourced labor, which is cost-effective for attackers.'
  relevance_score: 7
  source: llm_enhanced
  text: So in less technologically or less advanced, they could just employ thousands
    of vendors to try to read all right, try to send maybe mass scan messages and
    so on and so forth. They think are able to record the phone number out of it,
    you know, then just button that phone number.
  topic: safety
- impact_reason: Acknowledges the nascent stage of AI regulation compliance, suggesting
    that organizations are still pioneering best practices.
  relevance_score: 7
  source: llm_enhanced
  text: Given that this is a relatively new issue, I wouldn't say there's a gold standard
    in terms of, you know, responding to this increase in regulation.
  topic: strategy
- impact_reason: Suggests that established information authorities (like academic
    publishers) are uniquely positioned to leverage GenAI effectively due to their
    existing high-quality data assets.
  relevance_score: 7
  source: llm_enhanced
  text: And they're really showing themselves to be very adept at wielding these technologies
    in a way that lean into all their advantages when it comes to traditional data
    governance, right? Who has better information, small 'i' information than, than,
    you know, the academic publishing houses.
  topic: business/strategy
- impact_reason: Sets the context for the discussion, emphasizing the rapid evolution
    of the data landscape since the early days of major tech platforms.
  relevance_score: 6
  source: llm_enhanced
  text: It's 2025. It's a brand new world. I came up with Google in grade school in
    the early era of the search application. A lot has changed.
  topic: strategy
source: Unknown Source
summary: '## Podcast Episode Summary: Driving Data Security in Unstructured and Structured
  Data for Customer Analytics - with Jiaxi Zhu of Google


  This 26-minute episode of the AI and Business Podcast, featuring Jiaxi Zhu, Head
  of Analytics and Insights at Google, focuses on the critical challenges large enterprises
  face in securing and governing both structured and unstructured data, especially
  as they scale customer analytics in an AI-first world. The discussion navigates
  the blurring lines between operational data, behavioral signals, and third-party
  information, emphasizing the necessity of balancing innovation with stringent compliance
  and ethical standards.


  ### 1. Focus Area

  The primary focus is **Data Governance and Security for Customer Analytics**, specifically
  addressing the complexities introduced by the proliferation of **unstructured data**
  (text, transcripts, images, video) compared to traditional structured data. Key
  themes include data lineage, PII protection within complex data types, navigating
  evolving global AI regulations (like the EU AI Act), and establishing proactive
  ethical AI principles.


  ### 2. Key Technical Insights

  *   **Unstructured Data Documentation Challenge:** Documenting unstructured data
  (like large text blocks or videos) is significantly harder than structured data
  because its richness makes defining its meaning and lineage complex. Documentation
  must align directly with the intended **use case** (e.g., tying transcripts to specific
  customer profiles vs. general sentiment analysis).

  *   **Leveraging NLP for PII Detection:** Securing unstructured data requires advanced
  techniques, particularly **Natural Language Processing (NLP) models**, to scan text
  and identify sensitive Personally Identifiable Information (PII) embedded within
  it, which cannot be easily flagged by predefined field structures.

  *   **Image Recognition for Document Scans:** For scanned documents (like records),
  **image recognition techniques** are necessary to accurately determine what information
  is embedded, as these often contain sensitive data that might be overlooked by traditional
  cataloging methods (highlighted by the Equifax incident).


  ### 3. Business/Investment Angle

  *   **Proactive Regulatory Alignment:** Organizations must move beyond reactive
  compliance and proactively monitor evolving regulatory landscapes (like the EU AI
  Act) and academic research to anticipate future requirements for AI deployment.

  *   **Risk/Reward Trade-off in AI Use Cases:** Companies should inventory all potential
  AI analytics use cases and prioritize implementation based on a trade-off analysis:
  maximizing **business impact** while minimizing **regulatory risk**. High-risk use
  cases should be phased in only after regulatory rules are finalized.

  *   **Data Quality as an Ethical Foundation:** High-quality data for AI must be
  defined not just by accuracy, but by being **free of biases and embedded discrimination**,
  requiring contextual analysis of language and tone, especially in unstructured sources.


  ### 4. Notable Companies/People

  *   **Jiaxi Zhu (Google):** Guest and Head of Analytics and Insights, providing
  an authoritative perspective on large-scale data challenges within a leading tech
  firm.

  *   **Google:** Mentioned as the context for internal and external data protection
  strategies.

  *   **Equifax:** Cited as a historical example where poor protection of sensitive
  data embedded in document scans led to a massive security incident.


  ### 5. Future Implications

  The industry is moving toward a necessity for **Explainable AI (XAI)** to build
  consumer trust by clarifying the logic behind AI responses. Furthermore, data governance
  must evolve beyond traditional user/department access controls to incorporate **AI
  systems themselves** as potential data consumers, requiring updated, granular access
  controls for these emerging technologies. Localization and contextual understanding
  of bias (regional dialects, cultural context) will become a major discipline in
  data science.


  ### 6. Target Audience

  This episode is most valuable for **Data Governance Professionals, Chief Data Officers
  (CDOs), AI/ML Strategy Leaders, and Security Architects** operating within large
  enterprises that handle significant volumes of customer data and are scaling AI-driven
  personalization efforts.'
tags:
- artificial-intelligence
- generative-ai
- investment
- google
title: Driving Data Security in Unstructured and Structured Data for Customer Analytics
  - with Jiaxi Zhu of Google
topics:
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 54
  prominence: 1.0
  topic: artificial intelligence
- keywords:
  - generative ai
  - genai
  - chatgpt
  - gpt
  - claude
  - text generation
  - image generation
  mentions: 1
  prominence: 0.1
  topic: generative ai
- keywords:
  - investment
  - funding
  - valuation
  - ipo
  - acquisition
  mentions: 1
  prominence: 0.1
  topic: investment
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-10-05 13:02:53 UTC -->
