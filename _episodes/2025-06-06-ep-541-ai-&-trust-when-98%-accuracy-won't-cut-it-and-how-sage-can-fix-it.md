---
companies:
- category: unknown
  confidence: medium
  context: This is the Everyday AI Show, the everyday podcast where we simplify AI
    and br
  name: Everyday AI Show
  position: 12
- category: unknown
  confidence: medium
  context: ng our video, our livestream, you see I am at the Sage Future conference
    here in Atlanta, and how Sage is reall
  name: Sage Future
  position: 901
- category: unknown
  confidence: medium
  context: e you are too. What's going on, y'all? My name is Jordan Wilson. I'm the
    host of Everyday AI. This is your daily
  name: Jordan Wilson
  position: 1120
- category: unknown
  confidence: medium
  context: y'all? My name is Jordan Wilson. I'm the host of Everyday AI. This is your
    daily livestream podcast and free d
  name: Everyday AI
  position: 1151
- category: unknown
  confidence: medium
  context: e. I am in Atlanta at the Sage Future conference. And I'm excited to welcome
    our guest for today, Aaron H
  name: And I
  position: 1669
- category: unknown
  confidence: medium
  context: . And I'm excited to welcome our guest for today, Aaron Harris, the CTO
    of Sage. Aaron, thank you so much for jo
  name: Aaron Harris
  position: 1717
- category: unknown
  confidence: medium
  context: on't know Sage, tell us what Sage is. Sure. Yeah. So Sage is a global software
    company that focuses on acco
  name: So Sage
  position: 1987
- category: unknown
  confidence: medium
  context: all over the world. And our headquarters here in North America is obviously
    here in Atlanta. It's coming has bee
  name: North America
  position: 2343
- category: unknown
  confidence: medium
  context: 90 or 95% accurate, why does that not work? Yeah. So I mean, there's so
    many ways to address that questi
  name: So I
  position: 3055
- category: unknown
  confidence: medium
  context: ook at the CFO in a company and the finance team. That CFO trades on trust.
    Right? Their job is to create co
  name: That CFO
  position: 3214
- category: unknown
  confidence: medium
  context: ', "Wait, I need that," especially when it came to Sage Copilot. So can
    you explain a little bit for maybe our au'
  name: Sage Copilot
  position: 4992
- category: unknown
  confidence: medium
  context: I yet working in a more almost deterministic way? But I saw that there's
    been billions of predictions, mi
  name: But I
  position: 7706
- category: unknown
  confidence: medium
  context: y won't—we won't get another chance. I grew up in Silicon Valley, probably
    like a lot of people in your audience,
  name: Silicon Valley
  position: 13096
- category: unknown
  confidence: medium
  context: patents on this. So we call this whole thing the Sage AI Factory. And if
    you see me talk to our customers or analy
  name: Sage AI Factory
  position: 15840
- category: unknown
  confidence: medium
  context: ny total organizations you have using kind of the AI Copilot features inside
    Sage right now. So we have tens o
  name: AI Copilot
  position: 16256
- category: unknown
  confidence: medium
  context: cated businesses. So we launched early access for Sage Intacct about six
    or eight months ago. And I guess the th
  name: Sage Intacct
  position: 16749
- category: unknown
  confidence: medium
  context: lever. We put a button in the product that said, "See My Data." And when
    a user clicked that button, we would p
  name: See My Data
  position: 18717
- category: unknown
  confidence: medium
  context: p shows up at that point in front of a prospect, "Show My Data," and they
    got the full transparency. The full tr
  name: Show My Data
  position: 19450
- category: unknown
  confidence: medium
  context: nstead of that webcam, we pop up what we call the Sage Trust Label. And
    in that trust label—this is kind of like a n
  name: Sage Trust Label
  position: 20434
- category: unknown
  confidence: medium
  context: think is going to be—or maybe this is it, right? Because I think every
    single company that's trying to put o
  name: Because I
  position: 21424
- category: unknown
  confidence: medium
  context: '''re going to have to just keep adapting as we go. So Aaron, we''ve talked
    about a lot in today''s conversation'
  name: So Aaron
  position: 23239
- category: ai_application
  confidence: high
  context: A global software company focusing on accounting, HR, and payroll, which
    is heavily integrating AI (Sage Copilot) into its products, emphasizing trust
    and accuracy in financial tasks.
  name: Sage
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Sage's specific AI offering, powered by fine-tuned large language models,
    designed for high-accuracy accounting tasks.
  name: Sage Copilot
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: Sage's proprietary infrastructure built to automate the training, updating,
    and safety monitoring of their tens of thousands of deployed AI models.
  name: Sage AI Factory
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as a general example of a Large Language Model (LLM) that is
    often not good at math or creative accounting.
  name: ChatGPT
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as a large, off-the-shelf model (estimated two trillion parameters)
    whose general capabilities are powerful but still prone to mistakes and high cost
    for Sage's specific needs.
  name: GPT-4
  source: llm_enhanced
- category: organization
  confidence: high
  context: The industry association that accredits CPAs. Sage is partnering with them
    to use their professional content to further train their specialized AI model.
  name: AICPA (American Institute of Certified Public Accountants)
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: Mentioned historically as one of the pioneers in the Software as a Service
    (SaaS) model, setting precedents for automated, non-disruptive upgrades, which
    is compared to Sage's AI deployment strategy.
  name: Salesforce
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: A specific product line from Sage for which early access to AI Copilot
    features was launched.
  name: Sage Intacct
  source: llm_enhanced
date: 2025-06-06 15:00:00 +0000
duration: 27
has_transcript: false
insights:
- actionable: false
  confidence: medium
  extracted: AI
  text: the problem with AI is the industry and the technology is moving so fast that
    the regulatory environment around it hasn't kept up.
  type: problem_identification
layout: episode
llm_enhanced: true
original_url: https://pscrb.fm/rss/p/www.buzzsprout.com/2175779/episodes/17292904-ep-541-ai-trust-when-98-accuracy-won-t-cut-it-and-how-sage-can-fix-it.mp3
processing_date: 2025-10-05 11:29:48 +0000
quotes:
- length: 90
  relevance_score: 4
  text: And so that's the big breakthrough with large language models that sit behind
    Sage Copilot
  topics: []
- length: 186
  relevance_score: 4
  text: And how do we get to the point where you have a product like Sage Copilot
    that can accurately take advantage of the powers of generative AI yet working
    in a more almost deterministic way
  topics: []
- length: 267
  relevance_score: 3
  text: So without you going into—because I'm sure we could talk about this part for
    hours—how did we get to the point where yes, you can feel confident as one of
    the global leaders in the space to say, "Yeah, you can go use AI for some of your
    most important financial tasks
  topics: []
- length: 146
  relevance_score: 3
  text: Our biggest objective or the biggest obstacle to getting customers to buy
    the product is that they were not willing to put their data in the cloud
  topics: []
- length: 108
  relevance_score: 3
  text: And you know, we sort of scratch our heads at that now, but you have to imagine
    how new this was at the time
  topics: []
- length: 271
  relevance_score: 3
  text: But as we wrap up, what do you think is the one most important takeaway for
    those people, whether they're a CPA, whether they're a CFO, or a huge organization,
    what's the one biggest takeaway that you want people to know from Sage Future
    here when it comes to trust in AI
  topics: []
- length: 118
  relevance_score: 3
  text: What we've learned through all of our conversations is the biggest signal
    of trust is the company behind the AI, right
  topics: []
- impact_reason: A strong warning about the dangers of deploying low-accuracy AI in
    high-stakes domains like finance, setting a high bar for enterprise adoption.
  relevance_score: 10
  source: llm_enhanced
  text: Sometimes being 90 or 95% correct could be bad. It could be a recipe for disaster
    when it comes to your business's AI plan in 2025 and beyond.
  topic: safety/business
- impact_reason: Illustrates the extreme precision required in accounting, emphasizing
    that traditional LLM accuracy levels are wholly inadequate for regulated financial
    tasks.
  relevance_score: 10
  source: llm_enhanced
  text: If I'm a penny off in the basic equations of accounting, they will hunt that
    penny down, right, for days until they find it. They may not ever give up until
    they find that penny. So 99% accuracy, that's not going to cut it, right? It's
    got to be perfect.
  topic: technical/business
- impact_reason: 'Provides a crucial architectural principle for building reliable
    AI systems: use the right tool for the job (e.g., deterministic code for math,
    LLMs for language).'
  relevance_score: 10
  source: llm_enhanced
  text: One of the first rules of building trusted AI is not to use AI when traditional
    development will work better. So if you want AI to do math, we're going to give
    AI a calculator to do that math with.
  topic: technical/strategy
- impact_reason: 'Describes a critical safety and deployment strategy: building robust
    human-in-the-loop review mechanisms based on confidence scoring.'
  relevance_score: 10
  source: llm_enhanced
  text: We're going to over-index on understanding, have we met that level [of accuracy]?
    And if not, how do we engage a human properly to review the work?
  topic: safety/strategy
- impact_reason: 'Provides a concrete example of successful enterprise AI strategy:
    leveraging smaller, highly fine-tuned models (7B parameters) instead of relying
    solely on massive, general-purpose models.'
  relevance_score: 10
  source: llm_enhanced
  text: We started with a model that's seven billion parameters, right? And we fine-tuned
    it from there... We can get it down to a seven billion parameter model, and we
    can fine-tune it to be really, really, really good at these accounting tasks we
    want it to do.
  topic: technical/architecture
- impact_reason: A powerful strategic pivot away from the traditional tech mantra
    ('move fast and break things') toward a culture of caution and accountability
    required for high-stakes AI.
  relevance_score: 10
  source: llm_enhanced
  text: I grew up in Silicon Valley, probably like a lot of people in your audience,
    and the mantra in Silicon Valley has always been 'move fast and break things.'
    When you're building this kind of AI in this industry, we've got to have a completely
    different culture. So I talk about it—it's kind of pithy—but 'accept humility,
    embrace responsibility.'
  topic: strategy/safety
- impact_reason: A direct critique of the traditional 'move fast and break things'
    ethos, proposing a necessary cultural shift ('accept humility, embrace responsibility')
    for high-stakes AI development.
  relevance_score: 10
  source: llm_enhanced
  text: The mantra in Silicon Valley has always been 'move fast and break things.'
    When you're building this kind of AI in this industry, we've got to have a completely
    different culture. So I talk about it—it's kind of pithy—but 'accept humility,
    embrace responsibility.'
  topic: strategy/safety
- impact_reason: Introduces the 'Trust Label' concept—a concrete, actionable solution
    for transparency in AI, analogous to a nutrition label, detailing model provenance
    and data usage.
  relevance_score: 10
  source: llm_enhanced
  text: We're going to put it in each AI feature where a user can click it, and what's
    going to happen is instead of that webcam, we pop up what we call the Sage Trust
    Label. And in that trust label—this is kind of like a nutrition label—we're going
    to be super transparent about, 'Okay, what are the models that we used to build
    this? Are we training our own models? If so, how do we use your data in the training
    of those models?'
  topic: safety/technical
- impact_reason: A direct, cautionary statement about the inherent fallibility of
    current AI systems, crucial for setting realistic expectations for users and stakeholders.
  relevance_score: 10
  source: llm_enhanced
  text: AI is not foolproof. It's going to have problems.
  topic: safety/limitations
- impact_reason: Highlights the critical threshold for AI accuracy in business applications,
    moving beyond 'good enough' to near-perfection, especially in finance.
  relevance_score: 9
  source: llm_enhanced
  text: What if good isn't good enough? Right? I think it's something that business
    leaders are constantly thinking about when it comes to AI.
  topic: business/strategy
- impact_reason: Defines the core value proposition of financial data integrity and
    explains why trust is the non-negotiable foundation for AI adoption in the finance
    sector.
  relevance_score: 9
  source: llm_enhanced
  text: The CFO trades on trust. Right? Their job is to create confidence not only
    within the business, but with stakeholders... And the minute that CFO puts something
    out that has a mistake in it, they're going to lose that credibility. They lose
    that trust.
  topic: business/strategy
- impact_reason: Directly addresses the known weakness of base LLMs (mathematical
    reasoning) and warns against using them for tasks requiring deterministic calculation.
  relevance_score: 9
  source: llm_enhanced
  text: Large language models by themselves, right? So if you're using something like
    ChatGPT, not always the best at math, right? ... We don't want creative accounting,
    and we certainly don't want them doing math, right?
  topic: technical/limitations
- impact_reason: 'Highlights the dual challenges of using proprietary frontier models
    for enterprise tasks: accuracy gaps and prohibitive operational costs.'
  relevance_score: 9
  source: llm_enhanced
  text: The off-the-shelf models... they still make mistakes. But second, they're
    incredibly expensive. Right? So if we wanted to go about not just operating these
    models, but sort of get into the world of building one of these gigantic large
    language models, I'd never get the budget.
  topic: business/limitations
- impact_reason: Points to the rapid democratization and cost reduction in model customization
    (fine-tuning) as a key enabler for specialized enterprise AI.
  relevance_score: 9
  source: llm_enhanced
  text: Fast forward two years, and the efficiency and the capability of fine-tuning
    these models has increased rapidly. Right? So the cost has come down, the efficiencies
    have increased...
  topic: technical/trends
- impact_reason: Explains how fine-tuning is used not just for capability enhancement,
    but also for safety alignment, bias mitigation, and scope control (guardrailing).
  relevance_score: 9
  source: llm_enhanced
  text: When you're fine-tuning, you can sort of slough off the stuff that you don't
    want it to do. Right? We train our model to not accept toxic prompts. Right? We
    train it to be pleasant in the way that it interacts. And then, if the conversation's
    not about accounting, then we don't want to have that conversation.
  topic: safety/technical
- impact_reason: 'Signals a major trend: industry bodies collaborating directly with
    AI developers to embed certified, high-quality knowledge into models, boosting
    industry trust.'
  relevance_score: 9
  source: llm_enhanced
  text: We're partnering with the AICPA, which is the industry association that accredits
    CPAs. They're now going to make their professional content available to us to
    train into the model.
  topic: business/trends
- impact_reason: Reinforces the concept of 'zero tolerance for error' in initial enterprise
    AI deployments, emphasizing the importance of the first user experience.
  relevance_score: 9
  source: llm_enhanced
  text: If a CFO uses our Copilot and their first experience is a mistake, they won't—we
    won't get another chance.
  topic: business/strategy
- impact_reason: Details the extreme technical challenge of MLOps for personalized,
    continuously updated enterprise AI, requiring automation beyond standard SaaS
    release cycles.
  relevance_score: 9
  source: llm_enhanced
  text: I don't want a weekly release. I want you to automate the training of this
    AI and detect when it's improved enough and then automatically update the version.
    But it gets worse, Mr. Developer. You need to be able to do this on a customer-by-customer
    basis.
  topic: technical
- impact_reason: Provides concrete examples of advanced, patented safety mechanisms
    built into the ML infrastructure (detecting drift and hallucination).
  relevance_score: 9
  source: llm_enhanced
  text: We've got systems that detect model drift and launch a process to get a data
    scientist involved. We've got a couple of safety mechanisms that detect hallucination.
    This is where we've actually gotten some of our patents on this.
  topic: technical/safety
- impact_reason: Clearly states the regulatory lag in AI, forcing companies to create
    their own internal trust mechanisms rather than relying on external compliance
    standards.
  relevance_score: 9
  source: llm_enhanced
  text: The problem with AI is the industry and the technology is moving so fast that
    the regulatory environment around it hasn't kept up. So we can't rely on a lot
    of external signals, right, that you can trust the AI.
  topic: safety/regulation
- impact_reason: Identifies brand reputation and the perceived trustworthiness of
    the vendor as the primary driver for customer adoption of complex AI, especially
    for non-technical users.
  relevance_score: 9
  source: llm_enhanced
  text: What we've learned through all of our conversations is the biggest signal
    of trust is the company behind the AI, right? I'm not a sophisticated person,
    maybe I don't know how to evaluate this, but hey, that's a brand that I trust.
  topic: business/strategy
- impact_reason: Highlights that brand trust and the reputation of the developing
    company are primary factors for user adoption, especially when technical understanding
    is low.
  relevance_score: 9
  source: llm_enhanced
  text: conversations is the biggest signal of trust is the company behind the AI,
    right?
  topic: business/strategy
- impact_reason: Details the evolution of AI deployment, moving from hidden, specialized,
    multi-model pipelines (task-based AI) to interactive LLMs.
  relevance_score: 8
  source: llm_enhanced
  text: The first way we call task-based AI. This is AI that you don't necessarily
    see it work... we had to go build our own models—models plural, right? We've got
    five models just, you know, some of them are looking for the total, some of them
    are checking the work of the other models...
  topic: technical/architecture
- impact_reason: Identifies the shift to LLMs as a fundamental breakthrough enabling
    user direction and conversational interaction in enterprise AI.
  relevance_score: 8
  source: llm_enhanced
  text: The big breakthrough with large language models that sit behind Sage Copilot.
    Now you can be directive of the way AI works and sort of how it gets its job done.
  topic: technical/breakthroughs
- impact_reason: A concise strategic mandate for product design when integrating conversational
    AI into high-stakes workflows.
  relevance_score: 8
  source: llm_enhanced
  text: You've got to design for confidence now.
  topic: strategy/business
- impact_reason: Details the specialized data required for deep domain expertise,
    moving beyond general web data to professional, certified content.
  relevance_score: 8
  source: llm_enhanced
  text: We've trained it on accounting textbooks and accounting exams. We've trained
    it on content that helps it to sort of understand and speak in the vernacular
    of accounts and financial analysts.
  topic: technical/training
- impact_reason: Offers a counter-narrative to job displacement fears, showing that
    regulated industries are moving toward co-development and integration rather than
    outright replacement.
  relevance_score: 8
  source: llm_enhanced
  text: The accounting industry, which early on the headlines were saying accountants
    aren't going to exist, I think it's incredibly interesting that the accounting
    industry is not just embracing AI, they're contributing to the development of
    AI models.
  topic: predictions/business
- impact_reason: Contrasts the initial fear of job replacement with the reality of
    industry participation in model development, signaling maturation in AI adoption.
  relevance_score: 8
  source: llm_enhanced
  text: I think it's incredibly interesting that the accounting industry is not just
    embracing AI, they're contributing to the development of AI models.
  topic: predictions/strategy
- impact_reason: Introduces a key concept ('Sage AI Factory') that frames the entire
    infrastructure required for safe, scalable, and continuously updated enterprise
    AI deployment.
  relevance_score: 8
  source: llm_enhanced
  text: So we call this whole thing the Sage AI Factory. And if you see me talk to
    our customers or analysts, partners about AI, I'm invariably going to talk about
    the Sage AI Factory because I think it's so important to understand behind the
    scenes, like how does the factory work? How does the stuff get built? And how
    do I know that you're taking steps to make sure that it's safe?
  topic: strategy/technical
- impact_reason: A powerful, historical anecdote demonstrating the extreme lengths
    required to build initial trust in cloud/data security, serving as an analogy
    for current AI trust challenges.
  relevance_score: 8
  source: llm_enhanced
  text: We would pop up a window that had a webcam in the data center pointing at
    the server that had their data on it... we got the full transparency. The full
    transparency. They saw the data and then some.
  topic: strategy/business
- impact_reason: A realistic assessment that trust is not a solved problem but an
    ongoing process requiring continuous adaptation as AI evolves.
  relevance_score: 8
  source: llm_enhanced
  text: I think we all need to be a bit honest that there's going to continue to be
    lots of reasons to not trust AI, right? It's just broader than just the accounting
    field. So I think we've got to have this mindset that this isn't one step in the
    journey, and we're going to have to continue evaluating and looking at how are
    people feeling about trust in AI...
  topic: safety/strategy
- impact_reason: 'Actionable advice for AI vendors on maintaining credibility: honesty
    about limitations is crucial for long-term trust.'
  relevance_score: 8
  source: llm_enhanced
  text: You've got to be transparent, you've got to be credible, you've got to be
    willing to admit that, hey, AI is not foolproof. It's going to have problems.
  topic: safety/business
- impact_reason: Illustrates the user perspective where trust overrides technical
    evaluation, emphasizing the importance of established brand equity in the AI space.
  relevance_score: 8
  source: llm_enhanced
  text: I'm not a sophisticated person, maybe I don't know how to evaluate this, but
    hey, that's a brand that I trust.
  topic: business/strategy
- impact_reason: Contrasts the rigidity of older, high-accuracy AI systems with the
    flexibility offered by newer generative models.
  relevance_score: 7
  source: llm_enhanced
  text: The limitation of this approach [task-based AI] is that you can't really interact
    with that AI, and that AI has to be very, very carefully orchestrated, scripted.
  topic: technical/strategy
- impact_reason: Illustrates a prudent, phased rollout strategy for high-risk AI,
    starting with lower-stakes environments before moving to complex enterprise systems.
  relevance_score: 7
  source: llm_enhanced
  text: We started small. We started with small businesses that have simple accounting
    needs... But we've also sort of gone into now more sophisticated businesses.
  topic: business/strategy
- impact_reason: 'Highlights the practical business value of transparency mechanisms:
    streamlining the sales and evaluation cycle by preemptively answering deep technical
    trust questions.'
  relevance_score: 7
  source: llm_enhanced
  text: I think it's going to get the CTO off the phone. So when you get a customer
    who's evaluating your software... If we've got this trust label, it just makes
    it easy for people to understand and evaluate.
  topic: business
- impact_reason: A strong philosophical statement emphasizing proactive responsibility
    in shaping technological outcomes.
  relevance_score: 7
  source: llm_enhanced
  text: The future is the future that we build, and taking on the responsibility to
    build that future is pretty serious.
  topic: strategy
source: Unknown Source
summary: '## Podcast Episode Summary: Ep 541: AI & Trust: When 98% accuracy won''t
  cut it and how Sage can fix it


  This episode of the Everyday AI Show, recorded live from the Sage Future conference,
  dives deep into the critical issue of **trust in Artificial Intelligence**, particularly
  within high-stakes domains like finance and accounting, where near-perfect accuracy
  is non-negotiable. Host Jordan Wilson interviews **Aaron Harris, CTO of Sage**,
  to explore how Sage is engineering trust into its AI offerings, specifically Sage
  Copilot, to meet the stringent demands of financial professionals.


  ---


  ### 1. Focus Area

  The primary focus is **Trustworthy AI in Enterprise Software**, specifically within
  **Financial and Accounting Operations (Back Office)**. Key themes include the inadequacy
  of standard LLM performance (like 90-95% accuracy) for financial reporting, the
  necessity of deterministic, verifiable AI outputs, and the technical and cultural
  shifts required to deploy AI responsibly in regulated industries.


  ### 2. Key Technical Insights

  *   **Hybrid Model Approach for Accuracy:** Sage prioritizes using traditional,
  deterministic methods (like giving an LLM a calculator for math) over relying solely
  on generative models for tasks requiring absolute precision. For complex tasks like
  invoice reading, they built **dozens of specialized, proprietary models** rather
  than relying on off-the-shelf LLMs that might only achieve 75-80% accuracy on critical
  sub-tasks like finding the invoice total.

  *   **Fine-Tuning for Domain Expertise:** To achieve high accuracy and relevance,
  Sage fine-tuned a smaller, more efficient **7-billion-parameter model** (as opposed
  to massive trillion-parameter models). This fine-tuning incorporated product documentation,
  API code, accounting textbooks, and CPA exam materials, effectively creating an
  expert model for their specific domain.

  *   **The Sage AI Factory:** This proprietary infrastructure automates the training,
  deployment, and updating of tens of thousands of models on a customer-by-customer
  basis, while incorporating safety mechanisms to detect **model drift and hallucination**
  (for which Sage has secured patents).


  ### 3. Business/Investment Angle

  *   **Trust as the Ultimate Barrier to Entry:** In finance, the CFO''s credibility
  hinges on perfect accuracy. Any AI mistake erodes trust instantly, meaning the tolerance
  for error is near zero, unlike in creative or strategic applications.

  *   **Shifting from "Move Fast and Break Things":** The mantra for deploying mission-critical
  AI must change to **"Accept humility, embrace responsibility."** Rushing deployment
  leads to irreversible negative first impressions.

  *   **Industry Collaboration for Trust:** Sage is partnering with the **AICPA (American
  Institute of Certified Public Accountants)** to incorporate their professional content
  into model training, signaling a major shift where industry bodies actively contribute
  to building trusted financial AI.


  ### 4. Notable Companies/People

  *   **Aaron Harris (CTO, Sage):** The featured expert, detailing Sage’s technical
  strategy for building trusted, highly accurate AI solutions for accounting, HR,
  and payroll software.

  *   **Sage:** The global software company headquartered in the UK, focusing on back-office
  solutions, and the developer of **Sage Copilot**.

  *   **AICPA:** The professional body accrediting CPAs, whose partnership signifies
  industry validation and contribution to AI development.


  ### 5. Future Implications

  The industry is moving toward **explicit transparency mechanisms** to bridge the
  trust gap left by lagging regulation. The concept of the **"Trust Label"**—a standardized,
  easily digestible "nutrition label" for AI features detailing models used, data
  handling, and safety safeguards—is positioned as a necessary evolution to simplify
  customer evaluation and reduce the burden on technical leadership. This continuous
  commitment to transparency suggests that trust-building features will become standard
  requirements, not optional add-ons, for enterprise AI adoption.


  ### 6. Target Audience

  This episode is highly valuable for **CFOs, Finance Leaders, CTOs, Enterprise Software
  Developers, and AI Product Managers** operating in regulated or high-stakes data
  environments who need to understand the practical engineering required to move beyond
  experimental AI to reliable, production-grade systems.'
tags:
- artificial-intelligence
- generative-ai
- ai-infrastructure
- startup
title: 'Ep 541: AI & Trust: When 98% accuracy won''t cut it and how Sage can fix it'
topics:
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 100
  prominence: 1.0
  topic: artificial intelligence
- keywords:
  - generative ai
  - genai
  - chatgpt
  - gpt
  - claude
  - text generation
  - image generation
  mentions: 6
  prominence: 0.6
  topic: generative ai
- keywords:
  - gpu
  - tensor
  - training
  - inference
  - model deployment
  - vector database
  mentions: 5
  prominence: 0.5
  topic: ai infrastructure
- keywords:
  - startup
  - entrepreneur
  - founder
  - venture
  mentions: 1
  prominence: 0.1
  topic: startup
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-10-05 11:29:48 UTC -->
