---
companies:
- category: unknown
  confidence: medium
  context: This is the Everyday AI Show, the everyday podcast where we simplify AI
    and br
  name: Everyday AI Show
  position: 12
- category: unknown
  confidence: medium
  context: ght. If this is your first time, welcome. This is Everyday AI. My name
    is Jordan Wilson, and welcome. This is y
  name: Everyday AI
  position: 874
- category: unknown
  confidence: medium
  context: st time, welcome. This is Everyday AI. My name is Jordan Wilson, and welcome.
    This is your daily live stream podc
  name: Jordan Wilson
  position: 898
- category: unknown
  confidence: medium
  context: please help me welcome to the show. There we have Smurthy Kurubandandhan.
    Smurthy, thank you for joining the Everyday AI s
  name: Smurthy Kurubandandhan
  position: 2303
- category: unknown
  confidence: medium
  context: rthy, my name is Smurthy Kurubandandhan, based in Los Angeles, meaningful
    couple of decades, but background edu
  name: Los Angeles
  position: 2603
- category: unknown
  confidence: medium
  context: cially now, the world we're living in with AI and Gen AI, the implications
    of that, the usage of that is q
  name: Gen AI
  position: 3414
- category: unknown
  confidence: medium
  context: e you seen that play out in the health tech side? Because I would assume
    it's no different, right? It's one o
  name: Because I
  position: 7440
- category: unknown
  confidence: medium
  context: work on is how do they implement a RAG, which is Retrieval Augmented Generation,
    to make sure that the data that they're extracti
  name: Retrieval Augmented Generation
  position: 9477
- category: unknown
  confidence: medium
  context: 'ant to keep prompting to train it further, right? So I think that would
    be my ask: creating this glass m'
  name: So I
  position: 13267
- category: unknown
  confidence: medium
  context: about RAG, Retrieval Augmented Generation, right? And I don't know, at
    least for me, and maybe it's just
  name: And I
  position: 13427
- category: unknown
  confidence: medium
  context: rsion of, you know, RAG, I think that'd be great. But I think it's very
    important for us to get grounded.
  name: But I
  position: 14804
- category: tech
  confidence: high
  context: oint today where you have open-source models from OpenAI, right, with their
    new GPT OSS, you have new vari
  name: Openai
  position: 19362
- category: unknown
  confidence: medium
  context: -source models from OpenAI, right, with their new GPT OSS, you have new
    variants of, you know, Gemma 3. So
  name: GPT OSS
  position: 19392
- category: ai_infrastructure
  confidence: medium
  context: Mentioned as an example of a rumored $500 billion investment in data centers
    for AI, used to frame a discussion about future AI scaling.
  name: Stargate project
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as a source of open-source models (GPT OSS) that are becoming
    more powerful.
  name: OpenAI
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Specific open-source model variant mentioned from OpenAI.
  name: GPT OSS
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: Mentioned as a new variant of an open-source model, implying a developer
    (likely Google/DeepMind).
  name: Gemma 3
  source: llm_enhanced
- category: organization
  confidence: low
  context: The speaker mentioned talking to the head of the AMA regarding the health
    tech scene and AI adoption.
  name: AMA (American Medical Association)
  source: llm_enhanced
date: 2025-08-21 14:00:00 +0000
duration: 26
has_transcript: false
insights:
- actionable: true
  confidence: medium
  extracted: connect in five years and see whether the world has gone
  text: we should connect in five years and see whether the world has gone.
  type: recommendation
layout: episode
llm_enhanced: true
original_url: https://pscrb.fm/rss/p/www.buzzsprout.com/2175779/episodes/17707963-ep-594-data-dreams-digital-delusions-the-role-of-ai-in-health-tech.mp3
processing_date: 2025-10-04 20:28:33 +0000
quotes:
- length: 136
  relevance_score: 6
  text: Not just data because we know we all need it for large language models, for
    generative AI, for our companies to leverage that technology
  topics: []
- length: 185
  relevance_score: 4
  text: This is a business decision which each company is making in order to be ahead
    in terms of the Gen AI, just as a competition in the market, you by just general
    lean access to data, right
  topics:
  - competition
  - market
- length: 203
  relevance_score: 4
  text: But given the current administration and the regulations, obviously trying
    to move the workforce to the US, have the job market be really strong here, obviously,
    the investments in the US have been large
  topics:
  - market
  - investment
- length: 87
  relevance_score: 4
  text: So you had just mentioned a little bit about RAG, Retrieval Augmented Generation,
    right
  topics: []
- length: 181
  relevance_score: 4
  text: It seems like people are just hoping that, you know, the scaling laws of large
    language models and larger context windows, right, they're going to get rid of
    the need for RAG, right
  topics: []
- length: 122
  relevance_score: 3
  text: The largest companies in the world are spending trillions of dollars building
    out data centers for artificial intelligence
  topics: []
- length: 58
  relevance_score: 3
  text: And artificial intelligence in health tech is also not new
  topics: []
- impact_reason: Directly challenges the assumption that massive data investment solves
    quality issues, focusing on the 'garbage in, garbage out' problem compounded by
    user prompting uncertainty.
  relevance_score: 10
  source: llm_enhanced
  text: how much of this data is truly clean? How much of that is truly modeled? And
    then on the other side, users like you and me and just everyone else, even data
    scientists, how many of them are actually prompting, right? How many of these
    answers are right?
  topic: technical/safety
- impact_reason: Articulates the critical gap between model output, user interaction,
    and the severe consequences of error in regulated or high-stakes environments
    like healthcare.
  relevance_score: 10
  source: llm_enhanced
  text: There's a little bit of, you know, disconnect, I would say, between what's
    being trained, what's being prompted, what's been coming out, and obviously in
    healthcare, the weightage of those outcomes are really, really high stakes.
  topic: safety/technical
- impact_reason: Offers a specific, actionable technical solution (RAG) to combat
    hallucinations and data staleness, emphasizing the need for real-time, cross-checked
    extraction over relying on static, massive datasets.
  relevance_score: 10
  source: llm_enhanced
  text: how much of these models and answers that we are retrieving is accurate, right?
    So some of the things that I do advise clients and work on is how do they implement
    a RAG, which is Retrieval Augmented Generation, to make sure that the data that
    they're extracting is from the right data sets and is being cross-checked live
    and is not just, you know, from the abundance of stored data that is not real-time.
  topic: technical
- impact_reason: Frames RAG not just as a technical tool, but as a necessary 'checkpoint'
    mechanism for data-driven systems, highlighting its foundational importance.
  relevance_score: 10
  source: llm_enhanced
  text: I personally, Jordan, believe that everything in life needs a checkpoint,
    right? Every process needs a checkpoint, and it's healthy for especially a data-driven
    system to have a checkpoint, which is what RAG is in a very simple way, right?
  topic: strategy/technical
- impact_reason: Strongly links RAG/grounding to hallucination prevention and warns
    about the societal risk of unchecked AI output leading to widespread misinformation.
  relevance_score: 10
  source: llm_enhanced
  text: The grounding prevents hallucinations. Without the grounding, we're all just
    taking information and becoming these bodies of misinformation because perception
    is reality. What we read is true.
  topic: safety/technical
- impact_reason: Articulates the unique caution required in healthcare AI adoption,
    emphasizing that stakes are life-and-death, justifying a slower, more deliberate
    pace ('going slow to go fast').
  relevance_score: 10
  source: llm_enhanced
  text: Because healthcare, unlike other industries, such as people's lives, right?
    This is not retail. I mean, obviously, they touch people's lives, but not, you
    know, the actual lives. I think going slow to go fast is important.
  topic: safety/strategy
- impact_reason: Provides a multi-step diagnostic framework for mitigating hallucinations,
    centering the solution on data source verification and RAG grounding.
  relevance_score: 10
  source: llm_enhanced
  text: 'Where is the data being extracted from? That is the first step, right? The
    second one is understanding: is the data that''s being extracted from the prompt,
    is it live? Is it accurate? Is it from a web source? Like, are those sources credible?
    That''s why RAG comes into play, the grounding of that is key.'
  topic: technical/safety
- impact_reason: Provides a concrete, high-stakes example illustrating the catastrophic
    real-world impact (mental, physical, financial) of an AI diagnostic hallucination.
  relevance_score: 10
  source: llm_enhanced
  text: Say someone puts in an MRI and X-ray saying, 'Does this person have, say,
    cancer?' And say the AI system is hallucinating and says, 'Yes, the potential
    of this person having cancer is 80 percent,' and it's wrong. Think about the mental,
    the physical, the financial burden on the patient, on the provider.
  topic: safety
- impact_reason: Highlights the massive, potentially speculative, investment trend
    in AI infrastructure and questions its guaranteed return, especially regarding
    data quality vs. quantity.
  relevance_score: 9
  source: llm_enhanced
  text: The largest companies in the world are spending trillions of dollars building
    out data centers for artificial intelligence. You have single companies investing
    hundreds of billions of dollars hoping that more data and maybe even better data
    will make AI exponentially better. But is that a reality or is that a delusion?
  topic: business/strategy
- impact_reason: Provides a concrete, high-impact use case for Gen AI in healthcare
    (reducing burnout via scribing) and contextualizes it with a concerning statistic
    about physician attrition.
  relevance_score: 9
  source: llm_enhanced
  text: physicians using Gen AI could be for scribing for clinical notes, obviously
    a very positive change given physician burnout, right? A couple of years back,
    we had 800,000 physicians; today, I'm going to say we have 600,000 physicians.
    We're dropping quite a bit, right?
  topic: predictions/business
- impact_reason: Uses the 'organic fruit' analogy to stress the necessity of deep
    provenance checking (source, process) in healthcare AI, where the stakes are human
    lives, unlike consumer labeling.
  relevance_score: 9
  source: llm_enhanced
  text: We have no clue, right? It's a similar example, but the weightage and the
    high stakes of healthcare is really high because, you know, it's we're dealing
    with lives. So it's important for us to really go back to what is the source,
    what is the process, you know, what is the end outcome?
  topic: safety/strategy
- impact_reason: 'Provides direct advice to investors/executives: shift investment
    focus from pure infrastructure to education, RAG implementation, security guardrails,
    and outcome measurement.'
  relevance_score: 9
  source: llm_enhanced
  text: my ask is obviously investments are important, right? But when they're making
    these investments, make the investment, to your point, on data education. What
    does the process look like? Comment on investing in RAG, in the guardrails of
    the framework and security, and then the obviously the end outcomes...
  topic: business/strategy
- impact_reason: Advocates for radical transparency in the AI development pipeline—data
    sources, training frequency, and process—as the foundation for building user trust.
  relevance_score: 9
  source: llm_enhanced
  text: have some kind of a transparency on where, what, what's happening, what data
    sets are they truly using? Like, create like a transparent pipeline on the training,
    what's being trained, how often it's being trained, and then the entire process
    pipeline.
  topic: safety/business
- impact_reason: 'Highlights a current industry debate: whether scaling LLMs inherently
    solves the need for external grounding mechanisms like RAG.'
  relevance_score: 9
  source: llm_enhanced
  text: It seems like people are just hoping that, you know, the scaling laws of large
    language models and larger context windows, right, they're going to get rid of
    the need for RAG, right?
  topic: technical/trends
- impact_reason: Provides a clear, practical definition of RAG emphasizing its role
    in providing real-time, trusted data retrieval.
  relevance_score: 9
  source: llm_enhanced
  text: RAG is when you promise something and then the system is actually actively
    checking from live resources as you type in, and it's not pulling data from something
    stored, you know, 10 years back or 20 years back. So it's more real-time, it's
    accurate data, it's live, which is more trusted.
  topic: technical
- impact_reason: Places the onus on leadership to implement grounding mechanisms (RAG)
    as a core pillar, especially in high-stakes domains like healthcare.
  relevance_score: 9
  source: llm_enhanced
  text: So I think the responsibility and the imperative goes on the leaders to create
    that RAG as a grounding, as an important pillar to be able to do what they're
    doing, especially in healthcare.
  topic: business/safety
- impact_reason: Uses a powerful analogy ('too much sugar') to articulate the problem
    of data abundance—more data isn't automatically better, raising concerns about
    data quality and responsible use.
  relevance_score: 9
  source: llm_enhanced
  text: 'But too much sugar leads to diabetes and other issues, right? So that''s
    where I struggle with quite honestly: as to how much data is good data, and then
    how do you truly make sure this is responsible in execution of data?'
  topic: safety/strategy
- impact_reason: Raises the critical, often overlooked, security threat of adversarial
    actors injecting malicious or confusing data into training sets.
  relevance_score: 9
  source: llm_enhanced
  text: I mean, I discussed, are there bad actors creating fake data sets to confuse
    the system? Possibly, right? So until we get to the point of, you know, a trusted
    way of really managing these data sets and extracting them, I think it's a very
    long and tumultuous process.
  topic: safety
- impact_reason: 'A concise strategic recommendation for high-stakes industries: measured
    deployment is necessary despite the pressure to adopt quickly.'
  relevance_score: 9
  source: llm_enhanced
  text: I think going slow to go fast is important. And hence, I do see why healthcare
    is behind in terms of the implementations and using it because it does—it does
    impact life, right?
  topic: strategy
- impact_reason: Directly addresses the severe downstream consequences of unchecked
    hallucinations in a critical sector, moving beyond mere inaccuracy to real-world
    harm.
  relevance_score: 9
  source: llm_enhanced
  text: How do hallucinations, especially hallucinations that maybe get unchecked
    or kind of go to production on the health tech side, how does that impact, you
    know, research, you know, patient quality of life, and just the overall direction
    of health companies?
  topic: safety
- impact_reason: Sets the central theme of the discussion, contrasting the high hopes
    (dreams) surrounding data investment with the potential pitfalls (delusions) in
    a high-stakes field like health tech.
  relevance_score: 8
  source: llm_enhanced
  text: 'We''re going to be talking about data dreams and digital delusions: the role
    of AI in health tech.'
  topic: strategy
- impact_reason: Introduces the often-overlooked ethical and public health cost of
    AI infrastructure development (environmental and societal impact), framing it
    as a public health call out.
  relevance_score: 8
  source: llm_enhanced
  text: when someone is investing in a data center, I wrote a piece just maybe last
    year on just the sustainable impact of data centers, right? There is a high cost
    on environmental pollution, on just mental health, physical health, and all those
    things that happen in the creation of the data centers.
  topic: safety/ethics
- impact_reason: 'Provides a clear, three-pronged summary of the primary business
    drivers for Gen AI adoption in healthcare leadership: cost reduction, efficiency
    gains, and clinician well-being.'
  relevance_score: 8
  source: llm_enhanced
  text: 'But obviously, the three stacks where I see where leadership is using it
    is one: cost takeout, operational efficiency, obviously reducing burnout for physician,
    physicians and clinicians.'
  topic: business
- impact_reason: Draws a crucial philosophical distinction between 'honesty' (stating
    facts) and 'transparency' (revealing the underlying process/components), which
    is vital for building trust in complex AI systems.
  relevance_score: 8
  source: llm_enhanced
  text: Honesty is saying, 'Smurthy, I went for dinner,' and you say, 'I went to X
    for dinner and it was with friends,' right? That's honesty. But he said what's
    really true or authentic is transparency. If you said, 'I went to Javier's and
    I met Jordan, Eve, and Alice for dinner,' that's transparency, right?
  topic: strategy/ethics
- impact_reason: Identifies the 'chain of thought' reasoning process as a key, measurable
    component of Gen AI performance that needs scrutiny, linking it to accuracy and
    speed.
  relevance_score: 8
  source: llm_enhanced
  text: Because as you know, there is a chain of thought managing Gen AI is reasoning—how
    actively and accurately and how fast is the reasoning happening?
  topic: technical
- impact_reason: 'Summarizes the ultimate goal for trustworthy AI: a completely observable,
    ''glass box'' model where internal processes are visible to auditors and users.'
  relevance_score: 8
  source: llm_enhanced
  text: creating this very glass model of Gen AI, I think would be incredible, right?
  topic: technical/safety
- impact_reason: Advocates for 'glass box' AI, emphasizing the need for interpretability
    and visibility into complex Generative AI systems.
  relevance_score: 8
  source: llm_enhanced
  text: Seeing that, like creating this very glass model of Gen AI, I think would
    be incredible, right?
  topic: strategy/technical
- impact_reason: Describes RAG's role in complex operational scenarios (like insurance
    claims) as an objective 'source of truth' and accountability mechanism.
  relevance_score: 8
  source: llm_enhanced
  text: It's almost like how do you—it's kind of a mediator that holds both parties
    accountable and holds like a source of truth. So to me, I think it is important.
  topic: business/strategy
- impact_reason: Identifies the shift towards powerful, deployable open-source models
    and questions its specific impact on highly regulated sectors like health tech.
  relevance_score: 8
  source: llm_enhanced
  text: But now as we look forward, okay, we are at a point today where you have open-source
    models from OpenAI, right, with their new GPT OSS, you have new variants of, you
    know, Gemma 3. So you have models that are open source, you can download them,
    you can run them on-prem, no internet, anything else, right, that are more powerful
    than what we had 18 months ago. How might this change?
  topic: trends/business
- impact_reason: Illustrates a common career pivot/upskilling path in the current
    tech landscape—combining domain expertise (public health) with necessary technical
    skills (data science).
  relevance_score: 7
  source: llm_enhanced
  text: My background education is primarily in robotics and public health. Also recently
    completing my master's in data science because I figured that's where the world
    is going.
  topic: strategy/career
- impact_reason: Connects massive AI infrastructure investment directly to geopolitical
    and regulatory incentives (onshoring/job creation), showing external drivers beyond
    pure technological need.
  relevance_score: 7
  source: llm_enhanced
  text: But given the current administration and the regulations, obviously trying
    to move the workforce to the US, have the job market be really strong here, obviously,
    the investments in the US have been large.
  topic: business/strategy
- impact_reason: A classic, timely reminder about the ethical obligations accompanying
    the massive investment and power of modern AI infrastructure.
  relevance_score: 7
  source: llm_enhanced
  text: With great power comes great responsibility. I just don't want people to forget
    that.
  topic: safety/strategy
source: Unknown Source
summary: '## Podcast Episode Summary: EP 594: Data Dreams & Digital Delusions: The
  role of AI in health tech


  This episode of the Everyday AI Show, hosted by Jordan Wilson, features guest Smurthy
  Kurubandandhan, a health tech executive with expertise in robotics, public health,
  and data science. The core discussion revolves around the massive, multi-billion
  dollar investments in AI data centers and infrastructure, questioning whether this
  scale of investment truly translates into exponentially better, safer outcomes,
  particularly in the high-stakes environment of health technology. The conversation
  balances the excitement around AI''s potential with the critical need for data integrity,
  transparency, and robust grounding mechanisms to prevent "digital delusions" like
  hallucinations.


  ### 1. Focus Area

  The primary focus is the **application, challenges, and strategic investment surrounding
  Artificial Intelligence (specifically Generative AI) within the Health Tech sector.**
  Key themes include the necessity of data quality over sheer quantity, the risk of
  AI hallucinations in clinical settings, and the strategic implementation of grounding
  techniques like RAG.


  ### 2. Key Technical Insights

  *   **The Criticality of RAG (Retrieval Augmented Generation):** RAG is emphasized
  as a vital technical checkpoint to ground AI outputs in live, accurate data sources,
  preventing hallucinations. Without this grounding, systems risk becoming "bodies
  of misinformation," which is unacceptable in healthcare.

  *   **Transparency in the AI Pipeline:** The need for a "glass model" of Gen AI
  was proposed, where organizations must be transparent about the data sets used for
  training, the frequency of retraining, and the reasoning chain of the model to build
  trust and accountability.

  *   **Data Volume vs. Data Quality:** The discussion challenges the assumption that
  simply accumulating massive amounts of data (as evidenced by huge data center investments)
  will automatically solve AI problems. The quality, cleanliness, and relevance of
  the data are paramount, especially when dealing with high-stakes decisions.


  ### 3. Business/Investment Angle

  *   **Investment Drivers are Competitive:** Large-scale data center investments
  are driven by a business imperative to maintain a competitive edge in the Gen AI
  market, often coupled with geopolitical incentives (e.g., US-based job creation).

  *   **Focus Beyond Infrastructure:** While infrastructure spending is high, there
  is a call for responsible investment that includes funding for **data education,
  implementing robust guardrails (like RAG), and security frameworks**, rather than
  just raw compute power.

  *   **Health Tech Adoption Pace:** Healthcare is lagging in widespread Gen AI implementation
  compared to other sectors due to the extreme sensitivity surrounding patient lives
  (PHI) and the high cost of errors, necessitating a "slow to go fast" approach.


  ### 4. Notable Companies/People

  *   **Smurthy Kurubandandhan:** The expert guest, whose background spans robotics,
  public health, and data science, provided the critical perspective on balancing
  technological advancement with public health responsibility.

  *   **Large Tech Companies:** Mentioned generally as the entities making "hundreds
  of billions of dollars" in data center investments (e.g., referencing the scale
  of projects like Stargate).

  *   **OpenAI/Gemma:** Mentioned in the context of the growing availability of powerful,
  downloadable, open-source models, which could accelerate adoption in privacy-conscious
  sectors like health tech if run on-premise.


  ### 5. Future Implications

  The industry is heading toward a necessary reckoning where **data integrity and
  verifiable reasoning will supersede raw model size.** There is an expectation that
  AI will significantly reduce physician burnout (e.g., through clinical note scribing)
  and optimize enterprise functions (HR, supply chain, F&A). However, the future success
  in health tech hinges on establishing **unwavering transparency and accountability**
  to mitigate the catastrophic impact of unchecked hallucinations on patient care,
  finances, and mental well-being.


  ### 6. Target Audience

  This episode is highly valuable for **Health Tech Executives, Digital Health Strategists,
  AI Product Leaders, and Investors** focused on the intersection of AI infrastructure
  and regulated industries. It provides actionable insights on implementation strategy
  (RAG) and risk management in high-stakes data environments.'
tags:
- artificial-intelligence
- investment
- generative-ai
- ai-infrastructure
- startup
- openai
title: 'EP 594: Data Dreams & Digital Delusions: The role of AI in health tech'
topics:
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 66
  prominence: 1.0
  topic: artificial intelligence
- keywords:
  - investment
  - funding
  - valuation
  - ipo
  - acquisition
  mentions: 19
  prominence: 1.0
  topic: investment
- keywords:
  - generative ai
  - genai
  - chatgpt
  - gpt
  - claude
  - text generation
  - image generation
  mentions: 3
  prominence: 0.3
  topic: generative ai
- keywords:
  - gpu
  - tensor
  - training
  - inference
  - model deployment
  - vector database
  mentions: 1
  prominence: 0.1
  topic: ai infrastructure
- keywords:
  - startup
  - entrepreneur
  - founder
  - venture
  mentions: 1
  prominence: 0.1
  topic: startup
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-10-04 20:28:33 UTC -->
