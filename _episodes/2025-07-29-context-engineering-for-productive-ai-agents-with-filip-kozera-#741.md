---
companies:
- category: tech
  confidence: high
  context: This podcast is supported by Google. Hi folks, Paige Bailey here from the
    Google Deep
  name: Google
  position: 29
- category: unknown
  confidence: medium
  context: This podcast is supported by Google. Hi folks, Paige Bailey here from the
    Google DeepMind DevRel team. For ou
  name: Paige Bailey
  position: 47
- category: unknown
  confidence: medium
  context: d by Google. Hi folks, Paige Bailey here from the Google DeepMind DevRel
    team. For our developers out there, we know there
  name: Google DeepMind DevRel
  position: 74
- category: unknown
  confidence: medium
  context: ight, everyone. Welcome to another episode of the TWIM AI podcast. I am
    your host, Sam Charrington. Today,
  name: TWIM AI
  position: 1215
- category: unknown
  confidence: medium
  context: r episode of the TWIM AI podcast. I am your host, Sam Charrington. Today,
    I'm joined by Philip Prezerra. Philip is
  name: Sam Charrington
  position: 1248
- category: unknown
  confidence: medium
  context: your host, Sam Charrington. Today, I'm joined by Philip Prezerra. Philip
    is founder and CEO at Wordware. Before we
  name: Philip Prezerra
  position: 1286
- category: unknown
  confidence: medium
  context: ays-on listening devices based on GPT-2 and BERT. And I must say I was
    a little bit before my time. It fe
  name: And I
  position: 2419
- category: unknown
  confidence: medium
  context: rOff. We don't talk about these moments enough in Silicon Valley. It's
    always so grind, grind, grind. But I sailed
  name: Silicon Valley
  position: 2705
- category: unknown
  confidence: medium
  context: licon Valley. It's always so grind, grind, grind. But I sailed the Atlantic,
    I climbed a couple peaks in
  name: But I
  position: 2757
- category: unknown
  confidence: medium
  context: ing to the underlying tools and what they can do. So I did it out like
    to bring a world where we have an
  name: So I
  position: 9010
- category: unknown
  confidence: medium
  context: we're currently in a closed beta for the kind of AI OS product. And we
    basically have, you know, a macOS
  name: AI OS
  position: 15725
- category: unknown
  confidence: medium
  context: ke, hey, actually, if I would have scraped all of Stack Overflow, those
    probably 400 instances of this question be
  name: Stack Overflow
  position: 19001
- category: unknown
  confidence: medium
  context: e in 2025, we are pivoting away from $10 million? Like Monas had $20 million
    of ARR and they pivoted away. And
  name: Like Monas
  position: 22378
- category: unknown
  confidence: medium
  context: ou don't have data like access to, you know, your Google Sheets and your
    Notion, you cannot respond or draft a re
  name: Google Sheets
  position: 23943
- category: tech
  confidence: high
  context: access to, you know, your Google Sheets and your Notion, you cannot respond
    or draft a response to an ema
  name: Notion
  position: 23966
- category: unknown
  confidence: medium
  context: a, a, a, a particular of Flash, how is it called? Not Flashpoint. Like
    holding all of your, all of your Slack data
  name: Not Flashpoint
  position: 24385
- category: unknown
  confidence: medium
  context: who, you know, like I can see what they're doing. Like I can see that they
    want to become a universal AI a
  name: Like I
  position: 25661
- category: unknown
  confidence: medium
  context: e? Yeah. Oh, this look like when we have that AI, Johnny AI stuff that
    just like that, uh, OpenAI is paying $
  name: Johnny AI
  position: 26550
- category: tech
  confidence: high
  context: that AI, Johnny AI stuff that just like that, uh, OpenAI is paying $6.5
    billion for, and it just listens t
  name: Openai
  position: 26591
- category: unknown
  confidence: medium
  context: it without having to add a bot into your meeting. Which I think is the
    main innovation of Granola is that y
  name: Which I
  position: 32665
- category: big_tech
  confidence: high
  context: The podcast is supported by Google. Mentioned in relation to Google DeepMind
    DevRel team and Gemini 2.5 Flash.
  name: Google
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Paige Bailey is from the Google DeepMind DevRel team.
  name: Google DeepMind
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: A specific model/product developed by Google/DeepMind, discussed for its
    speed and reasoning power.
  name: Gemini 2.5 Flash
  source: llm_enhanced
- category: ai_startup
  confidence: high
  context: Philip Prezerra's company, focused on building software where words are
    the code (natural language programming) and building companion agents.
  name: Wordware
  source: llm_enhanced
- category: ai_research
  confidence: medium
  context: Mentioned as precursors to the Transformer architecture, indicating research/historical
    context in neural networks.
  name: LSTMs
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: The foundational architecture for modern LLMs, mentioned in the context
    of historical research.
  name: Transformer architecture
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: An early language model used by the speaker in a previous company venture.
  name: GPT-2
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: An early language model used by the speaker in a previous company venture.
  name: BERT
  source: llm_enhanced
- category: company_exit
  confidence: high
  context: The company the speaker exited before starting Wordware.
  name: CareerOff
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as an existing tool for building agentic workflows, contrasting
    with Wordware's natural language approach.
  name: Zapier
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned alongside Zapier as a tool for building agentic workflows.
  name: Make
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: A specific agentic framework/technique (Reasoning and Acting) used by Wordware's
    execution system.
  name: ReAct agent
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: Likely referring to Anthropic's Claude Opus model, mentioned in the context
    of context window size (200,000 tokens).
  name: Opus
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Mentioned in the context of context window size (1 million tokens), referring
    to Google's models.
  name: Gemini
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: Mentioned as a known agent communication schema, which Wordware's internal
    system partially overlaps with.
  name: A2A (Agent-to-Agent protocol)
  source: llm_enhanced
- category: ai_research
  confidence: medium
  context: Mentioned alongside A2A as a schema for tool communication.
  name: ACP (Agent Communication Protocol)
  source: llm_enhanced
- category: external_service
  confidence: medium
  context: Mentioned as an external service/website that a tool might call (e.g.,
    'walk out my dog' tool calling Rover website).
  name: Rover
  source: llm_enhanced
- category: ai_startup
  confidence: high
  context: Mentioned as an example of an agentic swarm coding tool.
  name: Graphi
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as an agentic coding tool that engineers work with.
  name: Codex
  source: llm_enhanced
- category: ai_startup
  confidence: high
  context: Mentioned as an agentic coding tool that engineers work with.
  name: Devin
  source: llm_enhanced
- category: investment_accelerator
  confidence: high
  context: Y Combinator, the accelerator from which the speaker's company raised their
    biggest round.
  name: YC
  source: llm_enhanced
- category: ai_startup
  confidence: high
  context: Mentioned as a company that pivoted despite having $10 million ARR, illustrating
    the high bar in the AI market.
  name: Winsurf
  source: llm_enhanced
- category: ai_startup
  confidence: high
  context: Mentioned as a company that pivoted away from $20 million ARR, illustrating
    the high bar in the AI market.
  name: Monas
  source: llm_enhanced
- category: enterprise_software
  confidence: high
  context: Mentioned regarding blocking API access for Glean and their position as
    a major enterprise data silo owner.
  name: Salesforce
  source: llm_enhanced
- category: enterprise_software
  confidence: high
  context: Mentioned regarding blocking API access for Glean and restricting data
    holding in new terms and conditions.
  name: Slack
  source: llm_enhanced
- category: ai_startup
  confidence: high
  context: A company dependent on accessing customer data silos, whose API access
    was reportedly blocked by Salesforce and Slack.
  name: Glean
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: Mentioned for offering an offering that allows site owners to charge agents
    to scrape content.
  name: Cloudflare
  source: llm_enhanced
- category: productivity_software
  confidence: high
  context: Mentioned as a key data silo/application whose data access is being fought
    over by AI agents.
  name: Notion
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: Mentioned in the context of European data access competition.
  name: ChatGPT
  source: llm_enhanced
- category: ai_startup
  confidence: high
  context: Mentioned as a company aiming to become a universal AI agent, potentially
    losing money on transcription to acquire data.
  name: Granola
  source: llm_enhanced
- category: ai_company
  confidence: high
  context: Mentioned in relation to the $6.5 billion deal for 'AI, Johnny AI stuff'
    that listens to everything (likely referring to a specific acquisition or product
    like the rumored Scarlett Johansson voice integration or a similar audio AI venture).
  name: OpenAI
  source: llm_enhanced
- category: productivity_software
  confidence: high
  context: Mentioned as a project manager like Asana, whose core value proposition
    might be shifting due to data ownership dynamics.
  name: ClickUp
  source: llm_enhanced
- category: productivity_software
  confidence: medium
  context: Used as a comparison point for ClickUp.
  name: Asana
  source: llm_enhanced
date: 2025-07-29 19:37:00 +0000
duration: 46
has_transcript: false
insights:
- actionable: true
  confidence: medium
  extracted: force people to describe it a little bit more
  text: we should force people to describe it a little bit more.
  type: recommendation
- actionable: true
  confidence: medium
  extracted: know whether that authority has been given to that particular tool
  text: we should know whether that authority has been given to that particular tool.
  type: recommendation
- actionable: false
  confidence: medium
  extracted: work will look, it's exactly that. It's the data that the agent cannot
    find, the taste or creativity that it cannot come up with on its own, surfaces
    to the human as work. All right, everyone. Welcome to another episode of the TWIM
    AI podcast. I am your host, Sam Charrington. Today, I'm joined by Philip Prezerra.
    Philip
  text: the future of work will look, it's exactly that. It's the data that the agent
    cannot find, the taste or creativity that it cannot come up with on its own, surfaces
    to the human as work. All right, everyone. Welcome to another episode of the TWIM
    AI podcast. I am your host, Sam Charrington. Today, I'm joined by Philip Prezerra.
    Philip is founder and CEO at Wordware.
  type: prediction
- actionable: false
  confidence: medium
  extracted: work, the fight happening at the application layer. All of these things
    will be interesting to dig into together. But let's get started by having you
    share a little bit about your background and introduce yourself to our audience.
    Sure. So very long story short, I actually was pretty lucky with my choice of
    research. I did research into essentially LSTMs back in 2016, which were the precursors
    to the Transformer architecture. In 2018, I started my first company trying to
    document human memory with always-on listening devices based on GPT-2 and BERT.
    And I must say I was a little bit before my time. It felt like banging my head
    against the wall sometimes with GPT-2, you know, surely promising but not really
    being there. Again, long story short, ended up exiting that company to CareerOff.
    We don't talk about these moments enough in Silicon Valley. It's always so grind,
    grind, grind. But I sailed the Atlantic, I climbed a couple peaks in Nepal, and
    I was back at it. And this time around, we essentially approached Wordware as
    the new software where the words are actually the code, hence kind of the new
    take on natural language programming. In the beginning, we were a much more developer-focused
    platform. We found some fault in our hypotheses, and right now, we're building
    Wordware as essentially a companion that helps you build other background agents.
    And we can get into what background agents are in a second. That's super interesting.
    And right now, there's a big risk that this suddenly becomes a sailing podcast.
    We'll dig into that topic, but I'm going to resist that and talk a little bit
    more about the agentics side of things. You know, when I looked at what you guys
    are doing, it touched on some themes that I found super interesting. I've built
    a bunch of agentic workflows with tools like Zapier and Make and the like. And
    your proposition to users
  text: the future of work, the fight happening at the application layer. All of these
    things will be interesting to dig into together. But let's get started by having
    you share a little bit about your background and introduce yourself to our audience.
    Sure. So very long story short, I actually was pretty lucky with my choice of
    research. I did research into essentially LSTMs back in 2016, which were the precursors
    to the Transformer architecture. In 2018, I started my first company trying to
    document human memory with always-on listening devices based on GPT-2 and BERT.
    And I must say I was a little bit before my time. It felt like banging my head
    against the wall sometimes with GPT-2, you know, surely promising but not really
    being there. Again, long story short, ended up exiting that company to CareerOff.
    We don't talk about these moments enough in Silicon Valley. It's always so grind,
    grind, grind. But I sailed the Atlantic, I climbed a couple peaks in Nepal, and
    I was back at it. And this time around, we essentially approached Wordware as
    the new software where the words are actually the code, hence kind of the new
    take on natural language programming. In the beginning, we were a much more developer-focused
    platform. We found some fault in our hypotheses, and right now, we're building
    Wordware as essentially a companion that helps you build other background agents.
    And we can get into what background agents are in a second. That's super interesting.
    And right now, there's a big risk that this suddenly becomes a sailing podcast.
    We'll dig into that topic, but I'm going to resist that and talk a little bit
    more about the agentics side of things. You know, when I looked at what you guys
    are doing, it touched on some themes that I found super interesting. I've built
    a bunch of agentic workflows with tools like Zapier and Make and the like. And
    your proposition to users is that you allow them to build these kinds of workflows
    or agents with natural language, as opposed to dragging boxes around and doing
    a lot of pointy-clicky, which sounds really interesting.
  type: prediction
- actionable: false
  confidence: medium
  extracted: work will look like, it's exactly that. It's the data that the agent
    cannot find, the taste or creativity that it cannot, you know, come up with on
    its own, surfaces to the human as work. And, you know, that's on the, that's on
    the reflection part of things. So how to figure out what tool to use and when.
    But there
  text: the future of work will look like, it's exactly that. It's the data that the
    agent cannot find, the taste or creativity that it cannot, you know, come up with
    on its own, surfaces to the human as work. And, you know, that's on the, that's
    on the reflection part of things. So how to figure out what tool to use and when.
    But there is also a part where it just lacks the right tools.
  type: prediction
- actionable: false
  confidence: medium
  extracted: like developing new programming paradigms and frameworks and the like.
    And the example that comes to mind and illustrates this for me
  text: the future of like developing new programming paradigms and frameworks and
    the like. And the example that comes to mind and illustrates this for me is AIs
    are really good at like creating React applications.
  type: prediction
layout: episode
llm_enhanced: true
original_url: https://pscrb.fm/rss/p/traffic.megaphone.fm/MLN9863568954.mp3?updated=1753817752
processing_date: 2025-10-04 22:34:54 +0000
quotes:
- length: 124
  relevance_score: 3
  text: But actually, what we found out is that it's good to have a graceful kind
    of graceful ability to fail in that aspect as well
  topics: []
- impact_reason: Introduces a practical control mechanism ('thinking budgets') for
    developers to manage the trade-off between model intelligence, speed, and cost
    in deployment.
  relevance_score: 10
  source: llm_enhanced
  text: And crucially, we've added controls, like setting thinking budgets, so you
    can decide how much reasoning to apply, optimizing for latency and costs.
  topic: Technical insights/Business advice
- impact_reason: 'Provides a crucial insight into building robust agents: the necessity
    of structured human-in-the-loop feedback within iterative processes (reflection
    loops).'
  relevance_score: 10
  source: llm_enhanced
  text: What you end up needing to do is incorporate human feedback even inside of
    these reflection loops. So basically the job becomes how to make sure that the
    agent knows what it doesn't know and to bring in the human at the right time into
    these reflection loops.
  topic: Safety/Practical lessons
- impact_reason: A strong metaphor positioning natural language as the fundamental,
    low-level interface for interacting with LLMs.
  relevance_score: 10
  source: llm_enhanced
  text: The thing that matters the most right now is the natural language. It is essentially
    the assembly code of LLMs, and putting that abstraction front and center is very
    important.
  topic: Strategy/Technical insights
- impact_reason: Offers a concrete, empirical limitation regarding context window
    management and tool proliferation, suggesting diminishing returns or confusion
    when too many tools are presented to advanced models.
  relevance_score: 10
  source: llm_enhanced
  text: We have seen like a big, big drop in performance when presenting like even
    Opus 4 with more than 15 tools.
  topic: Technical insights/Limitations
- impact_reason: 'Lists critical missing metadata fields for robust tool definitions:
    required context, error feedback mechanisms, and authorization levels.'
  relevance_score: 10
  source: llm_enhanced
  text: Required context, because if you just end up calling the tool and not giving
    it the right context to kind of move forward on that task, let's use less. It
    should have feedback in some way. So if you already call that tool and that tool
    returned an error, you kind of want to call it again from the main agent and give
    it feedback. Authority is an important one.
  topic: Safety/Practical lessons
- impact_reason: 'Draws a powerful analogy: just as GUIs were the UX for humans interacting
    with databases, new protocols (like enhanced MCPs) are needed as the ''UX for
    agents.'''
  relevance_score: 10
  source: llm_enhanced
  text: I just know that like, basically, you need to find yourself on the right side
    of the wave. So it seems right now that an MCP is a wave, which essentially means
    that people are putting, you know, for the last 20 years, we've been putting a
    GUI on top of databases. And that's called essentially a UX for humans. And what
    we're trying to do right now is to try to define what is the best UX for agents
    to interact with that particular database...
  topic: Strategy/Predictions
- impact_reason: 'Provides a concise definition of the core challenge in building
    reliable autonomous systems: uncertainty quantification and timely human escalation.'
  relevance_score: 10
  source: llm_enhanced
  text: basically the job becomes how to make sure that the agent knows what it doesn't
    know and to bring in the human at the right time into these reflection loops.
  topic: safety/strategy
- impact_reason: 'A powerful prediction about the shift in developer roles due to
    agentic tools: moving from individual contributor to manager/overseer of AI agents.'
  relevance_score: 10
  source: llm_enhanced
  text: your job becomes, you know, the agent becomes less of an augment, you know,
    a way to augment you as a developer, but a way to augment you as a developer manager
    kind of thing.
  topic: predictions
- impact_reason: 'Highlights a crucial future requirement: documentation must be optimized
    for AI consumption, not just human readability, to drive adoption of new tech.'
  relevance_score: 10
  source: llm_enhanced
  text: I've got to make it really easy for agents to kind of take all the, you know,
    documentation, for example, you know, it becomes really key, but not necessarily
    for the humans, but for the AIs that will need to consume it so that they can
    help people write code with it.
  topic: technical/strategy
- impact_reason: 'Identifies a major emerging threat: data platform owners restricting
    third-party agent/AI access to proprietary data silos, impacting data liberation
    efforts.'
  relevance_score: 10
  source: llm_enhanced
  text: Salesforce and Slack blocking API access for Glean, which I think has a lot
    of implications for a company like yours that depends on getting access to, you
    know, your customers' data in these silos.
  topic: business/safety
- impact_reason: Provides concrete evidence (Slack T&Cs) of major platforms actively
    restricting data portability to maintain control, creating friction for external
    AI services.
  relevance_score: 10
  source: llm_enhanced
  text: one is that like people will start closing it off. And we can see Slack basically
    in their new terms and conditions basically blocks you from holding a, a, a, a
    particular of Flash, how is it called? Not Flashpoint. Like holding all of your,
    all of your Slack data.
  topic: safety/business
- impact_reason: Specifically targets CRM/ERP, arguing their core value is data lock-in,
    making them vulnerable to agents that can bypass the traditional UX.
  relevance_score: 10
  source: llm_enhanced
  text: But, you know, for things like CRM and things like ERP systems and many of
    the tools, particularly in enterprise, like the business logic is relatively thin.
    And the value is in, you know, the data that, you know, the users have put into
    this database.
  topic: predictions
- impact_reason: 'Explains the existential threat AI agents pose to incumbents like
    Salesforce: agents become the new ''front door,'' bypassing the proprietary application
    interface.'
  relevance_score: 10
  source: llm_enhanced
  text: And if this, this front end, the front door to that is shifting from a UX
    to something else to an agent, uh, you know, Salesforce and, you know, others
    who have all this data are, you know, they don't want to necessarily see that
    front door experience clawed back by like publishing an MCP and letting users
    bypass, you know, that Salesforce experience.
  topic: business/strategy
- impact_reason: 'Core insight: AI agents eliminate the need for polished, human-centric
    UX by allowing direct, natural language querying of underlying data structures
    (like a database).'
  relevance_score: 10
  source: llm_enhanced
  text: But then AI steps in and, uh, hey, like the, uh, the user experience that
    needs to be beautiful for humans can be just as like a freaking SQL database and
    you have all the information very easily accessible.
  topic: technical/predictions
- impact_reason: Identifies LLM code generation (specifically SQL) as the 'magical
    part' that transforms the prompt into a powerful, data-accessing interface, effectively
    replacing traditional application logic.
  relevance_score: 10
  source: llm_enhanced
  text: One thing that AI is great at is writing SQL queries. So, uh, you know, then,
    yeah. So that's the magical part, right? The whole UX ends up being at prompt
    with an ability to write code being in this case SQL and the data.
  topic: technical
- impact_reason: 'Highlights a key trend in model development: balancing speed (latency)
    with enhanced reasoning capabilities, specifically naming a new model iteration.'
  relevance_score: 9
  source: llm_enhanced
  text: Gemini 2.5 Flash aims right at that challenge. It's got the speed you expect
    from Flash, but with upgraded reasoning power.
  topic: AI technology trends
- impact_reason: Challenges a common misconception in agent design, suggesting power
    doesn't automatically equate to autonomy.
  relevance_score: 9
  source: llm_enhanced
  text: I think a lot of people think that more powerful agents mean more autonomous
    agents. I actually think that's false.
  topic: Predictions/Strategy
- impact_reason: 'Defines the future division of labor between humans and AI agents:
    humans handle gaps in knowledge, taste, and creativity.'
  relevance_score: 9
  source: llm_enhanced
  text: It's the data that the agent cannot find, the taste or creativity that it
    cannot come up with on its own, surfaces to the human as work.
  topic: Predictions/Future of work
- impact_reason: 'Defines the core philosophy of Wordware: treating natural language
    instructions as executable code.'
  relevance_score: 9
  source: llm_enhanced
  text: We essentially approached Wordware as the new software where the words are
    actually the code, hence kind of the new take on natural language programming.
  topic: Business/Strategy
- impact_reason: 'Articulates the strategy of abstracting complexity: keeping the
    powerful underlying engine while simplifying the user input mechanism to natural
    language documents.'
  relevance_score: 9
  source: llm_enhanced
  text: We essentially want to simplify the entry point toward where the engine stays
    the same, but we kind of want to make sure that humans know how to express the
    idea and the assignment for the agent. And as long as they can write it in a document
    format, it can be executed.
  topic: Business advice
- impact_reason: Explains the inherent cost/latency trade-off when relying on highly
    flexible, reasoning-based agents (like ReAct) versus explicit, deterministic tool
    calls.
  relevance_score: 9
  source: llm_enhanced
  text: Obviously at the beginning, the latency and the cost of it is much higher
    because you are essentially using a ReAct agent behind all of it, trying to make
    sense of it and not make explicit tool calls, but rather have that agent decide
    on what to call, what code to write, etc.
  topic: Technical insights/Cost management
- impact_reason: Explicitly names and recommends the ReAct (Reasoning and Acting)
    framework as the mechanism for tool selection within the agent loop.
  relevance_score: 9
  source: llm_enhanced
  text: And once it starts on the assignment, it uses a ReAct agent, that's a very
    famous paper, I'll recommend reading, and basically calls different tools in their
    reflection loop.
  topic: Technical insights
- impact_reason: Critiques the inherent limitations of simple descriptions (like standard
    MCP metadata) and advocates for richer, more structured metadata for tools.
  relevance_score: 9
  source: llm_enhanced
  text: That sticky note lacks things. So it lacks a couple of different, in the end,
    it's still a description. It's just we should force people to describe it a little
    bit more. So things that we are thinking of as only as good as the description
    that people are giving to the underlying tools and what they can do.
  topic: Strategy/Technical insights
- impact_reason: 'Identifies a critical bottleneck: the data beautifully structured
    for human consumption (GUIs) is not yet structured for agent consumption, necessitating
    new interaction paradigms.'
  relevance_score: 9
  source: llm_enhanced
  text: '...it''s just people are catching on that if you''re linear, you need to
    actually put out a way for agents to interact with all of that data that you,
    you know, beautifully present to humans, but have not found the way to present
    to AI.'
  topic: Strategy/Future of work
- impact_reason: 'Defines a critical emerging problem: designing the User Experience
    (UX) not for humans, but for other AI agents interacting with data systems.'
  relevance_score: 9
  source: llm_enhanced
  text: what we're trying to do right now is to try to define what is the best UX
    for agents to interact with that particular database, which, you know, both SaaS
    as a database with some manipulation and a graphical interface.
  topic: technical/predictions
- impact_reason: Points out the current gap where data presentation optimized for
    humans is inaccessible or unusable by AI agents, necessitating new interface layers.
  relevance_score: 9
  source: llm_enhanced
  text: It's just people are catching on that if you're linear, you need to actually
    put out a way for agents to interact with all of that data that you, you know,
    beautifully present to humans, but have not found the way to present to AI.
  topic: strategy/technical
- impact_reason: A counter-intuitive and important distinction challenging the common
    assumption that increased capability automatically leads to reduced human oversight.
  relevance_score: 9
  source: llm_enhanced
  text: I actually think that's false [that more powerful agents mean more autonomous
    agents].
  topic: safety/strategy
- impact_reason: Draws a direct analogy between managing highly skilled but flawed
    junior staff (interns) and managing AI outputs, highlighting delegation skill
    as key.
  relevance_score: 9
  source: llm_enhanced
  text: I think about the people who have had experience managing interns, have faced
    in our extremely good technically, but know which parts to delegate.
  topic: business/strategy
- impact_reason: 'Identifies the boundary of current AI utility: problems lacking
    sufficient training data require human intervention, even for expert engineers.'
  relevance_score: 9
  source: llm_enhanced
  text: in the particular parts where you as an engineer understand that there is
    not much training data for that particular problem, then you end up solving it
    yourself.
  topic: technical/limitations
- impact_reason: Emphasizes the strategic importance of understanding the underlying
    training data landscape to predict where an LLM will perform well.
  relevance_score: 9
  source: llm_enhanced
  text: This is very important to kind of understand for which problem there is a
    lot of training data and kind of develop that intuition to be like, hey, actually,
    if I would have scraped all of Stack Overflow, those probably 400 instances of
    this question being asked, that's that's perfect.
  topic: strategy/technical
- impact_reason: Illustrates the extreme speed and volatility of the AI market, where
    established strategies can be invalidated by sudden shifts in adjacent technology
    trends (like the resurgence of low-code).
  relevance_score: 9
  source: llm_enhanced
  text: we realized that we're going against low-code. A year ago, low-code wasn't
    really that big of a thing, you know, and it's just such a crazy industry.
  topic: business
- impact_reason: Points to the monetization/gatekeeping of web scraping for AI agents,
    suggesting a future where data access is explicitly priced.
  relevance_score: 9
  source: llm_enhanced
  text: Cloudflare came out with an offering that, you know, going to allow publishers
    or site owners to charge agents to come and scrape their content.
  topic: business/predictions
- impact_reason: Establishes the fundamental dependency of knowledge work automation
    on seamless, comprehensive access to internal, siloed data sources.
  relevance_score: 9
  source: llm_enhanced
  text: automating all of these tasks requires the access to all of that data. If
    you don't have data like access to, you know, your Google Sheets and your Notion,
    you cannot respond or draft a response to an email asking for a particular update
    about some financial metric.
  topic: technical/business
- impact_reason: Predicts the risk of data fragmentation where major platforms build
    proprietary, walled-garden AI agents, leading to inefficiency and increased cost
    for users.
  relevance_score: 9
  source: llm_enhanced
  text: it might be that everyone becomes really greedy. And everyone who has that
    data will try to become their own AI agent. So you'll have an AI agent with Notion,
    with Slack, and they will charge you for each call. I think that will be suboptimal.
  topic: predictions/business
- impact_reason: Highlights a critical trend where platform providers (like Slack)
    are restricting third-party access to user data via ToS changes, directly impacting
    AI agent builders like Glean.
  relevance_score: 9
  source: llm_enhanced
  text: And what I'm seeing is three different ways that this can play out. So one
    is, maybe two, one is that like people will start closing it off. And we can see
    Slack basically in their new terms and conditions basically blocks you from holding
    a, a, a, a particular of Flash, how is it called? Not Flashpoint. Like holding
    all of your, all of your Slack data.
  topic: business/strategy
- impact_reason: References a major investment/acquisition (likely relating to voice
    AI/ambient computing, e.g., Humane/Aura/OpenAI's rumored plans) and highlights
    the friction when data ownership clashes with AI service provision.
  relevance_score: 9
  source: llm_enhanced
  text: And I'm like, oh, shit. So you guys are like, yeah, it's hiding from me. And
    it's an interesting, like, you know, way in, you know, how will this look like?
    Yeah. Oh, this look like when we have that AI, Johnny AI stuff that just like
    that, uh, OpenAI is paying $6.5 billion for, and it just listens to everything.
  topic: technical/business
- impact_reason: 'Provides a fundamental re-framing of enterprise software value:
    it''s often just a thin UX layer over valuable stored data.'
  relevance_score: 9
  source: llm_enhanced
  text: a lot of the apps we use are UX on a database. And the value, and maybe that's
    an oversimplification. Maybe it's a UX on some business logic on a database.
  topic: strategy
- impact_reason: 'Pinpoints the core competitive advantage: seamless, background data
    capture without requiring users to manually add a bot or third-party participant
    to a meeting.'
  relevance_score: 9
  source: llm_enhanced
  text: Which I think is the main innovation of Granola is that you don't have to
    have this upward third thing.
  topic: technical/strategy
- impact_reason: An anecdote illustrating the difficulty and premature timing of early
    LLM applications before models reached sufficient capability (pre-GPT-3/4 era).
  relevance_score: 8
  source: llm_enhanced
  text: In 2018, I started my first company trying to document human memory with always-on
    listening devices based on GPT-2 and BERT. And I must say I was a little bit before
    my time. It felt like banging my head against the wall sometimes with GPT-2, you
    know, surely promising but not really being there.
  topic: Practical lessons
- impact_reason: Provides a concise, fundamental definition of an AI agent's core
    operational structure.
  relevance_score: 8
  source: llm_enhanced
  text: Each agent in its simplest form is just a reflection loop with the ability
    to call tools.
  topic: Technical insights
- impact_reason: 'Uses a mathematical analogy ($f(x)$) to clearly define the components
    of an agent execution: context/data (X) and the assignment/goal (function f).'
  relevance_score: 8
  source: llm_enhanced
  text: The resources, the context, let's say all of your data from Slack is the X
    in $f(x)$, you know, and the assignment is the function.
  topic: Technical insights
- impact_reason: Reinforces the necessity of actively pruning the tool set provided
    to the agent to maintain performance, even with powerful models.
  relevance_score: 8
  source: llm_enhanced
  text: The agent will have to choose from, you know, a set of tools, but we definitely
    limit the number.
  topic: Practical lessons
- impact_reason: Suggests a spectrum where even 'tools' can be agentic wrappers around
    APIs, blurring the line between simple functions and complex agents.
  relevance_score: 8
  source: llm_enhanced
  text: Most of our tools are actually agentic. So they run some kind of follow-on
    on that on, you know, before they actually process and just use an API, right?
    In the end, it's an API route for natural natural natural language.
  topic: Technical insights
- impact_reason: Clearly defines the spectrum of complexity in agentic systems, ranging
    from fully autonomous agents to deterministic tools.
  relevance_score: 8
  source: llm_enhanced
  text: There's like a, you know, there's a little bit of a spectrum there between
    what is a full powerful agent and what is a basic tool, which is deterministic.
  topic: Strategy
- impact_reason: Highlights the necessity of tailoring AI/agent architecture to specific
    business needs rather than relying solely on generalized frameworks (like A2A).
  relevance_score: 8
  source: llm_enhanced
  text: what you'll end up doing in your own architecture is to use something that
    works just for you.
  topic: strategy
- impact_reason: 'A practical, actionable model for human-agent collaboration: the
    agent manages the human''s workload based on its own failures/limitations.'
  relevance_score: 8
  source: llm_enhanced
  text: And you almost need to manage a to-do list for the human. So everything where
    the agent cannot figure the stuff out, you know, it will be like, hey, I added
    it to your to-do. Good luck.
  topic: business/strategy
- impact_reason: Argues for the 'companion' model of AI integration where human responsibility
    remains intact, contrasting it with mandated tool adoption where accountability
    dissolves.
  relevance_score: 8
  source: llm_enhanced
  text: So you still have the responsibility for its work, which works better than
    like a top-to-bottom push from the management of using some particular tool. Because
    then nobody ends up taking responsibility for its outputs.
  topic: business/strategy
- impact_reason: A sharp observation that current architectural choices (even in AI
    implementation) are often constrained by the human talent available, mirroring
    historical software decisions.
  relevance_score: 8
  source: llm_enhanced
  text: we're basically choosing like our suboptimal architectural decision based
    on the employees we have available, right? You're not going to write your Stack
    in Java if you only have Python developers.
  topic: business/strategy
- impact_reason: 'Signals a major shift: AI''s proficiency in existing paradigms (like
    React) will influence the adoption and creation of future programming languages/frameworks.'
  relevance_score: 8
  source: llm_enhanced
  text: I've thought a lot about how AI changes the future of like developing new
    programming paradigms and frameworks and the like.
  topic: predictions
- impact_reason: Reflects on the dramatically increased performance expectations in
    the current market, evidenced by companies pivoting despite achieving $10M+ ARR.
  relevance_score: 8
  source: llm_enhanced
  text: it's just crazy how just the bar has gotten so high. There are a lot of lessons
    and takeaways in the whole Winsurf thing.
  topic: business
- impact_reason: 'Presents the counter-argument: the utility derived from unified,
    indexed data access might force platforms to remain open, driven by user demand.'
  relevance_score: 8
  source: llm_enhanced
  text: There's a completely different world where, you know, there's so much benefit
    from chatting with your indexed data on Notion via cloud that Notion just cannot
    close it.
  topic: strategy
- impact_reason: Predicts a fragmented future where data owners build proprietary
    AI agents, leading to high costs and inefficiency ('suboptimal'), contrasting
    with a more integrated agent ecosystem.
  relevance_score: 8
  source: llm_enhanced
  text: And it might be that everyone becomes really greedy. And everyone who has
    that data will try to become their own AI agent. So you'll have an AI agent with
    Notion, with Slack, and they will charge you for each call. I think that will
    be suboptimal.
  topic: predictions
- impact_reason: Draws a distinction between regulatory environments (Europe vs. US)
    regarding competition and data access, suggesting regulation will heavily influence
    AI agent market structure.
  relevance_score: 8
  source: llm_enhanced
  text: I have no clue how it would pan out in America where, you know, there's not
    such strong anti-competition. So there's not such strong proactivity into kind
    of making sure that competition is healthy.
  topic: safety/regulation
- impact_reason: A powerful anecdote illustrating vendor lock-in and punitive pricing
    for data access (API fees), highlighting why startups seek alternative data access
    methods.
  relevance_score: 8
  source: llm_enhanced
  text: I remember as a, you know, as a small Salesforce user, it's like, you know,
    you could be paying $50 or $60 a user per month, but to get access to the API,
    you need to spend another $10,000 a year. It's like, it's my data. Like, what
    the hell?
  topic: business
- impact_reason: Brings up the role of existing privacy regulations (GDPR/CCPA) as
    potential levers for AI startups to legally compel data access from incumbents.
  relevance_score: 8
  source: llm_enhanced
  text: Where will regulations step in, uh, you know, based on GDPR or CCPA, you can
    just request all of your data and they are obliged to give it to you.
  topic: safety/regulation
- impact_reason: 'Summarizes the shift: the agent experience is defined by speed and
    direct data access, rendering traditional application ''blocks'' obsolete.'
  relevance_score: 8
  source: llm_enhanced
  text: Suddenly that's all called as like almost like an agent experience, right?
    And how quick that is, how, uh, you basically don't need any of the blocks. So
    the data problem is very high on my mind.
  topic: strategy
- impact_reason: Suggests AI can drastically lower the barrier to creating new data
    connectors, potentially automating or simplifying API integration compared to
    manual partnership building.
  relevance_score: 8
  source: llm_enhanced
  text: But like, you get MCPs, even where there are no MCPs, you can probably use
    an AI to slurp in an API and like, make it accessible to your system.
  topic: technical
- impact_reason: Analyzes Granola's success as being heavily dependent on perfect
    timing (post-COVID meeting culture) and a key technical innovation (virtual audio
    routing) that bypassed the need for meeting bots.
  relevance_score: 8
  source: llm_enhanced
  text: And the main, I think they were very, very lucky that they hit the right timing
    after COVID where yeah, that like essentially crisp used to be something that
    reduces the noise before all the big platforms had it. And they basically created
    a virtual microphone and their virtual speaker that wrote like basically sent
    data to both your headphones and their system.
  topic: business/strategy
- impact_reason: Provides historical context on the evolution of sequence modeling,
    linking LSTMs to the Transformer revolution.
  relevance_score: 7
  source: llm_enhanced
  text: I did research into essentially LSTMs back in 2016, which were the precursors
    to the Transformer architecture.
  topic: Technical insights
- impact_reason: Describes an early, complex agentic approach (chaining different
    models) that preceded the current focus on simplified user entry points.
  relevance_score: 7
  source: llm_enhanced
  text: At the beginning, we were much more focused on developers and then very technical
    users, where essentially you are sending particular snippets of text to different
    LLMs and kind of really embracing the chain of technique by enabling you to also
    call different models.
  topic: Practical lessons
- impact_reason: Demystifies Multi-Agent Communication Protocols (MCPs) by framing
    them as standardized, single-task personas or tools within a system.
  relevance_score: 7
  source: llm_enhanced
  text: MCPs are just tools. The only difference between them is that we agreed that
    let's say you're running a team and each person in the team has some particular
    function, okay, and they know how to do one thing.
  topic: Technical insights
- impact_reason: Frames protocols like A2A (Agent-to-Agent) as communication schemas,
    applicable whether the interacting entities are simple tools or full agents.
  relevance_score: 7
  source: llm_enhanced
  text: All of this is a schema of how to communicate between tools, or if you want
    them to be agentic, you can call them agents.
  topic: Technical insights
- impact_reason: A high-level strategic insight suggesting that success in the current
    AI landscape depends on aligning with dominant technological shifts (the 'wave').
  relevance_score: 7
  source: llm_enhanced
  text: basically, you need to find yourself on the right side of the wave.
  topic: strategy
- impact_reason: 'A philosophical point on the current competitive advantage of humans:
    legal accountability and the ability to be held responsible.'
  relevance_score: 7
  source: llm_enhanced
  text: we are better than AIs. We have a, we are a legal entity that has responsibilities,
    can get fired, and we give it.
  topic: safety/strategy
- impact_reason: Reiterates the strategic imperative of aligning with dominant tech
    trends (the 'wave') to avoid unnecessary friction.
  relevance_score: 7
  source: llm_enhanced
  text: It's very interesting of like when are you going against the wave versus kind
    of being able to stay on the wave.
  topic: strategy
- impact_reason: Direct, hard-won business advice regarding CEO mental health and
    managing internal morale during uncertain M&A processes.
  relevance_score: 7
  source: llm_enhanced
  text: don't get burned out as a CEO and don't involve yourself with potential acquisitions
    which might fall through. And or like, don't tell your team about it.
  topic: business
- impact_reason: 'Presents the counter-scenario: if the utility of external AI agents
    accessing data is high enough, platform owners might be forced to allow access
    due to user demand.'
  relevance_score: 7
  source: llm_enhanced
  text: And there's a completely different world where, you know, there's so much
    benefit from chatting with your indexed data on Notion via cloud that Notion just
    cannot close it.
  topic: strategy
- impact_reason: Identifies a specific company (Granola) aiming for a 'universal AI
    agent' role focused on conversational data, illustrating a key market strategy.
  relevance_score: 7
  source: llm_enhanced
  text: So a great example of this is Granola, who, you know, like I can see what
    they're doing. Like I can see that they want to become a universal AI agent for
    everything that gets said.
  topic: business
- impact_reason: Discusses the practical limitations and potential circumvention of
    data rights requests (like GDPR's 'right to portability') when faced with vendor
    resistance or charging models.
  relevance_score: 7
  source: llm_enhanced
  text: But that would mean that, you know, as a startup, you might have to ask about
    it, like we will ask on your behalf every 24 hours. You know, like, and also like,
    if they end up charging for it, you know, that's, that's like, and they might
    try to block it in some way, unless like, well, GDPR is pretty like airtight.
  topic: safety/regulation
- impact_reason: Highlights the competitive landscape where startups are fighting
    to become the primary data aggregator/owner, rather than just being a connector.
  relevance_score: 7
  source: llm_enhanced
  text: And basically how to make sure there's like startups right now which try to
    do exactly the same, but also build lock and Notion and make sure that they own
    that.
  topic: business
- impact_reason: 'Defines the old model of integration platforms (like Zapier): high
    friction, relationship-heavy work proportional to the number of connectors.'
  relevance_score: 7
  source: llm_enhanced
  text: I think probably the most complex thing in that business [Zapier] is managing
    all these connectors and, you know, building relationships with these partners
    and getting them over the hurdle of like, you know, one connector at a time to
    build out this catalog.
  topic: business
- impact_reason: Suggests that future data control battles might rely more on legal
    enforcement ('litigation') than partnership, and questions whether the UX will
    be for *adding* data or *querying* it.
  relevance_score: 7
  source: llm_enhanced
  text: It's building litigation. I completely agree. I think this will essentially
    which parts of your resources in that dossier that we've mentioned before ends
    up being something that you wrap a UX for the users to add data into is a question
    mark.
  topic: safety/strategy
- impact_reason: Contrasts the relationship-building required for data dumps with
    the technical approach, suggesting that forced data extraction is legally complex,
    not just a business relationship issue.
  relevance_score: 6
  source: llm_enhanced
  text: you're like, oh, a vendor thing is like building relationships with these
    companies where you're asking for their data dumps every day, which doesn't sound
    easy either.
  topic: business/strategy
source: Unknown Source
summary: '## Podcast Summary: Context Engineering for Productive AI Agents with Filip
  Kozera - #741


  This episode of the TWIM AI podcast features Sam Charrington in conversation with
  Filip Kozera, Founder and CEO of Wordware, focusing on the philosophy and engineering
  behind building productive AI agents, particularly through the lens of **Context
  Engineering** and natural language programming.


  ### 1. Focus Area

  The discussion centers on the evolution of AI agents, moving beyond simple tool-calling
  to sophisticated, context-aware systems driven by natural language instructions.
  Key areas covered include:

  *   **Context Engineering:** Managing and structuring the context (the "dossier")
  fed to LLMs for execution.

  *   **Agent Architecture:** Utilizing ReAct loops, tool selection, and the limitations
  of current agentic patterns (like MCPs).

  *   **Future of Work:** The shift from micromanaging agents to managing human-in-the-loop
  feedback and delegation.

  *   **Data Silos and Access:** The challenges posed by platform providers (like
  Slack/Salesforce) restricting API access for third-party agents.


  ### 2. Key Technical Insights

  *   **The Dossier Concept:** An agent''s execution context is framed as a "dossier,"
  which includes the assignment (the function $f(x)$), the resources/context (the
  $x$, e.g., Slack data), and is truncated to fit context windows.

  *   **Tool Limitation and Performance:** Presenting an LLM (even powerful ones like
  Opus 4) with too many tools (e.g., over 15) causes a significant drop in performance,
  necessitating intelligent tool selection or limiting the repository size based on
  the task.

  *   **Enhancing MCPs:** While acknowledging the utility of standard **Model-Centric
  Protocols (MCPs)** (the "sticky note" description for tools), Wordware enhances
  them by explicitly injecting metadata like required context, error feedback mechanisms,
  and authority levels via JSON within the description field.


  ### 3. Business/Investment Angle

  *   **The Low-Code/No-Code Pivot:** Wordware initially targeted developers but pivoted
  to a more user-focused, natural language programming approach, inspired by the low-code
  market, recognizing that the primary bottleneck is human expression, not engine
  capability.

  *   **The Rising Bar for Success:** The rapid evolution of the market is highlighted
  by recent pivots of highly funded companies (like Winsurf and Monas) despite achieving
  significant ARR ($10M-$20M), indicating that established revenue is no longer a
  guarantee of survival against new paradigms.

  *   **Data Access as a Moat/Barrier:** Platform providers (Slack, Salesforce) are
  beginning to restrict data access for third-party agents (e.g., Glean), potentially
  leading to a future where major data holders become proprietary AI agents, charging
  per call.


  ### 4. Notable Companies/People

  *   **Filip Kozera (Wordware):** Proponent of natural language as the "assembly
  code of LLMs" and architect of the agent execution framework.

  *   **Wordware:** Building a companion AI OS designed to manage and mediate background
  agents, emphasizing human oversight.

  *   **Zapier/Make:** Used as comparative examples of existing workflow automation
  tools that Wordware aims to simplify via natural language.

  *   **Graphi/Agentic Coding Tools:** Cited as an analogy for how agentic systems
  evolve from augmentation to developer management roles.


  ### 5. Future Implications

  The future of work centers on **graceful failure and human-in-the-loop integration**.
  Agents will not become fully autonomous; instead, their productivity relies on knowing
  what they don''t know and surfacing specific needs (missing data, required creativity/taste,
  authentication issues) to the human via structured to-do lists or intervention points.
  This shifts the human role from executor to manager/approver. Furthermore, the industry
  is moving toward defining better **UX for agents** interacting with data silos,
  analogous to how GUIs defined UX for humans over the last two decades.


  ### 6. Target Audience

  This episode is highly valuable for **AI/ML Engineers, Product Managers building
  agentic systems, CTOs, and Venture Capitalists** interested in the practical engineering
  challenges, architectural decisions, and commercial viability of next-generation
  AI applications.'
tags:
- artificial-intelligence
- ai-infrastructure
- startup
- generative-ai
- investment
- google
- openai
title: 'Context Engineering for Productive AI Agents with Filip Kozera - #741'
topics:
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 65
  prominence: 1.0
  topic: artificial intelligence
- keywords:
  - gpu
  - tensor
  - training
  - inference
  - model deployment
  - vector database
  mentions: 6
  prominence: 0.6
  topic: ai infrastructure
- keywords:
  - startup
  - entrepreneur
  - founder
  - venture
  mentions: 5
  prominence: 0.5
  topic: startup
- keywords:
  - generative ai
  - genai
  - chatgpt
  - gpt
  - claude
  - text generation
  - image generation
  mentions: 4
  prominence: 0.4
  topic: generative ai
- keywords:
  - investment
  - funding
  - valuation
  - ipo
  - acquisition
  mentions: 1
  prominence: 0.1
  topic: investment
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-10-04 22:34:54 UTC -->
