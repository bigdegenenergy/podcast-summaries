---
companies:
- category: unknown
  confidence: medium
  context: Welcome everyone to the AI and Business Podcast. I'm Matthew D'Mello, editorial
    director here at
  name: Business Podcast
  position: 31
- category: unknown
  confidence: medium
  context: come everyone to the AI and Business Podcast. I'm Matthew D'Mello, editorial
    director here at Emerge AI Resea
  name: Matthew D
  position: 53
- category: unknown
  confidence: medium
  context: . I'm Matthew D'Mello, editorial director here at Emerge AI Research. Today's
    guest is Achille Kunger, vice president
  name: Emerge AI Research
  position: 97
- category: unknown
  confidence: medium
  context: ctor here at Emerge AI Research. Today's guest is Achille Kunger, vice
    president and quantitative analytics at Bar
  name: Achille Kunger
  position: 134
- category: tech
  confidence: high
  context: which we are trying to use, even if you're using OpenAI or something, there's
    a lot of layers being done
  name: Openai
  position: 2219
- category: unknown
  confidence: medium
  context: m entering AI systems just as a financial leader? So I think one is, as
    I said, the data training datase
  name: So I
  position: 3633
- category: unknown
  confidence: medium
  context: hey don't actually end up like having the system. And I think we talked
    so much in the last episode about
  name: And I
  position: 4500
- category: unknown
  confidence: medium
  context: to make sure these models are robust and secure. Solving AI with AI, which
    is its own, at least, challenge in
  name: Solving AI
  position: 4727
- category: unknown
  confidence: medium
  context: least, challenge in terms of securing the buy-in. But I'm curious what
    you think an ideal safety dashboar
  name: But I
  position: 4818
- category: unknown
  confidence: medium
  context: AI regulations really being truly driven. In the United States, it's a
    little bit more piecemeal. Of course, Cal
  name: United States
  position: 9449
- category: unknown
  confidence: medium
  context: '''re starting to see more laws go into effect, the EU AI Act as of February
    this past year, what are the bigge'
  name: EU AI Act
  position: 9797
- category: unknown
  confidence: medium
  context: hype cycle if we're not in the middle of it yet. Generative AI tools, I
    think, across the board, really show a l
  name: Generative AI
  position: 11183
- category: unknown
  confidence: medium
  context: ecutive thought leaders, everyone from the CIO of Goldman Sachs to the
    head of AI at Raytheon, and AI pioneers li
  name: Goldman Sachs
  position: 16527
- category: unknown
  confidence: medium
  context: the head of AI at Raytheon, and AI pioneers like Joshua Bengio. With nearly
    a million annual listeners, AI and B
  name: Joshua Bengio
  position: 16593
- category: unknown
  confidence: medium
  context: eve you can help other leaders move the needle on AI ROI, visit emerge.com
    and fill out our thought leader
  name: AI ROI
  position: 17057
- category: tech
  confidence: high
  context: today's episode, consider leaving us a review on Apple Podcasts and let
    us know what you learned, found
  name: Apple
  position: 17468
- category: unknown
  confidence: medium
  context: today's episode, consider leaving us a review on Apple Podcasts and let
    us know what you learned, found helpful,
  name: Apple Podcasts
  position: 17468
- category: unknown
  confidence: medium
  context: director here at Emerge AI Research. On behalf of Daniel Fajella, our CEO
    and head of research, as well as the res
  name: Daniel Fajella
  position: 17812
- category: ai_application
  confidence: high
  context: The employer of the guest, Achille Kunger, focusing on quantitative analytics
    and deploying customer-facing AI systems in financial services.
  name: Barclays
  source: llm_enhanced
- category: ai_company
  confidence: high
  context: Mentioned as a provider of AI models that Barclays' governance teams implement
    layers of protection around before use.
  name: OpenAI
  source: llm_enhanced
- category: ai_security_vendor
  confidence: high
  context: Sponsor of the special series on consumer risk and content safety.
  name: ActiveFence
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: The organization producing the 'AI and Business Podcast' and the employer
    of the host, Matthew D'Mello.
  name: Emerge AI Research
  source: llm_enhanced
- category: general_business
  confidence: medium
  context: Mentioned as a comparison point for customer experience issues (checkout
    line) versus high-stakes financial services interactions.
  name: Target
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as an example of a company whose CIO has been featured on the
    podcast, indicating involvement in enterprise AI transformation.
  name: Goldman Sachs
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as an organization whose head of AI has been featured on the
    podcast, indicating involvement in enterprise AI adoption.
  name: Raytheon
  source: llm_enhanced
- category: ai_researcher
  confidence: high
  context: Mentioned as an AI pioneer who has been featured on the show, indicating
    a connection to foundational AI research/thought leadership.
  name: Joshua Bengio
  source: llm_enhanced
- category: ecosystem_tool
  confidence: low
  context: Platform mentioned for leaving reviews, part of the podcast distribution
    ecosystem.
  name: Apple Podcasts
  source: llm_enhanced
- category: ecosystem_tool
  confidence: low
  context: Platform mentioned for following the podcast.
  name: X (formerly Twitter)
  source: llm_enhanced
- category: ecosystem_tool
  confidence: low
  context: Platform mentioned for following the podcast.
  name: LinkedIn
  source: llm_enhanced
date: 2025-05-12 07:00:00 +0000
duration: 20
has_transcript: false
insights:
- actionable: false
  confidence: medium
  extracted: 'customer-facing systems in financial services, and what new safety challenges
    might emerge? Yeah, I think it will take some time to fully embrace the agentic
    AI and generative in financial institutions just because of the previous thing
    we talked about: regulations. We have to be very careful, but having said that,
    it'
  text: 'the future of customer-facing systems in financial services, and what new
    safety challenges might emerge? Yeah, I think it will take some time to fully
    embrace the agentic AI and generative in financial institutions just because of
    the previous thing we talked about: regulations. We have to be very careful, but
    having said that, it is coming.'
  type: prediction
layout: episode
llm_enhanced: true
original_url: https://traffic.libsyn.com/secure/techemergence/Business_-_5.12.25_-_Akhil_Khunger.mp3?dest-id=151434
processing_date: 2025-10-05 18:27:21 +0000
quotes:
- length: 185
  relevance_score: 4
  text: First, embedding safety into client-facing AI requires addressing technical
    vulnerabilities like prompt injection, model jailbreaking, and flawed training
    data right at the design stage
  topics: []
- length: 138
  relevance_score: 4
  text: Are you driving AI transformation at your organization, or maybe you're guiding
    critical decisions on AI investment strategy or deployment
  topics:
  - investment
- length: 27
  relevance_score: 3
  text: So you have to look at that
  topics: []
- length: 276
  relevance_score: 3
  text: But I'm curious, just as you're starting to see more laws go into effect,
    the EU AI Act as of February this past year, what are the biggest regulatory and
    technical hurdles that you see in deploying customer-facing AI systems with built-in
    safety and transparency requirements
  topics: []
- length: 134
  relevance_score: 3
  text: But yeah, like you just—when the law comes, you have to be more careful and
    also need to present to regulators what work has been done
  topics: []
- length: 275
  relevance_score: 3
  text: So I think the challenges there mainly are that sometimes you have to leave
    some of the functionality which can impact user experience at times, or even experience
    within the firm, to make sure that you always fulfill regulatory demands and then
    also to make them comfortable
  topics: []
- impact_reason: Directly names core security risks (prompt injection, jailbreaking)
    relevant to all LLM deployments and highlights the tension between security and
    UX.
  relevance_score: 10
  source: llm_enhanced
  text: He walks us through key risks like prompt injection, model jailbreaking, and
    flawed training data, and how financial institutions are building guardrails without
    compromising user experience.
  topic: safety
- impact_reason: Describes a form of malicious instruction injection or system compromise
    via specific prompts, illustrating a sophisticated security threat beyond simple
    misinformation.
  relevance_score: 10
  source: llm_enhanced
  text: And then sometimes, like, virus in a way, like there could be bugs added through
    the system that if some user gives a specific command, this can throw back something
    which can give something like go to some other place in the—and just start of
    where we're going somewhere else, like within the whole industry, like in the
    AI system.
  topic: safety
- impact_reason: Highlights the critical risk of cross-account or holistic customer
    impact stemming from localized prompts, especially in complex financial profiles.
  relevance_score: 10
  source: llm_enhanced
  text: If a customer has some account with the company and they're trying to do some—they
    have multiple accounts, basically—and they're trying to do something with one
    place, what if they do give some prompts here? How are their multiple accounts
    impacted together?
  topic: safety
- impact_reason: A stark warning about the potential for catastrophic, unintended
    financial consequences due to subtle prompt ambiguity affecting large positions.
  relevance_score: 10
  source: llm_enhanced
  text: Because they might be indirectly impacting something else by trying to give
    something in front. So you have to be very careful because, like, sometimes client
    positions could be very big, and they may not even realize when they're giving
    prompts that they were thinking they're looking at a very short portfolio, but
    it could actually, because of the naming or something, go to the other side and
    really hamper everything.
  topic: safety
- impact_reason: 'Identifies the core technical challenge of agentic systems: opacity
    and difficulty in tracing execution paths due to independent, interacting components.'
  relevance_score: 10
  source: llm_enhanced
  text: So I think the first challenge is, because there are so many hidden layers
    in agentic AI—agents working independently or interacting—it can get difficult
    to understand the model.
  topic: technical/safety
- impact_reason: 'Provides a crucial testing methodology for agentic systems: decomposition
    and testing of individual agent components rather than just the final outcome.'
  relevance_score: 10
  source: llm_enhanced
  text: So that's where we need to, while testing, decouple the processes and then
    try to see if the individual parts are giving the right output, not again look
    at the final results of that agentic AI process.
  topic: technical
- impact_reason: 'Identifies the core technical and interpretability challenge of
    agentic systems: opacity due to complex, multi-agent interactions.'
  relevance_score: 10
  source: llm_enhanced
  text: the first challenge is, because there are so many hidden layers in agentic
    AI—agents working independently or interacting—it can get difficult to understand
    the model.
  topic: technical/safety
- impact_reason: 'Provides a crucial, actionable testing methodology for complex agentic
    systems: modular validation rather than end-to-end black-box testing.'
  relevance_score: 10
  source: llm_enhanced
  text: while testing, decouple the processes and then try to see if the individual
    parts are giving the right output, not again look at the final results of that
    agentic AI process.
  topic: technical/strategy
- impact_reason: A strong warning about marketing hype versus actual capability in
    the vendor landscape, advising caution against superficial claims of 'agentic'
    functionality.
  relevance_score: 10
  source: llm_enhanced
  text: you're probably going to see, especially from the vendor space, a lot of pop-up
    technologies that may claim they're agentic but really they're kind of glorified
    chatbots.
  topic: business/strategy
- impact_reason: Defines the true benchmark for agentic AI (cross-program interaction,
    complex inquiry resolution) and predicts it is still several years out.
  relevance_score: 10
  source: llm_enhanced
  text: the specific functionality of working with systems that can jump between programs,
    perform searches, do deep research, know where to go within an organization to
    solve a complex customer inquiry, is a few years away from that for a lot of the
    reasons that you describe.
  topic: predictions/technical
- impact_reason: Provides a concise list of critical technical safety risks that must
    be addressed proactively during the design phase of customer-facing AI.
  relevance_score: 10
  source: llm_enhanced
  text: embedding safety into client-facing AI requires addressing technical vulnerabilities
    like prompt injection, model jailbreaking, and flawed training data right at the
    design stage.
  topic: safety/technical
- impact_reason: A foundational principle for secure AI development, listing specific,
    high-priority vulnerabilities.
  relevance_score: 10
  source: llm_enhanced
  text: First, embedding safety into client-facing AI requires addressing technical
    vulnerabilities like prompt injection, model jailbreaking, and flawed training
    data right at the design stage.
  topic: safety/technical
- impact_reason: 'Indicates the breadth of the discussion, covering the three pillars
    of enterprise AI deployment: governance, validation (stress testing), and compliance.'
  relevance_score: 9
  source: llm_enhanced
  text: The conversation also covers model governance, stress testing, and regulatory
    shifts across global markets.
  topic: governance
- impact_reason: Highlights the emerging importance of agentic AI in customer environments
    and the necessary prerequisites (trust, transparency) for adoption.
  relevance_score: 9
  source: llm_enhanced
  text: Achille shares a forward-looking view on deploying agentic tech in generative
    AI and customer environments and what it takes to foster trust, transparency,
    and resilience in next-generation financial AI systems.
  topic: predictions
- impact_reason: Emphasizes the necessity of applying traditional, robust testing
    methodologies (even for production monitoring) to new AI systems.
  relevance_score: 9
  source: llm_enhanced
  text: Secondly, I think it's very important that you use old-school build test cases
    in your models, like, and if the test cases fail, it should give you an error,
    like even in production, right?
  topic: technical/safety
- impact_reason: Defines the critical gatekeeping role of Model Governance and Validation
    teams before production deployment.
  relevance_score: 9
  source: llm_enhanced
  text: And then new persons can enter prompts. So it's about testing a lot of things,
    and then do these all systems are looked by the model governance, model validation
    teams. They validate all these models so that they don't go into production without
    proper checks in place.
  topic: governance
- impact_reason: 'Points out a fundamental risk in using foundation models: domain
    misalignment between general training data and specific industry requirements
    (finance).'
  relevance_score: 9
  source: llm_enhanced
  text: So I think one is, as I said, the data training dataset, right? Because these
    models are trained on, like, very large-scale data industry worldwide, so some
    of the data may not be applicable to finance.
  topic: safety/technical
- impact_reason: Emphasizes that regulatory compliance requires not just adherence,
    but demonstrable evidence of preparation and testing ('present to regulators what
    work has been done').
  relevance_score: 9
  source: llm_enhanced
  text: But yeah, like you just—when the law comes, you have to be more careful and
    also need to present to regulators what work has been done.
  topic: safety/regulation
- impact_reason: 'Details the specific documentation and transparency required by
    regulators: evidence of testing, data handling protocols, and incident response
    plans.'
  relevance_score: 9
  source: llm_enhanced
  text: Lot of governance processes need to be there, like need to show them all the
    tests we have done, have proper evidence, all the data we are storing, and how
    are we dealing with the problems which might be coming, and showing them, because
    they want transparency.
  topic: governance/regulation
- impact_reason: Advocates for initial human-in-the-loop validation (shadow testing)
    for agentic AI against human expert performance.
  relevance_score: 9
  source: llm_enhanced
  text: Then it has to be backed also by having, initially at least, some actual people
    in a customer-facing role sitting with it and trying to see what would be their
    output versus what the agentic AI is giving.
  topic: safety/strategy
- impact_reason: Highlights the primary barrier (regulation) to adopting advanced
    agentic AI in highly regulated sectors like finance, setting a realistic timeline
    expectation.
  relevance_score: 9
  source: llm_enhanced
  text: 'it will take some time to fully embrace the agentic AI and generative in
    financial institutions just because of the previous thing we talked about: regulations.'
  topic: business/predictions
- impact_reason: Shifts the focus from technology cost to the significant investment
    required for robust testing and validation frameworks for advanced AI.
  relevance_score: 9
  source: llm_enhanced
  text: it's a benchmarking, basically. So that requires, I think the challenge then
    becomes the investment, not just in the technology but implementing the testing.
  topic: business/strategy
- impact_reason: Emphasizes that regulatory friction and lessons learned from the
    initial GenAI hype cycle will impose a slower, more cautious adoption curve in
    finance.
  relevance_score: 9
  source: llm_enhanced
  text: there's going to be a much heftier speed limit to the way these systems have
    been brought in, especially for regulated industries, than what we see elsewhere,
    especially when we're coming hot off a hype cycle for generative AI writ large.
  topic: strategy/safety
- impact_reason: Connects UX design directly to compliance and testing requirements,
    stressing that governance cannot be an afterthought.
  relevance_score: 9
  source: llm_enhanced
  text: as generative AI reaches customers directly, aligning user experience with
    rigorous governance, model stress testing, and evolving regulatory standards becomes
    essential.
  topic: safety/business
- impact_reason: States the fundamental requirement for public acceptance and regulatory
    approval of customer-facing AI systems.
  relevance_score: 9
  source: llm_enhanced
  text: trust and transparency are make-or-break factors, from disclosure practices
    to system explainability.
  topic: safety/strategy
- impact_reason: A powerful strategic statement suggesting that safety must be communicated
    and demonstrable to stakeholders (customers, regulators), not just implemented
    internally.
  relevance_score: 9
  source: llm_enhanced
  text: Building resilient AI systems means making safety visible, not just operational.
  topic: strategy/safety
- impact_reason: Highlights the necessary integration of governance and testing into
    the user-facing product lifecycle.
  relevance_score: 9
  source: llm_enhanced
  text: Secondly, as generative AI reaches customers directly, aligning user experience
    with rigorous governance, model stress testing, and evolving regulatory standards
    becomes essential.
  topic: safety/strategy
- impact_reason: Reiterates the non-negotiable importance of transparency for adoption
    and compliance.
  relevance_score: 9
  source: llm_enhanced
  text: And finally, trust and transparency are make-or-break factors, from disclosure
    practices to system explainability.
  topic: safety/strategy
- impact_reason: Sets the stage for a deep dive into the critical, high-stakes area
    of customer-facing AI safety within the regulated financial sector.
  relevance_score: 8
  source: llm_enhanced
  text: Today's guest is Achille Kunger, vice president and quantitative analytics
    at Barclays. Achille returns to the program to explore the evolving landscape
    of customer-facing AI in financial services with a focus on embedding safety and
    security into client-facing systems.
  topic: strategy
- impact_reason: 'Reveals a key enterprise strategy: restricting access to raw, full-capability
    models via governance layers to mitigate immediate risk.'
  relevance_score: 8
  source: llm_enhanced
  text: So the codes which we are trying to use, even if you're using OpenAI or something,
    there's a lot of layers being done before it goes to the digital modeler by the
    governance teams that you cannot use all features of AI.
  topic: business/strategy
- impact_reason: Stresses the need for cross-functional validation (not just ML engineers)
    for customer-facing AI due to the unpredictable nature of user inputs.
  relevance_score: 8
  source: llm_enhanced
  text: So it has to be very comprehensive. So it has to be thought about by different
    people, not just by one person, especially when it's customer-facing, and new
    persons can enter prompts.
  topic: governance
- impact_reason: Provides a blueprint for an AI safety dashboard using tiered alerting
    (Green/Amber/Red) based on predefined metric thresholds.
  relevance_score: 8
  source: llm_enhanced
  text: So I think, like, there are a lot of, firstly, like a lot of monitoring metrics
    should be defined in a way that you need to make sure that if you have, like,
    for example, in some areas more than a certain percent, like it throws up some
    error and shows up a warning or gives like colors like green, amber, red, those
    kind of things to give you a warning as well.
  topic: technical/governance
- impact_reason: Mandates that UI/UX testing must be as rigorous as functional testing,
    involving governance teams to ensure safe and intuitive interaction.
  relevance_score: 8
  source: llm_enhanced
  text: Then for that, I think we just need to make sure that the UI is being tested
    multiple times by multiple users, by multiple governance teams, and then it is—and
    then it's not just tested for accuracy, but also for user experience.
  topic: governance
- impact_reason: Proposes using AI itself to analyze interaction metadata (e.g., time
    spent, prior issues) to contextualize and potentially filter unreliable user feedback
    scores.
  relevance_score: 8
  source: llm_enhanced
  text: That's why I think AI can really help because they can look at whatever the
    interaction they have—all the interactions are recorded, so recorded, or like,
    no, so they know, okay, this person also faces this issue, so maybe that's why
    this score could be ignored or something at times.
  topic: technical
- impact_reason: 'Confirms the trade-off: regulatory demands often force the disabling
    of potentially useful features to ensure compliance and safety.'
  relevance_score: 8
  source: llm_enhanced
  text: I think the challenges there mainly are that sometimes you have to leave some
    of the functionality which can impact user experience at times, or even experience
    within the firm, to make sure that you always fulfill regulatory demands...
  topic: business/regulation
- impact_reason: A sober prediction that regulatory caution will significantly slow
    the adoption of advanced agentic AI in highly regulated sectors like finance.
  relevance_score: 8
  source: llm_enhanced
  text: 'I think it will take some time to fully embrace the agentic AI and generative
    in financial institutions just because of the previous thing we talked about:
    regulations.'
  topic: predictions
- impact_reason: Offers a nuanced perspective on AI performance, acknowledging that
    AI might outperform humans in specific tasks, necessitating careful benchmarking.
  relevance_score: 8
  source: llm_enhanced
  text: sometimes human error can also come in, that the actual person can give you
    the raw answer, agentic AI can give you the right answer.
  topic: strategy/predictions
- impact_reason: A direct prediction tempering expectations regarding the speed of
    advanced AI deployment, especially in sensitive areas.
  relevance_score: 8
  source: llm_enhanced
  text: So it could take much more time than previously thought.
  topic: predictions
- impact_reason: Reinforces the need for interpretability and modular testing as a
    direct response to the complexity of agentic systems.
  relevance_score: 8
  source: llm_enhanced
  text: it can get difficult to understand the model. So that's where we need to,
    while testing, decouple the processes...
  topic: technical/safety
- impact_reason: Provides external validation and context for the skepticism regarding
    current vendor claims of advanced AI capabilities.
  relevance_score: 8
  source: llm_enhanced
  text: A lot of financial leaders in other industries have tended to describe this,
    that you're probably going to see... a lot of pop-up technologies that may claim
    they're agentic but really they're kind of glorified chatbots.
  topic: business/predictions
- impact_reason: 'Offers a practical business strategy for high-value clients: maintaining
    a human oversight layer (relationship manager) even when AI is deployed.'
  relevance_score: 7
  source: llm_enhanced
  text: For very big clients, it's very important to have not just AI systems talking
    to them automatically, have like a special relationship manager assigned to them
    for a very big client.
  topic: business/strategy
- impact_reason: Suggests proactive user education on prompt engineering as a key
    component of customer experience and safety for advanced AI tools.
  relevance_score: 7
  source: llm_enhanced
  text: But the idea is to also at times help the clients know how to give the prompts
    and make them feel easy, okay, they'll be helped, not just like they're doing
    something on their own.
  topic: business
- impact_reason: 'A crucial reminder about data quality in feedback loops: user satisfaction
    scores can be noisy (false positives/negatives) and require contextual validation.'
  relevance_score: 7
  source: llm_enhanced
  text: A customer may just give you a bad score because they had some other problem,
    and it will give you a false score. So not always you have positive—they can be
    false positives.
  topic: technical/safety
- impact_reason: 'Offers a balanced view: AI systems must be benchmarked against humans,
    acknowledging that humans are also fallible and AI might sometimes outperform
    them.'
  relevance_score: 7
  source: llm_enhanced
  text: And then also need to realize that sometimes human error can also come in,
    that the actual person can give you the raw answer, agentic AI can give you the
    right answer.
  topic: strategy
- impact_reason: A balanced view acknowledging necessary caution while confirming
    the inevitability of advanced AI adoption.
  relevance_score: 7
  source: llm_enhanced
  text: We have to be very careful, but having said that, it is coming.
  topic: predictions
- impact_reason: Practical advice on rigorous testing protocols, emphasizing the need
    for comprehensive adversarial or varied input testing.
  relevance_score: 7
  source: llm_enhanced
  text: I have to give multiple tryouts, multiple user prompts to ensure that we're
    not missing anything.
  topic: technical/strategy
- impact_reason: Classic ROI justification for large upfront technology investments,
    specifically applied to AI testing infrastructure.
  relevance_score: 7
  source: llm_enhanced
  text: So it will be large investments, but ultimately it is supposed to save a lot
    of money over a longer period.
  topic: business
- impact_reason: Summarizes the necessary rigorous validation process for agentic
    AI as a formal benchmarking exercise.
  relevance_score: 6
  source: llm_enhanced
  text: So it's a benchmarking, basically.
  topic: technical
- impact_reason: Acts as a summary marker, signaling the most critical, distilled
    advice from the conversation.
  relevance_score: 6
  source: llm_enhanced
  text: Achille shared three key takeaways for financial leaders building safer customer-facing
    AI systems.
  topic: strategy
source: Unknown Source
summary: '## Comprehensive Summary: How Financial Services Are Building Safer Customer-Facing
  AI - with Akhil Khunger of Barclays


  This podcast episode, featuring Akhil Khunger, VP of Quantitative Analytics at Barclays,
  focuses on the critical challenge of embedding safety, security, and robust governance
  into customer-facing Artificial Intelligence (AI) systems within the highly regulated
  financial services industry. The discussion moves beyond backend stress testing
  to address the specific risks associated with deploying generative AI directly to
  clients, emphasizing the need to balance user experience with regulatory compliance
  and risk mitigation.


  ### 1. Focus Area

  The primary focus is **Customer-Facing AI Safety and Governance in Financial Services**.
  Key topics covered include mitigating specific AI vulnerabilities (prompt injection,
  jailbreaking), the role of model governance and validation teams, the impact of
  global regulatory shifts (like the EU AI Act), and the cautious future deployment
  of agentic and generative AI in client interactions.


  ### 2. Key Technical Insights

  *   **Layered Input Protection:** Safety begins before the model sees the input;
  governance teams implement layers to restrict access to certain AI features or data,
  effectively filtering out potential threats or inappropriate data flows before they
  reach the core model.

  *   **Comprehensive Test Cases in Production:** Financial institutions must utilize
  old-school, comprehensive test cases that are continuously run, even in production
  environments, to catch anomalies arising from new data or unexpected user prompts,
  with failures triggering immediate alerts.

  *   **Decoupling Agentic Processes:** For emerging agentic AI, understanding the
  model requires decoupling the complex, multi-layered processes to test individual
  components for correct output, rather than relying solely on the final result of
  the autonomous chain.


  ### 3. Business/Investment Angle

  *   **Regulatory Compliance as a Driver:** Regulatory pressure necessitates robust
  documentation, evidence of testing, and transparency to regulators, which can sometimes
  require sacrificing certain functionalities that might otherwise enhance the user
  experience.

  *   **High Investment in Testing for Agentic AI:** The adoption of sophisticated
  agentic systems will require significant upfront investment in testing infrastructure
  and human oversight (benchmarking against human performance) before widespread deployment,
  potentially slowing adoption rates compared to less regulated sectors.

  *   **Balancing UX and Security:** For high-value clients, maintaining a "velvet
  rope" experience means integrating AI support with dedicated relationship managers
  to guide prompt usage and ensure comfort, though this level of personalized oversight
  is not scalable for the general customer base.


  ### 4. Notable Companies/People

  *   **Akhil Khunger (Barclays):** The featured expert, providing practical insights
  from a major financial institution on AI governance and risk management.

  *   **Barclays:** The context for the discussion, representing a large, regulated
  entity navigating these challenges.

  *   **OpenAI (Mentioned):** Referenced as an example of a foundational model provider
  whose outputs require significant pre-processing and governance layers by the bank.


  ### 5. Future Implications

  The industry is moving toward a future where **trust and transparency are visible
  operational requirements**, not just backend processes. While agentic AI holds immense
  potential for automation, its deployment in customer-facing roles will be significantly
  slower and more deliberate in finance due to the complexity of auditing multi-step
  autonomous actions and the stringent regulatory environment. There will be a greater
  emphasis on using AI itself to analyze user interactions (e.g., time spent on a
  task, repeated errors) to contextualize feedback scores and identify genuine issues
  versus false positives.


  ### 6. Target Audience

  This episode is most valuable for **AI/Tech Professionals, Risk Management Leaders,
  Compliance Officers, and Business Strategists** operating within highly regulated
  industries, particularly **Financial Services**, who are responsible for deploying,
  governing, or investing in customer-facing generative AI solutions.


  ---

  **Comprehensive Narrative Summary:**


  The conversation with Akhil Khunger centered on the transition of AI safety from
  internal stress testing to external, customer-facing deployment. Khunger stressed
  that mitigating risks like prompt injection starts at the input stage, requiring
  governance teams to strip down foundational models before use. A core defense mechanism
  involves rigorous, comprehensive test cases that must function even in live production,
  validated by dedicated model governance and validation teams before any system goes
  live.


  A major concern highlighted is the integrity of the training data, which may contain
  information irrelevant or even prohibited for financial use cases, necessitating
  careful curation. Furthermore, Khunger addressed the delicate balance between security
  and user experience (UX). While high-value clients may receive personalized human
  oversight to ease them into new AI tools, scalability demands that the UI itself
  be rigorously tested for experience, not just accuracy, with feedback loops informed
  by AI analysis of interaction metrics.


  The discussion then pivoted to regulatory pressures, particularly the EU AI Act,
  noting that compliance often forces trade-offs against optimal UX, requiring banks
  to meticulously document all testing and governance processes for regulators demanding
  transparency. Finally, the future of agentic AI was examined cautiously. Khunger
  warned that the hidden layers of agentic systems make them difficult to audit, suggesting
  a slow, phased adoption requiring extensive benchmarking against human performance
  and significant investment in testing infrastructure before these complex systems
  can be trusted with direct customer interactions. The overarching theme is that
  for financial AI to succeed near the customer, safety must be made visible and auditable
  across all dimensions.'
tags:
- artificial-intelligence
- generative-ai
- ai-infrastructure
- investment
- openai
- apple
title: How Financial Services Are Building Safer Customer-Facing AI - with Akhil Khunger
  of Barclays
topics:
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 78
  prominence: 1.0
  topic: artificial intelligence
- keywords:
  - generative ai
  - genai
  - chatgpt
  - gpt
  - claude
  - text generation
  - image generation
  mentions: 7
  prominence: 0.7
  topic: generative ai
- keywords:
  - gpu
  - tensor
  - training
  - inference
  - model deployment
  - vector database
  mentions: 3
  prominence: 0.3
  topic: ai infrastructure
- keywords:
  - investment
  - funding
  - valuation
  - ipo
  - acquisition
  mentions: 3
  prominence: 0.3
  topic: investment
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-10-05 18:27:21 UTC -->
