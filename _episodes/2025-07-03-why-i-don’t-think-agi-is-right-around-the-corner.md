---
companies:
- category: unknown
  confidence: medium
  context: f a blog post I wrote on June 3rd, 2025, titled, "Why I Don't Think AGI
    is Right Around the Corner." Quote, "
  name: Why I Don
  position: 77
- category: unknown
  confidence: medium
  context: t I wrote on June 3rd, 2025, titled, "Why I Don't Think AGI is Right Around
    the Corner." Quote, "Things take
  name: Think AGI
  position: 89
- category: unknown
  confidence: medium
  context: June 3rd, 2025, titled, "Why I Don't Think AGI is Right Around the Corner."
    Quote, "Things take longer to happen
  name: Right Around
  position: 102
- category: unknown
  confidence: medium
  context: identify clips from the transcript to tweet out. Sometimes I'll get them
    to co-write an essay with me, passage
  name: Sometimes I
  position: 1405
- category: unknown
  confidence: medium
  context: ck of continual learning is a huge, huge problem. The LLM baseline at many
    tasks might be higher than the a
  name: The LLM
  position: 1883
- category: unknown
  confidence: medium
  context: next student reads your notes and tries to play a Charlie Parker riff.
    When they fail, you refine your instruction
  name: Charlie Parker
  position: 2887
- category: unknown
  confidence: medium
  context: is looks like a long rolling context window, like Claude Code has, which
    compacts the session memory into a sum
  name: Claude Code
  position: 5130
- category: unknown
  confidence: medium
  context: hone using a long text summary of your learnings. Even Claude Code will
    often reverse a hard optimization that we en
  name: Even Claude Code
  position: 5508
- category: unknown
  confidence: medium
  context: o see them automated within the next five years." If AI progress totally
    stalls today, I think less than
  name: If AI
  position: 6158
- category: unknown
  confidence: medium
  context: t goes away. Sure, many tasks will get automated. Claude Code Opus can
    technically rewrite autogenerated transcripts
  name: Claude Code Opus
  position: 6292
- category: unknown
  confidence: medium
  context: learning how to do every single job in the world. An AI that is capable
    of online learning might function
  name: An AI
  position: 7605
- category: tech
  confidence: high
  context: progress. However, I'm not expecting to see some OpenAI livestream where
    they announce that continual lea
  name: Openai
  position: 7788
- category: unknown
  confidence: medium
  context: this big bottleneck totally solved. Computer use. When I interviewed the
    topic researchers, Shultz Douglas
  name: When I
  position: 8212
- category: unknown
  confidence: medium
  context: er use. When I interviewed the topic researchers, Shultz Douglas and Trenton
    Brickett on my podcast, they said tha
  name: Shultz Douglas
  position: 8254
- category: unknown
  confidence: medium
  context: rviewed the topic researchers, Shultz Douglas and Trenton Brickett on my
    podcast, they said that they expect reliabl
  name: Trenton Brickett
  position: 8273
- category: tech
  confidence: high
  context: ell an AI, go do my taxes. Go through your email, Amazon orders, and Slack
    messages, and it emails back an
  name: Amazon
  position: 8630
- category: unknown
  confidence: medium
  context: e it to contradict them on the technical details. Before I let an AI do
    that, I do know here are three reaso
  name: Before I
  position: 8982
- category: unknown
  confidence: medium
  context: lengths increase, rollouts have to become longer. The AI needs to do two
    hours worth of a general computer
  name: The AI
  position: 9176
- category: unknown
  confidence: medium
  context: e relationships are between different components. Maybe RL fine-tuning
    is so sample-efficient that you don't
  name: Maybe RL
  position: 10209
- category: unknown
  confidence: medium
  context: pect, seem to have taken a long time to iron out. The RL procedure which
    DeepSeek explained in their R1 pa
  name: The RL
  position: 10785
- category: unknown
  confidence: medium
  context: going to be like one of these spoiled children on Hacker News who could
    be handed a golden egg-laying goose and
  name: Hacker News
  position: 11576
- category: unknown
  confidence: medium
  context: ng in the domains that they're most competent in. Giving Claude Code a
    vague spec and then sitting around for 10 minut
  name: Giving Claude Code
  position: 12339
- category: ai_developer
  confidence: high
  context: Mentioned in the context of releasing innovations quickly and as a benchmark
    for AI progress (e.g., GPT-4, and implicitly the lab structure incentivized to
    release innovations quickly).
  name: OpenAI
  source: llm_enhanced
- category: ai_developer
  confidence: high
  context: Mentioned implicitly through the product 'Claude Code' and 'Claude 3 Opus'.
  name: Anthropic
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: A specific product mentioned, likely from Anthropic, known for having a
    long rolling context window and being used for software engineering tasks.
  name: Claude Code
  source: llm_enhanced
- category: ai_model
  confidence: high
  context: Mentioned as an example of a smart model whose reasoning traces demonstrate
    actual reasoning capabilities.
  name: Claude 3 Opus
  source: llm_enhanced
- category: ai_model
  confidence: high
  context: Mentioned alongside Claude 3 Opus as an example of a smart model demonstrating
    reasoning capabilities.
  name: Gemini 2.5
  source: llm_enhanced
- category: ai_developer
  confidence: high
  context: Mentioned regarding their R1 paper and the RL procedure they explained,
    which took two years to implement after GPT-4's launch.
  name: DeepSeek
  source: llm_enhanced
- category: ai_developer
  confidence: medium
  context: Mentioned via a quote from their post on automated software engineering
    regarding the limitations of available training data.
  name: Mechanize
  source: llm_enhanced
- category: ai_model
  confidence: high
  context: Used as a benchmark for language capabilities and a point in time reference
    (launch date used to measure time to 01 launch).
  name: GPT-4
  source: llm_enhanced
- category: ai_model
  confidence: high
  context: Used as a benchmark for cool but not practically useful models, compared
    to current computer use agents.
  name: GPT-3
  source: llm_enhanced
- category: ai_model
  confidence: high
  context: Used as a benchmark to describe the current state of computer use agents.
  name: GPT-2
  source: llm_enhanced
- category: ai_model
  confidence: high
  context: Mentioned as the successor/result of the RL procedure explained in the
    DeepSeek R1 paper, launched two years after GPT-4.
  name: '01'
  source: llm_enhanced
- category: external_entity
  confidence: medium
  context: Mentioned as an external entity (government agency) that an AI agent would
    need to interact with to file taxes, implying interaction with external systems.
  name: IRS
  source: llm_enhanced
- category: media_platform
  confidence: high
  context: The podcast hosting the narration, where the speaker discusses their own
    efforts building LLM tools.
  name: Thorekage podcast
  source: llm_enhanced
date: 2025-07-03 21:19:05 +0000
duration: 14
has_transcript: false
insights:
- actionable: true
  confidence: medium
  extracted: expect to see them automated within the next five years
  text: we should expect to see them automated within the next five years.
  type: recommendation
layout: episode
llm_enhanced: true
original_url: https://api.substack.com/feed/podcast/167473378/f0f9396353d538833aa6e64a05e4ad0b.mp3
processing_date: 2025-10-05 04:38:01 +0000
quotes:
- length: 194
  relevance_score: 5
  text: You could talk about circuits and training distributions and RL and whatever,
    but the most proximal, concise, and accurate explanation is simply that it's powered
    by baby artificial intelligence
  topics: []
- length: 127
  relevance_score: 4
  text: The LLM baseline at many tasks might be higher than the average human's, but
    there's no way to give a model high-level feedback
  topics: []
- length: 78
  relevance_score: 4
  text: Two, we don't have a large pre-training corpus of multimodal computer use
    data
  topics: []
- impact_reason: Identifies 'continual learning' (or online learning) as the single
    most critical missing capability preventing LLMs from functioning as true, improving
    employees.
  relevance_score: 10
  source: llm_enhanced
  text: The fundamental problem is that LLMs don't get better over time the way a
    human would. This lack of continual learning is a huge, huge problem.
  topic: technical
- impact_reason: 'A major prediction: solving continuous learning will unlock a massive,
    non-linear jump in AI value, leading to a potential ''intelligence explosion.'''
  relevance_score: 10
  source: llm_enhanced
  text: When we do solve continuous learning, we'll see a huge discontinuity in the
    value of these models.
  topic: predictions
- impact_reason: Suggests that the *mechanism* of continuous learning, when combined
    with massive parallelism, could lead to rapid self-improvement (superintelligence)
    even without fundamental architectural breakthroughs.
  relevance_score: 10
  source: llm_enhanced
  text: An AI that is capable of online learning might functionally become a super
    intelligence quite rapidly without any further algorithmic progress.
  topic: predictions
- impact_reason: This is a crucial analogy comparing current AI agents for computer
    use to the early LLM era (GPT-2), explaining *why* they aren't yet fully capable
    (sparse rewards, unfamiliar primitives) despite having a smart base model.
  relevance_score: 10
  source: llm_enhanced
  text: I think we're in the GPT-2 era for computer use, but we have no pre-training
    corpus, and the models are optimizing for a much sparser reward over a much longer
    time horizon using action primitives that they're unfamiliar with.
  topic: technical/comparison/limitations
- impact_reason: This is a classic, highly relevant strategic observation (often attributed
    to Amara's Law) applied here to the timeline of AGI, setting the stage for the
    author's nuanced perspective.
  relevance_score: 9
  source: llm_enhanced
  text: Things take longer to happen than you think they will, and then they happen
    faster than you thought they could.
  topic: strategy
- impact_reason: 'Pinpoints the core bottleneck preventing current LLMs from achieving
    widespread, human-level economic transformation: the lack of fundamental capabilities
    beyond language generation.'
  relevance_score: 9
  source: llm_enhanced
  text: Rather, I think it's genuinely hard to get normal human-like labor out of
    LLMs. And this has to do with some fundamental capabilities that these models
    lack.
  topic: limitations
- impact_reason: Provides a crucial definition of human value in the workplace, contrasting
    it directly with the static nature of current LLMs.
  relevance_score: 9
  source: llm_enhanced
  text: The reason humans are so valuable and useful is not mainly their raw intelligence.
    It's their ability to build up context, interrogate their own failures, and pick
    up small improvements and efficiencies as they practice a task.
  topic: predictions
- impact_reason: Critiques the current state of model improvement methods (prompting/RLHF)
    as fundamentally inadequate substitutes for organic, continuous learning.
  relevance_score: 9
  source: llm_enhanced
  text: But this is the only modality that we, as users, have to teach LLMs anything.
    Yes, there's RL fine-tuning, but it's just not a deliberate adaptive process the
    way human learning is.
  topic: technical
- impact_reason: 'A critical insight into the data requirements for general agency:
    scaling text data is insufficient for complex, multimodal, agentic tasks.'
  relevance_score: 9
  source: llm_enhanced
  text: For the past decade of scaling, we've been spoiled by the enormous amount
    of internet data that was freely available to us. This was enough to crack natural
    language processing, but not for getting models to become reliable competent agents.
  topic: technical
- impact_reason: A powerful, evocative statement confirming that current top-tier
    models exhibit genuine, albeit nascent, reasoning capabilities that defy simple
    mechanistic explanations.
  relevance_score: 9
  source: llm_enhanced
  text: Giving Claude Code a vague spec and then sitting around for 10 minutes until
    it's zero-shot working out the location is a wild experience. How did it do that?
    You could talk about circuits and training distributions and RL and whatever,
    but the most proximal, concise, and accurate explanation is simply that it's powered
    by baby artificial intelligence.
  topic: technical
- impact_reason: A concrete, quantitative prediction about the *current* economic
    impact ceiling of LLMs without further breakthroughs (specifically continuous
    learning).
  relevance_score: 9
  source: llm_enhanced
  text: If AI progress totally stalls today, I think less than 25% of white-collar
    employment goes away.
  topic: predictions
- impact_reason: Distinguishes between task automation (subtasks) and job replacement
    (actual employees), linking the latter to the context/learning deficit.
  relevance_score: 9
  source: llm_enhanced
  text: Yes, technically, AI might be able to perform a lot of subtasks somewhat satisfactorily,
    but their inability to build up context will make it impossible to have them operate
    as actual employees at your firm.
  topic: business
- impact_reason: A direct statement confirming the speaker's belief that current progress
    has crossed a threshold into genuine machine intelligence, moving beyond mere
    pattern matching.
  relevance_score: 9
  source: llm_enhanced
  text: At this point, part of you has to be thinking, it's actually working. We're
    making machines that are intelligent.
  topic: predictions/breakthroughs
- impact_reason: A concrete, high-value business prediction based on achieving complex,
    multi-step, real-world task completion (end-to-end business process automation).
  relevance_score: 9
  source: llm_enhanced
  text: 'An AI that can do taxes end-to-end for my small business as well as a competent
    general manager could in a week...: 2028.'
  topic: predictions/business impact
- impact_reason: A major prediction concerning the integration of continuous, personalized
    learning into AI agents, which is key for achieving true human-level adaptability
    in dynamic job roles.
  relevance_score: 9
  source: llm_enhanced
  text: 'An AI that learns on the job as easily, organically, seamlessly, and quickly
    as a human for any white-collar work...: 2032.'
  topic: predictions/societal impact
- impact_reason: A strong, memorable statement characterizing the nature of AGI progress—high
    probability of rapid arrival or a slower, more marginal pace, emphasizing the
    urgency of the current decade.
  relevance_score: 9
  source: llm_enhanced
  text: AGI timelines are very lognormal. It's either this decade or bust.
  topic: predictions/strategy
- impact_reason: A strong, contrarian stance challenging the common hyperbole that
    current LLMs are already as transformative as the internet, setting up the core
    argument about current limitations.
  relevance_score: 8
  source: llm_enhanced
  text: I think that the LLMs of today would still be far more economically transformative
    than the internet. I disagree.
  topic: business
- impact_reason: Provides a grounded, skeptical counterpoint to aggressive near-term
    agent timelines, based on practical deployment hurdles rather than just theoretical
    limits.
  relevance_score: 8
  source: llm_enhanced
  text: I'm skeptical. I'm not an AI researcher, so far be it to contradict them on
    the technical details. Before I let an AI do that, I do know here are three reasons
    I bet against this capability being unlocked within the next year.
  topic: predictions
- impact_reason: Uses the R1/01 timeline as evidence that even seemingly 'simple'
    algorithmic innovations take years, suggesting complex agentic UIs will take much
    longer.
  relevance_score: 8
  source: llm_enhanced
  text: Seeing how long it took to implement the idea, 'Hey, let's train our model
    to solve verifiable math and coding problems,' makes me think that we're underestimating
    the difficulty of solving a much gnarlier problem of computer UIs, where you're
    operating on a totally different modality with much less data.
  topic: strategy
- impact_reason: Advocates for probabilistic planning rather than fixed timelines,
    validating preparation for high-impact, low-probability events like ASI.
  relevance_score: 8
  source: llm_enhanced
  text: My probability distribution is super wide, and I want to emphasize that I
    do believe in probability distributions, which means that work to prepare for
    a mid-2028 ASI still makes a ton of sense.
  topic: strategy
- impact_reason: 'Presents an alternative path to rapid societal change: broad deployment
    of learning-capable AIs across the economy, rather than just a self-improving
    software loop.'
  relevance_score: 8
  source: llm_enhanced
  text: Even if there isn't a software-only singularity with models rapidly building
    smarter and smarter successor systems, we might still see something that looks
    like a broadly deployed intelligence explosion.
  topic: predictions
- impact_reason: A specific, damning example illustrating the brittleness of summarizing
    complex, engineered context (even in code) into text for memory retention.
  relevance_score: 8
  source: llm_enhanced
  text: Even Claude Code will often reverse a hard optimization that we engineered
    together before I hit slash compact, because the explanation for why it was made
    didn't make it into the summary.
  topic: technical
- impact_reason: Provides concrete, relatable examples of 'simple' tasks where current
    LLMs underperform significantly (5/10), grounding the argument against immediate
    AGI.
  relevance_score: 8
  source: llm_enhanced
  text: I'll try to get them to rewrite origin in a transcripts for readability, the
    way a human would, or I'll get them to identify clips from the transcript to tweet
    out. Sometimes I'll get them to co-write an essay with me, passage by passage.
    Now, these are simple, self-contained, short horizon, language in, language out
    tasks, the kinds of assignments that should be dead center in the LLMs repertoire,
    and these models are five out of ten at these tasks.
  topic: limitations
- impact_reason: A concise, almost philosophical framing of current advanced AI capabilities—acknowledging
    intelligence without needing to fully unpack the underlying complex mechanisms
    (circuits, RL, etc.).
  relevance_score: 8
  source: llm_enhanced
  text: The most proximal, concise, and accurate explanation is simply that it's powered
    by baby artificial intelligence.
  topic: strategy/framing
- impact_reason: Provides a historical benchmark (GPT-2 to GPT-4 timeline) to temper
    expectations for the timeline of achieving the equivalent breakthrough in complex
    computer use agents.
  relevance_score: 8
  source: llm_enhanced
  text: Preparing taxes for our small business feels like for computer use what GPT-4
    was for language, and it took four years to get from GPT-2 to GPT-4.
  topic: predictions/strategy
- impact_reason: Acknowledges the current technical hurdle (online learning integration)
    but uses historical context (GPT-1 to now) to argue that this hurdle is likely
    surmountable within the predicted timeframe.
  relevance_score: 8
  source: llm_enhanced
  text: Now, while I don't see an obvious way to slot in continuous online learning
    into current models, seven years is a really long time. GPT-1 had just come out
    seven years ago.
  topic: technical/challenges/predictions
- impact_reason: Provides a specific, quantitative driver for recent AI progress (4x
    scaling of compute), which is a fundamental insight for understanding current
    trajectory and future investment.
  relevance_score: 8
  source: llm_enhanced
  text: AI progress over the last decade has been driven by scaling training compute
    for frontier systems over 4x
  topic: technical/strategy
- impact_reason: A practical expectation regarding the release cadence of major AI
    breakthroughs, suggesting continuous learning won't appear overnight as a perfect
    solution.
  relevance_score: 7
  source: llm_enhanced
  text: I expect to get lots of heads-up before we see this big bottleneck totally
    solved.
  topic: strategy
- impact_reason: A counter-argument to pessimism, suggesting that experiencing the
    peak capability of current models (like Claude 3 Opus) reveals genuine, nascent
    intelligence.
  relevance_score: 7
  source: llm_enhanced
  text: Part of the reason some people are too pessimistic is that they haven't played
    around with the smartest models operating in the domains that they're most competent
    in.
  topic: strategy
- impact_reason: 'A specific limitation forecast: current models struggle with sustained,
    multi-step, end-to-end projects, even if they can perform individual steps well
    (contrasting with the 2028 prediction).'
  relevance_score: 7
  source: llm_enhanced
  text: I'm saying that these models won't be capable of end-to-end handling a week-long
    and quite involved project, which involves computer use.
  topic: limitations/predictions
source: Unknown Source
summary: '## Podcast Episode Summary: Why I Don’t Think AGI Is Right Around the Corner


  This podcast episode features a narrated reading of a blog post from June 3rd, 2025,
  where the host argues against the immediate arrival of Artificial General Intelligence
  (AGI), despite acknowledging the massive recent progress in Large Language Models
  (LLMs). The central thesis is that current LLMs fundamentally lack the capability
  for **continual, organic, on-the-job learning**, which is the key differentiator
  between today''s powerful tools and truly transformative, human-level general intelligence.


  ---


  **1. Focus Area:**

  The discussion centers on the **limitations of current LLMs** in achieving AGI,
  specifically focusing on the **lack of continual learning** and the challenges in
  developing **reliable, end-to-end computer use agents**. The comparison is drawn
  between the static capabilities of current models and the adaptive nature of human
  employees.


  **2. Key Technical Insights:**

  *   **The Continual Learning Bottleneck:** Current LLMs are stuck with their out-of-the-box
  abilities. While prompt engineering offers minor adjustments, it cannot replicate
  the iterative, context-building, and failure-interrogating learning process humans
  employ on the job (analogized to learning the saxophone).

  *   **Context Window Brittleness:** While long context windows (like Claude Code''s
  compaction feature) offer temporary session memory, titrating rich, task-specific
  experience into a text summary is brittle, especially outside text-heavy domains
  like software engineering.

  *   **Computer Use Modality Gap:** Developing reliable computer use agents (e.g.,
  doing taxes end-to-end) is significantly harder than language tasks due to the need
  to process multimodal inputs (images/video) and the lack of a sufficiently large,
  pre-training corpus for complex UI interaction data.


  **3. Business/Investment Angle:**

  *   **Limited Near-Term Transformation:** The host disagrees with the view that
  current LLMs are transformative even if progress stalls; he estimates less than
  25% of white-collar employment would be automated without continuous learning capabilities.

  *   **Value Discontinuity Upon Solving Learning:** The true economic discontinuity—a
  broadly deployed intelligence explosion—will only occur when continuous, organic
  learning is solved, making the next two decades potentially more impactful than
  the immediate future.

  *   **Skepticism on Near-Term Agent Rollout:** The host is skeptical that fully
  autonomous, week-long computer use agents (like end-to-end tax filing) will arrive
  by the end of 2026, suggesting the difficulty is comparable to the leap from GPT-2
  to GPT-4 in language.


  **4. Notable Companies/People:**

  *   **Routager, Dornbush:** Quoted for the adage: "Things take longer to happen
  than you think they will, and then they happen faster than you thought they could."

  *   **Shoto and Trenton (Brickett):** Mentioned for holding the opposing view that
  stalled AI progress would still automate 25% of white-collar work within five years
  due to the ease of data collection on job tasks.

  *   **Claude Code/Claude 3 Opus/Gemini 2.5:** Cited as examples of models demonstrating
  impressive, albeit static, reasoning capabilities.

  *   **DeepSeek (R1 paper):** Referenced to illustrate how even seemingly simple
  algorithmic innovations (like verifiable problem training) required significant
  engineering time (two years from GPT-4 to 01).


  **5. Future Implications:**

  The industry is heading toward a massive inflection point, but it is delayed until
  the **continuous learning bottleneck is solved (predicted around 2032 for human-level
  on-the-job learning)**. Once solved, the ability for AI models to amalgamate learnings
  across all copies will lead to a rapid, broad deployment of intelligence, potentially
  resembling a "super intelligence" without requiring further fundamental algorithmic
  breakthroughs.


  **6. Target Audience:**

  **AI/ML Professionals, Tech Strategists, and Venture Capitalists** focused on long-term
  AI timelines and the practical deployment challenges of current foundation models
  in enterprise settings.'
tags:
- artificial-intelligence
- generative-ai
- ai-infrastructure
- openai
- anthropic
title: Why I don’t think AGI is right around the corner
topics:
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 62
  prominence: 1.0
  topic: artificial intelligence
- keywords:
  - generative ai
  - genai
  - chatgpt
  - gpt
  - claude
  - text generation
  - image generation
  mentions: 13
  prominence: 1.0
  topic: generative ai
- keywords:
  - gpu
  - tensor
  - training
  - inference
  - model deployment
  - vector database
  mentions: 6
  prominence: 0.6
  topic: ai infrastructure
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-10-05 04:38:01 UTC -->
