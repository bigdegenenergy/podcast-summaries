---
actionable_items:
- action: potentially
  category: investigation
  full_context: 'you could potentially '
  priority: medium
companies:
- category: unknown
  confidence: medium
  context: ou missed it in May, episode. Welcome back to the Super Data Science Podcast.
    I am your host, John Cron. This is an in case yo
  name: Super Data Science Podcast
  position: 91
- category: unknown
  confidence: medium
  context: o the Super Data Science Podcast. I am your host, John Cron. This is an
    in case you missed it episode that hi
  name: John Cron
  position: 135
- category: unknown
  confidence: medium
  context: first of my four highlights from May, I speak to John Rose, Global CTO
    and Chief AI Officer at the computing
  name: John Rose
  position: 336
- category: unknown
  confidence: medium
  context: y four highlights from May, I speak to John Rose, Global CTO and Chief
    AI Officer at the computing giant Dell.
  name: Global CTO
  position: 347
- category: unknown
  confidence: medium
  context: ts from May, I speak to John Rose, Global CTO and Chief AI Officer at the
    computing giant Dell. What a guest. John a
  name: Chief AI Officer
  position: 362
- category: unknown
  confidence: medium
  context: ople that can do things better than other people. At Dell, we have the
    best thermal and cooling people in t
  name: At Dell
  position: 2059
- category: unknown
  confidence: medium
  context: eresting because for the first couple of years of Gen AI, we actually went
    after the first one. A chatbot,
  name: Gen AI
  position: 2518
- category: unknown
  confidence: medium
  context: ll to you in raw format, it would be of no value. If I embedded it into
    a vector database and presented
  name: If I
  position: 2902
- category: unknown
  confidence: medium
  context: we do have are self-driving cars. They've been in San Francisco and other
    places where if you geo-fence it, if yo
  name: San Francisco
  position: 4559
- category: unknown
  confidence: medium
  context: Bottom line is, you take these two technologies. First Gen Gen AI, which
    is what we call reactive AI, that a human
  name: First Gen Gen AI
  position: 5985
- category: unknown
  confidence: medium
  context: n tools such as AI agents and RAG-based chatbots. And I recommend listening
    to the entire episode to hear
  name: And I
  position: 7940
- category: unknown
  confidence: medium
  context: All right. My next clip is from episode 885 with Yorun Jonsons and Ty's
    Newdorp. In maybe one of the liveliest c
  name: Yorun Jonsons
  position: 8184
- category: unknown
  confidence: medium
  context: ajor Dutch utility Alliander helped them to write Python Polars, the definitive
    guide. Earlier in the episode, yo
  name: Python Polars
  position: 8426
- category: unknown
  confidence: medium
  context: ', I talked to Sikh''s founder, the space engineer, Mary Spio, about the
    potential for Sikh to revitalize the w'
  name: Mary Spio
  position: 13323
- category: unknown
  confidence: medium
  context: ch 100,000 students via Sikh. So where do you see VR Sikh potentially having
    a long-term impact on improvin
  name: VR Sikh
  position: 14147
- category: unknown
  confidence: medium
  context: t was like, you know, Europe needs this much. US, North America needs this
    much. It was like 4.6 million total. A
  name: North America
  position: 14400
- category: unknown
  confidence: medium
  context: worked with also felt better equipped. The reason Baptist Health was looking
    at the nursing residences is because
  name: Baptist Health
  position: 17679
- category: unknown
  confidence: medium
  context: My last clip is from episode 891 where I speak to Martin Brunthaler about
    the lessons he learned as the founder of Ad
  name: Martin Brunthaler
  position: 19384
- category: unknown
  confidence: medium
  context: nboard a generic source from a database or from a REST API, you want all
    the data types need to be aligned.
  name: REST API
  position: 21446
- category: unknown
  confidence: medium
  context: p combining various sources and all those things. But I think it's very
    critical to get the quality right
  name: But I
  position: 21768
- category: big_tech
  confidence: high
  context: Global CTO and Chief AI Officer John Rose discusses applying AI to the
    enterprise, including RAG systems and agentic systems.
  name: Dell
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: A high-performance DataFrame library discussed in detail, replacing pandas
    in high-throughput data processing pipelines.
  name: Polars
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: The legacy Python data manipulation library that Polars is being implemented
    to replace due to performance limitations.
  name: pandas
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: A Dutch utility company and the first known production instance where Polars
    was implemented to speed up data pipelines.
  name: Alliander
  source: llm_enhanced
- category: ai_infrastructure
  confidence: medium
  context: Mentioned as the provider of the cloud instance where the Alliander data
    processing was running before optimization.
  name: AWS
  source: llm_enhanced
- category: ai_startup
  confidence: medium
  context: The organization where Polars was being developed, and where the speakers
    promoting Polars were working.
  name: Xamlian
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: A new platform for education utilizing VR capabilities, discussed in relation
    to scaling specialist education and training for autonomous vehicles (eVTOLs).
  name: SIEK (Sikh)
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: The company whose founder is discussing lessons learned in implementing
    conversational AI products ('data conversations') and data quality infrastructure.
  name: AdVarity
  source: llm_enhanced
- category: N/A (Client/User)
  confidence: high
  context: Client that used the speaker's VR platform to develop a CPR training program.
  name: Children's Hospital
  source: llm_enhanced
- category: N/A (Client/User)
  confidence: high
  context: Entity considering the VR platform for nursing residency training to improve
    confidence and reduce turnover.
  name: Baptist Health
  source: llm_enhanced
- category: ai_infrastructure
  confidence: medium
  context: The company plans to use different models for different tasks (SQL compilation,
    qualification), implying reliance on external or internal LLM providers.
  name: Large Language Model (LLM) Providers
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: A built-in feature of their data quality monitoring component, relying
    on machine learning for identifying problematic data sets.
  name: Anomaly Detection Systems
  source: llm_enhanced
date: 2025-06-06 11:00:00 +0000
duration: 30
has_transcript: false
insights:
- actionable: false
  confidence: medium
  extracted: 'work in episode 887, and in this clip, I asked him to define two terms:
    AI agent and RAG-based chatbot. Let''s talk about the natural next step that has
    emerged after generative AI, which'
  text: 'the future of work in episode 887, and in this clip, I asked him to define
    two terms: AI agent and RAG-based chatbot. Let''s talk about the natural next
    step that has emerged after generative AI, which is agentic systems, because as
    generative AI has become powerful enough, as LLMs have become reliable enough,
    we''ve started to be able to rely on them more and more on their own.'
  type: prediction
- actionable: false
  confidence: medium
  extracted: an enterprise. Well, yep, still got proprietary data and still got unique
    skills, except now I have a path to digitize both of them. And that's the thing
    that's going to profoundly change most enterprises. John touches on an important
    point about the future of AI being in the interconnectivity between tools such
    as AI agents and RAG-based chatbots. And I recommend listening to the entire episode
    to hear more about how John's team applies such integrations at Dell. Based on
    the social media response, listeners absolutely loved that episode. All right.
    My next clip
  text: the future of an enterprise. Well, yep, still got proprietary data and still
    got unique skills, except now I have a path to digitize both of them. And that's
    the thing that's going to profoundly change most enterprises. John touches on
    an important point about the future of AI being in the interconnectivity between
    tools such as AI agents and RAG-based chatbots. And I recommend listening to the
    entire episode to hear more about how John's team applies such integrations at
    Dell. Based on the social media response, listeners absolutely loved that episode.
    All right. My next clip is from episode 885 with Yorun Jonsons and Ty's Newdorp.
  type: prediction
layout: episode
llm_enhanced: true
original_url: https://www.podtrac.com/pts/redirect.mp3/chrt.fm/track/E581B9/arttrk.com/p/VI4CS/pscrb.fm/rss/p/traffic.megaphone.fm/SUPERDATASCIENCEPTYLTD6783802980.mp3?updated=1749049954
processing_date: 2025-10-05 11:37:43 +0000
quotes:
- length: 236
  relevance_score: 6
  text: A lot of our listeners are either hands-on data science practitioners, like
    machine learning engineers, AI engineers, data scientists themselves, or people
    who are interested in building products or companies that leverage generative
    AI
  topics: []
- length: 203
  relevance_score: 4
  text: 'John and I had a detailed conversation about multi-agent teams, quantum computing,
    and the future of work in episode 887, and in this clip, I asked him to define
    two terms: AI agent and RAG-based chatbot'
  topics: []
- length: 260
  relevance_score: 4
  text: Let's talk about the natural next step that has emerged after generative AI,
    which is agentic systems, because as generative AI has become powerful enough,
    as LLMs have become reliable enough, we've started to be able to rely on them
    more and more on their own
  topics: []
- length: 126
  relevance_score: 4
  text: A chatbot, a RAG system, all of these things are just tools that allow us
    to unlock and create value from our proprietary data
  topics: []
- length: 27
  relevance_score: 4
  text: What is a RAG-based chatbot
  topics: []
- length: 143
  relevance_score: 4
  text: John touches on an important point about the future of AI being in the interconnectivity
    between tools such as AI agents and RAG-based chatbots
  topics: []
- length: 114
  relevance_score: 3
  text: And you need, for example, 100,000 eVTOL pilots within the next few years,
    which means you have to train a million
  topics: []
- impact_reason: 'Clearly delineates the two major phases/applications of enterprise
    AI: Reactive AI (RAG/Data unlocking) and Agentic AI (Skill digitization). This
    provides a strategic framework for AI adoption.'
  relevance_score: 10
  source: llm_enhanced
  text: Agents are the second one [part of applying AI to the enterprise]. The reason
    for that is the source of differentiation of an enterprise.
  topic: strategy
- impact_reason: Provides a concise, functional definition of RAG systems, positioning
    them as the first wave of enterprise AI focused on data leverage.
  relevance_score: 10
  source: llm_enhanced
  text: A chatbot, a RAG system, all of these things are just tools that allow us
    to unlock and create value from our proprietary data. What is a RAG-based chatbot?
    It is a tool that takes proprietary data and makes it generative.
  topic: technical
- impact_reason: 'Defines agentic systems by their core function: automating and distributing
    skills, moving beyond simple data retrieval.'
  relevance_score: 10
  source: llm_enhanced
  text: Agents go after the second one [unique skills]. They are about the digitization
    of a skill. They are about saying, I'm not just interested in unlocking the data.
    I'm interested in distributing the work.
  topic: technical
- impact_reason: A crucial reality check, tempering AGI hype by emphasizing that current
    agents are narrow, geo-fenced, or scope-limited, similar to early autonomous vehicles.
  relevance_score: 10
  source: llm_enhanced
  text: The reality of agents is that they are actually the digitization of more narrow
    skills. I use this self-driving car example. I do not have a self-driving car
    today that can drive anywhere in any situation and navigate it successfully.
  topic: limitations
- impact_reason: Provides a clear taxonomy differentiating 'Human-in-the-Loop' (Reactive
    AI) from 'Human-on-the-Loop' (Agentic AI), marking a fundamental shift in workflow
    automation.
  relevance_score: 10
  source: llm_enhanced
  text: Reactive AI, that a human is in the loop and the human asks the AI to do something
    and it gives an immediate response. But ultimately, the human is the doer of the
    work... And then you move over to this second generation of agentic AI, which
    are complementary. And now you have a situation where the human is on the loop.
    They are the supervisor.
  topic: technical
- impact_reason: This is a detailed architectural breakdown of an agent, contrasting
    it sharply with RAG systems by emphasizing the 'body' (tool use, function serving)
    and persistent memory/knowledge graph.
  relevance_score: 10
  source: llm_enhanced
  text: An agentic environment has large language models, but they're used for part
    of the equation. They act as someone of its brain, but it has a body. It has a
    knowledge graph where it creates its own representation of data that it represents
    what it's learned and its memories and its evolution of skills. It has interfaces
    around it that allow it to reach out into a real world, something called tool
    use and function serving where it can actually go and activate a tool and interact
    with the world and perceive things.
  topic: technical
- impact_reason: 'Provides a powerful, pseudo-scientific justification for VR training
    efficacy: memory formation and experiential learning are indistinguishable from
    reality for the brain.'
  relevance_score: 10
  source: llm_enhanced
  text: And then the other aspect is the fact that in VR, the brain hasn't developed
    the ability to differentiate between what you do in VR for the first time, we're
    creating memories, right? So it's almost as if you're actually flying the aircraft.
    It's almost as if you're actually, you know, moving the equipment and doing all
    these things. And then you're going to have a memory which means you're building
    experience.
  topic: technical
- impact_reason: Reveals a deeply disturbing and unethical current training practice
    (using vulnerable populations as physical training dummies), making the ethical
    case for simulation technology overwhelming.
  relevance_score: 10
  source: llm_enhanced
  text: Today what some hospitals do to train is they hire low-income people and pay
    them and then they can test intubation on them. Oh my goodness. But once to perforate
    their organs for $50, I mean, not me. I don't want to do that. And unfortunately,
    you have the homeless, the elderly, some people also do the testing on the elderly
    with Alzheimer's and to train the nurses how to do the intubation.
  topic: safety
- impact_reason: 'The foundational prerequisite for any successful data-driven or
    LLM-based application: Garbage In, Garbage Out.'
  relevance_score: 10
  source: llm_enhanced
  text: I think one really critical piece is the quality of the data underneath.
  topic: technical
- impact_reason: 'A sophisticated architectural insight: employing a ''mixture of
    experts'' approach where specialized LLMs (or models fine-tuned for specific tasks
    like SQL generation vs. summarization) are used for different parts of the application
    workflow.'
  relevance_score: 10
  source: llm_enhanced
  text: And to be fair, the plan is also at the moment we committed to one model,
    but there is also the plan to use different models for different aspects of our
    capability. So for example, we could use a different model to compile our SQL
    query, a different model to do the pre-flight qualification
  topic: technical
- impact_reason: 'This is a key strategic insight: advocating for a multi-model architecture
    (a ''model mosaic'') rather than relying on a single monolithic LLM for all tasks.'
  relevance_score: 10
  source: llm_enhanced
  text: the plan is also at the moment we committed to one model, but there is also
    the plan to use different models for different aspects of our capability.
  topic: Strategy/Architecture
- impact_reason: Provides a concrete example of task-specific model routing, which
    optimizes performance, cost, and potentially accuracy by matching the right tool
    (model) to the job.
  relevance_score: 10
  source: llm_enhanced
  text: So for example, we could use a different model to compile our SQL query, a
    different model to do the pre-flight qualification
  topic: Architecture/Business
- impact_reason: 'Reiterates the fundamental, sustainable source of competitive advantage
    in the AI era: unique, proprietary data.'
  relevance_score: 9
  source: llm_enhanced
  text: The first is your proprietary data. You know things other people don't know.
    That's actually very powerful. That's why you don't share your proprietary data
    with people.
  topic: business
- impact_reason: Identifies the second, often overlooked, source of enterprise differentiation,
    which agents are now poised to digitize.
  relevance_score: 9
  source: llm_enhanced
  text: The second source of differentiation is the unique skills in your organization,
    that you have people that can do things better than other people.
  topic: strategy
- impact_reason: This describes the shift from prompt engineering (telling the AI
    *how* to do something) to objective setting (telling the AI *what* to achieve),
    a key characteristic of true agents.
  relevance_score: 9
  source: llm_enhanced
  text: I'm just going to give it an objective and let it go. I'm doing this aligned
    to the skills that I need it to do.
  topic: predictions
- impact_reason: 'A strong prediction summarizing the long-term impact: agents provide
    the pathway to digitize the second core pillar of enterprise value (skills), completing
    the AI transformation loop.'
  relevance_score: 9
  source: llm_enhanced
  text: Yep, still got proprietary data and still got unique skills, except now I
    have a path to digitize both of them. And that's the thing that's going to profoundly
    change most enterprises.
  topic: predictions
- impact_reason: Quantifies the massive efficiency gains (memory reduction) achieved
    by migrating to Polars, providing a tangible ROI metric for data engineering modernization.
  relevance_score: 9
  source: llm_enhanced
  text: We hashed it all the way down from 500 to 40 gigabytes, which makes it a lot
    more doable to calculations.
  topic: business
- impact_reason: 'A critical lesson for practitioners adopting high-performance data
    libraries: direct translation fails; idiomatic rewriting based on understanding
    the underlying execution model is necessary.'
  relevance_score: 9
  source: llm_enhanced
  text: You can't just translate pandas to Polars. You really have to reason about
    the inputs and the outputs and then do it in an idiomatic way, right?
  topic: practical lessons
- impact_reason: Directly links automation/new industries (like autonomous vehicles)
    to an urgent, massive need for rapid, scalable workforce training—a key societal
    impact of technological change.
  relevance_score: 9
  source: llm_enhanced
  text: The reason why we're getting interest from the likes of the eVTOLs of the
    world is because this is a brand new industry, right? So for example, you have
    the mass displacement of a lot of the current jobs as we know it. And they also
    have to train people for all these new autonomous vehicles, new, you know, all
    these new industries that are coming out as a result of automation.
  topic: predictions
- impact_reason: Quantifies the training bottleneck created by emerging high-tech
    industries and validates VR simulation as the only viable solution.
  relevance_score: 9
  source: llm_enhanced
  text: You need, for example, 100,000 eVTOL pilots within the next few years, which
    means you have to train a million. You cannot put a million people in these very
    expensive aircraft. It's also very dangerous.
  topic: business
- impact_reason: Pinpoints the psychological barrier (fear of causing harm) preventing
    skill acquisition in high-stakes professions, which VR training directly mitigates
    by allowing safe failure.
  relevance_score: 9
  source: llm_enhanced
  text: A lot of people that a lot of nurses by nature are very, very caring. So a
    lot of them are afraid that they don't want to hurt someone. So by now being able
    to learn and make the mistakes, they don't want to make a mistake on a real person.
  topic: safety
- impact_reason: Directly asks for the prerequisites and best practices for deploying
    LLMs in data analytics products, highly relevant for the AI/ML business audience.
  relevance_score: 9
  source: llm_enhanced
  text: What are the kinds of lessons that you've learned in implementing a product
    like data conversations at AdVarity? What do you need to do? All the things you
    need to line up in advance of bringing in a large language model and having conversations
    work effectively with data.
  topic: business
- impact_reason: 'Specifies the practical requirements for data quality beyond simple
    completeness: alignment and harmonization across sources.'
  relevance_score: 9
  source: llm_enhanced
  text: From a more practical perspective, you need a complete data set that is also
    very well aligned with all the various sources that you have. Harmonization plays
    a role in this as well.
  topic: technical
- impact_reason: 'A crucial architectural pattern for data pipelines: maintaining
    immutable raw data for auditability and iterative refinement of transformations.'
  relevance_score: 9
  source: llm_enhanced
  text: We keep always a raw data set that can then be used as a starting point to
    reiterate on transformations, for example.
  topic: technical
- impact_reason: Reinforces the importance of metadata—data dictionaries and lineage—as
    essential components for making conversational data interfaces trustworthy.
  relevance_score: 9
  source: llm_enhanced
  text: I think it's useful. And maybe one thing to add to the previous question,
    in terms of quality, like I already said, the data dictionary descriptions, understanding
    of lineage is very critical as well.
  topic: technical
- impact_reason: 'Describes a practical MLOps/LLMOps strategy: continuous testing
    against a golden dataset of expected responses.'
  relevance_score: 9
  source: llm_enhanced
  text: The data science team is having a continuous test on, you know, we have a
    kind of a predefined set of responses that we expect from our questions. And we
    can monitor on those and improve and test models as we go.
  topic: AI/ML
- impact_reason: 'Highlights the goal of the first agent wave: creating autonomous
    manifestations of specific skills, rather than just interactive tools.'
  relevance_score: 8
  source: llm_enhanced
  text: The first generation of agents are saying, could I take a task, a skill, and
    could I move it into AGI, not as a tool that a person uses, but as a manifestation
    of that skill autonomously that I can just tell it to do something?
  topic: technical
- impact_reason: Highlights the gap between theoretical library exploration and real-world
    production stress-testing, where edge cases and missing features become apparent.
  relevance_score: 8
  source: llm_enhanced
  text: When you're just, when you actually need to put it into production, when you
    have a real problem to solve, that's also when you start to notice the limits,
    right? Or maybe inconsistencies or missing functionality.
  topic: practical lessons
- impact_reason: Highlights the crucial difference between theoretical use/prototyping
    and real-world production deployment, a common realization when scaling any technology,
    including AI/ML systems.
  relevance_score: 8
  source: llm_enhanced
  text: hen you actually need to put it into production, when you have a real problem
    to solve, that's also when you start to notice the limits, right? Or maybe inconsistencies
    or missing functionality.
  topic: strategy
- impact_reason: Provides concrete data points on the scale of the global education
    crisis, framing the need for technological intervention.
  relevance_score: 8
  source: llm_enhanced
  text: In the US, for example, there's a shortage of 400,000 kindergarten grade 12
    teachers... And post-secondary institutions, there will also be shortages coming
    because those workforces are unusually old.
  topic: strategy
- impact_reason: 'Defines the core value proposition of scalable education technology:
    leveraging expert knowledge across massive geographies.'
  relevance_score: 8
  source: llm_enhanced
  text: So a platform like Sikh, we allow a single individual to be able to teach
    at scale. So they can present their course virtually. And then people are also
    able to experience it.
  topic: business
- impact_reason: Identifies another critical sector (healthcare staffing) facing imminent
    collapse due to workforce aging and high turnover, creating a market for simulation
    training.
  relevance_score: 8
  source: llm_enhanced
  text: The reason Baptist Health was looking at the nursing residences is because
    there's such a huge gap between nurses. The average age of a nurse today is 50
    years old. That's how big the gap is because a lot of people are staying a year
    or two and then they're leaving.
  topic: strategy
- impact_reason: Emphasizes proactive data governance and quality gates before data
    reaches production systems, especially those powered by LLMs.
  relevance_score: 8
  source: llm_enhanced
  text: You want to prevent kind of not saying dirty, but problematic data sets to
    hit your production environment.
  topic: safety
- impact_reason: Points to the use of AI/LLMs to automate data wrangling and transformation
    composition, a key productivity gain in MLOps/DataOps.
  relevance_score: 8
  source: llm_enhanced
  text: There is also obviously today, an AI system helping you to compose those transformations.
    But this is specifically very useful for those type of generic sources. You can,
    it's kind of a simplified data wrangling exercise, if you will.
  topic: AI/ML
- impact_reason: 'Actionable advice: Dedicated teams and formal frameworks are necessary
    for continuous quality assurance of LLM outputs.'
  relevance_score: 8
  source: llm_enhanced
  text: We have a dedicated team taking care of benchmarking and analyzing the quality
    of responses. We'll be using frameworks to monitor that.
  topic: business
- impact_reason: Highlights the critical necessity of post-deployment monitoring and
    quality assurance for AI systems, moving beyond initial training.
  relevance_score: 8
  source: llm_enhanced
  text: arking and analyzing the quality of responses.
  topic: Strategy/Deployment
- impact_reason: Emphasizes the iterative nature of modern AI development (CI/CD for
    ML), where testing drives immediate improvement cycles.
  relevance_score: 8
  source: llm_enhanced
  text: And we can monitor on those and improve and test models as we go.
  topic: Strategy/Deployment
- impact_reason: Illustrates the massive resource requirements (memory footprint)
    of legacy data processing pipelines (Python/Pandas/R) that tools like Polars aim
    to solve.
  relevance_score: 7
  source: llm_enhanced
  text: We were running this on a single AWS instance that had over 700 gigs of RAM.
  topic: technical
- impact_reason: Provides a specific, concrete example of a missing feature in a newer
    library (Polars) compared to an incumbent (Pandas), illustrating the trade-offs
    in adoption.
  relevance_score: 7
  source: llm_enhanced
  text: For example, there was this random sampling with weights, right? That's something
    that you can do in pandas... That's something, maybe even up until this point,
    something that Polars doesn't have.
  topic: technical
- impact_reason: Shows how documentation and educational efforts (writing a book)
    force a deeper, more comprehensive review of API design and completeness than
    typical feature-based development.
  relevance_score: 7
  source: llm_enhanced
  text: Hey, why is there no inline operator for the XOR operation, right? That's
    something that nobody ever thinks about. But when you, when you need to put in
    a table in your book and you need to fill in, you know, all the pieces, that's
    when you start noticing these kind of things.
  topic: practical lessons
- impact_reason: 'Sets the stage for the major theme: using advanced technology (VR/platforms)
    to solve systemic educational access problems.'
  relevance_score: 7
  source: llm_enhanced
  text: I talked to Sikh's founder, the space engineer, Mary Spio, about the potential
    for Sikh to revitalize the way we learn and make even specialist education accessible
    worldwide.
  topic: predictions
- impact_reason: Shows how immersive training can reveal critical knowledge gaps that
    passive learning methods (like reading or video) fail to address.
  relevance_score: 7
  source: llm_enhanced
  text: The interesting thing is this was for new mothers because actually before
    I did the CPR program, I didn't even know there was a difference between infant,
    child, and adult CPR, and a lot of new moms don't either.
  topic: safety
- impact_reason: A strong philosophical statement connecting learning theory across
    education and business strategy.
  relevance_score: 7
  source: llm_enhanced
  text: Being able to make mistakes and learn from them is such a core part of education.
    Learning from past mistakes is also an unavoidable part of running a business.
  topic: strategy
- impact_reason: Highlights the need for domain-specific, intelligent data quality
    monitoring, moving beyond generic checks.
  relevance_score: 7
  source: llm_enhanced
  text: There are specific monitors for data quality in marketing. There's a concept
    called naming conventions, for example, for key names that we can monitor and
    act on in an intelligent manner.
  topic: technical
- impact_reason: Illustrates the rapid iteration required in the current generative
    AI product landscape.
  relevance_score: 7
  source: llm_enhanced
  text: We iterate very quickly. So we have, you know, we're going through, I'd say
    a pretty fast-paced development cycle with this, adding features as, you know,
    like every week.
  topic: business
- impact_reason: Indicates a structured, systematic approach to MLOps and model governance,
    rather than ad-hoc checks.
  relevance_score: 7
  source: llm_enhanced
  text: We'll be using frameworks to monitor that.
  topic: Deployment/Strategy
- impact_reason: Signals a shift in focus toward immersive technology (VR/Metaverse)
    applications in education, suggesting this is a key area for future tech investment/development.
  relevance_score: 6
  source: llm_enhanced
  text: From writing nonfiction, I turn to Sikh, CEEK, a new platform for education
    with VR capabilities.
  topic: technology trends
- impact_reason: Illustrates how detailed API/library design choices become bottlenecks
    or points of friction during serious application development.
  relevance_score: 6
  source: llm_enhanced
  text: Also, when you write, you start to look at things from a little bit of a higher
    level. So sometimes we noticed inconsistencies in naming or missing methods. Like,
    hey, why is there no inline operator for the XOR operation, right?
  topic: technical
source: Unknown Source
summary: '## Podcast Episode Summary: 894: In Case You Missed It in May 2025


  This "In Case You Missed It" episode of the Super Data Science Podcast, hosted by
  John Cron, compiles key highlights from four significant interviews conducted in
  May 2025, focusing on the evolution of AI from generative models to agentic systems,
  the practical adoption of high-performance data tools, the transformative potential
  of VR in specialized education, and the critical prerequisites for successful conversational
  AI implementation.


  ---


  ### 1. Focus Area

  The episode covers four distinct, yet interconnected, areas at the forefront of
  technology and business transformation:

  1. **Agentic Systems vs. Generative AI:** The shift from reactive AI (RAG-based
  chatbots) to autonomous, skill-digitizing AI agents.

  2. **High-Performance Data Processing:** Real-world adoption and performance benefits
  of the **Polars** data manipulation library over Pandas in enterprise settings.

  3. **Immersive Learning (VR/Metaverse):** Utilizing platforms like **Sikh** to address
  global teacher shortages and scale specialized, high-stakes training (e.g., aviation,
  healthcare).

  4. **Data Quality for Conversational AI:** The non-negotiable role of data harmonization,
  lineage, and quality monitoring for effective LLM-powered data conversations.


  ### 2. Key Technical Insights

  *   **Agentic Architecture:** Agents are distinct from RAG systems; they possess
  a "body" including a knowledge graph, memory, and tool-use interfaces, allowing
  them to operate autonomously based on objectives, moving beyond the human-in-the-loop
  model of reactive AI.

  *   **Polars Performance Gains:** Real-world implementation at Alliander demonstrated
  massive efficiency gains, shrinking a 500GB data processing job down to 40GB through
  idiomatic Polars implementation and code restructuring, highlighting significant
  memory and speed improvements over Pandas.

  *   **VR Memory Encoding:** VR training leverages the brain''s inability to immediately
  differentiate between virtual and real experience, allowing users to build experiential
  memories and gain practical skills (like flying an eVTOL or performing CPR) without
  real-world risk or cost.

  *   **Data Foundation for LLMs:** For conversational data products, achieving high
  data quality—including harmonization, aligned data types, and robust monitoring
  for anomalies—is more critical than the choice of the LLM itself.


  ### 3. Business/Investment Angle

  *   **Enterprise Differentiation:** The next wave of enterprise AI value lies in
  **Agentic Systems**, which digitize unique organizational *skills*, whereas the
  first wave (RAG) focused on unlocking proprietary *data*.

  *   **Efficiency in Data Pipelines:** Companies using Polars can drastically reduce
  cloud computing costs and processing times, making previously infeasible large-scale
  data tasks manageable on smaller infrastructure.

  *   **Scaling Specialized Workforce Training:** VR platforms address critical shortages
  (e.g., 4.6 million educators globally, massive need for eVTOL pilots) by allowing
  one expert to train hundreds of thousands simultaneously, offering a superior, safer,
  and cheaper alternative to physical training.

  *   **Risk Mitigation in Conversational Data Products:** Investing in robust data
  quality monitoring and lineage tools is essential to prevent "problematic data sets"
  from undermining the reliability and trustworthiness of LLM-driven insights.


  ### 4. Notable Companies/People

  *   **John Rose (Dell):** Global CTO and Chief AI Officer, provided the framework
  distinguishing between RAG/Reactive AI and Agentic AI.

  *   **Yorun Jonsons & Ty''s Newdorp:** Authors of the O''Reilly book on Polars,
  detailed their successful migration project at **Alliander** (a major Dutch utility).

  *   **Mary Spio (Sikh):** Founder of the VR education platform, discussed its application
  in scaling training for high-demand fields like eVTOL aviation and reducing medical
  training risks (e.g., intubation practice).

  *   **Martin Brunthaler (AdVarity):** Founder who discussed lessons learned in implementing
  "data conversations," emphasizing the necessity of data quality infrastructure underneath
  the LLM layer.


  ### 5. Future Implications

  The industry is rapidly moving toward **autonomous execution** via agentic systems
  that can be delegated complex objectives, fundamentally changing how work is distributed
  within organizations. Furthermore, specialized, high-fidelity training will increasingly
  migrate to immersive environments like VR to overcome physical limitations, cost
  barriers, and safety concerns, particularly in rapidly evolving sectors. The success
  of these advanced AI applications hinges entirely on the underlying quality and
  governance of enterprise data.


  ### 6. Target Audience

  This episode is highly valuable for **AI/ML Engineers, Data Scientists, CTOs, Heads
  of Data Strategy, and Technology Investors** interested in the practical implementation,
  architectural evolution, and strategic business impact of next-generation AI tools
  and high-performance computing frameworks.'
tags:
- artificial-intelligence
- generative-ai
- ai-infrastructure
- startup
title: '894: In Case You Missed It in May 2025'
topics:
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 55
  prominence: 1.0
  topic: artificial intelligence
- keywords:
  - generative ai
  - genai
  - chatgpt
  - gpt
  - claude
  - text generation
  - image generation
  mentions: 3
  prominence: 0.3
  topic: generative ai
- keywords:
  - gpu
  - tensor
  - training
  - inference
  - model deployment
  - vector database
  mentions: 2
  prominence: 0.2
  topic: ai infrastructure
- keywords:
  - startup
  - entrepreneur
  - founder
  - venture
  mentions: 2
  prominence: 0.2
  topic: startup
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-10-05 11:37:43 UTC -->
