---
companies:
- category: unknown
  confidence: medium
  context: Welcome everyone to the AI and Business Podcast. I'm Matthew Damello, editorial
    director here at
  name: Business Podcast
  position: 31
- category: unknown
  confidence: medium
  context: come everyone to the AI and Business Podcast. I'm Matthew Damello, editorial
    director here at Emerge AI Research. T
  name: Matthew Damello
  position: 53
- category: unknown
  confidence: medium
  context: . I'm Matthew Damello, editorial director here at Emerge AI Research. Today's
    guest is Dr. Anker Sharma, head of medic
  name: Emerge AI Research
  position: 97
- category: unknown
  confidence: medium
  context: here at Emerge AI Research. Today's guest is Dr. Anker Sharma, head of
    medical affairs for medical devices in d
  name: Anker Sharma
  position: 138
- category: tech
  confidence: high
  context: o the point where under many legal contexts, your Apple Watch is by all
    means considered under the law an
  name: Apple
  position: 1283
- category: unknown
  confidence: medium
  context: o the point where under many legal contexts, your Apple Watch is by all
    means considered under the law and regu
  name: Apple Watch
  position: 1283
- category: unknown
  confidence: medium
  context: re likely coming from yet another company, right? The AI developers aren't
    usually the companies that are
  name: The AI
  position: 6694
- category: unknown
  confidence: medium
  context: there's different notified bodies, there it's the EU AI Act and different
    countries have all their different
  name: EU AI Act
  position: 8530
- category: unknown
  confidence: medium
  context: re no generative LLMs that are in the SaMD space. The SaMD space currently
    in the US is all predictive model
  name: The SaMD
  position: 9630
- category: unknown
  confidence: medium
  context: didn't actually get B. I got a deviation of that. And I can still then
    take some action as a physician on
  name: And I
  position: 11733
- category: unknown
  confidence: medium
  context: ecutive thought leaders, everyone from the CIO of Goldman Sachs to the
    head of AI at Raytheon and AI pioneers lik
  name: Goldman Sachs
  position: 16459
- category: unknown
  confidence: medium
  context: o the head of AI at Raytheon and AI pioneers like Yoshua Bengio. With nearly
    a million annual listeners, AI and B
  name: Yoshua Bengio
  position: 16524
- category: unknown
  confidence: medium
  context: eve you can help other leaders move the needle on AI ROI, visit emerj.com
    and fill out our Thought Leaders
  name: AI ROI
  position: 16990
- category: unknown
  confidence: medium
  context: eedle on AI ROI, visit emerj.com and fill out our Thought Leaders Submission
    Form. That's emerj.com and click on Be an Expert. You
  name: Thought Leaders Submission Form
  position: 17031
- category: unknown
  confidence: medium
  context: today's episode, consider leaving us a review on Apple Podcasts and let
    us know what you learned, found helpful,
  name: Apple Podcasts
  position: 17405
- category: ai_research
  confidence: high
  context: The organization hosting the 'AI and Business Podcast' and featuring executive
    thought leaders on AI adoption.
  name: Emerge AI Research
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: The employer of the guest, Dr. Anker Sharma, who works in medical affairs
    for medical devices and digital radiology, implying internal AI/ML integration
    efforts.
  name: Bayer
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: The sponsor of the podcast episode.
  name: Medable
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: Mentioned as an example of a consumer device that is legally considered
    a medical device, implying it uses embedded AI/ML for health monitoring.
  name: Apple Watch
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as the prime example of generative, large language models dominating
    the news cycle, used here as a general reference point for generative AI.
  name: ChatGPT
  source: llm_enhanced
- category: regulatory_body
  confidence: high
  context: The US regulatory body mentioned repeatedly in the context of regulating
    AI as Software as a Medical Device (SaMD).
  name: FDA
  source: llm_enhanced
- category: regulatory_body
  confidence: high
  context: The upcoming European regulation framework discussed in relation to regulating
    generative models in healthcare.
  name: EU AI Act
  source: llm_enhanced
- category: enterprise_user
  confidence: medium
  context: Mentioned as an example of an organization whose CIO has been featured
    on the podcast, indicating enterprise AI adoption.
  name: Goldman Sachs
  source: llm_enhanced
- category: enterprise_user
  confidence: medium
  context: Mentioned as an example of an organization whose head of AI has been featured
    on the podcast, indicating enterprise AI adoption.
  name: Raytheon
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: Mentioned as an AI pioneer who has been featured on the podcast, linking
    the show to foundational AI research figures.
  name: Yoshua Bengio
  source: llm_enhanced
date: 2025-06-24 06:00:00 +0000
duration: 19
has_transcript: false
insights:
- actionable: false
  confidence: medium
  extracted: healthcare. And great to have this wonderful perspective, not just on
    medical devices, but true to your last answer, I mean, what qualifies as a medical
    device
  text: the future of healthcare. And great to have this wonderful perspective, not
    just on medical devices, but true to your last answer, I mean, what qualifies
    as a medical device is becoming inherent to how we look at technology across the
    space.
  type: prediction
layout: episode
llm_enhanced: true
original_url: https://traffic.libsyn.com/secure/techemergence/Business_-_6.24.25_-_Ankur_Sharma.mp3?dest-id=151434
processing_date: 2025-10-05 07:20:52 +0000
quotes:
- length: 141
  relevance_score: 4
  text: Are you driving AI transformation at your organization, or maybe you're guiding
    critical decisions on AI investments, strategy, or deployment
  topics:
  - investment
- length: 82
  relevance_score: 3
  text: And then you have to think about, okay, well, how do these AI tools get their
    data
  topics: []
- length: 87
  relevance_score: 3
  text: Right now, as far as I'm aware, there are no generative LLMs that are in the
    SaMD space
  topics: []
- impact_reason: Crucially distinguishes the heavily regulated segment of healthcare
    AI (predictive models/SaMD) from unregulated tools, emphasizing the high regulatory
    bar for clinical decision support.
  relevance_score: 10
  source: llm_enhanced
  text: the bulk of the work is in predictive models that are regulated by the FDA
    as software as a medical device. They're the same kinds of rules and regulations
    that apply to them [sutures or your knee implants].
  topic: regulation/technical
- impact_reason: Provides a stark summary of the interoperability crisis in healthcare
    IT, which directly starves AI models of the comprehensive data needed for robust
    performance.
  relevance_score: 10
  source: llm_enhanced
  text: Just like all your healthcare providers are in silos, all your electronic
    records are in silos. There's electronic health records, there's PACS systems,
    there's RIS systems, there's your labs have different systems, they may or may
    not all talk to each other and AI kind of needs some of all that data depending
    on what it's trying to do.
  topic: technical/business
- impact_reason: 'This is a key technical/regulatory distinction: current regulated
    AI (SaMD) relies on deterministic, fixed input/output (predictive), whereas generative
    AI creates novel content, creating a regulatory gap.'
  relevance_score: 10
  source: llm_enhanced
  text: As far as I'm aware, there are no generative LLMs that are in the SaMD space.
    The SaMD space currently in the US is all predictive models, meaning we know that
    if we give it input A, we know that it will give me a prediction based on A and
    it's always going to work that way. There's a fixed structure to input an output
    for predictive models. It's not creating its own content...
  topic: technical/regulation
- impact_reason: 'Explains why generative AI is harder to validate in real-world clinical
    settings than controlled trial models: the lack of transparency into the ''steps''
    taken to reach an output makes monitoring deviation difficult.'
  relevance_score: 10
  source: llm_enhanced
  text: In clinical practice, in real-world patient use, some of those guardrails
    that exist in a trial setting are not there... In generative, it's not necessarily
    as clear because I'm not getting the work behind this scene, right? I'm not getting
    all the steps that it took to give me the output.
  topic: safety/technical
- impact_reason: 'Provides a crucial distinction in the current regulatory status:
    established predictive AI vs. the emerging, less-defined regulatory space for
    GenAI.'
  relevance_score: 10
  source: llm_enhanced
  text: While predictive models are already regulated as medical devices, generative
    AI still exists largely outside those frameworks, raising new governance questions.
  topic: safety/regulation
- impact_reason: Articulates the core safety and monitoring challenge for regulated
    AI in medicineâ€”ensuring predictable performance and mitigating misinterpretation
    risks.
  relevance_score: 9
  source: llm_enhanced
  text: How do you apply the same amount of monitoring for potential harms that can
    happen? How do you do those things? How do you make sure that they work as intended
    and that there's not a misinterpretation of the AI that could result in harm to
    the patient?
  topic: safety/regulation
- impact_reason: Pinpoints the fundamental tension between AI's data hunger and strict
    healthcare privacy mandates (like HIPAA), a major barrier to deployment.
  relevance_score: 9
  source: llm_enhanced
  text: How do you deal with data privacy, right? There's all these rules that we
    have around what data can be used by who and what can be disclosed by whom. And
    when you have AI algorithms in the mix, they obviously need access to a lot of
    the data to be able to put their output to a physician.
  topic: safety/business
- impact_reason: Provides a clear, practical example of a high-value, non-regulated
    use case for generative AI (patient communication/summarization), contrasting
    it with regulated SaMD.
  relevance_score: 9
  source: llm_enhanced
  text: Then you have all these non-regulated tools and those are kind of the AI tools
    that help a physician or help a patient. You know what? A radiologist wrote up
    a report about your CT and sent you the report, but it's written in medical language,
    but an AI tool could take that and rewrite it for you with a synopsis in the summary
    and more of a general layman's terms that helps you as the patient understand
    better.
  topic: technical/predictions
- impact_reason: 'Describes the likely evolution path: non-regulated efficiency tools
    gradually incorporating regulated, high-value diagnostic/treatment planning features,
    forcing regulatory review.'
  relevance_score: 9
  source: llm_enhanced
  text: '...but the next step would be versions of those programs that are adding
    regulated steps or processes that add value in other parts of those tangential
    work streams, right? With the physician who''s, okay, I''m writing in my report,
    that can be given because that''s not regulated. But hey, can this also then help
    me with what I''m trying to do on a diagnosis for treatment planning, etc., as
    I write this out? Yeah, then that would maybe be a regulated medical device.'
  topic: predictions/regulation
- impact_reason: Identifies reimbursement as a massive, unsolved business hurdle preventing
    widespread adoption of validated AI tools, even after regulatory approval.
  relevance_score: 9
  source: llm_enhanced
  text: We have all these tools, and they're not necessarily getting reimbursed. And
    until there's reimbursement...
  topic: business
- impact_reason: Highlights the critical challenge of explainability and trust in
    AI outputs, especially in high-stakes fields like patient care, where the 'why'
    behind a decision is as important as the decision itself.
  relevance_score: 9
  source: llm_enhanced
  text: I'm not getting all the steps that it took to give me the output. And it's
    a lot harder for me to adjust and say, hey, how do I actually know? Did this give
    me what I really want? And is it accurate to what I need for my patient decision?
  topic: safety/limitations
- impact_reason: 'Clearly delineates the regulatory boundary shift in healthcare AI:
    moving from efficiency tools to tools impacting diagnosis/treatment immediately
    triggers medical device regulation.'
  relevance_score: 9
  source: llm_enhanced
  text: '...But hey, can this also then help me with what I''m trying to do on a diagnosis
    for treatment planning, etc., as I write this out? Yeah, then that would maybe
    be a regulated medical device.'
  topic: safety/regulation
- impact_reason: A strong prediction linking financial/regulatory clarity (reimbursement)
    directly to massive positive acceleration in patient benefit via AI adoption.
  relevance_score: 9
  source: llm_enhanced
  text: if we can get this reimbursement pathway going, it's going to just accelerate
    that entire adoption curve of AI and digital tools in healthcare, which is going
    to be fantastic for patients, I think, in the long run.
  topic: predictions
- impact_reason: 'Reiterates the central theme: financial mechanisms are the bottleneck
    for innovation adoption in regulated sectors.'
  relevance_score: 9
  source: llm_enhanced
  text: reimbursement is a major hurdle. Without clear paths for compensating the
    use of AI tools, especially those focused on diagnostics and care planning, widespread
    adoption will remain slow.
  topic: business
- impact_reason: 'Focuses on the critical integration challenge: AI must fit seamlessly
    into complex, multi-stakeholder clinical workflows, where outputs cascade downstream.'
  relevance_score: 8
  source: llm_enhanced
  text: Where are they using these tools? Where are they using them and where is the
    work that they're doing? And maybe there's different tools that are being used
    at different points in the care pathway that actually impact people downstream,
    right?
  topic: strategy/business
- impact_reason: Emphasizes patient consent and education as a necessary, often overlooked,
    prerequisite for AI adoption, framing it as a fundamental ethical/legal step.
  relevance_score: 8
  source: llm_enhanced
  text: The patients, it's their data. So they first have to actually acknowledge
    that these or be informed that these AI tools are being used, how they're being
    used, what does that mean for their data, what does that mean for the physicians.
  topic: safety/ethics
- impact_reason: Highlights the current regulatory and governance vacuum, forcing
    individual hospitals to create bespoke, potentially inconsistent, AI adoption
    frameworks.
  relevance_score: 8
  source: llm_enhanced
  text: there's no standardized guidance on how to approach this in healthcare systems,
    it's really kind of an institution-by-institution approach...
  topic: regulation/strategy
- impact_reason: 'Offers a clear roadmap for near-term generative AI adoption: focus
    on efficiency and comprehension tools that fall outside strict diagnostic regulation.'
  relevance_score: 8
  source: llm_enhanced
  text: I think where you're going to start seeing or where you are seeing more of
    these generative models come to fruition in practice is in the things that help
    physicians do their jobs a little bit more efficiently and the things that help
    patients understand what's happening with their care more efficiently. These are
    the non-regulated things...
  topic: business/predictions
- impact_reason: 'Identifies the initial, low-hanging fruit for generative AI adoption
    in healthcare: efficiency gains in non-regulated administrative or patient communication
    tasks.'
  relevance_score: 8
  source: llm_enhanced
  text: where you're going to start seeing or where you are seeing more of these generative
    models come to fruition in practice is in the things that help physicians do their
    jobs a little bit more efficiently and the things that help patients understand
    what's happening with their care more efficiently. These are the non-regulated
    things...
  topic: business/predictions
- impact_reason: Articulates the mismatch between current reimbursement structures
    (often tied to procedures or direct interventions) and the value proposition of
    AI tools (which are often diagnostic or planning aids that *lead* to better outcomes).
  relevance_score: 8
  source: llm_enhanced
  text: Reimbursement is really tied to an outcome, but a lot of these tools are an
    outcome-based tools. They're really tools for diagnoses or planning or something
    else that still drive value.
  topic: business/strategy
- impact_reason: 'Suggests a strategic entry point for AI companies in healthcare:
    targeting areas where reimbursement pathways are clearer, thereby accelerating
    market entry and adoption.'
  relevance_score: 8
  source: llm_enhanced
  text: '...essentially we now have maybe a pathway in the US of where we can see
    potential AI uses in healthcare, especially tied to clinical pieces where there
    are maybe easier pathways for reimbursement, which would then hopefully increase
    this adoption rate...'
  topic: business/strategy
- impact_reason: Indicates a fundamental shift in regulatory thinking where the function
    (impact on decision-making) rather than the form dictates classification, affecting
    all new tech.
  relevance_score: 8
  source: llm_enhanced
  text: what qualifies as a medical device is becoming inherent to how we look at
    technology across the space.
  topic: safety/regulation
- impact_reason: Summarizes the core operational and ethical hurdles facing AI deployment
    in healthcare beyond just regulatory approval.
  relevance_score: 8
  source: llm_enhanced
  text: AI tools in healthcare face major adoption challenges from data privacy and
    patient consent to interoperability between siloed clinical systems.
  topic: business/strategy
- impact_reason: Highlights the broad and sometimes surprising scope of medical device
    regulation, setting the stage for the complexity of AI in consumer-facing health
    tech.
  relevance_score: 7
  source: llm_enhanced
  text: under many legal contexts, your Apple Watch is by all means considered under
    the law and regulations a medical device.
  topic: strategy/regulation
- impact_reason: A strategic caution against over-restriction driven by fear, arguing
    that excessive safety measures can stifle the beneficial potential of AI innovation.
  relevance_score: 7
  source: llm_enhanced
  text: we often default to the how do we be safe is by being the most restrictive.
    And it's not always the right answer when you want to be able to leverage the
    capacity of AI tools...
  topic: strategy
- impact_reason: Acknowledges the historical inertia of the healthcare sector while
    recognizing AI as a unique catalyst forcing rapid technological change.
  relevance_score: 7
  source: llm_enhanced
  text: healthcare tends to be a slow adopter of technology, but AI has kind of kickstarted
    a wave through healthcare.
  topic: predictions/strategy
- impact_reason: A high-level strategic statement emphasizing the transformative,
    non-incremental nature of AI's impact on the healthcare industry.
  relevance_score: 7
  source: llm_enhanced
  text: Truly a watershed moment, I think we're going to see in the future of healthcare.
  topic: strategy
- impact_reason: Highlights the podcast's credibility and reach by naming high-profile
    guests, signaling its importance in the enterprise AI discourse.
  relevance_score: 5
  source: llm_enhanced
  text: The AI and Business Podcast wants to hear from you. Each year, Emerge AI Research
    features hundreds of executive thought leaders, everyone from the CIO of Goldman
    Sachs to the head of AI at Raytheon and AI pioneers like Yoshua Bengio.
  topic: general/marketing
source: Unknown Source
summary: '## Comprehensive Summary: AI in Healthcare Devices and the Challenge of
  Data Privacy - with Dr. Ankur Sharma at Bayer


  This podcast episode, featuring Dr. Ankur Sharma, Head of Medical Affairs for Medical
  Devices and Digital Radiology at Bayer, provided an in-depth analysis of the significant
  hurdles facing the integration of Artificial Intelligence (AI) into healthcare devices
  and clinical workflows. The discussion centered on the complex interplay between
  technological deployment, stringent data privacy regulations, and evolving regulatory
  frameworks.


  **Main Narrative Arc and Key Discussion Points:**


  The conversation began by establishing the broad challenges in deploying AI in medical
  settings, moving beyond the hype of generative models (like ChatGPT) to focus on
  the regulated reality of **Software as a Medical Device (SaMD)**, which are subject
  to the same rigorous scrutiny as physical implants. Dr. Sharma detailed that the
  primary obstacles are multi-faceted: **interoperability** between siloed healthcare
  systems (EHRs, PACS, RIS), securing **patient consent** for data usage, and navigating
  **regulatory uncertainty**. A crucial element highlighted was the necessity of **patient
  education** regarding AI use and its implications for their data. The discussion
  then pivoted to the regulatory distinction between fixed, **predictive models**
  (currently regulated SaMD) and dynamic, **generative tools**, noting that LLMs are
  largely outside the current regulated medical device space but represent the next
  frontier. Finally, the conversation addressed the critical barrier of **reimbursement**,
  arguing that slow adoption is directly linked to the lack of clear pathways for
  compensating the use of AI tools that drive diagnostic or planning value.


  **1. Focus Area:**

  The primary focus was the **integration and governance of AI in regulated healthcare
  devices (SaMD)**, specifically addressing the challenges of **data privacy, regulatory
  compliance (FDA/EU AI Act), interoperability, and clinical workflow integration**.
  A key distinction was made between regulated predictive AI and currently non-regulated
  generative AI in clinical settings.


  **2. Key Technical Insights:**

  *   **SaMD Regulation:** Predictive AI models used for clinical outcomes or diagnosis
  are regulated by the FDA identically to physical medical devices, requiring rigorous
  monitoring for intended use and potential harm.

  *   **Generative vs. Predictive Models:** Currently regulated SaMD in the US are
  predominantly predictive (fixed input/output structures). Generative LLMs, which
  create novel content, lack clear regulatory pathways for use as medical devices,
  though non-regulated uses (e.g., summarizing reports for patients) are emerging.

  *   **Clinical Workflow Integration Difficulty:** AI tools often fail to integrate
  seamlessly because healthcare data resides in disparate, siloed systems (EHRs, PACS),
  creating friction when feeding data to third-party AI developers.


  **3. Business/Investment Angle:**

  *   **Adoption Bottleneck:** Widespread adoption of valuable AI tools is severely
  hampered by the lack of clear **reimbursement pathways** tied to outcomes, forcing
  healthcare systems to adopt new technologies slowly.

  *   **Governance Fragmentation:** Due to a lack of standardized guidance, AI governance
  in healthcare is currently an **institution-by-institution approach**, creating
  complexity for vendors and internal deployment teams.

  *   **Future Acceleration:** If clear reimbursement pathways for AI-driven diagnostics
  and planning are established, the adoption curve for digital tools in healthcareâ€”which
  has historically been slowâ€”will accelerate significantly.


  **4. Notable Companies/People:**

  *   **Dr. Ankur Sharma (Bayer):** Guest expert, Head of Medical Affairs for Medical
  Devices and Digital Radiology, providing industry perspective on regulatory and
  deployment challenges.

  *   **FDA (US) & EU AI Act (EU):** Key regulatory bodies/frameworks dictating the
  compliance landscape for medical AI.

  *   **Medable:** Sponsor of the episode.


  **5. Future Implications:**

  The industry is moving toward a future where AI will increasingly bridge the gap
  between controlled **clinical research** and messy **real-world patient care**.
  The next wave of regulated AI will likely involve generative models that move beyond
  simple efficiency tasks (like report summarization) into regulated processes that
  aid in diagnosis and treatment planning. The resolution of reimbursement issues
  is the critical inflection point for this acceleration.


  **6. Target Audience:**

  This episode is highly valuable for **Healthcare Executives, Regulatory Affairs
  Professionals, HealthTech Investors, Clinical Informatics Specialists, and Product
  Leaders** developing AI solutions for medical devices, as it clearly outlines the
  current regulatory and commercial friction points.'
tags:
- artificial-intelligence
- generative-ai
- investment
- apple
title: AI in Healthcare Devices and the Challenge of Data Privacy - with Dr. Ankur
  Sharma at Bayer
topics:
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 59
  prominence: 1.0
  topic: artificial intelligence
- keywords:
  - generative ai
  - genai
  - chatgpt
  - gpt
  - claude
  - text generation
  - image generation
  mentions: 3
  prominence: 0.3
  topic: generative ai
- keywords:
  - investment
  - funding
  - valuation
  - ipo
  - acquisition
  mentions: 1
  prominence: 0.1
  topic: investment
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-10-05 07:20:52 UTC -->
