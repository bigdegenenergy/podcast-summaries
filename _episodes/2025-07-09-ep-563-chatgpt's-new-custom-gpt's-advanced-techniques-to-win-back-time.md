---
companies:
- category: unknown
  confidence: medium
  context: This is the Everyday AI Show, the everyday podcast where we simplify AI
    and br
  name: Everyday AI Show
  position: 12
- category: tech
  confidence: high
  context: o boost your career, business, and everyday life. OpenAI's custom GPTs
    have gotten some huge under-the-hoo
  name: Openai
  position: 197
- category: unknown
  confidence: medium
  context: too. All right, let's get it started. Welcome to Everyday AI. What's going
    on, y'all? My name's Jordan Wilson,
  name: Everyday AI
  position: 993
- category: unknown
  confidence: medium
  context: to Everyday AI. What's going on, y'all? My name's Jordan Wilson, and this
    thing, it's for you. Everyday AI is a d
  name: Jordan Wilson
  position: 1040
- category: unknown
  confidence: medium
  context: ke sure that you tune in. We're going to have Dr. Ben Gortzel, who literally
    coined the term AGI. He's one of t
  name: Ben Gortzel
  position: 2127
- category: unknown
  confidence: medium
  context: alk about what's new inside of these custom GPTs. So OpenAI originally
    rolled these out almost two years ago,
  name: So OpenAI
  position: 2447
- category: unknown
  confidence: medium
  context: tom GPTs to bring in third-party data via an API. So I'm going to show
    you the back end, how to do that,
  name: So I
  position: 3777
- category: unknown
  confidence: medium
  context: ce, are you guys excited? Good morning to Jay and Big Bogey face there.
    Kathleen saying hello from New York.
  name: Big Bogey
  position: 4160
- category: unknown
  confidence: medium
  context: Big Bogey face there. Kathleen saying hello from New York. Hello, Kathleen.
    Robert joining here from Raleig
  name: New York
  position: 4209
- category: unknown
  confidence: medium
  context: ello, Kathleen. Robert joining here from Raleigh, North Carolina. Come
    on and raise up. Cecilia, in my hometown, C
  name: North Carolina
  position: 4270
- category: unknown
  confidence: medium
  context: p. Cecilia, in my hometown, Chicago, saying happy Hump Day. It's good to
    see you all. Monica joining from Ch
  name: Hump Day
  position: 4355
- category: unknown
  confidence: medium
  context: rent comments coming in from different platforms. And I'm doing this all
    unedited, unscripted. So if you
  name: And I
  position: 4900
- category: unknown
  confidence: medium
  context: example of that, you can only use GPT-4o or 4o.1. And GPTs to build them,
    you have to be on a paid plan to u
  name: And GPTs
  position: 6267
- category: tech
  confidence: high
  context: be honest, whether we're talking about ChatGPT or Google Gemini, even Claude,
    as much as I kind of drag Cl
  name: Google
  position: 6512
- category: unknown
  confidence: medium
  context: be honest, whether we're talking about ChatGPT or Google Gemini, even Claude,
    as much as I kind of drag Claude th
  name: Google Gemini
  position: 6512
- category: tech
  confidence: high
  context: at it in the wrong way, you hit your rate limits. Microsoft Copilot, whatever,
    the $20, $25, $30 a month, wha
  name: Microsoft
  position: 6658
- category: unknown
  confidence: medium
  context: at it in the wrong way, you hit your rate limits. Microsoft Copilot, whatever,
    the $20, $25, $30 a month, whatever it
  name: Microsoft Copilot
  position: 6658
- category: unknown
  confidence: medium
  context: Wednesday, we did part one of this, our new AI at Work Wednesdays, I think
    is what we're calling it. Are you guys l
  name: Work Wednesdays
  position: 7249
- category: unknown
  confidence: medium
  context: you're like, okay, what the heck does this mean? When I'm talking with
    ChatGPT, I'm on a Pro plan, so the
  name: When I
  position: 9736
- category: unknown
  confidence: medium
  context: 96,000 words if you're on a paid ChatGPT plan, so ChatGPT Plus, you're
    working with a 32,000 token context windo
  name: ChatGPT Plus
  position: 9892
- category: unknown
  confidence: medium
  context: '''ve been using every day, you''ve gone through our Prime Prompt Polish
    process, and you have a lot of good information a'
  name: Prime Prompt Polish
  position: 11166
- category: tech
  confidence: high
  context: drop-off between those and everyone else, right? Perplexity has deep research,
    you know, everyone has deep re
  name: Perplexity
  position: 12251
- category: unknown
  confidence: medium
  context: re they're pinpoint specific, do not generalize." And OpenAI's deep research
    asked me a couple of questions. I
  name: And OpenAI
  position: 12718
- category: unknown
  confidence: medium
  context: . So now I have a GPT that I built that's called "Everyday AI Episode Researcher."
    So I'm saying, "Based on the recent trends I me
  name: Everyday AI Episode Researcher
  position: 13983
- category: unknown
  confidence: medium
  context: data." And I'm going to say, "In this GPT, in the Everyday AI Episode Researcher
    GPT, I love typing live, nothing I love more, and pla
  name: Everyday AI Episode Researcher GPT
  position: 14171
- category: unknown
  confidence: medium
  context: nother GPT that I've built. I've called this one "The Evergreen Episode
    Hunter." All right. So I'm actually going to go ahead. A
  name: The Evergreen Episode Hunter
  position: 16466
- category: unknown
  confidence: medium
  context: d of show you what this looks like. Okay. So this Evergreen Episode Hunter,
    it's actually a little complex, right? So now I'
  name: Evergreen Episode Hunter
  position: 16665
- category: unknown
  confidence: medium
  context: about this with my wife the other day. It's like Prime Day. Like I used
    to literally create spreadsheets lik
  name: Prime Day
  position: 20277
- category: unknown
  confidence: medium
  context: with my wife the other day. It's like Prime Day. Like I used to literally
    create spreadsheets like with l
  name: Like I
  position: 20288
- category: unknown
  confidence: medium
  context: revisit step one, just like a human would, right? The GPT-4o model could
    not do that, right? And that's why
  name: The GPT
  position: 22630
- category: unknown
  confidence: medium
  context: 'o take advantage of context stacking.


    All right. Then I''ll go through here. Anyways, eventually it came u'
  name: Then I
  position: 23956
- category: unknown
  confidence: medium
  context: 'gave me, okay, these are some pretty good ones. "Regulation Reality Check:
    Explain how the EU AI Act obligations arriving i'
  name: Regulation Reality Check
  position: 24105
- category: unknown
  confidence: medium
  context: 'ones. "Regulation Reality Check: Explain how the EU AI Act obligations
    arriving in August 2025, that''s aroun'
  name: EU AI Act
  position: 24147
- category: tech
  confidence: high
  context: ery podcast. Companies like Adobe, Microsoft, and Nvidia have partnered
    with us because they trust our exp
  name: Nvidia
  position: 25416
- category: unknown
  confidence: medium
  context: beginning, right? For enterprise teams, people on ChatGPT Teams, etc.—this
    is great that you can set a recommende
  name: ChatGPT Teams
  position: 28943
- category: unknown
  confidence: medium
  context: you wanted the advanced episode. So when I click "Create Actions," so remember,
    when you do this, unfortunately, a
  name: Create Actions
  position: 29899
- category: unknown
  confidence: medium
  context: 'can''t do that.


    All right. So I''m going to click "Create New Action." So this might seem confusing
    because what you''r'
  name: Create New Action
  position: 30413
- category: unknown
  confidence: medium
  context: uld think. And the reason being is ChatGPT has an Actions GPT. So when
    you—a lot of people don't know this—when
  name: Actions GPT
  position: 30684
- category: unknown
  confidence: medium
  context: that not pulls in information, that writes to my Google Calendar. How do
    I do this?" So this Actions GPT is create
  name: Google Calendar
  position: 30954
- category: unknown
  confidence: medium
  context: 'you have to do is copy and paste it.


    All right. But I''m going to give you an even easier way. So yes, i'
  name: But I
  position: 31981
- category: unknown
  confidence: medium
  context: today and give you an example of how this works. So Zapier is great. If
    you don't know Zapier, it essentiall
  name: So Zapier
  position: 33380
- category: unknown
  confidence: medium
  context: w one here. There we go. So there's an option to "Import Schema from URL."
    So with Zapier, it's the same URL. I c
  name: Import Schema
  position: 34060
- category: ai_developer
  confidence: high
  context: The creator of custom GPTs, ChatGPT, GPT-4o, 4o mini, and the platform
    where deep research capabilities are discussed.
  name: OpenAI
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: The primary product discussed, specifically custom GPTs and the underlying
    models (GPT-4o, GPT-4).
  name: ChatGPT
  source: llm_enhanced
- category: ai_researcher
  confidence: high
  context: An individual mentioned who coined the term AGI (Artificial General Intelligence),
    indicating involvement in foundational AI research.
  name: Dr. Ben Gortzel
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned alongside ChatGPT as a major LLM platform, specifically noting
    its deep research capabilities.
  name: Google Gemini
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as a competing LLM platform (with models Sonnet and Opus) whose
    limitations (like lack of model switching/context stacking) are contrasted with
    ChatGPT.
  name: Claude
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: Mentioned as another major commercial AI product, often compared in terms
    of subscription cost.
  name: Microsoft Copilot
  source: llm_enhanced
- category: ai_search_engine
  confidence: high
  context: Mentioned as having deep research capabilities, though noted as having
    a drop-off compared to OpenAI and Google Gemini.
  name: Perplexity
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Mentioned as a large company that partners with the podcast host for generative
    AI education/strategy.
  name: Adobe
  source: llm_enhanced
- category: big_tech
  confidence: high
  context: Mentioned as a large company that partners with the podcast host for generative
    AI education/strategy.
  name: Microsoft
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: Mentioned as a large company that partners with the podcast host for generative
    AI education/strategy. Also heavily implied as an AI infrastructure provider.
  name: Nvidia
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: Mentioned as an example of a popular API/platform (in digital marketing/SEO)
    whose documentation could be used with the Actions GPT.
  name: Semrush
  source: llm_enhanced
- category: ai_application
  confidence: medium
  context: Mentioned as an example of a popular API/platform (in digital marketing/SEO)
    whose documentation could be used with the Actions GPT.
  name: Ahrefs
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: A platform mentioned as an easier way to connect GPTs to external APIs
    (like sending emails or adding to a calendar) without deep technical knowledge.
  name: Zapier
  source: llm_enhanced
date: 2025-07-09 14:00:00 +0000
duration: 47
has_transcript: false
layout: episode
llm_enhanced: true
original_url: https://pscrb.fm/rss/p/www.buzzsprout.com/2175779/episodes/17476919-ep-563-chatgpt-s-new-custom-gpt-s-advanced-techniques-to-win-back-time.mp3
processing_date: 2025-10-05 03:28:15 +0000
quotes:
- length: 200
  relevance_score: 5
  text: So whether you're looking for ChatGPT training for thousands or just need
    help building your front-end AI strategy, you can partner with us too, just like
    some of the biggest companies in the world do
  topics: []
- length: 65
  relevance_score: 4
  text: So here's what's new with GPTs, and this is from OpenAI's website
  topics: []
- length: 235
  relevance_score: 4
  text: And what if that's a chat that you've been using every day, you've gone through
    our Prime Prompt Polish process, and you have a lot of good information and you're
    getting great outputs from ChatGPT or from whatever large language model
  topics: []
- length: 169
  relevance_score: 4
  text: So I already had it find, so my deep research query, I said, "Find the 20
    biggest trending topics from May 2025 to July 2025 in generative AI, large language
    models, etc
  topics: []
- length: 117
  relevance_score: 4
  text: Because the transformer models, to get the most out of them, you really had
    to be a stud at prompt engineering, right
  topics: []
- length: 134
  relevance_score: 4
  text: Maybe your company has been tinkering with large language models for a year
    or more but can't really get traction to find ROI on GenAI
  topics: []
- length: 157
  relevance_score: 4
  text: Companies like Adobe, Microsoft, and Nvidia have partnered with us because
    they trust our expertise in educating the masses around generative AI to get ahead
  topics: []
- length: 67
  relevance_score: 4
  text: The problem is, I don't think anyone aside from OpenAI knows, right
  topics: []
- length: 57
  relevance_score: 3
  text: So in today's episode, here's what we're going to go over
  topics: []
- length: 65
  relevance_score: 3
  text: And GPTs to build them, you have to be on a paid plan to use them
  topics: []
- length: 283
  relevance_score: 3
  text: So I know a lot of people, if they don't want to spend the $20 a month, but
    y'all, let's be honest, whether we're talking about ChatGPT or Google Gemini,
    even Claude, as much as I kind of drag Claude through the month for, if you look
    at it in the wrong way, you hit your rate limits
  topics: []
- length: 92
  relevance_score: 3
  text: Microsoft Copilot, whatever, the $20, $25, $30 a month, whatever it is, is
    a literal bargain
  topics: []
- length: 129
  relevance_score: 3
  text: Perplexity has deep research, you know, everyone has deep research, but OpenAI's
    and Google Gemini's are in a league of their own
  topics: []
- length: 119
  relevance_score: 3
  text: This should give me three, sorry, some of the biggest AI news trends, trending
    topics over the last two or three months
  topics: []
- length: 41
  relevance_score: 3
  text: That's the thing about doing it live here
  topics: []
- length: 117
  relevance_score: 3
  text: And then the Actions GPT will essentially write that schema for you, and then
    all you have to do is copy and paste it
  topics: []
- impact_reason: Directly addresses building for the new GPT-4o model, emphasizing
    its advanced capabilities like reasoning, planning, and agentic tool use—key trends
    in current AI.
  relevance_score: 10
  source: llm_enhanced
  text: We're going to talk about how to build GPTs with 4o in mind, the new 4o model
    from ChatGPT that can think, reason, logic, plan ahead, and it can agentically
    use the different tools at its disposal.
  topic: technical/trends
- impact_reason: This is the core definition of 'context stacking'—the ability to
    chain specialized tools (GPTs) without losing the overall conversational context.
  relevance_score: 10
  source: llm_enhanced
  text: You can use different modes, different GPTs in the same context window, and
    it takes in all of that information.
  topic: technical
- impact_reason: Draws a sharp distinction between older transformer models (requiring
    heavy prompt engineering) and the 4o series, highlighting the latter's inherent
    agentic reasoning capabilities.
  relevance_score: 10
  source: llm_enhanced
  text: The difference between the GPT-4 kind of, quote unquote, transformer model
    and the 4o series model that you can use—I mean, they're agentic in their absolutely
    amazing.
  topic: AI technology trends
- impact_reason: 'The most critical comparison: 4o''s ability to self-correct and
    loop back (human-like reasoning) is what unlocked the utility of GPTs, unlike
    the static GPT-4 transformer.'
  relevance_score: 10
  source: llm_enhanced
  text: It decided on its own, this 4o model, that it kind of had to go back and revisit
    step one, just like a human would, right? The GPT-4o model could not do that,
    right? And that's why I think the GPTs originally, not saying they flopped, but
    they just weren't super useful, right?
  topic: AI technology trends
- impact_reason: 'Crucial advice for enterprise deployment: matching model capability
    (e.g., 4o Pro) to task complexity to manage latency and potentially cost/resource
    usage.'
  relevance_score: 10
  source: llm_enhanced
  text: The good thing is, you can use on your GPTs, you can decide what model to
    use. There's a model selector, but you can also set preferred methods. So maybe
    if you do want to build these for your team... Sometimes you might not need 4o
    Pro, right? If it's more of a simple, 'Hey, rewriting content,' right? Because
    if you're using 4o Pro, depending on what your query is, you might be waiting
    10 minutes for a response when you might only need to wait 10 seconds.
  topic: business/strategy
- impact_reason: 'Identifies a significant current limitation: using Custom Actions
    (API calls) restricts users to GPT-4o/4o.1 and potentially excludes access to
    more advanced ''thinking'' capabilities (if those are distinct from the 4o/4o.1
    models themselves, or perhaps referring to older, slower models).'
  relevance_score: 10
  source: llm_enhanced
  text: if you're using custom actions, bringing in information from an API, then
    you are only able to use the GPT-4o or the GPT-4o.1 model. So there's some trade-off.
    So essentially, if you're going out and fetching dynamic data via an API, then
    you can't use the thinking models.
  topic: technical/limitations
- impact_reason: A critical security warning regarding API key management within custom
    GPT configurations, emphasizing the risk of financial loss if keys are exposed.
  relevance_score: 10
  source: llm_enhanced
  text: if you make this public, someone could, in theory, extract your API information,
    and if you're paying for something, they could run up the bill, right? So you
    never want to hardcode the API in here.
  topic: safety/security
- impact_reason: 'Identifies a key functional gap in native GPT connectors: the ability
    to read data (emails, calendar) exists, but the ability to *write* or *act* (e.g.,
    reply to email, schedule) is missing, which Zapier solves.'
  relevance_score: 10
  source: llm_enhanced
  text: So I did this—different things I can send an email, which is great because
    in GPTs right now with the new connectors, if you're using deep research, you
    can read emails, you can read your calendar, right? But you can't write.
  topic: technical/limitations
- impact_reason: 'Provides a clear, concise definition and the core value proposition
    of Custom GPTs: specialization and reusability to save time.'
  relevance_score: 9
  source: llm_enhanced
  text: I like to tell people it's a custom version of ChatGPT that you can use not
    everywhere, but essentially everywhere inside of ChatGPT. So it's a way to make
    ChatGPT kind of smaller, smarter, and more specific for your needs, and then to
    be able to reuse it at any time without wasting a bunch of time, right? Sharing
    files, going back and forth, trying to get ChatGPT to respond exactly how you
    want it to. You can just create a custom GPT for that.
  topic: technical/business
- impact_reason: Introduces a novel, time-saving technique ('context stacking') that
    the host claims to have coined, indicating a focus on advanced, practical workflow
    optimization.
  relevance_score: 9
  source: llm_enhanced
  text: We're going to learn about what I call context stacking and doing that with
    GPTs. It's an advanced technique, but it's actually really simple, and it's going
    to save you a ton of time.
  topic: technical/strategy
- impact_reason: Points to a crucial integration technique (Custom Actions/APIs) for
    making GPTs functional in real-world business workflows by accessing external
    data.
  relevance_score: 9
  source: llm_enhanced
  text: We're going to go over how to use custom actions inside of custom GPTs to
    bring in third-party data via an API.
  topic: technical/deployment
- impact_reason: Confirms a major update allowing granular model selection within
    GPTs, enabling better cost/performance optimization for specific tasks.
  relevance_score: 9
  source: llm_enhanced
  text: 'Creators can now choose the full set of ChatGPT models: GPT-4o, 4o mini,
    and more when building custom GPTs, making it easier to fine-tune performance
    for different tasks, industries, and workflows.'
  topic: technical/trends
- impact_reason: Highlights a current competitive advantage for OpenAI (model switching/context
    retention) and hints at the future direction of autonomous model selection (pre-GPT-5).
  relevance_score: 9
  source: llm_enhanced
  text: ChatGPT actually has a huge advantage, and I'm actually very surprised that
    the other AI labs haven't caught on, right? Although this may change in the future
    as OpenAI any week, month now, kind of goes to this GPT-5 architecture where the
    system will kind of choose on its own what model to use.
  topic: technical/trends
- impact_reason: Provides specific, actionable data on context window sizes for different
    paid tiers, crucial for managing large inputs.
  relevance_score: 9
  source: llm_enhanced
  text: When I'm talking with ChatGPT, I'm on a Pro plan, so the context window is
    128,000 tokens, which is about 96,000 words if you're on a paid ChatGPT plan,
    so ChatGPT Plus, you're working with a 32,000 token context window, which is about
    28,000 words.
  topic: technical
- impact_reason: Provides a direct competitive comparison, highlighting a major functional
    limitation in rival models (Claude) that OpenAI's architecture currently overcomes.
  relevance_score: 9
  source: llm_enhanced
  text: I mean, you can't even switch models in Claude, right? So if you're using
    Claude for Sonnet and you're like, oh man, I'd really love to use Claude for Opus
    right now, and you go to switch, and it's like, 'Start new chat.' So what that
    means is that it has no idea, no context, and you essentially have to start over.
  topic: technical/strategy
- impact_reason: Highlights a significant competitive advantage in advanced web-browsing/agentic
    research capabilities between the leading models (OpenAI/Google) and competitors.
  relevance_score: 9
  source: llm_enhanced
  text: I think ChatGPT and Google Gemini have the best deep research, and there's
    a pretty big drop-off between those and everyone else, right?
  topic: AI technology trends
- impact_reason: Illustrates the concept of 'context stacking'—combining external
    research (from the deep research step) with proprietary, custom data within a
    specialized GPT.
  relevance_score: 9
  source: llm_enhanced
  text: So now I have a GPT that I built that's called "Everyday AI Episode Researcher."
    So I'm saying, "Based on the recent trends I mentioned above in your response,
    please look at my episode data."
  topic: Technical insights
- impact_reason: 'Clearly defines the ''context stacking'' workflow: Research -> Agentic
    Tool Use (Custom GPT) -> Enhanced Capability via the 4o model.'
  relevance_score: 9
  source: llm_enhanced
  text: I use deep research, right? And now I @-mentioned or use one of my other GPTs.
    And now because these GPTs can use the 4o model, they're capable of so much more,
    right?
  topic: AI technology trends
- impact_reason: 'Shows the multi-step agentic process: 1. Internal Data Analysis
    (finding evergreen topics) -> 2. External Research (updating the topics).'
  relevance_score: 9
  source: llm_enhanced
  text: So this GPT not only does that, but then also when it finds these evergreen
    episodes... will then go agentically do research for me.
  topic: Technical insights
- impact_reason: 'Crucial advice for iterative improvement: using the ''chain of thought''
    trace not just for debugging, but for self-improvement and refining future prompts/instructions.'
  relevance_score: 9
  source: llm_enhanced
  text: So always look at that summarized chain of thought, see what it's seeing because
    then I'm always going to see what works well when I'm using this custom GPT and
    what doesn't.
  topic: Practical lessons
- impact_reason: 'A vital technical workaround: explicitly instructing the GPT to
    summarize its reasoning in the output ensures persistence beyond the volatile
    context window.'
  relevance_score: 9
  source: llm_enhanced
  text: So later, if I go back into this chat, I'm not going to be able to pull on
    that summarized chain of thought. So in the custom instructions, I tell it to
    put into its reply its thought process and key findings.
  topic: Technical insights
- impact_reason: 'Identifies a common pain point in the industry: the gap between
    experimentation (''tinkering'') and achieving measurable Return on Investment
    (ROI) from GenAI adoption.'
  relevance_score: 9
  source: llm_enhanced
  text: Are you still running in circles trying to figure out how to actually grow
    your business with AI? Maybe your company has been tinkering with large language
    models for a year or more but can't really get traction to find ROI on GenAI.
  topic: Business advice
- impact_reason: Highlights an immediate, high-stakes regulatory deadline (EU AI Act)
    relevant to all businesses dealing with AI, emphasizing the need for proactive
    preparation.
  relevance_score: 9
  source: llm_enhanced
  text: '"Regulation Reality Check: Explain how the EU AI Act obligations arriving
    in August 2025, that''s around the corner, and what small and medium businesses
    must do to prepare now."'
  topic: safety/regulation
- impact_reason: Reveals the opaque nature of proprietary model behavior (tokenization/analysis)
    even for advanced users, suggesting that token usage for complex inputs is non-deterministic
    and model-dependent.
  relevance_score: 9
  source: llm_enhanced
  text: The problem is, I don't think anyone aside from OpenAI knows, right? I've
    done manual testing in this. The reason being is it uses different techniques
    to essentially tokenize or to analyze that PDF, and sometimes it'll go back multiple
    times.
  topic: technical/limitations
- impact_reason: Demonstrates the power of natural language programming/prompting
    for building custom tools (GPTs), lowering the barrier to entry for non-developers.
  relevance_score: 9
  source: llm_enhanced
  text: You can literally talk to ChatGPT to build it. You don't even have to go in
    on the back end and tweak the settings. You can just say, 'Hey, my website is
    your everydayai.com... build me a GPT to do episode research.'
  topic: technical/deployment
- impact_reason: 'Highlights a powerful, underutilized feature: OpenAI''s built-in
    Actions GPT that assists in generating the necessary technical schema (JSON/YAML)
    for API integration.'
  relevance_score: 9
  source: llm_enhanced
  text: when you go into actions, there's a 'Get help from an Actions GPT.' So I could
    just say as an example, 'I want to create a GPT that pulls in information from
    my or that not pulls in information, that writes to my Google Calendar. How do
    I do this?'
  topic: technical/deployment
- impact_reason: 'Provides a concrete, high-value use case for the Actions GPT: automating
    the creation of complex API integrations (like pulling SEO data) by leveraging
    existing documentation.'
  relevance_score: 9
  source: llm_enhanced
  text: if you're using, I don't know, a very popular API... like if you're in digital
    marketing, maybe you're using Semrush, Ahrefs, right? Like these SEO content platforms,
    you know, you can literally just grab their API documentation, paste it in, and
    say, 'I'm trying to create a GPT that will pull my website's keyword rankings
    instantly,' right? And then here's all the API information. And then the Actions
    GPT will essentially write that schema for you, and then all you have to do is
    copy and paste it.
  topic: technical/deployment
- impact_reason: Presents Zapier as the easiest, low-code/no-code solution for enabling
    GPTs to interact with external services via APIs, bypassing the need to manually
    write schema.
  relevance_score: 9
  source: llm_enhanced
  text: 'But I''ll tell you an even easier one and do a demo of it here real quick:
    Zapier. Zapier, y''all.'
  topic: technical/deployment
- impact_reason: Articulates a highly desired workflow enhancement—combining deep
    research/reading capabilities with immediate action/writing capabilities—achievable
    via external tools like Zapier.
  relevance_score: 9
  source: llm_enhanced
  text: And there are times I'm like, 'Man, I wish while I was in here, I could just
    add something quickly to my calendar or I could use deep research and go through
    my Gmail but then actually reply to them.' Well, you can do that going through
    this process with Zapier.
  topic: predictions/strategy
- impact_reason: Highlights the rapid pace of AI updates (specifically Custom GPTs)
    and the value of staying current via specialized content sources.
  relevance_score: 8
  source: llm_enhanced
  text: OpenAI's custom GPTs have gotten some huge under-the-hood updates, and unless
    you're listening to this show every day or maybe reading our free daily newsletter
    every day, there's a good chance that you could have missed it.
  topic: strategy
- impact_reason: 'Provides a critical technical constraint for developers: Custom
    Actions currently restrict model choice to the latest versions of GPT-4o.'
  relevance_score: 8
  source: llm_enhanced
  text: If you do use custom actions, which we're going to be showing an example of
    that, you can only use GPT-4o or 4o.1.
  topic: technical/limitations
- impact_reason: 'Clearly explains the practical implication of context window limits:
    information loss over long conversations.'
  relevance_score: 8
  source: llm_enhanced
  text: If you end up having between you and ChatGPT a 56,000-word conversation, it's
    going to forget the first 28,000. So it only has a running memory of the last
    28,000 words of context.
  topic: technical/limitations
- impact_reason: Emphasizes the high cost (starting over) of platforms lacking context
    retention across model or tool changes.
  relevance_score: 8
  source: llm_enhanced
  text: If it doesn't have context stacking or model switching built in, you're screwed.
    You got to start over, right?
  topic: strategy
- impact_reason: Offers a strong comparative assessment of the state-of-the-art in
    agentic web research capabilities, favoring OpenAI and Google.
  relevance_score: 8
  source: llm_enhanced
  text: I already ran a deep research query in ChatGPT... OpenAI's and Google Gemini's
    are in a league of their own.
  topic: technical/trends
- impact_reason: Quantifies the impressive scale of agentic research performed by
    the LLM in a single query (138 searches, 64 sources), demonstrating advanced automation.
  relevance_score: 8
  source: llm_enhanced
  text: It did essentially 138 different Googles in order to, you know, I say Google
    just as a general way to say search the web. And then it looked at 64 different
    sources and then it created a document for me here.
  topic: technical/predictions
- impact_reason: Defines and praises the capability of 'deep research' features as
    being agentic, moving beyond simple retrieval to active, multi-step investigation.
  relevance_score: 8
  source: llm_enhanced
  text: Essentially, it will go through and agentically research something for you
    in a very impressive manner.
  topic: Technical insights
- impact_reason: Quantifies the scale of agentic work performed by the LLM in a single
    research task, illustrating the efficiency gain over manual research.
  relevance_score: 8
  source: llm_enhanced
  text: So I'm showing the activity. It did essentially 138 different Googles in order
    to, you know, I say Google just as a general way to say search the web. And then
    it looked at 64 different sources and then it created a document for me here.
  topic: Technical insights
- impact_reason: Emphasizes the power of custom instructions and data uploading for
    fine-tuning a GPT's behavior across various conversational contexts.
  relevance_score: 8
  source: llm_enhanced
  text: So I've shared all of my podcast data. I've given it custom instructions on,
    "Hey, when I use this, whether I'm using it in a dedicated mode or I'm using it
    in the context of a different chat, here's exactly what you should do," and I've
    kind of fine-tuned it to do exactly what I want.
  topic: Practical lessons
- impact_reason: Demonstrates the integration of code execution (Python script) within
    the GPT workflow for complex data analysis tasks, moving beyond simple text generation.
  relevance_score: 8
  source: llm_enhanced
  text: So it's doing data analysis on my file that I upload, and it's going to slowly
    go through here. It's going to start pulling out different ideas.
  topic: Technical insights
- impact_reason: Details the specific analytical logic (decay curves, outlier detection)
    built into the custom GPT, showing advanced data science application.
  relevance_score: 8
  source: llm_enhanced
  text: So what it does is it goes through and it created a little, short little algorithm
    or formula to find my average seven-day, 30-day, 90-day kind of decay, and then
    it finds outliers in that...
  topic: Technical insights
- impact_reason: Highlights the reduction in prompt complexity when using well-configured
    GPTs; the system handles the context and research parameters automatically.
  relevance_score: 8
  source: llm_enhanced
  text: I don't even have to say like, "Oh, look up information from 2025. These are
    the topics I care about," etc. It's going to go through, it's going to find and
    extract that information from the spreadsheet, and then I've already given it
    very specific instructions on how it should be researching.
  topic: Practical lessons
- impact_reason: Stresses that building effective AI tools requires continuous iteration
    and updating of the custom instructions/data based on observed performance.
  relevance_score: 8
  source: llm_enhanced
  text: Then the next time I use that, I'm going to keep that in mind, and I'm probably
    going to go back and update the GPT as well. So these are not just use them once
    and forget it.
  topic: Strategy
- impact_reason: Provides empirical evidence that content related to AI regulation
    has sustained, long-term audience interest, signaling a major strategic focus
    area for content creators and businesses.
  relevance_score: 8
  source: llm_enhanced
  text: So it went through, it found that some of my episodes that are talking about
    regulations and laws and legalities, right, they perform well even outside of
    that normal seven-day decay window.
  topic: strategy/business
- impact_reason: Poses a highly specific, practical question about tokenization efficiency
    and cost management when processing complex, data-heavy documents like tax PDFs.
  relevance_score: 8
  source: llm_enhanced
  text: How do PDFs full of tax play in token usage?
  topic: technical/cost
- impact_reason: Details the seamless integration mechanism between Zapier and the
    GPT builder, allowing for instant schema loading via a shared URL.
  relevance_score: 8
  source: llm_enhanced
  text: So there's an option to 'Import Schema from URL.' So with Zapier, it's the
    same URL. I click that, I paste, I click 'Import,' and bam, it loads up the schema.
  topic: technical
- impact_reason: Signals high-value upcoming content featuring a foundational figure
    in AI research (AGI), suggesting deep dives into future AI concepts.
  relevance_score: 7
  source: llm_enhanced
  text: We're going to have Dr. Ben Gortzel, who literally coined the term AGI. He's
    one of the OGs in the AI world.
  topic: predictions/strategy
- impact_reason: Strong business advice asserting that the cost of premium LLM access
    (like ChatGPT Plus) is highly justified given the productivity gains.
  relevance_score: 7
  source: llm_enhanced
  text: The $20, $25, $30 a month, whatever it is, is a literal bargain.
  topic: business
- impact_reason: Offers a practical financial strategy for users wanting to leverage
    paid features temporarily for creation, then downgrade while retaining functionality.
  relevance_score: 7
  source: llm_enhanced
  text: You can do it for a few months, build a bunch of GPTs, and then if you don't
    want to keep paying, you can still use those GPTs. You just can't modify them
    anymore if you're on a free plan.
  topic: business/strategy
- impact_reason: Demonstrates a complex, future-dated, and highly specific research
    query that showcases the potential for LLMs to perform targeted market intelligence.
  relevance_score: 7
  source: llm_enhanced
  text: I said, "Find the 20 biggest trending topics from May 2025 to July 2025 in
    generative AI, large language models, etc. Make sure they're pinpoint specific,
    do not generalize."
  topic: Business advice
- impact_reason: Provides practical advice on pre-prompting/context setting ('warming
    up the chat') before executing complex agentic tasks, a key strategy for better
    results.
  relevance_score: 7
  source: llm_enhanced
  text: What are the things that you're constantly doing? In a lot of times, I would
    even start before I even do a deep research query. I would usually start by sharing
    context and kind of warming the chat up a bit, going through the PPP process.
  topic: Practical lessons
- impact_reason: Provides a concrete business problem (identifying long-tail content
    value) that is being solved using AI analysis of proprietary data.
  relevance_score: 7
  source: llm_enhanced
  text: I'm trying to find outliers. Okay. So what that means is sometimes I'll have
    episodes, right? Most of our daily episodes, they get traction for about a week,
    and then for the most part, after a week, they just kind of fizzle there... But
    I'm trying to find episodes that have evergreen power.
  topic: Business advice
- impact_reason: Provides realistic performance benchmarks (latency) for complex agentic
    tasks using the 4o model, managing user expectations.
  relevance_score: 7
  source: llm_enhanced
  text: I didn't want to keep you guys waiting for too long because sometimes these
    GPTs, especially when you're using the 4o series model, they can take like just
    a GPT could take three to five minutes, right? A deep research query might take
    anywhere from two to 20.
  topic: Practical lessons
- impact_reason: Provides a timely, high-value, and specific business/compliance topic
    driven by AI research, demonstrating the model's ability to connect trends to
    actionable advice.
  relevance_score: 7
  source: llm_enhanced
  text: 'Regulation Reality Check: Explain how the EU AI Act obligations arriving
    in August 2025, that''s around the corner, and what small and medium businesses
    must do to prepare now.'
  topic: Predictions/Business advice
- impact_reason: Emphasizes the importance of source citation/transparency in agentic
    workflows to build user trust and verify outputs.
  relevance_score: 7
  source: llm_enhanced
  text: So not only that, is it did some research in here as well when it went to
    future episode ideas, and then it gave me all the sources and the headlines that
    I used as well, so you can have a little bit of confidence in it.
  topic: Safety/Trust
- impact_reason: 'Teases the next advanced topic: Custom Actions, which allows GPTs
    to interact with external APIs, representing the next major leap in agentic capability.'
  relevance_score: 7
  source: llm_enhanced
  text: I love doing these things live as much as possible. We're still going to do
    one live here when we talk about custom actions inside of GPTs.
  topic: AI technology trends
- impact_reason: Acts as a strong testimonial and validation point for the speaker's
    expertise in GenAI education, signaling where major tech players are investing
    their resources (i.e., workforce education).
  relevance_score: 7
  source: llm_enhanced
  text: Companies like Adobe, Microsoft, and Nvidia have partnered with us because
    they trust our expertise in educating the masses around generative AI to get ahead.
  topic: business
- impact_reason: Reinforces the inherent variability and non-deterministic nature
    of generative AI processes, which has implications for consistency and auditing.
  relevance_score: 7
  source: llm_enhanced
  text: I would assume that even they would say that it varies, right? Because generative
    AI is generative, it's going to do something a little bit different each time.
  topic: technical/limitations
- impact_reason: 'Explains the underlying mechanism of the ''Create'' tab in the GPT
    builder: conversational input is translated into structured configuration code/instructions.'
  relevance_score: 7
  source: llm_enhanced
  text: So if you build it on the front end, conversational with ChatGPT, it essentially
    synthesizes that information and it fills in the configuration instructions.
  topic: technical
- impact_reason: This describes a highly streamlined, low-code/no-code approach to
    building integrations or automations, highlighting ease of use and rapid deployment.
  relevance_score: 7
  source: llm_enhanced
  text: You go to the Zapier page, you get their template, you update it based on
    the action that you build, and bam, that's it.
  topic: business/strategy (low-code adoption)
- impact_reason: Establishes the host's proprietary terminology for a technique they
    are about to explain, signaling unique educational content.
  relevance_score: 6
  source: llm_enhanced
  text: Context stacking is a term that we've kind of, I guess, coined and have taught
    people as well over the years.
  topic: strategy
- impact_reason: Offers a practical limitation/usability note regarding custom GPT
    deployment across different OpenAI interfaces.
  relevance_score: 6
  source: llm_enhanced
  text: So you can hit—that's the big thing about GPTs. You can use them almost anywhere
    where there's a text box. Well, so you can't actually use them inside Projects,
    which is a big bummer.
  topic: Practical lessons
- impact_reason: General business promotion, but highlights the strategy of leveraging
    expert interviews for educational content creation.
  relevance_score: 5
  source: llm_enhanced
  text: You can go learn from hundreds of experts that we've interviewed over the
    years on our free website and get that daily newsletter.
  topic: business
- impact_reason: Suggests an automated or self-generating process for defining data
    structures (schemas), which is a common goal in modern API/integration development,
    though the context is too narrow to judge its technical depth.
  relevance_score: 5
  source: llm_enhanced
  text: he schema up by itself.
  topic: technical/integration
- impact_reason: Indicates the speaker is aware of the presentation flow issues, which
    is a minor insight into presentation style or audience management.
  relevance_score: 3
  source: llm_enhanced
  text: Sorry, live stream audience, I know I'm jumping all over.
  topic: strategy (presentation)
- impact_reason: A standard closing procedure for a live event, signaling time constraints.
  relevance_score: 2
  source: llm_enhanced
  text: If you do have a question, we're wrapping up here, so get it in now.
  topic: strategy (event management)
source: Unknown Source
summary: '## Podcast Episode Summary: Ep 563: ChatGPT''s New Custom GPT''s: Advanced
  techniques to win back time


  This episode of the Everyday AI Show focuses on advanced, time-saving techniques
  for leveraging OpenAI''s newly updated Custom GPTs, particularly in conjunction
  with the powerful GPT-4o model. The host emphasizes that recent under-the-hood updates
  have significantly enhanced the utility of these custom tools.


  ### 1. Focus Area

  The primary focus is on **Advanced Custom GPT Utilization and Workflow Automation**.
  Specific topics covered include:

  *   **Context Stacking:** An advanced technique for maintaining conversational context
  across different models or specialized GPTs within a single chat session.

  *   **GPTs Built for GPT-4o:** Utilizing the enhanced reasoning, planning, and agentic
  capabilities of the GPT-4o model within custom environments.

  *   **Custom Actions (API Integration):** Implementing third-party data retrieval
  via APIs within custom GPTs for non-technical users.

  *   **Practical Automation Examples:** Demonstrating how to use these techniques
  for tasks like research synthesis, content planning, and identifying evergreen content
  performance.


  ### 2. Key Technical Insights

  *   **Context Stacking Advantage:** ChatGPT''s unique ability to switch between
  different models (e.g., GPT-4o, 4o mini) while retaining the conversation''s context
  window (up to 128k tokens on Pro plans) is a major advantage over competitors like
  Claude, which often force a new chat upon model switching.

  *   **GPT-4o''s Agentic Leap:** The shift to GPT-4o models within custom GPTs enables
  true agentic behavior—the ability to think, reason, plan ahead, and iteratively
  use tools (like web browsing or code execution) based on self-determined needs,
  something the older transformer models struggled with.

  *   **Preserving Chain of Thought:** A crucial tip for maximizing context window
  utility is to instruct the custom GPT in its configuration instructions to output
  its thought process and key findings in its final response, ensuring that critical
  reasoning steps are saved within the visible context for later reference.


  ### 3. Business/Investment Angle

  *   **Bargain Subscription Value:** The host strongly argues that the ~$20 monthly
  subscription for advanced AI tools (like ChatGPT Plus) is a "literal bargain" given
  the productivity gains and access to cutting-edge models like GPT-4o.

  *   **Automation of Specialized Workflows:** Custom GPTs allow businesses to codify
  complex, repetitive internal processes (e.g., market research analysis, content
  auditing) into reusable, highly specific tools, leading to significant time savings
  for employees.

  *   **Data-Driven Content Strategy:** The "Evergreen Episode Hunter" example shows
  how GPTs can analyze proprietary performance data (spreadsheets) alongside real-time
  web research to proactively identify and outline high-potential content updates,
  directly impacting content ROI.


  ### 4. Notable Companies/People

  *   **OpenAI:** The central focus, specifically regarding the updates to Custom
  GPTs and the introduction of the GPT-4o model.

  *   **Dr. Ben Gortzel:** Mentioned as an upcoming guest, noted for coining the term
  AGI, highlighting the show''s commitment to high-level AI discussions.

  *   **Jordan Wilson (Host):** The creator of the "context stacking" term and the
  architect behind the practical, time-saving GPT examples demonstrated.


  ### 5. Future Implications

  The conversation suggests the industry is moving toward **highly capable, agentic
  custom assistants** that operate seamlessly across different data sources and reasoning
  steps. The emphasis on GPT-4o’s reasoning capabilities indicates that future AI
  adoption will rely less on perfect initial prompting and more on the AI''s ability
  to self-correct and iterate through complex tasks autonomously.


  ### 6. Target Audience

  This episode is highly valuable for **AI Practitioners, Business Leaders, and Power
  Users** who already utilize ChatGPT Plus and are looking to move beyond basic prompting
  to build sophisticated, time-saving automation workflows using the latest model
  capabilities.'
tags:
- generative-ai
- artificial-intelligence
- ai-infrastructure
- openai
- google
- microsoft
- nvidia
title: 'Ep 563: ChatGPT''s New Custom GPT''s: Advanced techniques to win back time'
topics:
- keywords:
  - generative ai
  - genai
  - chatgpt
  - gpt
  - claude
  - text generation
  - image generation
  mentions: 143
  prominence: 1.0
  topic: generative ai
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 106
  prominence: 1.0
  topic: artificial intelligence
- keywords:
  - gpu
  - tensor
  - training
  - inference
  - model deployment
  - vector database
  mentions: 1
  prominence: 0.1
  topic: ai infrastructure
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-10-05 03:28:15 UTC -->
