---
companies:
- category: unknown
  confidence: medium
  context: o it as well, which is quite surprising. Today on Training Data, we're
    joined by Block CTO, Donji Prasana. Earlie
  name: Training Data
  position: 574
- category: unknown
  confidence: medium
  context: rprising. Today on Training Data, we're joined by Block CTO, Donji Prasana.
    Earlier this year, Block released
  name: Block CTO
  position: 605
- category: unknown
  confidence: medium
  context: oday on Training Data, we're joined by Block CTO, Donji Prasana. Earlier
    this year, Block released Goose, which i
  name: Donji Prasana
  position: 616
- category: unknown
  confidence: medium
  context: for you. Goose is used widely for everything from Jack Dorsey's first web
    of BitChat to non-engineers vibe codi
  name: Jack Dorsey
  position: 798
- category: unknown
  confidence: medium
  context: s, but if you build bombs with it, it's terrible. So I think AI is very
    similar in that regard. It has a
  name: So I
  position: 2128
- category: unknown
  confidence: medium
  context: to do a lot of good. We've already seen that with Alpha Fold and all of
    the great things similar to that, but
  name: Alpha Fold
  position: 2250
- category: unknown
  confidence: medium
  context: ds on who's holding it and what their purpose is. But I was thinking about
    it specifically for us at Bloc
  name: But I
  position: 2468
- category: unknown
  confidence: medium
  context: . Absolutely. Our two main pillars are Square and Cash App. So Square serves
    merchants and sellers. And Cash
  name: Cash App
  position: 4463
- category: unknown
  confidence: medium
  context: ly. Our two main pillars are Square and Cash App. So Square serves merchants
    and sellers. And Cash App serves
  name: So Square
  position: 4473
- category: unknown
  confidence: medium
  context: Cash App. So Square serves merchants and sellers. And Cash App serves consumers
    as a financial services app. And
  name: And Cash App
  position: 4513
- category: unknown
  confidence: medium
  context: e industry and is also energy and cost efficient. And I believe we've done
    that with RIG. So it's an impr
  name: And I
  position: 5190
- category: unknown
  confidence: medium
  context: the other half he did end up hiring me. No good. Did Goose and Prasanna?
    Well, with the other components of
  name: Did Goose
  position: 8153
- category: unknown
  confidence: medium
  context: And I worked very closely with Brian, who was our Cash App CEO and Jack
    to help create this separation. And a lo
  name: Cash App CEO
  position: 10079
- category: unknown
  confidence: medium
  context: ingular organizational focus is really important. And Jack was a huge proponent
    of that view as well. Have y
  name: And Jack
  position: 10592
- category: unknown
  confidence: medium
  context: the UI. And it is built using what's known as the Model Context Protocol
    or the MCP, which you might have heard of. And Go
  name: Model Context Protocol
  position: 12958
- category: unknown
  confidence: medium
  context: otocol or the MCP, which you might have heard of. And Goose was one of
    the earliest adopters of the MCP. And
  name: And Goose
  position: 13024
- category: tech
  confidence: high
  context: s. So all of our existing systems, be it Gmail or Google Docs, be it Square
    Payments, any of these things,
  name: Google
  position: 13347
- category: unknown
  confidence: medium
  context: s. So all of our existing systems, be it Gmail or Google Docs, be it Square
    Payments, any of these things, and
  name: Google Docs
  position: 13347
- category: unknown
  confidence: medium
  context: isting systems, be it Gmail or Google Docs, be it Square Payments, any
    of these things, and orchestrate workflows b
  name: Square Payments
  position: 13366
- category: tech
  confidence: high
  context: we did in Q3. And then it goes away. It looks in Snowflake, pulls out the
    data. It might look in Looker, Tab
  name: Snowflake
  position: 13588
- category: unknown
  confidence: medium
  context: . And then it can deliver all of that as a PDF or Google Doc and even email
    it for you. So this is kind of giv
  name: Google Doc
  position: 13799
- category: unknown
  confidence: medium
  context: s developed by one of our engineers whose name is Brad Axen. And he had
    been developing this thesis that agen
  name: Brad Axen
  position: 14667
- category: unknown
  confidence: medium
  context: ve their weight. Why is it called Goose? That's a Top Gun reference. So
    it is. I wasn't sure. Brad looks, h
  name: Top Gun
  position: 14961
- category: unknown
  confidence: medium
  context: s laptop. So we have this really cool tool called Headless Goose. And it
    runs, for example, in our CI pipeline. An
  name: Headless Goose
  position: 20127
- category: unknown
  confidence: medium
  context: e. We were using BitChat yesterday. It's amazing. Was Goose built on Goose?
    Yeah, it was the initial version
  name: Was Goose
  position: 21653
- category: unknown
  confidence: medium
  context: literally everything he does, including Slack or Google Meet calls, everything
    in between. And it intervenes f
  name: Google Meet
  position: 22559
- category: unknown
  confidence: medium
  context: use cases, they like the Cloud family of models. And GPT-4 is now getting
    pretty close in capability as we
  name: And GPT
  position: 27112
- category: unknown
  confidence: medium
  context: if I want to know some historical fact about the Soviet Union, it's going
    to tell me that instantly. But if I a
  name: Soviet Union
  position: 28279
- category: unknown
  confidence: medium
  context: g, I fully expect that number to keep ticking up. So Block has a long history
    of participating in the open s
  name: So Block
  position: 29643
- category: unknown
  confidence: medium
  context: open source contribution. So I used to work with Bob Lee, who was our CTO
    before me, our first CTO. And it
  name: Bob Lee
  position: 30551
- category: unknown
  confidence: medium
  context: that don't have the same level of competition as Silicon Valley, for example.
    And we were very early to tap into
  name: Silicon Valley
  position: 38260
- category: unknown
  confidence: medium
  context: sit there and come up with something on your own. The LLMs are surprisingly
    good at writing performance code
  name: The LLMs
  position: 41159
- category: unknown
  confidence: medium
  context: or that, you definitely need manual intervention. Where I think humans
    are called for is in the higher-leve
  name: Where I
  position: 41563
- category: unknown
  confidence: medium
  context: nd there's different numbers for different teams. Like I said, engineers
    in the most engaged engineers wit
  name: Like I
  position: 43602
- category: unknown
  confidence: medium
  context: plex and difficult for agents to work with. Yeah. As I told you before,
    in AI-first teams, it's pretty m
  name: As I
  position: 43828
- category: unknown
  confidence: medium
  context: teams, it's pretty much all entirely vibe coded. So Goose itself, every
    PR that is opened is written by Goo
  name: So Goose
  position: 43911
- category: ai_application
  confidence: high
  context: The primary AI agent/application being discussed, developed by Block, capable
    of autonomous software building and workflow automation.
  name: Goose
  source: llm_enhanced
- category: ai_developer_company
  confidence: high
  context: The company developing Goose, Cash App, Bitkey, and Proto. Mentioned for
    its culture of experimentation and fostering internal AI projects.
  name: Block
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: An internal project/experiment at Block, mentioned alongside Goose and
    Cash App.
  name: Bitkey
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: An internal project/experiment at Block, mentioned alongside Goose and
    Cash App.
  name: Proto
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: A decentralized chat application built using Goose.
  name: BitChat
  source: llm_enhanced
- category: ai_application
  confidence: high
  context: An extension of Goose that runs in CI pipelines, automatically fixing vulnerability
    tickets.
  name: Headless Goose
  source: llm_enhanced
- category: ai_model_provider
  confidence: medium
  context: General reference to companies providing underlying foundation models (like
    OpenAI, Google, Anthropic, etc.).
  name: LLM providers
  source: llm_enhanced
- category: ai_model_provider
  confidence: high
  context: Refers to providers of open-source LLMs that require adaptation (tool shim)
    to use Goose's capabilities.
  name: Open source providers
  source: llm_enhanced
- category: ai_infrastructure
  confidence: high
  context: Mentioned as a plugin/provider that supports open-source LLMs, allowing
    them to run locally.
  name: Ollama
  source: llm_enhanced
- category: ai_model_provider
  confidence: high
  context: An open-source LLM model mentioned as being used by privacy-conscious users
    who want tokens to stay on their laptop.
  name: Qwen
  source: llm_enhanced
- category: ai_model_provider
  confidence: high
  context: An open-source LLM model mentioned as being used by privacy-conscious users.
  name: DeepSeek
  source: llm_enhanced
- category: ai_model_provider
  confidence: medium
  context: A group of models (likely referring to Google's Gemini/Cloud models or
    similar) preferred by users for coding use cases.
  name: Cloud family of models
  source: llm_enhanced
- category: ai_model_provider
  confidence: high
  context: Mentioned as a proprietary model whose capability is approaching parity
    in certain areas.
  name: GPT-4
  source: llm_enhanced
- category: ai_research
  confidence: high
  context: Mentioned in reference to a report suggesting that few Fortune 500 companies
    are benefiting from AI.
  name: MIT
  source: llm_enhanced
- category: investment_firm
  confidence: high
  context: Venture capital firm that started an open-source fellowship inspired by
    conversations about open source.
  name: Sequoia
  source: llm_enhanced
- category: open_source_project
  confidence: high
  context: Referenced historically in the lineage of open-source ethos.
  name: GNU
  source: llm_enhanced
date: 2025-09-30 09:00:00 +0000
duration: 60
has_transcript: false
insights:
- actionable: false
  confidence: medium
  extracted: how we realize utility from AI. And it turned out to be right. And we
    ringfenced him and gave him a team of six or seven people. And they've really
    punched above their weight. Why
  text: the future of how we realize utility from AI. And it turned out to be right.
    And we ringfenced him and gave him a team of six or seven people. And they've
    really punched above their weight. Why is it called Goose? That's a Top Gun reference.
  type: prediction
- actionable: false
  confidence: medium
  extracted: unlocking coding capability from these models
  text: the future of unlocking coding capability from these models is swarm intelligence.
  type: prediction
layout: episode
llm_enhanced: true
original_url: https://audio.listennotes.com/e/p/ac7a1c92c8fd4cbb8bc9857f268f50a9/
processing_date: 2025-10-06 05:24:35 +0000
quotes:
- length: 160
  relevance_score: 4
  text: It's deep learning and the ability to do more than just classification or
    clustering or those common machine learning use cases that traditional ML was
    aimed at
  topics: []
- length: 159
  relevance_score: 4
  text: Have you had to embrace a different, almost product building mindset to build
    around LLMs and generative AI compared to how your developers are used to working
  topics: []
- length: 209
  relevance_score: 4
  text: But can you leverage open source model X because it's small enough and it's
    cheap enough to run 50, 60, 500, a thousand copies of and that accumulated capability
    is greater than any single large language model
  topics: []
- length: 286
  relevance_score: 4
  text: It could be a hierarchical swarm where you leverage some large language models,
    like some very capable models to do the planning for you or to do the reintegration
    for you and you break things down into very small, almost nano services that these
    simpler models can bite off and consume
  topics: []
- length: 188
  relevance_score: 4
  text: You mentioned at the beginning of our conversation that generative AI is the
    big difference between what you were doing with machine learning before and how
    you're hoping to embrace AI now
  topics: []
- length: 77
  relevance_score: 3
  text: So there's a lot of wild things that are, you have to have the stomach for
    it
  topics: []
- length: 48
  relevance_score: 3
  text: Yeah, you have to stop thinking like an engineer
  topics: []
- length: 83
  relevance_score: 3
  text: And you have to start thinking more like a data scientist for lack of a better
    term
  topics: []
- impact_reason: A strong testament to emergent capabilities in AI agents, suggesting
    that LLMs can discover optimal workflows that human engineers might overlook,
    emphasizing the value of letting agents explore.
  relevance_score: 10
  source: llm_enhanced
  text: We find that Goose is more capable than if you tried to figure out how to
    make a tool Goose friendly. So it figures things out in surprising ways that you
    wouldn't think of as a human. And it does it quicker than you might do it as well,
    which is quite surprising.
  topic: predictions/technical
- impact_reason: A concrete example of organizational restructuring (moving from silos/GMs
    to functional centralization) specifically to enable deep technological focus
    (AI/Platform), showing how org design must adapt to technological shifts.
  relevance_score: 10
  source: llm_enhanced
  text: Progressively, we started to unwind our GM structure... and we brought them
    all together and actually adding our platform teams to that... made it that much
    more powerful and gave us a really strong springboard.
  topic: business/strategy
- impact_reason: 'This is the core architectural insight: treating *all* internal
    functions (including IT/DevOps) as standardized capabilities accessible via an
    agent middleware layer (Goose). This is a blueprint for enterprise AI transformation.'
  relevance_score: 10
  source: llm_enhanced
  text: We treated the corporate side like that too. So creating an issue, opening
    a PR, all of these are just capabilities. And then we put an agent middleware
    layer on top, so effectively Goose. And all our UIs are now evolving to talk to
    our capabilities through this agent layer.
  topic: technical/strategy
- impact_reason: Defines the Model Context Protocol (MCP) as the crucial 'glue' or
    abstraction layer that allows general-purpose agents to reliably interact with
    proprietary or existing enterprise tools.
  relevance_score: 10
  source: llm_enhanced
  text: Goose is built using what's known as the Model Context Protocol or the MCP,
    which you might have heard of. And the MCP is just a fancy way of saying, we're
    going to create a set of formalized wrappers for existing tools or capabilities
    and expose them to your AI agent.
  topic: technical
- impact_reason: 'This is a fundamental reframing of enterprise architecture necessary
    for agent adoption: shifting focus from monolithic systems/products to discrete,
    addressable capabilities.'
  relevance_score: 10
  source: llm_enhanced
  text: We looked at Block, not as here's an enterprise and here's some tools and
    here's our products and here's our business. But everything is a capability at
    Block.
  topic: strategy/technical
- impact_reason: 'This describes a core architectural shift: using an agent layer
    (Goose) as middleware to connect UIs to underlying capabilities (tools/APIs),
    which unlocked significant value. This is a key pattern for modern AI application
    development.'
  relevance_score: 10
  source: llm_enhanced
  text: And we put an agent middleware layer on top, so effectively Goose. And all
    our UIs are now evolving to talk to our capabilities through this agent layer.
    And that's unlocked an enormous amount of value.
  topic: Strategy/Architecture
- impact_reason: This is a powerful, concrete example of end-to-end workflow orchestration
    by an agent, demonstrating complex data retrieval, analysis, visualization, and
    delivery across multiple enterprise systems.
  relevance_score: 10
  source: llm_enhanced
  text: So you give it a little prompt and say, I want a marketing report of how we
    did in Q3. And then it goes away. It looks in Snowflake, pulls out the data. It
    might look in Looker, Tableau, any of these other systems. Builds a bunch of charts
    using programming tools that it knows about. And then it can deliver all of that
    as a PDF or Google Doc and even email it for you.
  topic: Predictions/Utility
- impact_reason: 'Addresses a critical safety/security concern for autonomous agents:
    the blast radius is constrained by the user''s existing permissions, framing the
    agent as a ''sidekick'' rather than an independent entity.'
  relevance_score: 10
  source: llm_enhanced
  text: Goose acts as you. So it's not like a wild robot going off, running into our
    data centers and doing its own thing. It follows the same access controls that
    each user has. And so its blast radius is highly limited to any actions humans
    take or to that individual's authorization level.
  topic: Safety/Security
- impact_reason: 'A bold claim about self-improvement and bootstrapping: the agent
    is writing most of its own code, pointing toward a future where AI builds and
    maintains itself, limited only by current complexity ceilings.'
  relevance_score: 10
  source: llm_enhanced
  text: We also use Goose to build Goose. So the vast majority of Goose's code is
    written by Goose. And so we almost fully bootstrapped it. There's still some human-written
    code in there that's at a level of complexity that Goose hasn't reached yet, but
    our goal is for it to be completely autonomous and for each release for it to
    rewrite itself 100% from scratch.
  topic: Predictions/Technical Breakthrough
- impact_reason: A perfect analogy distinguishing the LLM (the 'brain') from the agent
    framework (the 'arms and legs' or execution layer). This clarifies the necessary
    components for real-world AI utility.
  relevance_score: 10
  source: llm_enhanced
  text: Is that the foundational architecture? I would look at Goose as the arms and
    legs. If you think of the LLM as a brain in a jar, that's not capable of anything
    except chatting with you. Goose gives it arms and legs to go out and act in the
    real world.
  topic: Technical/Conceptualization
- impact_reason: Provides a concrete, measurable KPI ('manual hours saved') for quantifying
    the ROI of internal AI tools, addressing skepticism about AI value in large enterprises.
  relevance_score: 10
  source: llm_enhanced
  text: We have a metric internally, which we track on a weekly basis. And that metric
    is very simply manual hours saved by Goose. And that metric started at 0% and
    now it's going to hit probably 25% of manual hours saved by the end of the year.
  topic: business/measurement
- impact_reason: A major prediction shifting focus from single, powerful agents to
    'swarm intelligence'—many smaller agents collaborating—as the key to unlocking
    complex capabilities.
  relevance_score: 10
  source: llm_enhanced
  text: My belief is that this way in which we're using these models is going to change
    dramatically. So so far, we have one model, maybe like a couple. And we have an
    AI agent on our laptop or desktop and it makes calls to that model... But I really
    think the future of unlocking coding capability from these models is swarm intelligence.
  topic: predictions/technical
- impact_reason: 'This is the core thesis supporting swarm intelligence: the power
    of scale and distribution of cheaper, smaller models can surpass the capability
    of one monolithic proprietary model.'
  relevance_score: 10
  source: llm_enhanced
  text: But can you leverage open source model X because it's small enough and it's
    cheap enough to run 50, 60, 500, a thousand copies of and that accumulated capability
    is greater than any single large language model.
  topic: predictions/strategy
- impact_reason: A strong endorsement from a CTO that the AI-assisted coding workflow
    (vibe coding) is already the primary method for daily coding tasks, even for evaluation.
  relevance_score: 10
  source: llm_enhanced
  text: I write code every day, and it's all through Goose. It's all through vibe
    code or through some of the other AI agents when I'm evaluating how good they
    are. So I very rarely manually write code.
  topic: technical
- impact_reason: 'Identifies the current practical limitation of LLMs in coding: context
    window size restricts them from safely refactoring massive, complex legacy codebases,
    favoring smaller, isolated tasks.'
  relevance_score: 10
  source: llm_enhanced
  text: I think that it's more effective to vibe code these smaller tools like dashboards
    and reports and interactive kind of systems on a per individual basis rather than
    make massive changes to 10 million line code bases.
  topic: technical
- impact_reason: 'Pinpoints a critical current failure mode for AI coding assistants:
    lack of knowledge regarding proprietary, internal APIs and complex domain-specific
    frameworks.'
  relevance_score: 10
  source: llm_enhanced
  text: Well, where they do fail is understanding how to call proprietary APIs, because
    these are not in the training set often. And especially if you have very complex
    proprietary frameworks, then they can struggle to reason about them.
  topic: technical
- impact_reason: Provides a concrete, measurable statistic (30-40% code generation)
    for AI assistance in complex, legacy environments, setting a benchmark for current
    productivity gains.
  relevance_score: 10
  source: llm_enhanced
  text: engineers in the most engaged engineers with Goose probably generate about
    30 to 40% of the code they write in existing legacy code bases, which are very,
    very complex and difficult for agents to work with.
  topic: technical
- impact_reason: 'Presents the aspirational future state: ''AI-first teams'' where
    the AI agent generates 100% of the code for new projects (like Goose itself),
    indicating a complete paradigm shift.'
  relevance_score: 10
  source: llm_enhanced
  text: As I told you before, in AI-first teams, it's pretty much all entirely vibe
    coded. So Goose itself, every PR that is opened is written by Goose.
  topic: predictions
- impact_reason: This highlights a philosophy of empowering AI agents (Goose) through
    direct interaction and learning rather than rigid pre-programming, which is a
    key trend in agent development.
  relevance_score: 9
  source: llm_enhanced
  text: Our approach has been to not overengineer it. So we like to let Goose learn
    from doing things.
  topic: strategy/technical
- impact_reason: A concise definition of a practical, open-source AI agent designed
    for local execution and task automation, setting the stage for understanding its
    utility.
  relevance_score: 9
  source: llm_enhanced
  text: Goose, which is an open source, extensible agent that can do work on your
    computer for you.
  topic: technical
- impact_reason: A striking example of AI-assisted development where the agent being
    built is also contributing significantly to its own codebase, illustrating the
    accelerating feedback loop in software engineering.
  relevance_score: 9
  source: llm_enhanced
  text: Goose team actually writing the vast majority of net new code for the Goose
    codebase itself. Talk about recursion.
  topic: technical/trends
- impact_reason: Provides a clear demarcation between traditional ML (focused on prediction/classification)
    and modern Generative AI (enabled by deep learning), which is essential for framing
    current industry shifts.
  relevance_score: 9
  source: llm_enhanced
  text: I think generative AI is the difference, right? It's deep learning and the
    ability to do more than just classification or clustering or those common machine
    learning use cases that traditional ML was aimed at.
  topic: technical/trends
- impact_reason: 'A candid admission of being behind and the critical strategic decision
    required: centralizing leadership and driving company-wide transformation, rather
    than isolated experiments.'
  relevance_score: 9
  source: llm_enhanced
  text: I said hire someone, not me, who can be CTO, and get our company transformed
    to using AI, because we're well behind the eight-ball and we need to get ahead.
  topic: business/strategy
- impact_reason: Demonstrates the power of the agent architecture (using MCP) to achieve
    true cross-application workflow automation, moving beyond single-tool prompting.
  relevance_score: 9
  source: llm_enhanced
  text: Goose has been able to connect to all of our systems. So all of our existing
    systems, be it Gmail or Google Docs, be it Square Payments, any of these things,
    and orchestrate workflows between them completely on its own.
  topic: technical/predictions
- impact_reason: 'A prediction about the future of user interfaces: they will increasingly
    become front-ends to an underlying agent orchestration layer rather than direct
    interfaces to applications.'
  relevance_score: 9
  source: llm_enhanced
  text: All our UIs are now evolving to talk to our capabilities through this agent
    layer. And that's unlocked an enormous amount of value. We're just at the beginning
    of that transition.
  topic: predictions/technical
- impact_reason: Provides a concise, accessible definition of the Model Context Protocol
    (MCP) as a standardization layer for tool/capability wrapping, crucial for agent
    interoperability.
  relevance_score: 9
  source: llm_enhanced
  text: The MCP is just a fancy way of saying, we're going to create a set of formalized
    wrappers for existing tools or capabilities and expose them to your AI agent.
  topic: Technical/Protocol
- impact_reason: 'Highlights a massive, unexpected productivity gain: non-technical
    users achieving software creation capabilities via agents, democratizing development.'
  relevance_score: 9
  source: llm_enhanced
  text: We never expected our sales guy or our financial person to be writing software
    dashboards for themselves. But it turns out it's possible and it doesn't take
    long, it doesn't take much work to do.
  topic: Predictions/Impact
- impact_reason: 'Defines the core principle of robust agent design: maximizing autonomous
    looping and self-correction when facing obstacles, a key technical challenge in
    agent reliability.'
  relevance_score: 9
  source: llm_enhanced
  text: Goose is very much about pushing autonomy. So we let the agent loop run as
    far as it can. So if it stumbles, if it hits obstacles, it'll back up and it'll
    try another approach.
  topic: Technical/Agent Design
- impact_reason: Shows a mature, production-ready application of autonomous agents
    in DevOps (CI pipeline for security fixes), balanced with necessary human oversight
    (audit/review) before deployment.
  relevance_score: 9
  source: llm_enhanced
  text: We have this really cool tool called Headless Goose. And it runs, for example,
    in our CI pipeline. And every time there's a vulnerability ticket filed by InfraSec,
    Headless Goose will go and try to fix that vulnerability automatically. But all
    our code follows very strict audit and review procedures. And so a human has to
    agree, read everything and be sure that this is the right fix before it enters
    any production environment.
  topic: Business/Deployment
- impact_reason: Illustrates the extreme potential of hyper-personalized, context-aware
    agents that proactively act on implied intent derived from ambient communication,
    though this level requires significant user comfort.
  relevance_score: 9
  source: llm_enhanced
  text: He has Goose watching literally everything he does, including Slack or Google
    Meet calls, everything in between. And it intervenes for him in really surprising
    ways. So he'll be talking with one of his colleagues about a new feature idea.
    And then a few hours later, he'll see that Goose has already tried to develop
    this feature and open a PR for it. He's not asked it.
  topic: Predictions/Future Interaction
- impact_reason: Highlights the importance of model agnosticism in agent architecture.
    Using a pluggable system ensures the agent layer (Goose) can adapt instantly to
    new, better LLMs without requiring a full rewrite.
  relevance_score: 9
  source: llm_enhanced
  text: Goose under the hood uses a variety of different underlying foundation models.
    We have a pluggable provider system so we can essentially use any LLM that's capable
    of tool calling.
  topic: Technical/Architecture
- impact_reason: 'A crucial lesson for AI product builders: resist over-engineering
    tool interfaces for the AI. The agent''s emergent capability to interact with
    standard tools often surpasses human attempts to optimize for the AI.'
  relevance_score: 9
  source: llm_enhanced
  text: I find that Goose is more capable than if you tried to figure out how to make
    a tool Goose friendly. So it figures things out in surprising ways that you wouldn't
    think of as a human. And it does it quicker than you might do it as well, which
    is quite surprising.
  topic: Business/Lessons Learned
- impact_reason: 'This is a key philosophical takeaway for building AI agents: prioritize
    letting the model learn through execution (''learning from doing'') over extensive
    upfront engineering scaffolding.'
  relevance_score: 9
  source: llm_enhanced
  text: I would say that our approach has been to not overengineer it. So we like
    to let Goose learn from doing things.
  topic: strategy/product building
- impact_reason: Provides a specific technical insight into the current gap between
    proprietary (native tool calling) and open-source models, and a practical solution
    ('tool shim') to bridge that gap for open models.
  relevance_score: 9
  source: llm_enhanced
  text: The open source providers have no tool calling support, so they just generate
    text. Although some of them are fine-tuned to be better at tool use. So we have
    this system called tool shim, which basically adapts those LLMs to be able to
    use the MCP.
  topic: technical/model architectures
- impact_reason: Clearly defines the current limitation of general-purpose LLMs (lack
    of deep, specialized domain knowledge) and emphasizes the enduring value of expert
    human teams.
  relevance_score: 9
  source: llm_enhanced
  text: But if I am a researcher in neuroscience and like my wife is, and she wants
    to know something very particular about a type of dementia that she's researching,
    then it starts to struggle there. And really, when you put people with a lot of
    depth in an organization together, they tend to outperform the basic LLM capability.
  topic: limitations/predictions
- impact_reason: Suggests that current LLM utility is just the beginning; the real
    breakthrough ('utility phase') will come from advanced agentic architectures (middleware
    layers).
  relevance_score: 9
  source: llm_enhanced
  text: And that's really where we've seen most of the progress. And then we have
    another layer of advancement where which we're trying that I described earlier
    with our agentic middleware layer. That's, I think, going to unlock a whole lot
    more utility for us. But it's early days. I would say the utility phase of LLMs
    and agents is still ahead of us.
  topic: predictions/technical
- impact_reason: Quantifies the immediate productivity gain (8-10 hours/week) for
    engineers using specific AI tools, offering a tangible benchmark.
  relevance_score: 9
  source: llm_enhanced
  text: So engineers report eight to 10 hours per week right now with Goose in particular.
    But with the whole suite of AI tools and interventions like Headless Goose and
    other systems that we're encouraging, I fully expect that number to keep ticking
    up.
  topic: business/measurement
- impact_reason: 'Outlines a potential architecture for swarm intelligence: a hierarchical
    structure using large models for high-level planning and small models for execution
    (''nano services'').'
  relevance_score: 9
  source: llm_enhanced
  text: So I think there is a question around that and like it's a worthwhile research
    direction. I'm not exactly sure how it would, how it's going to play out. It could
    be a hierarchical swarm where you leverage some large language models, like some
    very capable models to do the planning for you or to do the reintegration for
    you and you break things down into very small, almost nano services that these
    simpler models can bite off and consume.
  topic: technical/architecture
- impact_reason: 'A powerful business case for remote work: it unlocks access to elite,
    specialized talent globally, outweighing potential coordination costs.'
  relevance_score: 9
  source: llm_enhanced
  text: there are some employees that we can only have because we support remote work.
    So we have certain employees who, you know, they're the leading lights in their
    industries or in their fields. And they would just never work for us if we weren't
    able to employ them, say, in Sweden or in Sydney as well.
  topic: business
- impact_reason: 'Quantifies the strategic advantage of distributed hiring: accessing
    top talent in less competitive markets leads to better retention and long-term
    stability.'
  relevance_score: 9
  source: llm_enhanced
  text: I think the benefit clearly outweighs that cost because we're able to hire
    these incredible engineers and retain them for six, seven, eight years in markets
    that don't have the same level of competition as Silicon Valley, for example.
  topic: business
- impact_reason: Directly names the context window as the primary technical bottleneck
    preventing LLMs from handling large-scale legacy code refactoring.
  relevance_score: 9
  source: llm_enhanced
  text: And that's purely a limitation of the context window and the ability of the
    LLMs to scale to that size.
  topic: technical
- impact_reason: 'Offers a powerful analogy for AI-assisted development: the LLM provides
    a productive ''skeleton'' or first draft, shifting the human role from creation
    to refinement, even for performance-critical code.'
  relevance_score: 9
  source: llm_enhanced
  text: But I would argue that even there, the developer is better off starting with
    an LLM to code first and then seeing where they can make improvements. So it's
    a little bit like a sculpture or if you're writing a short story or something
    like that, just having a skeleton to work from is much more productive than trying
    to sit there and come up with something on your own.
  topic: strategy
- impact_reason: 'Clearly defines the enduring human role in software development:
    high-level architecture, concurrency management (race conditions), and cross-system
    orchestration.'
  relevance_score: 9
  source: llm_enhanced
  text: Where I think humans are called for is in the higher-level architectural design,
    in understanding race conditions and coordinating, orchestrating across multiple
    systems in a topology.
  topic: strategy
- impact_reason: 'Clearly articulates the strategic pivot: generative AI represents
    a fundamental shift in capability compared to traditional ML, opening new avenues
    for product innovation.'
  relevance_score: 9
  source: llm_enhanced
  text: generative AI is the big difference between what you were doing with machine
    learning before and how you're hoping to embrace AI now.
  topic: strategy
- impact_reason: A classic, high-level framing of the dual-use nature of powerful
    technology, directly addressing the societal concerns around AI safety and intent.
  relevance_score: 8
  source: llm_enhanced
  text: AI is friend or foe? ... It really depends on who is developing it and to
    what purpose they're putting it. So nuclear medicine saves lives... but if you
    build bombs with it, it's terrible.
  topic: safety/strategy
- impact_reason: This reveals Block's core strategic mindset—treating technology adoption
    as fundamental to survival and growth, which is crucial for any incumbent facing
    AI disruption.
  relevance_score: 8
  source: llm_enhanced
  text: I've always thought of Block not as a financial services company, but as a
    technology company. So we've always been early to embrace whatever new technology
    there is and then figure out how best to serve our customers with it.
  topic: strategy
- impact_reason: 'A healthy competitive stance: prioritizing employee utility over
    proprietary lock-in. If the internal tool (Goose) isn''t the best, employees should
    use the best available external tool.'
  relevance_score: 8
  source: llm_enhanced
  text: If we can't compete on Goose with those tools, then Goose isn't doing its
    job. So we're very happy to provide licenses to any other AI tool that people
    want to use.
  topic: business/strategy
- impact_reason: 'Emphasizes the paradigm shift generative AI brings: moving ML application
    from specialized risk functions to pervasive utility across all business verticals.'
  relevance_score: 8
  source: llm_enhanced
  text: When you start to look at what deep learning can do, you're opening up the
    world to so much more, to literally every single vertical and function that we
    have at the company and beyond.
  topic: trends
- impact_reason: A surprising connection between the crypto mining hardware ecosystem
    and the current AI infrastructure supply chain, suggesting shared foundational
    needs (compute power).
  relevance_score: 8
  source: llm_enhanced
  text: One of the secrets about the AI infra industry is that many of the top AI
    infrastructure vendors used to be crypto mining providers.
  topic: technical/trends
- impact_reason: A pragmatic warning against a 'tool-first' approach to adoption,
    acknowledging that simply providing access doesn't guarantee effective integration.
  relevance_score: 8
  source: llm_enhanced
  text: There's no panacea to this. There's no sort of simple answer to getting AI
    into our workforce. We've tried the approach of, here's every single AI tool there
    is. Go ahead and use it, tell us what's working, what's not.
  topic: business/strategy
- impact_reason: Defines the scope of Goose as a local, general-purpose agent, contrasting
    with cloud-only solutions and emphasizing local control/deployment.
  relevance_score: 8
  source: llm_enhanced
  text: Goose is a general purpose AI agent. So it's a program that you can download
    and use on your laptop.
  topic: technical
- impact_reason: A strategic insight on organizational structure and innovation within
    large companies, suggesting that fostering autonomy (like with Goose) is key to
    preventing the 'infanticide' of promising internal projects.
  relevance_score: 8
  source: llm_enhanced
  text: It's a great story of how big companies can find talent and give them the
    space to flourish. I sometimes wonder that bigger companies are more at risk of
    infanticide than anything. They kill their own ideas.
  topic: Strategy/Business
- impact_reason: Provides diverse, real-world examples of agent utility beyond typical
    enterprise tasks, showcasing creative problem-solving by non-developers (Figma
    to site, travel planning).
  relevance_score: 8
  source: llm_enhanced
  text: The most interesting thing that I've noticed has been non-technical people
    finding creative uses for Goose. So everything from taking a Figma and saying,
    build this into a functioning site, to I saw someone who was taking a holiday
    in Paris, who had Goose build her a map of all of the interesting sites in Paris
    and do a little traveling salesman walk for her to get through all of those sites.
  topic: Utility/Impact
- impact_reason: Describes a practical method for capturing emergent agent success
    (learning by doing) and turning it into reusable, shareable knowledge ('recipes'),
    blending autonomy with structured learning.
  relevance_score: 8
  source: llm_enhanced
  text: We like to let Goose learn from doing things. So we also have this feature
    called recipes where if you try a workflow with Goose and you really like it,
    you can bake it into a script or what we call a recipe and then share it out with
    your teammates.
  topic: Business/Adoption
- impact_reason: A warning against premature optimization in agent tooling. The rapid
    evolution of foundation models means that bespoke engineering solutions might
    quickly become obsolete.
  relevance_score: 8
  source: llm_enhanced
  text: And with the rate at which LLMs are evolving, that capability is improving
    rapidly as well. So even if we did find something that we could build some engineering
    scaffolding around to make Goose more effective on some particular tool, the next
    release of the LLM provider might just blow that capability out of the water.
  topic: Strategy/Technical
- impact_reason: Highlights the rapid advancement and viability of running powerful,
    fast models locally (on-device inference), which is crucial for privacy-conscious
    users.
  relevance_score: 8
  source: llm_enhanced
  text: I just built one on the plane on the way here, which was using an embedded
    model provider, which is blindingly fast on our latest MacBooks.
  topic: technical/deployment
- impact_reason: A significant strategic decision by a major company (Block) to open-source
    a core AI product, signaling confidence and commitment to the open ecosystem.
  relevance_score: 8
  source: llm_enhanced
  text: We made the decision to open source Goose. And I think the company does a
    lot in other aspects of open source.
  topic: strategy/open source
- impact_reason: 'Provides a strong business case/philosophy for open-sourcing: leveraging
    the global community''s contribution vastly outweighs the internal team size.'
  relevance_score: 8
  source: llm_enhanced
  text: Well, we can either have our community of 3,000 plus engineers work on something
    or we could have the broader community of 30,000 plus engineers have a look at
    what we've worked on and contribute their ideas and benefit from that too.
  topic: business/strategy
- impact_reason: Articulates a strong preference for open weights but acknowledges
    the practical scaling barrier for the largest frontier models.
  relevance_score: 8
  source: llm_enhanced
  text: My preference would be for all models to be open source and open weights.
    I think that there's some trickiness to it just because of the scale involved
    in that unlike Goose, you can't really download these multi-trillion parameter
    models and run them.
  topic: safety/open source
- impact_reason: A philosophical statement advocating for AI models to be treated
    as essential, accessible public infrastructure (utility).
  relevance_score: 8
  source: llm_enhanced
  text: It should be like a utility the way the internet was imagined to be.
  topic: safety/philosophy
- impact_reason: Provides context and potential origin attribution for the term 'vibe
    coding' (using AI agents for rapid, iterative coding), signaling a shift in developer
    workflow.
  relevance_score: 8
  source: llm_enhanced
  text: Vibe coding, that's, I think, Goose basically pioneered vibe coding. I don't
    think it's too much of a statement to say that, or at least it was very early
    in the vibe coding world.
  topic: technical
- impact_reason: Asks a crucial measurement question about AI adoption velocity, indicating
    that tracking the percentage of AI-generated code is a key metric for measuring
    productivity impact.
  relevance_score: 8
  source: llm_enhanced
  text: Do you have a, and if you can't share us, okay, but I'm curious if you even
    look at how much of the code base is being written by Goose or being written by
    AI today and do a guess for how that might evolve over time.
  topic: business
- impact_reason: Cites a major scientific breakthrough (AlphaFold) as evidence of
    AI's positive potential, balancing the earlier warning about misuse.
  relevance_score: 7
  source: llm_enhanced
  text: We've already seen that with Alpha Fold and all of the great things similar
    to that, but it can also be used for some nefarious things.
  topic: safety/trends
- impact_reason: Highlights the historical application of ML in finance—risk mitigation—and
    establishes a baseline of existing ML maturity before the generative AI shift.
  relevance_score: 7
  source: llm_enhanced
  text: Our use of ML at Block was always on the risk side. So we would always focus
    on fraud, on spam and abuse, and things like that. And I think we got really good
    at it.
  topic: business/technical
- impact_reason: Details the initial, experimental phase of adopting a new technology
    (AI) within a large organization—small, funded bets across various ideas.
  relevance_score: 7
  source: llm_enhanced
  text: We did it sort of progressively. Initially, we invested in a number of special
    projects, bets, so we had maybe two to five engineers working on eight different
    projects.
  topic: business/strategy
- impact_reason: A philosophical pivot required for leveraging generative AI and agents
    effectively—moving away from deterministic, step-by-step engineering logic toward
    embracing emergent, probabilistic outcomes.
  relevance_score: 7
  source: llm_enhanced
  text: You have to stop thinking like an engineer. This is one thing that's been
    really hard for me.
  topic: Strategy/Mindset
- impact_reason: Identifies specific open-source models favored by privacy-conscious
    users for local/on-device inference.
  relevance_score: 7
  source: llm_enhanced
  text: So some people are very privacy conscious. They don't want a single token
    to leave their laptop. So they'll use Qwen and models like that, DeepSeek.
  topic: business/privacy
- impact_reason: 'Details a nuanced approach to model development: focusing internal
    efforts on specialized SLMs and research frontier models (like speech-to-speech),
    which they commit to open-sourcing.'
  relevance_score: 7
  source: llm_enhanced
  text: We don't develop LLMs ourselves, but we do develop SLMs, like smaller language
    models that are focused around customer service and risk. And we also develop
    other frontier models that we're doing purely for research. So we're working on
    a speech-to-speech model which we will open source and we'll publish all our findings.
  topic: technical/strategy
- impact_reason: Highlights the critical business need for speed and responsiveness
    in developer tools, linking local/fast interaction directly to team momentum and
    energy.
  relevance_score: 7
  source: llm_enhanced
  text: I always wish I could move faster. That's always been a bugbear for me. Like
    there's a certain responsiveness to tools that you use locally that are really
    energizing and that let you build momentum. And so I want that for teams.
  topic: business/strategy
- impact_reason: Demonstrates internal adoption and validation of the AI tool (Goose)
    by the company's own technology team, suggesting high confidence in its utility
    for production work.
  relevance_score: 7
  source: llm_enhanced
  text: Our technology team, in particular, is actually a customer, by the way. They're
    using Goose internally to build some of our own applications.
  topic: business
- impact_reason: Provides insight into the strategic rationale behind Block's foray
    into Bitcoin mining hardware (RIG)—focusing on efficiency and performance.
  relevance_score: 6
  source: llm_enhanced
  text: We had a thesis that we can build an incredibly powerful mining rig that competes
    with the best in the industry and is also energy and cost efficient.
  topic: business
- impact_reason: A strong defense of remote work, framing it not just as a perk, but
    as a necessity for accessing specific talent pools.
  relevance_score: 6
  source: llm_enhanced
  text: I think that there's a very simple fact about remote that gets missed. And
    that is there are some employees that we can only have because we support remote
    work.
  topic: strategy/business
source: Unknown Source
summary: '## Podcast Summary: Block CTO Dhanji Prasanna on Building the AI-First Enterprise
  with Goose


  This 59-minute episode of *Training Data* features Block CTO Dhanji Prasanna discussing
  Block''s aggressive pivot to become an "AI-First Enterprise," centered around their
  open-source, extensible AI agent, **Goose**. The conversation spans the strategic
  necessity of adopting generative AI, the technical architecture of autonomous agents,
  and the cultural shifts required for deep technological transformation.


  ### 1. Focus Area

  The primary focus is on **Autonomous AI Agents and Enterprise Transformation**.
  Key topics include:

  *   The strategic positioning of Block (Square, Cash App, Tidal) in the age of AI
  disruption.

  *   The technical framework of AI agents, specifically the **Model Context Protocol
  (MCP)**, which enables tool use.

  *   The organizational restructuring at Block to support centralized platform excellence
  and AI development.

  *   The practical application and security implications of using an agent like Goose
  for both technical and non-technical workflows.


  ### 2. Key Technical Insights

  *   **Goose as Agent Middleware:** Goose is framed not as an LLM itself, but as
  the "arms and legs" that provide the LLM (the "brain in a jar") the capability to
  interact with real-world digital systems via formalized wrappers (MCP).

  *   **MCP for Tool Integration:** The Model Context Protocol (MCP) is the foundational
  standard Block helped shape, allowing Goose to connect to and orchestrate workflows
  across existing enterprise tools (e.g., Snowflake, Google Docs, internal systems).

  *   **Autonomy via Looping and Recipes:** Goose prioritizes letting the agent loop
  run as far as possible, learning from stumbles. Users can "bake" successful workflows
  into **"recipes"** to share standardized, effective automation scripts.


  ### 3. Business/Investment Angle

  *   **AI as a Strength, Not a Threat:** Prasanna views AI as an opportunity to strengthen
  Block''s position, consistent with the company''s history of embracing disruptive
  technology (e.g., early card readers, blockchain).

  *   **Organizational Centralization for Velocity:** Block moved away from a siloed
  Group Manager (GM) structure to a centralized, functional organization to drive
  engineering excellence and unify policies, which was deemed necessary to keep pace
  with rapid AI industry shifts.

  *   **Agent Utility for Non-Engineers:** A major unexpected business insight is
  the successful adoption of Goose by non-technical staff (sales, finance) to build
  dashboards and tools, demonstrating that AI agents can democratize software creation.


  ### 4. Notable Companies/People

  *   **Dhanji Prasanna (Block CTO):** The driving force behind Block''s central AI
  mandate, having convinced Jack Dorsey of the necessity to transform the company
  into an AI-native organization.

  *   **Jack Dorsey (Block Founder):** Fully aligned with Prasanna on the AI agenda
  and a strong proponent of Bitcoin, whose early experimentation led to projects like
  BitChat being built using Goose.

  *   **Goose (The Agent):** The open-source, general-purpose AI agent developed internally,
  named after the *Top Gun* character.


  ### 5. Future Implications

  The conversation suggests the industry is moving toward **deep agentic workflows**
  where AI agents act as personalized sidekicks, capable of complex, multi-step tasks
  with minimal human oversight. Block is aiming for **full self-rewriting** of Goose,
  where each new release is written 100% autonomously by the previous version. Furthermore,
  the concept of **Headless Goose** operating in CI pipelines (e.g., automatically
  fixing security vulnerabilities) points toward autonomous operational infrastructure.


  ### 6. Target Audience

  This episode is highly valuable for **AI/ML Engineers, CTOs, Enterprise Architects,
  and Technology Strategists** focused on operationalizing LLMs, building agentic
  systems, and managing large-scale organizational transformation in response to generative
  AI.'
tags:
- artificial-intelligence
- generative-ai
- ai-infrastructure
- investment
- startup
- google
title: 'Block CTO Dhanji Prasanna: Building the AI-First Enterprise with Goose, their
  Open Source Agent'
topics:
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 106
  prominence: 1.0
  topic: artificial intelligence
- keywords:
  - generative ai
  - genai
  - chatgpt
  - gpt
  - claude
  - text generation
  - image generation
  mentions: 8
  prominence: 0.8
  topic: generative ai
- keywords:
  - gpu
  - tensor
  - training
  - inference
  - model deployment
  - vector database
  mentions: 3
  prominence: 0.3
  topic: ai infrastructure
- keywords:
  - investment
  - funding
  - valuation
  - ipo
  - acquisition
  mentions: 2
  prominence: 0.2
  topic: investment
- keywords:
  - startup
  - entrepreneur
  - founder
  - venture
  mentions: 1
  prominence: 0.1
  topic: startup
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-10-06 05:24:35 UTC -->
