---
companies:
- category: unknown
  confidence: medium
  context: s it is the product manager. Today, my guests are Hamil Hussein and Shreya
    Shankar. One of the most trending topi
  name: Hamil Hussein
  position: 1404
- category: unknown
  confidence: medium
  context: t manager. Today, my guests are Hamil Hussein and Shreya Shankar. One of
    the most trending topics on this podcast
  name: Shreya Shankar
  position: 1422
- category: tech
  confidence: high
  context: rise of eVals. Both the chief product officers of Anthropic and OpenAI
    shared that eVals are becoming the mos
  name: Anthropic
  position: 1568
- category: tech
  confidence: high
  context: Both the chief product officers of Anthropic and OpenAI shared that eVals
    are becoming the most important
  name: Openai
  position: 1582
- category: unknown
  confidence: medium
  context: r deal with delays in service for your customers. And Finn is trusted by
    over 5,000 customer service leaders
  name: And Finn
  position: 3932
- category: tech
  confidence: high
  context: e leaders and top AI companies like Anthropic and Synthesia. Because Finn
    is powered by the Finn AI engine, w
  name: Synthesia
  position: 4031
- category: unknown
  confidence: medium
  context: nd top AI companies like Anthropic and Synthesia. Because Finn is powered
    by the Finn AI engine, which is a cont
  name: Because Finn
  position: 4042
- category: unknown
  confidence: medium
  context: pic and Synthesia. Because Finn is powered by the Finn AI engine, which
    is a continuously improving system
  name: Finn AI
  position: 4073
- category: unknown
  confidence: medium
  context: ack into this flywheel of improving your product. So I would say, on the
    end, overall, unit tests are a
  name: So I
  position: 9926
- category: unknown
  confidence: medium
  context: expectations of how the system is going to work. With LLMs, it's a lot
    more service area. It's very stochast
  name: With LLMs
  position: 10768
- category: unknown
  confidence: medium
  context: f real estate example. It's from a company called Nurture Boss. I can share
    my screen to show you their website,
  name: Nurture Boss
  position: 11033
- category: unknown
  confidence: medium
  context: s going wrong. So I'm going to jump to that next. And I'm going to open
    an observability tool. And you ca
  name: And I
  position: 12593
- category: unknown
  confidence: medium
  context: wrote with you, we have the same example, but in Phoenix RAG, and I think
    I'm on your blog post, use Phoenix R
  name: Phoenix RAG
  position: 12916
- category: unknown
  confidence: medium
  context: em working as a leasing team member at Retreat at Acme Apartments." Remember,
    I said this is anonymized, so that's
  name: Acme Apartments
  position: 13925
- category: unknown
  confidence: medium
  context: see that the LLM calls some tools. It calls this Get Individual Information
    Tool and it pulls back that person's information. And
  name: Get Individual Information Tool
  position: 15078
- category: unknown
  confidence: medium
  context: versation. Okay, a user asked about availability. The AI said, "Oh, we
    don't really have that. Have a nice
  name: The AI
  position: 17107
- category: unknown
  confidence: medium
  context: is stage is, "Okay, I understand what's going on. Can I ask an LLM to do
    this process for me?" Great ques
  name: Can I
  position: 22033
- category: unknown
  confidence: medium
  context: n error?" it would say, "No, it did a great job." But Hamel had the context
    of knowing, "Oh, we don't actuall
  name: But Hamel
  position: 22567
- category: unknown
  confidence: medium
  context: l you feel like you're not learning anything new. Maybe Shreya should talk
    about that. Yeah, so there's actually
  name: Maybe Shreya
  position: 27968
- category: tech
  confidence: high
  context: Mentioned as one of the leading AI labs whose Chief Product Officer stated
    eVals are becoming the most important new skill for product builders. Also mentioned
    as a company whose teams are taking the eVals course.
  name: Anthropic
  source: llm_enhanced
- category: tech
  confidence: high
  context: Mentioned as one of the leading AI labs whose Chief Product Officer stated
    eVals are becoming the most important new skill for product builders. Also mentioned
    as a company whose teams are taking the eVals course.
  name: OpenAI
  source: llm_enhanced
- category: tech
  confidence: high
  context: The platform where the definitive online course on eVals taught by Hamil
    and Shreya is the number one course.
  name: Maven
  source: llm_enhanced
- category: tech
  confidence: high
  context: Sponsor of the podcast. Described as the number one AI agent for customer
    service, with a high average resolution rate, trusted by top AI companies like
    Anthropic.
  name: Finn
  source: llm_enhanced
- category: tech
  confidence: high
  context: Sponsor of the podcast. Described as an all-in-one research platform built
    for modern product and design teams, used for usability tests, interviews, surveys,
    etc.
  name: Dscout
  source: llm_enhanced
- category: tech
  confidence: high
  context: A company whose AI assistant for property managers (handling tasks like
    lead management and customer service) was used as a detailed, real-world example
    for building eVals.
  name: Nurture Boss
  source: llm_enhanced
- category: tech
  confidence: medium
  context: An observability tool where the speaker loaded the Nurture Boss application
    logs/traces to demonstrate error analysis for eVals.
  name: BrainTrust
  source: llm_enhanced
- category: tech
  confidence: medium
  context: Mentioned as an alternative tool (alongside Langsmith) where the Nurture
    Boss eVal example was documented in a blog post.
  name: Phoenix RAG
  source: llm_enhanced
- category: tech
  confidence: medium
  context: Mentioned as a tool that can be used to load application data for eVal
    analysis, similar to BrainTrust and Phoenix RAG.
  name: Langsmith
  source: llm_enhanced
- category: tech
  confidence: medium
  context: Mentioned as one of the top AI companies that trusts Finn for customer
    service.
  name: Synthesia
  source: llm_enhanced
- category: tech
  confidence: high
  context: Mentioned as an example of an LLM that would likely fail to identify a
    product smell/hallucination error without specific context.
  name: ChatGPT
  source: llm_enhanced
date: 2025-10-03 20:03:32 +0000
duration: 1
has_transcript: false
insights:
- actionable: false
  confidence: high
  source: llm_enhanced
  text: ''
  type: general
- actionable: false
  confidence: high
  source: llm_enhanced
  text: ''
  type: general
- actionable: false
  confidence: high
  source: llm_enhanced
  text: ''
  type: general
- actionable: false
  confidence: medium
  source: llm_enhanced
  text: ''
  type: general
- actionable: false
  confidence: high
  source: llm_enhanced
  text: ''
  type: general
- actionable: false
  confidence: high
  source: llm_enhanced
  text: ''
  type: general
- actionable: false
  confidence: high
  source: llm_enhanced
  text: ''
  type: general
- actionable: false
  confidence: high
  source: llm_enhanced
  text: ''
  type: general
- actionable: false
  confidence: high
  source: llm_enhanced
  text: ''
  type: general
- actionable: false
  confidence: medium
  source: llm_enhanced
  text: ''
  type: general
- actionable: false
  confidence: medium
  source: llm_enhanced
  text: ''
  type: general
- actionable: false
  confidence: high
  source: llm_enhanced
  text: ''
  type: general
- actionable: false
  confidence: high
  source: llm_enhanced
  text: ''
  type: general
- actionable: false
  confidence: high
  source: llm_enhanced
  text: ''
  type: general
- actionable: false
  confidence: medium
  source: llm_enhanced
  text: ''
  type: general
layout: episode
llm_enhanced: true
original_url: https://www.youtube.com/watch?v=BsWxPI9UM4c
processing_date: 2025-10-03 20:03:32 +0000
quotes:
- length: 136
  relevance_score: 5
  text: Both the chief product officers of Anthropic and OpenAI shared that eVals
    are becoming the most important new skill for product builders
  topics: []
- length: 88
  relevance_score: 4
  text: Finn is the highest performing AI agent on the market with a 65% average resolution
    rate
  topics:
  - market
- length: 70
  relevance_score: 3
  text: So I thought let's pull one up and show people, here's what an eVal is
  topics: []
- length: 112
  relevance_score: 3
  text: And you have to bring your context as an engineer or even a product context
    and say, "Hey, this is kind of weird
  topics: []
- impact_reason: This establishes eVals as the single most valuable activity for building
    successful AI products, highlighting its critical importance.
  relevance_score: 10
  source: llm_enhanced
  text: To build great AI products, you need to be really good at building eVals.
    It's the highest ROI activity you can engage in.
  topic: Technology/AI Products
- impact_reason: Addresses a major, common misconception in the AI space, warning
    against over-reliance on automated evaluation and stressing the need for human-driven
    processes.
  relevance_score: 9
  source: llm_enhanced
  text: The top one [misconception] is, we live in the age of AI. Can't the AI just
    e-value it? But it doesn't work.
  topic: Technology/AI Products
- impact_reason: Provides a concrete, actionable solution ('benevolent dictator')
    for overcoming committee paralysis in the eVal process, assigning clear ownership.
  relevance_score: 9
  source: llm_enhanced
  text: You can appoint one person whose taste that you trust. It should be the person
    with domain expertise. A lot of times it is the product manager.
  topic: Business/Startups
- impact_reason: Validates the significance of eVals by citing endorsements from leaders
    at top-tier AI labs, signaling a major industry shift.
  relevance_score: 10
  source: llm_enhanced
  text: Both the chief product officers of Anthropic and OpenAI shared that eVals
    are becoming the most important new skill for product builders.
  topic: Industry Trends
- impact_reason: Provides a concise, foundational definition of eVals, framing them
    as a systematic measurement discipline rather than just testing.
  relevance_score: 8
  source: llm_enhanced
  text: eVals is a way to systematically measure and improve an AI application.
  topic: Technology/AI Products
- impact_reason: 'Clearly articulates the pain point eVals solve: moving beyond unreliable
    ''vibe checks'' to manageable, data-driven iteration in complex AI systems.'
  relevance_score: 8
  source: llm_enhanced
  text: Before eVals, you would be left with guessing. You would maybe fix a prompt
    and hope that you're not breaking anything else with that prompt, and you might
    rely on vibe checks, which is totally fine, and vibe checks are good, and you
    should do vibe checks initially, but it can become very unmanageable, very fast.
  topic: Technology/AI Products
- impact_reason: Crucially differentiates eVals from traditional software unit tests,
    emphasizing their broader scope in measuring vague and open-ended AI performance.
  relevance_score: 9
  source: llm_enhanced
  text: I would say, on the end, overall, unit tests are a very small part of that
    very big puzzle.
  topic: Technology
- impact_reason: 'Offers a key methodological insight: grounding eVal creation in
    error analysis of real data, contrasting the LLM development lifecycle with traditional
    software engineering.'
  relevance_score: 8
  source: llm_enhanced
  text: You should start with some kind of data analysis to ground what you should
    even test. And that's a little bit different than software engineering where you
    have a lot more expectations of how the system is going to work.
  topic: Technology/Methodology
- impact_reason: Provides a pragmatic mindset for adoption, reducing the barrier to
    entry by focusing on iterative improvement over achieving initial perfection.
  relevance_score: 7
  source: llm_enhanced
  text: The goal is not to do eVals perfectly. It's to actually improve your product.
  topic: Business/Startups
- impact_reason: Highlights the organizational and cultural challenges surrounding
    eVal adoption, signaling that implementation requires navigating existing skepticism
    and past failures.
  relevance_score: 7
  source: llm_enhanced
  text: I did not realize how much controversy and drama there is around eVals. There's
    a lot of people with very strong opinions. People have been burned by eVals in
    the past.
  topic: Business/Industry Trends
- impact_reason: Highlights the critical necessity of product involvement in the LLM
    observability and error analysis process, emphasizing that user experience is
    the core product.
  relevance_score: 9
  source: llm_enhanced
  text: The first step in conquering data like this is just to write notes. So you've
    got to put your product hat on, which is why we're talking to you, because product
    people have to be in the room, and they have to be involved in doing this.
  topic: Technology/Product Management
- impact_reason: A strong warning against blindly automating LLM error analysis with
    other LLMs, stressing that domain context is essential for spotting subtle, critical
    errors like hallucinations.
  relevance_score: 10
  source: llm_enhanced
  text: 'I can guarantee you, I would bet money on this: if I put that into ChatGPT
    and asked, ''Is there an error?'' it would say, ''No, it did a great job.'' But
    Hamel had the context of knowing, ''Oh, we don''t actually have this virtual tour
    functionality.'''
  topic: Technology/AI Pitfalls
- impact_reason: Provides a concrete example of a high-impact hallucination (offering
    a non-existent feature) that manual review catches, underscoring the need for
    human oversight in agent development.
  relevance_score: 9
  source: llm_enhanced
  text: The first two or three can be very painful, but it doesn't—we can do a bunch
    of them really fast. So here's another one. And let's skip the system prompt again.
    And the user asks, 'Hey, I'm looking for a two- to three-bedroom with either one
    or two baths. Do you provide virtual tours?' And a bunch of tools are called.
    And it says, 'Hi, Sarah. Currently, we have three-bedroom, two-and-a-half-bathroom
    apartment available for $2,175. Unfortunately, we don't have any two-bedroom options
    at the moment. We do offer virtual tours. Let's schedule a tour, blah blah.' It
    just so happens that there's no virtual tour. Nice. It is hallucinating something
    that doesn't exist.
  topic: Technology/LLM Reliability
- impact_reason: Offers a pragmatic, actionable rule for efficient error analysis,
    preventing developers from getting bogged down in secondary issues.
  relevance_score: 8
  source: llm_enhanced
  text: The answer is just write down the first thing that you see that's wrong, the
    most upstream error. Don't worry about all the errors. Just capture the first
    thing that you see that's wrong and stop and move on.
  topic: Technology/Process Improvement
- impact_reason: 'Introduces a crucial organizational concept for maintaining velocity
    in AI development: assigning a single, trusted domain expert (the ''benevolent
    dictator'') to own the qualitative review process.'
  relevance_score: 10
  source: llm_enhanced
  text: Benevolent dictator is just a catchy term for the fact that when you're doing
    this open coding, a lot of teams get bogged down in having a committee do this...
    You need to cut through the noise in a lot of organizations. If you look really
    deeply, especially small, medium-sized companies, there's really like, you can
    appoint one person whose taste that you trust.
  topic: Business/Startup Strategy
- impact_reason: Clearly defines who the 'benevolent dictator' should be—the domain
    expert—which is vital for accurate qualitative assessment in specialized applications.
  relevance_score: 9
  source: llm_enhanced
  text: It should be the person with domain expertise. So in this case, it would be
    the person who understands the business of leasing, apartment leasing, and has
    context to understand if this makes sense. It's always a domain expert.
  topic: Business/Team Structure
- impact_reason: Applies a formal quantitative analysis concept ('theoretical saturation')
    to the qualitative process of LLM error review, providing a stopping criterion
    for iterative development.
  relevance_score: 8
  source: llm_enhanced
  text: There is a term in data analysis and quantitative analysis called theoretical
    saturation. So what this means is when you do all of these processes of looking
    at your data, when do you stop? It's when you are theoretically saturating, or
    you're not uncovering any new types of notes, new types of concepts, or nothing
    that will materially change the next part of your process.
  topic: Technology/Data Analysis
- impact_reason: Reiterates the fundamental power of simple quantitative analysis
    (counting categorized errors) after the qualitative review phase, emphasizing
    simplicity over complexity for actionable insights.
  relevance_score: 7
  source: llm_enhanced
  text: Basic counting is the most powerful analytical technique in data science because
    it's so simple, and it's kind of undervalued in many cases.
  topic: Technology/Data Analysis
- impact_reason: Addresses the immediate concern that manual error analysis seems
    unscalable, reassuring professionals that sampling and iterative review provide
    massive returns early on.
  relevance_score: 8
  source: llm_enhanced
  text: This feels very manual and unscalable. But as you said, this is just one step
    of the process, and there's a system to this, and it's just the first step. And
    you don't have to do it for all of your data. You can sample your data and just
    take a look.
  topic: Business/Process Management
- impact_reason: Provides strong anecdotal evidence for the value of the error analysis
    process, suggesting it quickly becomes indispensable for learning about application
    behavior.
  relevance_score: 7
  source: llm_enhanced
  text: Everyone that does this immediately gets addicted to it, and they say, 'This
    is the greatest thing that you can do when you're building an AI application.'
    You just learn a lot.
  topic: Technology/Development Culture
source: AI Channel UC6t1O76G0jYXOAoYCm153dA
summary:
- key_takeaways:
  - eVals are systematic data analytics used to measure and improve AI applications,
    considered the highest ROI activity for product builders.
  - The initial, crucial step in building eVals is manual error analysis (open coding)
    of application traces, which should not be fully automated by LLMs at this stage.
  - The 'benevolent dictator' concept suggests appointing a single domain expert to
    own the initial, rapid note-taking process to avoid committee slowdowns.
  - Builders should review traces until they reach 'theoretical saturation'—the point
    where they stop uncovering new types of errors or insights.
  - eVals are broader than traditional software unit tests, encompassing metrics,
    tracking user feedback (like thumbs up/down), and identifying new user cohorts.
  - Common misconceptions include believing an LLM can perform the initial error analysis
    or that eVals must be done perfectly from the start.
  overview: Evaluation (eVals) is emerging as the highest ROI and most critical new
    skill for building successful AI products, moving beyond simple 'vibe checks'
    to systematic measurement and improvement. The process begins with manual error
    analysis, or 'open coding,' where domain experts review application traces to
    identify and document issues, which is crucial before attempting automation. This
    foundational step allows builders to gain deep, actionable insights necessary
    for iterating confidently on complex, stochastic LLM applications.
  themes:
  - The Definition and Importance of eVals
  - 'The EVal Process: Error Analysis and Open Coding'
  - Misconceptions and Pitfalls in EVal Implementation
  - Structuring the EVal Process (Benevolent Dictator vs. Committee)
  - The Role of Domain Expertise in Evaluation
  - Moving from Manual Analysis to Systematic Metrics
tags:
- artificial-intelligence
- generative-ai
- anthropic
- openai
title: Why AI evals are the hottest new skill for product builders | Hamel Husain
  & Shreya Shankar
topics:
- keywords:
  - ai
  - machine learning
  - deep learning
  - neural networks
  - llm
  - large language model
  mentions: 90
  prominence: 1.0
  topic: artificial intelligence
- keywords:
  - generative ai
  - genai
  - chatgpt
  - gpt
  - claude
  - text generation
  - image generation
  mentions: 2
  prominence: 0.2
  topic: generative ai
---

<!-- Episode automatically generated from analysis data -->
<!-- Processing completed: 2025-10-03 20:03:32 UTC -->
